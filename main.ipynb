{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbYsqcZiCps9",
        "outputId": "39f4e4a4-ffa1-4210-a8d1-4f7353bdd185"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: swig in /usr/local/lib/python3.10/dist-packages (4.2.1)\n",
            "Requirement already satisfied: gym[box2d] in /usr/local/lib/python3.10/dist-packages (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym[box2d]) (1.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym[box2d]) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym[box2d]) (0.0.8)\n",
            "Requirement already satisfied: box2d-py==2.3.5 in /usr/local/lib/python3.10/dist-packages (from gym[box2d]) (2.3.5)\n",
            "Requirement already satisfied: pygame==2.1.0 in /usr/local/lib/python3.10/dist-packages (from gym[box2d]) (2.1.0)\n",
            "Requirement already satisfied: swig==4.* in /usr/local/lib/python3.10/dist-packages (from gym[box2d]) (4.2.1)\n"
          ]
        }
      ],
      "source": [
        "#Update Gym\n",
        "!pip install swig\n",
        "!pip install gym[box2d] --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sffYfT8yO1s",
        "outputId": "248afbf0-d10a-4b91-bb21-08f1e485f472"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.26.2\n"
          ]
        }
      ],
      "source": [
        "import gym\n",
        "print(gym.__version__)\n",
        "# NOTE: Version should be 0.26.02"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3-P-T38BFfm"
      },
      "source": [
        "# Define PPO Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "bgaZBJlxBDrW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.distributions import Categorical\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "class PolicyNetwork(torch.nn.Module):\n",
        "    def __init__(self, n=4, in_dim=128):\n",
        "        super(PolicyNetwork, self).__init__()\n",
        "\n",
        "        self.fc1 = torch.nn.Linear(in_dim, 128)\n",
        "        self.fc2 = torch.nn.Linear(128, 128)\n",
        "        self.fc3 = torch.nn.Linear(128, 128)\n",
        "        self.fc4 = torch.nn.Linear(128, n)\n",
        "        self.l_relu = torch.nn.LeakyReLU(0.1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.l_relu(self.fc1(x))\n",
        "        x = self.l_relu(self.fc2(x))\n",
        "        x = self.l_relu(self.fc3(x))\n",
        "        y = self.fc4(x)\n",
        "        y = F.softmax(y, dim=-1)\n",
        "        return y\n",
        "\n",
        "    def sample_action(self, state):\n",
        "\n",
        "        if not state is torch.Tensor:\n",
        "            state = torch.from_numpy(state).float().to(device)\n",
        "\n",
        "        if len(state.size()) == 1:\n",
        "            state = state.unsqueeze(0)\n",
        "\n",
        "        y = self(state)\n",
        "        dist = Categorical(y)\n",
        "        action = dist.sample()\n",
        "        log_probability = dist.log_prob(action)\n",
        "\n",
        "        return action.item(), log_probability.item()\n",
        "\n",
        "    def best_action(self, state):\n",
        "\n",
        "        if not state is torch.Tensor:\n",
        "            state = torch.from_numpy(state).float().to(device)\n",
        "\n",
        "        if len(state.size()) == 1:\n",
        "            state = state.unsqueeze(0)\n",
        "\n",
        "        y = self(state).squeeze()\n",
        "        action = torch.argmax(y)\n",
        "\n",
        "        return action.item()\n",
        "\n",
        "    def evaluate_actions(self, states, actions):\n",
        "        y = self(states)\n",
        "        dist = Categorical(y)\n",
        "        entropy = dist.entropy()\n",
        "        log_probabilities = dist.log_prob(actions)\n",
        "\n",
        "        return log_probabilities, entropy\n",
        "\n",
        "\n",
        "class ValueNetwork(torch.nn.Module):\n",
        "    def __init__(self, in_dim=128):\n",
        "        super(ValueNetwork, self).__init__()\n",
        "\n",
        "        self.fc1 = torch.nn.Linear(in_dim, 128)\n",
        "        self.fc2 = torch.nn.Linear(128, 128)\n",
        "        self.fc3 = torch.nn.Linear(128, 128)\n",
        "        self.fc4 = torch.nn.Linear(128, 1)\n",
        "        self.l_relu = torch.nn.LeakyReLU(0.1)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.l_relu(self.fc1(x))\n",
        "        x = self.l_relu(self.fc2(x))\n",
        "        x = self.l_relu(self.fc3(x))\n",
        "        y = self.fc4(x)\n",
        "\n",
        "        return y.squeeze(1)\n",
        "\n",
        "    def state_value(self, state):\n",
        "\n",
        "        if not state is torch.Tensor:\n",
        "            state = torch.from_numpy(state).float().to(device)\n",
        "\n",
        "        if len(state.size()) == 1:\n",
        "            state = state.unsqueeze(0)\n",
        "\n",
        "        y = self(state)\n",
        "\n",
        "        return y.item()\n",
        "\n",
        "\n",
        "def ac_loss_clipped(new_log_probabilities, old_log_probabilities, advantages, epsilon_clip=0.2):\n",
        "    probability_ratios = torch.exp(new_log_probabilities - old_log_probabilities)\n",
        "    clipped_probabiliy_ratios = torch.clamp(\n",
        "        probability_ratios, 1 - epsilon_clip, 1 + epsilon_clip\n",
        "    )\n",
        "\n",
        "    surrogate_1 = probability_ratios * advantages\n",
        "    surrogate_2 = clipped_probabiliy_ratios * advantages\n",
        "\n",
        "    return -torch.min(surrogate_1, surrogate_2)\n",
        "\n",
        "def train_combined_networks(policy_model, value_model, combined_optimizer, data_loader, epochs=40, clip=0.2):\n",
        "    c1 = 0.01  # Coefficient for entropy regularization\n",
        "    c2 = 0.5   # Coefficient for value loss weight\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        policy_losses = []\n",
        "        value_losses = []\n",
        "\n",
        "        for observations, actions, advantages, log_probabilities, rewards_to_go in data_loader:\n",
        "            observations = observations.float().to(device)\n",
        "            actions = actions.long().to(device)\n",
        "            advantages = advantages.float().to(device)\n",
        "            old_log_probabilities = log_probabilities.float().to(device)\n",
        "            rewards_to_go = rewards_to_go.float().to(device)\n",
        "\n",
        "            combined_optimizer.zero_grad()\n",
        "\n",
        "            new_log_probabilities, entropy = policy_model.evaluate_actions(observations, actions)\n",
        "            policy_loss = (\n",
        "                ac_loss_clipped(\n",
        "                    new_log_probabilities,\n",
        "                    old_log_probabilities,\n",
        "                    advantages,\n",
        "                    epsilon_clip=clip,\n",
        "                ).mean()\n",
        "                - c1 * entropy.mean()\n",
        "            )\n",
        "            policy_losses.append(policy_loss.item())\n",
        "\n",
        "            values = value_model(observations)\n",
        "            value_loss = c2 * F.mse_loss(values, rewards_to_go)\n",
        "            value_losses.append(value_loss.item())\n",
        "\n",
        "            total_loss = policy_loss + value_loss\n",
        "\n",
        "            total_loss.backward()\n",
        "            combined_optimizer.step()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "pgY5fBlQBL3X"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "def cumulative_sum(array, gamma=1.0):\n",
        "    curr = 0\n",
        "    cumulative_array = []\n",
        "\n",
        "    for a in array[::-1]:\n",
        "        curr = a + gamma * curr\n",
        "        cumulative_array.append(curr)\n",
        "\n",
        "    return cumulative_array[::-1]\n",
        "\n",
        "\n",
        "class Episode:\n",
        "    def __init__(self, gamma=0.99, lambd=0.95):\n",
        "        self.observations = []\n",
        "        self.actions = []\n",
        "        self.advantages = []\n",
        "        self.rewards = []\n",
        "        self.rewards_to_go = []\n",
        "        self.values = []\n",
        "        self.log_probabilities = []\n",
        "        self.gamma = gamma\n",
        "        self.lambd = lambd\n",
        "\n",
        "    def append(\n",
        "        self, observation, action, reward, value, log_probability, reward_scale=20\n",
        "    ):\n",
        "        self.observations.append(observation)\n",
        "        self.actions.append(action)\n",
        "        self.rewards.append(reward / reward_scale)\n",
        "        self.values.append(value)\n",
        "        self.log_probabilities.append(log_probability)\n",
        "\n",
        "    def end_episode(self, last_value):\n",
        "        rewards = np.array(self.rewards + [last_value])\n",
        "        values = np.array(self.values + [last_value])\n",
        "        deltas = rewards[:-1] + self.gamma * values[1:] - values[:-1]\n",
        "        self.advantages = cumulative_sum(deltas.tolist(), gamma=self.gamma * self.lambd)\n",
        "        self.rewards_to_go = cumulative_sum(rewards.tolist(), gamma=self.gamma)[:-1]\n",
        "\n",
        "\n",
        "def normalize_list(array):\n",
        "    array = np.array(array)\n",
        "    array = (array - np.mean(array)) / (np.std(array) + 1e-5)\n",
        "    return array.tolist()\n",
        "\n",
        "\n",
        "class History(Dataset):\n",
        "    def __init__(self):\n",
        "        self.episodes = []\n",
        "        self.observations = []\n",
        "        self.actions = []\n",
        "        self.advantages = []\n",
        "        self.rewards = []\n",
        "        self.rewards_to_go = []\n",
        "        self.log_probabilities = []\n",
        "\n",
        "    def free_memory(self):\n",
        "        del self.episodes[:]\n",
        "        del self.observations[:]\n",
        "        del self.actions[:]\n",
        "        del self.advantages[:]\n",
        "        del self.rewards[:]\n",
        "        del self.rewards_to_go[:]\n",
        "        del self.log_probabilities[:]\n",
        "\n",
        "    def add_episode(self, episode):\n",
        "        self.episodes.append(episode)\n",
        "\n",
        "    def build_dataset(self):\n",
        "        for episode in self.episodes:\n",
        "            self.observations += episode.observations\n",
        "            self.actions += episode.actions\n",
        "            self.advantages += episode.advantages\n",
        "            self.rewards += episode.rewards\n",
        "            self.rewards_to_go += episode.rewards_to_go\n",
        "            self.log_probabilities += episode.log_probabilities\n",
        "\n",
        "        assert (\n",
        "            len(\n",
        "                {\n",
        "                    len(self.observations),\n",
        "                    len(self.actions),\n",
        "                    len(self.advantages),\n",
        "                    len(self.rewards),\n",
        "                    len(self.rewards_to_go),\n",
        "                    len(self.log_probabilities),\n",
        "                }\n",
        "            )\n",
        "            == 1\n",
        "        )\n",
        "\n",
        "        self.advantages = normalize_list(self.advantages)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.observations)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return (\n",
        "            self.observations[idx],\n",
        "            self.actions[idx],\n",
        "            self.advantages[idx],\n",
        "            self.log_probabilities[idx],\n",
        "            self.rewards_to_go[idx],\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSRo2IPxBQQy"
      },
      "source": [
        "# TRAC Optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyERnJ0idJI9"
      },
      "source": [
        "## Define Erfi function in Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "1xN5ZOV0BSEo"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "# We depend on Erfi function, but python.special currently has no implementation.\n",
        "# We instead modify and rely on https://github.com/redsnic/torch_erf\n",
        "\n",
        "def polyval(x,coeffs):\n",
        "    \"\"\"Implementation of the Horner scheme to evaluate a polynomial\n",
        "\n",
        "    taken from https://discuss.pytorch.org/t/polynomial-evaluation-by-horner-rule/67124\n",
        "\n",
        "    Args:\n",
        "        x (torch.Tensor): variable\n",
        "        coeffs (torch.Tensor): coefficients of the polynomial\n",
        "    \"\"\"\n",
        "    curVal=0\n",
        "    for curValIndex in range(len(coeffs)-1):\n",
        "        curVal=(curVal+coeffs[curValIndex])*x[0]\n",
        "    return(curVal+coeffs[len(coeffs)-1])\n",
        "\n",
        "\n",
        "class ERF_1994(torch.nn.Module):\n",
        "    \"\"\"Class to compute the error function of a complex number (extends torch.special.erf behavior)\n",
        "\n",
        "    This class is based on the algorithm proposed in:\n",
        "    Weideman, J. Andre C. \"Computation of the complex error function.\" SIAM Journal on Numerical Analysis 31.5 (1994): 1497-1518\n",
        "    \"\"\"\n",
        "    def __init__(self, n_coefs):\n",
        "        \"\"\"Defaul constructor\n",
        "\n",
        "        Args:\n",
        "            n_coefs (integer): The number of polynomial coefficients to use in the approximation\n",
        "        \"\"\"\n",
        "        super(ERF_1994, self).__init__()\n",
        "        # compute polynomial coefficients and other constants\n",
        "        self.N = n_coefs\n",
        "        self.i = torch.complex(torch.tensor(0.),torch.tensor(1.))\n",
        "        self.M = 2*self.N\n",
        "        self.M2 = 2*self.M\n",
        "        self.k = torch.linspace(-self.M+1, self.M-1, self.M2-1)\n",
        "        self.L = torch.sqrt(self.N/torch.sqrt(torch.tensor(2.)))\n",
        "        self.theta = self.k*torch.pi/self.M\n",
        "        self.t = self.L*torch.tan(self.theta/2)\n",
        "        self.f = torch.exp(-self.t**2)*(self.L**2 + self.t**2)\n",
        "        self.a = torch.fft.fft(torch.fft.fftshift(self.f)).real/self.M2\n",
        "        self.a = torch.flipud(self.a[1:self.N+1])\n",
        "\n",
        "    def w_algorithm(self, z):\n",
        "        \"\"\"Compute the Faddeeva function of a complex number\n",
        "\n",
        "        The constant coefficients are computed in the constructor of the class.\n",
        "\n",
        "        Weideman, J. Andre C. \"Computation of the complex error function.\" SIAM Journal on Numerical Analysis 31.5 (1994): 1497-1518\n",
        "\n",
        "        Args:\n",
        "            z (torch.Tensor): A tensor of complex numbers (any shape is allowed)\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: w(z) for each element of z\n",
        "        \"\"\"\n",
        "        Z = (self.L+self.i*z)/(self.L-self.i*z)\n",
        "        p = polyval(Z.unsqueeze(0), self.a)\n",
        "        w = 2*p/(self.L-self.i*z)**2+(1/torch.sqrt(torch.tensor(torch.pi)))/(self.L-self.i*z)\n",
        "        return w\n",
        "\n",
        "    def forward(self, z):\n",
        "        \"\"\"Compute the error function of a complex number\n",
        "\n",
        "        The result is computed by manipulating the Faddeeva function.\n",
        "\n",
        "        Args:\n",
        "            z (torch.Tensor): A tensor of complex numbers (any shape is allowed)\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: erf(z) for each element of z\n",
        "        \"\"\"\n",
        "        # exploit the symmetry of the error function\n",
        "        # find the sign of the real part\n",
        "        sign_r = torch.sign(z.real)\n",
        "        sign_i = torch.sign(z.imag)\n",
        "        # flip sign of imaginary part if negative\n",
        "        z = torch.complex(torch.abs(z.real), torch.abs(z.imag))\n",
        "        out = -torch.exp(torch.log(self.w_algorithm(z*self.i)) - z**2) + 1\n",
        "        return torch.complex(out.real*sign_r, out.imag*sign_i)\n",
        "\n",
        "    def backward(self, z):\n",
        "        \"\"\"Compute the gradient of the error function of a complex number.\n",
        "\n",
        "        As we know the analytical derivative of the the error function, we can use it directly.\n",
        "\n",
        "        Args:\n",
        "            z (torch.Tensor): A tensor of complex numbers (any shape is allowed)\n",
        "        Returns:\n",
        "            torch.Tensor: grad(erf(z)) for each element of x\n",
        "        \"\"\"\n",
        "        return 2/torch.sqrt(torch.tensor(torch.pi))*torch.exp(-z**2)\n",
        "\n",
        "erf_torch = ERF_1994(128)\n",
        "\n",
        "def erfi(x):\n",
        "    if not torch.is_floating_point(x):\n",
        "        x = x.to(torch.float32)\n",
        "\n",
        "    # Convert x to a complex tensor where the real part is zero\n",
        "    ix = torch.complex(torch.zeros_like(x), x)\n",
        "\n",
        "    # Compute erf(ix) / i\n",
        "    erfi_x = erf_torch(ix).imag  # Extract the imaginary part of erf(ix)\n",
        "    return erfi_x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3zE2Hd0dZJm"
      },
      "source": [
        "## TRAC Wrapper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "2xccOJBKdTRU"
      },
      "outputs": [],
      "source": [
        "from typing import Tuple, Any, Callable, Dict\n",
        "import torch\n",
        "\n",
        "# We closely follow the meta-optimizer structure from the code in\n",
        "# Cutkosky et. al 2023\n",
        "def _init_state(\n",
        "        optimizer: torch.optim.Optimizer,\n",
        "        theta_ref: Dict[torch.Tensor, torch.Tensor],\n",
        "        betas: Tuple[float],\n",
        "        s_prev: float,\n",
        "        eps: float):\n",
        "    if '_trac' not in optimizer.state:\n",
        "        optimizer.state['_trac'] = {\n",
        "            'betas': torch.tensor(betas),\n",
        "            's_prev': torch.tensor(s_prev),\n",
        "            'eps': eps,\n",
        "            's': torch.zeros(len(betas)),\n",
        "            'theta_ref': {},\n",
        "            'variance': torch.zeros(len(betas)),\n",
        "            'sigma': torch.full((len(betas),), 1e-8),\n",
        "            'iter_count': 0,\n",
        "        }\n",
        "        _init_reference(optimizer, theta_ref)\n",
        "\n",
        "def _init_reference(\n",
        "        optimizer: torch.optim.Optimizer,\n",
        "        theta_ref: Dict[torch.Tensor, torch.Tensor],):\n",
        "    '''\n",
        "    Args:\n",
        "        optimizer: optimizer instance to store reference for.\n",
        "        theta_ref: mapping of parameters to their initial values at the start of optimization.\n",
        "    '''\n",
        "    for group in optimizer.param_groups:\n",
        "        for p in group['params']:\n",
        "            optimizer.state['_trac'][p] = {\n",
        "                'ref': theta_ref[p].clone(),\n",
        "            }\n",
        "            \n",
        "\n",
        "def _step(\n",
        "        optimizer: torch.optim.Optimizer,\n",
        "        base_step: Callable,\n",
        "        betas: Tuple[float],\n",
        "        s_prev: float,\n",
        "        eps: float,\n",
        "        ):\n",
        "    '''\n",
        "    Args:\n",
        "        optimizer: trac optimizer instance\n",
        "        base_step: The \"step\" function of the base optimizer\n",
        "        betas: list of beta values.\n",
        "        s_init: initial scale value.\n",
        "        eps: epsilon value.\n",
        "    '''\n",
        "\n",
        "    prev_grad = torch.is_grad_enabled()\n",
        "\n",
        "\n",
        "    torch.set_grad_enabled(False)\n",
        "    updates = {}\n",
        "    grads = {}\n",
        "    deltas = {}\n",
        "\n",
        "    for group in optimizer.param_groups:\n",
        "        for p in group['params']:\n",
        "\n",
        "            if p.grad is None:\n",
        "                grads[p] = None\n",
        "            else:\n",
        "                grads[p] = p.grad.clone()\n",
        "            updates[p] = p.data.clone()\n",
        "\n",
        "    torch.set_grad_enabled(prev_grad)\n",
        "    result = base_step(None)\n",
        "    torch.set_grad_enabled(False)\n",
        "    \n",
        "    _init_state(optimizer, updates, betas, s_prev, eps)\n",
        "    trac_state = optimizer.state['_trac']\n",
        "\n",
        "\n",
        "    for group in optimizer.param_groups:\n",
        "        for p in group['params']:\n",
        "            if grads[p] is None:\n",
        "                continue\n",
        "\n",
        "            theta_ref = trac_state[p]['ref']\n",
        "\n",
        "            deltas[p] = (updates[p] - theta_ref)/(torch.sum(trac_state['s']) + trac_state['eps'])\n",
        "\n",
        "            updates[p].copy_(p-updates[p])\n",
        "\n",
        "    h = 0.0\n",
        "    for group in optimizer.param_groups:\n",
        "        for p in group['params']:\n",
        "\n",
        "            if grads[p] is None:\n",
        "                continue\n",
        "\n",
        "            grad = grads[p]\n",
        "\n",
        "            delta = deltas[p]\n",
        "            product = torch.dot(delta.flatten(), grad.flatten())\n",
        "            if product.isnan():\n",
        "                raise ValueError(\"NaNs in product\")\n",
        "            h += product\n",
        "\n",
        "            delta.add_(updates[p])\n",
        "\n",
        "    device = h.device\n",
        "\n",
        "    for key in trac_state:\n",
        "        try:\n",
        "            if trac_state[key].device != device:\n",
        "                trac_state[key] = trac_state[key].to(device)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    s = trac_state['s']\n",
        "    s_prev = trac_state['s_prev']\n",
        "    betas = trac_state['betas']\n",
        "    eps = trac_state['eps']\n",
        "    variance = trac_state['variance'] \n",
        "    sigma = trac_state['sigma']                                 \n",
        "    trac_state['iter_count'] += 1\n",
        "\n",
        "    variance.mul_(\n",
        "        betas**2).add_(torch.square(h))\n",
        "    sigma.mul_(betas).sub_(h)\n",
        "    f_term = s_prev / (erfi(torch.tensor(1.0) / torch.sqrt(torch.tensor(2.0))))\n",
        "    s_term = erfi(sigma / (torch.sqrt(torch.tensor(2.0)) * torch.sqrt(variance) + eps))\n",
        "    if (f_term * s_term).isnan().any():\n",
        "        raise ValueError(\"NaNs in s\")\n",
        "    s.copy_(f_term * s_term)\n",
        "\n",
        "    for group in optimizer.param_groups:\n",
        "        for p in group['params']:\n",
        "\n",
        "            if grads[p] is None:\n",
        "                continue\n",
        "\n",
        "            theta_ref = trac_state[p]['ref']\n",
        "            delta = deltas[p]\n",
        "            s_sum = torch.sum(s)\n",
        "\n",
        "            scale = max(s_sum, 0.0)\n",
        "            p.copy_(theta_ref + delta * scale)\n",
        "\n",
        "    log_data = {\n",
        "        'iter_count': trac_state['iter_count'],\n",
        "        's': torch.sum(s).item(),\n",
        "    }\n",
        "\n",
        "    torch.set_grad_enabled(prev_grad)\n",
        "    return result, log_data\n",
        "\n",
        "\n",
        "class trac:\n",
        "    pass\n",
        "\n",
        "def is_trac(opt):\n",
        "    return isinstance(opt, trac)\n",
        "\n",
        "def start_trac(\n",
        "        log_file,\n",
        "        Base: Any,\n",
        "        betas: Tuple[float] = (0.9, 0.99, 0.999, 0.9999,\n",
        "                               0.99999, 0.999999),\n",
        "        s_prev: float = 1e-8,\n",
        "        eps: float = 1e-8,\n",
        "        ):\n",
        "\n",
        "    class TRACOPT(Base, trac):\n",
        "        '''\n",
        "        Wraps the base opt with trac.\n",
        "        \n",
        "        '''\n",
        "\n",
        "        def step(self):\n",
        "            result, log_data = _step(self, super().step, betas, s_prev, eps)\n",
        "            with open (log_file, 'a') as f:\n",
        "                f.write(str(log_data) + '\\n')\n",
        "            return result\n",
        "\n",
        "    TRACOPT.__name__ += Base.__name__\n",
        "\n",
        "    return TRACOPT\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZJjCxSEBqIn"
      },
      "source": [
        "# Lifelong Control Setting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5qXh9tafBtrn"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-06-11 11:38:13.373587: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-06-11 11:38:13.420720: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-06-11 11:38:25.120438: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import random\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "XcILqsPSDdQO"
      },
      "outputs": [],
      "source": [
        "# SET THE SEED\n",
        "seed = 2024\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "\n",
        "# num distribution shifts\n",
        "levels = 10\n",
        "\n",
        "# Hyperparameters\n",
        "lr = 0.01\n",
        "max_episodes = 2\n",
        "train_epochs = 5\n",
        "max_timesteps = 400\n",
        "state_scale = 1.0\n",
        "reward_scale = 20.0\n",
        "batch_size = 32\n",
        "\n",
        "# when to introduce distribution shift\n",
        "level_switch = 200\n",
        "max_iterations = levels * level_switch\n",
        "\n",
        "# peturbation range\n",
        "rp_range = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "ITlv3qL1B0Q7"
      },
      "outputs": [],
      "source": [
        "def get_peturbations(env_name, seed):\n",
        "  env = gym.make(env_name, render_mode=\"rgb_array\")\n",
        "  observation = env.reset()[0]\n",
        "  random_perturbations = [\n",
        "        np.random.normal(0, rp_range, observation.shape) for _ in range(levels)\n",
        "    ]\n",
        "  # make the first random perturbation zero\n",
        "  random_perturbations[0] = np.zeros(observation.shape)\n",
        "  return random_perturbations\n",
        "def train(env_name, opt_choice, random_perturbations):\n",
        "\n",
        "    # Create log txt files\n",
        "    trac_reward_log_file = f'logs/trac_reward_log_{env_name}_{seed}.txt'\n",
        "    base_reward_log_file = f'logs/base_reward_log_{env_name}_{seed}.txt'\n",
        "\n",
        "    # Setup env\n",
        "    env = gym.make(env_name, render_mode=\"rgb_array\")\n",
        "    observation = env.reset()[0]\n",
        "    n_actions = env.action_space.n\n",
        "    feature_dim = observation.size\n",
        "\n",
        "    tqdm_bar = tqdm(range(max_iterations), desc=\"Training\", unit=\"iteration\")\n",
        "\n",
        "    value_model = ValueNetwork(in_dim=feature_dim).to(device)\n",
        "    policy_model = PolicyNetwork(in_dim=feature_dim, n=n_actions).to(device)\n",
        "\n",
        "    trac_combined_optimizer = start_trac(log_file=f'logs/trac_{env_name}.text', Base=optim.Adam)(\n",
        "        [\n",
        "            {\"params\": policy_model.parameters(), \"lr\": lr},\n",
        "            {\"params\": value_model.parameters(), \"lr\": lr},\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    base_combined_optimizer = torch.optim.Adam(\n",
        "        [\n",
        "            {\"params\": policy_model.parameters(), \"lr\": lr},\n",
        "            {\"params\": value_model.parameters(), \"lr\": lr},\n",
        "        ]\n",
        "    )\n",
        "    if opt_choice == \"TRAC\":\n",
        "        combined_optimizer = trac_combined_optimizer\n",
        "        reward_log_file = trac_reward_log_file\n",
        "        print(\"USING TRAC.\")\n",
        "    if opt_choice == \"base\":\n",
        "        combined_optimizer = base_combined_optimizer\n",
        "        reward_log_file = base_reward_log_file\n",
        "    history = History()\n",
        "    level = 0\n",
        "    for ite in tqdm_bar:\n",
        "        # Switch perturbation level\n",
        "        if ite % level_switch == 0:\n",
        "            random_perturbation = random_perturbations[level]\n",
        "            level += 1\n",
        "\n",
        "        episodes_reward = []\n",
        "\n",
        "        for _ in range(max_episodes):\n",
        "            observation = env.reset()[0]\n",
        "            observation += random_perturbation\n",
        "            episode = Episode()\n",
        "\n",
        "            for timestep in range(max_timesteps):\n",
        "                action, log_probability = policy_model.sample_action(observation / state_scale)\n",
        "                value = value_model.state_value(observation / state_scale)\n",
        "\n",
        "                new_observation, reward, done, _, _ = env.step(action)\n",
        "                new_observation += random_perturbation\n",
        "\n",
        "                episode.append(\n",
        "                    observation=observation / state_scale,\n",
        "                    action=action,\n",
        "                    reward=reward,\n",
        "                    value=value,\n",
        "                    log_probability=log_probability,\n",
        "                    reward_scale=reward_scale,\n",
        "                )\n",
        "\n",
        "                observation = new_observation\n",
        "\n",
        "                if done:\n",
        "                    episode.end_episode(last_value=0)\n",
        "                    break\n",
        "\n",
        "                if timestep == max_timesteps - 1:\n",
        "                    value = value_model.state_value(observation / state_scale)\n",
        "                    episode.end_episode(last_value=value)\n",
        "\n",
        "            episodes_reward.append(reward_scale * np.sum(episode.rewards))\n",
        "            history.add_episode(episode)\n",
        "\n",
        "        mean_rewards = np.mean(episodes_reward)\n",
        "        tqdm_bar.set_postfix(mean_rewards=mean_rewards)\n",
        "\n",
        "        with open(reward_log_file, 'a') as f:\n",
        "            f.write(str(mean_rewards) + '\\n')\n",
        "        history.build_dataset()\n",
        "        data_loader = DataLoader(history, batch_size=batch_size, shuffle=True)\n",
        "        train_combined_networks(policy_model, value_model, combined_optimizer, data_loader, train_epochs)\n",
        "        history.free_memory()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iBE7Qhs-Fuw"
      },
      "source": [
        "### Plotting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "c4H3Ws0v-Da8"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def read_data(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        data = file.readlines()\n",
        "    return data\n",
        "\n",
        "def plot(env_name, seed):\n",
        "    # Read data from files\n",
        "    trac_data = read_data(f'logs/trac_reward_log_{env_name}_{seed}.txt')\n",
        "    base_data = read_data(f'logs/base_reward_log_{env_name}_{seed}.txt')\n",
        "\n",
        "    # Convert data to float\n",
        "    trac_data = [float(i) for i in trac_data]\n",
        "    base_data = [float(i) for i in base_data]\n",
        "\n",
        "\n",
        "    # Smooth trac and base data\n",
        "    window = 5\n",
        "    trac_data = np.convolve(trac_data, np.ones(window) / window, mode='valid')\n",
        "    base_data = np.convolve(base_data, np.ones(window) / window, mode='valid')\n",
        "\n",
        "    # Create a plot with seaborn\n",
        "    sns.set(style=\"darkgrid\")\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    plt.plot(base_data, label='Adam PPO', color='#4a69bd')\n",
        "    plt.plot(trac_data, label='TRAC PPO', color='#b71540')\n",
        "\n",
        "    plt.xlabel('Timesteps')\n",
        "    plt.ylabel('Mean Episode Reward')\n",
        "    plt.title(f'{env_name}', fontsize=24)\n",
        "    plt.legend()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pF8BK3-B6-_2"
      },
      "source": [
        "# Compare one seed results for Acrobot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kjeR_wo7DxW"
      },
      "source": [
        "## Train with Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjGAMqwk7F6R",
        "outputId": "566868e2-157d-4a13-a3a4-8fc7e5c7c5d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Online Peturbations are\n",
            "[array([0., 0., 0., 0., 0., 0.]), array([-5.239924  , -2.65058914,  0.91997724,  0.20410329,  2.10710556,\n",
            "        3.24808522]), array([-3.00127004, -0.55566338,  2.38799004,  1.72363065, -0.83409209,\n",
            "       -0.49907283]), array([ 1.88735471, -1.53262128,  0.41645746,  2.81744585, -2.97820802,\n",
            "       -2.95161707]), array([ 1.98169263, -1.76646085, -0.73236775, -3.06941007, -0.70315102,\n",
            "        1.27983623]), array([ 1.37847833,  1.51450473, -2.86109954, -0.8577586 , -1.37002372,\n",
            "       -0.25128173]), array([ 2.28917448,  0.65441957, -0.27345488,  0.35838783,  1.93795414,\n",
            "        0.01174018]), array([ 1.18101088, -0.78495275,  0.07182293, -0.66150991,  1.61755215,\n",
            "        0.10662189]), array([-2.63780402, -2.15956139, -0.75193655,  0.29745353,  3.62983768,\n",
            "        1.10499787]), array([-1.07844989,  1.85410224,  2.39777336,  0.03593557,  2.03176482,\n",
            "       -2.36861302])]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  14%|█▍        | 278/2000 [05:39<35:01,  1.22s/iteration, mean_rewards=-400]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[35], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAcrobot-v1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m opt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbase\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpeturbations\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[33], line 63\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(env_name, opt_choice, random_perturbations)\u001b[0m\n\u001b[1;32m     60\u001b[0m episode \u001b[38;5;241m=\u001b[39m Episode()\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m timestep \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_timesteps):\n\u001b[0;32m---> 63\u001b[0m     action, log_probability \u001b[38;5;241m=\u001b[39m \u001b[43mpolicy_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstate_scale\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m     value \u001b[38;5;241m=\u001b[39m value_model\u001b[38;5;241m.\u001b[39mstate_value(observation \u001b[38;5;241m/\u001b[39m state_scale)\n\u001b[1;32m     66\u001b[0m     new_observation, reward, done, _, _ \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n",
            "Cell \u001b[0;32mIn[24], line 37\u001b[0m, in \u001b[0;36mPolicyNetwork.sample_action\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     35\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(state)\n\u001b[1;32m     36\u001b[0m dist \u001b[38;5;241m=\u001b[39m Categorical(y)\n\u001b[0;32m---> 37\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[43mdist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m log_probability \u001b[38;5;241m=\u001b[39m dist\u001b[38;5;241m.\u001b[39mlog_prob(action)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m action\u001b[38;5;241m.\u001b[39mitem(), log_probability\u001b[38;5;241m.\u001b[39mitem()\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/distributions/categorical.py:132\u001b[0m, in \u001b[0;36mCategorical.sample\u001b[0;34m(self, sample_shape)\u001b[0m\n\u001b[1;32m    130\u001b[0m     sample_shape \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mSize(sample_shape)\n\u001b[1;32m    131\u001b[0m probs_2d \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprobs\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_events)\n\u001b[0;32m--> 132\u001b[0m samples_2d \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultinomial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprobs_2d\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_shape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m samples_2d\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extended_shape(sample_shape))\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "peturbations = get_peturbations(\"Acrobot-v1\", seed)\n",
        "print(\"Online Peturbations are\")\n",
        "print(peturbations)\n",
        "env = \"Acrobot-v1\"\n",
        "opt = \"base\"\n",
        "train(env, opt, peturbations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyCzCOmh7L6Z"
      },
      "source": [
        "## Train with TRAC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JieNwXI7NWy",
        "outputId": "e8c51e39-a390-4484-b04c-1f65f3993499"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Online Peturbations are\n",
            "[array([0., 0., 0., 0., 0., 0.]), array([ 2.17157788,  0.34053703,  2.23921071, -1.31344863, -5.58455019,\n",
            "       -1.31314464]), array([ 0.64917973, -3.78084544, -0.22526347,  1.38430828, -2.41044139,\n",
            "        0.2959818 ]), array([ 1.38837342, -0.41074039,  4.29486731, -1.89647011,  0.57554351,\n",
            "       -0.2898865 ]), array([ 0.69971711, -0.74984953,  1.69061481,  1.49414689, -2.87732306,\n",
            "       -1.74682857]), array([-2.14713326,  0.4396411 ,  0.69225986,  2.16534063,  2.05933155,\n",
            "        1.17132279]), array([ 0.59946581,  0.86106039,  2.59435245, -2.60952034, -1.13732226,\n",
            "       -2.84250946]), array([ 6.13985793,  0.84625234, -1.09965102, -3.67620658, -2.38453755,\n",
            "       -0.92809013]), array([ 2.8292598 ,  3.0283006 ,  2.54238781, -0.29499719, -1.99801052,\n",
            "        3.57734236]), array([ 1.31372917, -0.01099749, -0.65765122,  1.81880701, -1.59662735,\n",
            "       -1.40798752])]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:   0%|          | 0/2000 [00:00<?, ?iteration/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "USING PACE.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2000/2000 [1:01:54<00:00,  1.86s/iteration, mean_rewards=-400]\n"
          ]
        }
      ],
      "source": [
        "print(\"Online Peturbations are\")\n",
        "print(peturbations)\n",
        "opt = \"TRAC\"\n",
        "train(env, opt, peturbations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAkxrtxr7Pad"
      },
      "source": [
        "## Plot Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 584
        },
        "id": "xZGOsa1H7Q3Y",
        "outputId": "0007d167-694f-4524-dc51-a7da12b13d3e"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot(env,seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptPG30C4-R2J"
      },
      "source": [
        "# Compare one seed results for CartPole"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cf69AqiBCUaN"
      },
      "source": [
        "## Train with Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJPMtCpNCT4K",
        "outputId": "2ad36023-85e4-4995-9e3c-c94ceca9ec2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Online Peturbations are\n",
            "[array([0., 0., 0., 0.]), array([ 0.92782529,  1.36819143, -4.77377769, -0.01497228]), array([-1.09384215,  0.94978324, -3.06290554,  3.84519343]), array([-0.29138351, -0.60629324, -1.81915061,  2.01540922]), array([ 3.19307222, -2.58054596, -1.01671636,  1.86447184]), array([ 0.99047822, -1.5946504 ,  0.49790264,  1.99205513]), array([-1.79682735,  1.07068881,  2.16418162,  0.18512872]), array([-1.27086281,  1.18398122, -0.9168031 ,  4.79663024]), array([-2.0079268 ,  0.65043091,  2.79887304, -0.89485782]), array([-2.45459832, -2.20658831, -1.69573544, -1.09117524])]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2000/2000 [02:08<00:00, 15.58iteration/s, mean_rewards=9.5] \n"
          ]
        }
      ],
      "source": [
        "peturbations = get_peturbations(\"CartPole-v1\", seed)\n",
        "print(\"Online Peturbations are\")\n",
        "print(peturbations)\n",
        "env = \"CartPole-v1\"\n",
        "opt = \"base\"\n",
        "train(env, opt, peturbations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_ZKyg2MDQ5j"
      },
      "source": [
        "## Train with TRAC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsc96nqxCZ9_",
        "outputId": "1cd1bfcb-c2ae-44fd-e3ad-8b4eb015ec7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Online Peturbations are\n",
            "[array([0., 0., 0., 0.]), array([ 0.92782529,  1.36819143, -4.77377769, -0.01497228]), array([-1.09384215,  0.94978324, -3.06290554,  3.84519343]), array([-0.29138351, -0.60629324, -1.81915061,  2.01540922]), array([ 3.19307222, -2.58054596, -1.01671636,  1.86447184]), array([ 0.99047822, -1.5946504 ,  0.49790264,  1.99205513]), array([-1.79682735,  1.07068881,  2.16418162,  0.18512872]), array([-1.27086281,  1.18398122, -0.9168031 ,  4.79663024]), array([-2.0079268 ,  0.65043091,  2.79887304, -0.89485782]), array([-2.45459832, -2.20658831, -1.69573544, -1.09117524])]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/2000 [00:00<?, ?iteration/s, mean_rewards=26]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "USING TRAC.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   9%|▉         | 185/2000 [06:21<1:02:18,  2.06s/iteration, mean_rewards=400]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[37], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(peturbations)\n\u001b[1;32m      3\u001b[0m opt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTRAC\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpeturbations\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[33], line 64\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(env_name, opt_choice, random_perturbations)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m timestep \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_timesteps):\n\u001b[1;32m     63\u001b[0m     action, log_probability \u001b[38;5;241m=\u001b[39m policy_model\u001b[38;5;241m.\u001b[39msample_action(observation \u001b[38;5;241m/\u001b[39m state_scale)\n\u001b[0;32m---> 64\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[43mvalue_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstate_scale\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m     new_observation, reward, done, _, _ \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[1;32m     67\u001b[0m     new_observation \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m random_perturbation\n",
            "Cell \u001b[0;32mIn[24], line 91\u001b[0m, in \u001b[0;36mValueNetwork.state_value\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(state\u001b[38;5;241m.\u001b[39msize()) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     89\u001b[0m     state \u001b[38;5;241m=\u001b[39m state\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 91\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\u001b[38;5;241m.\u001b[39mitem()\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[24], line 76\u001b[0m, in \u001b[0;36mValueNetwork.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 76\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml_relu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     77\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml_relu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x))\n\u001b[1;32m     78\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml_relu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc3(x))\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "print(\"Online Peturbations are\")\n",
        "print(peturbations)\n",
        "opt = \"TRAC\"\n",
        "train(env, opt, peturbations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGj9Xlva-gZ_"
      },
      "source": [
        "## Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 584
        },
        "id": "BF41I9hz-hxl",
        "outputId": "2489d1f3-20d5-47ba-dd05-82ab01197469"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot(env,seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvrCDPnp8vhW"
      },
      "source": [
        "# Compare one seed results for LunarLander"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zl_ZQ9yy9JFc"
      },
      "source": [
        "## Train with Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "FP3apiGk8ym1",
        "outputId": "56181e99-3b0c-4763-f0cd-fb677c13fda0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Online Peturbations are\n",
            "[array([0., 0., 0., 0., 0., 0., 0., 0.]), array([-2.0079268 ,  0.65043091,  2.79887304, -0.89485782, -2.45459832,\n",
            "       -2.20658831, -1.69573544, -1.09117524]), array([ 0.17443612,  0.20773286,  1.37988336,  0.94118602, -3.22100874,\n",
            "        2.25633408, -1.40989297, -3.26433332]), array([ 0.80256681, -0.28995543, -1.23964918, -1.00915434,  1.83726094,\n",
            "       -0.04131756, -0.34566563,  0.43507223]), array([-2.61347919,  0.16253191, -0.49465057,  1.62261508,  0.21936038,\n",
            "        3.78905087,  1.18040223,  0.366775  ]), array([-1.25746734, -2.2225763 , -1.90403545,  3.55554009,  1.10756424,\n",
            "       -0.72152412,  2.56358724, -4.10257526]), array([-1.76960483, -0.40704985, -5.2108199 ,  3.25156089,  2.9457686 ,\n",
            "       -1.01028411,  0.08907027, -0.38054472]), array([ 2.60647874,  1.77401358,  0.10560635,  4.91972652, -1.88837331,\n",
            "       -0.7740599 ,  1.03906547,  0.74652167]), array([ 1.38343614, -0.10384657,  2.18803684,  1.92105522,  1.92164754,\n",
            "        0.52874226,  2.21652274, -1.1928955 ]), array([ 3.20886394,  0.88459322,  1.30593826, -2.89332244, -2.83006294,\n",
            "       -2.53234813,  2.85362429, -0.73383654])]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:   0%|          | 0/2000 [00:00<?, ?iteration/s]\u001b[A/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  if not isinstance(terminated, (bool, np.bool8)):\n",
            "\n",
            "Training:   0%|          | 0/2000 [00:01<?, ?iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:   0%|          | 1/2000 [00:02<1:13:24,  2.20s/iteration, mean_rewards=-147]\u001b[A\n",
            "Training:   0%|          | 1/2000 [00:02<1:13:24,  2.20s/iteration, mean_rewards=-178]\u001b[A\n",
            "Training:   0%|          | 2/2000 [00:02<41:50,  1.26s/iteration, mean_rewards=-178]  \u001b[A\n",
            "Training:   0%|          | 2/2000 [00:03<41:50,  1.26s/iteration, mean_rewards=-112]\u001b[A\n",
            "Training:   0%|          | 3/2000 [00:03<31:22,  1.06iteration/s, mean_rewards=-112]\u001b[A\n",
            "Training:   0%|          | 3/2000 [00:03<31:22,  1.06iteration/s, mean_rewards=-53] \u001b[A\n",
            "Training:   0%|          | 4/2000 [00:04<28:02,  1.19iteration/s, mean_rewards=-53]\u001b[A\n",
            "Training:   0%|          | 4/2000 [00:04<28:02,  1.19iteration/s, mean_rewards=-278]\u001b[A\n",
            "Training:   0%|          | 5/2000 [00:04<25:51,  1.29iteration/s, mean_rewards=-278]\u001b[A\n",
            "Training:   0%|          | 5/2000 [00:05<25:51,  1.29iteration/s, mean_rewards=-32.1]\u001b[A\n",
            "Training:   0%|          | 6/2000 [00:05<22:44,  1.46iteration/s, mean_rewards=-32.1]\u001b[A\n",
            "Training:   0%|          | 6/2000 [00:05<22:44,  1.46iteration/s, mean_rewards=-594] \u001b[A\n",
            "Training:   0%|          | 7/2000 [00:05<22:11,  1.50iteration/s, mean_rewards=-594]\u001b[A\n",
            "Training:   0%|          | 7/2000 [00:06<22:11,  1.50iteration/s, mean_rewards=-476]\u001b[A\n",
            "Training:   0%|          | 8/2000 [00:06<21:05,  1.57iteration/s, mean_rewards=-476]\u001b[A\n",
            "Training:   0%|          | 8/2000 [00:06<21:05,  1.57iteration/s, mean_rewards=-532]\u001b[A\n",
            "Training:   0%|          | 9/2000 [00:06<19:56,  1.66iteration/s, mean_rewards=-532]\u001b[A\n",
            "Training:   0%|          | 9/2000 [00:07<19:56,  1.66iteration/s, mean_rewards=-406]\u001b[A\n",
            "Training:   0%|          | 10/2000 [00:07<18:23,  1.80iteration/s, mean_rewards=-406]\u001b[A\n",
            "Training:   0%|          | 10/2000 [00:07<18:23,  1.80iteration/s, mean_rewards=-201]\u001b[A\n",
            "Training:   1%|          | 11/2000 [00:07<16:28,  2.01iteration/s, mean_rewards=-201]\u001b[A\n",
            "Training:   1%|          | 11/2000 [00:08<16:28,  2.01iteration/s, mean_rewards=-373]\u001b[A\n",
            "Training:   1%|          | 12/2000 [00:08<15:57,  2.08iteration/s, mean_rewards=-373]\u001b[A\n",
            "Training:   1%|          | 12/2000 [00:08<15:57,  2.08iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:   1%|          | 13/2000 [00:08<15:02,  2.20iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:   1%|          | 13/2000 [00:08<15:02,  2.20iteration/s, mean_rewards=-254]\u001b[A\n",
            "Training:   1%|          | 14/2000 [00:09<15:30,  2.13iteration/s, mean_rewards=-254]\u001b[A\n",
            "Training:   1%|          | 14/2000 [00:09<15:30,  2.13iteration/s, mean_rewards=-258]\u001b[A\n",
            "Training:   1%|          | 15/2000 [00:09<15:17,  2.16iteration/s, mean_rewards=-258]\u001b[A\n",
            "Training:   1%|          | 15/2000 [00:09<15:17,  2.16iteration/s, mean_rewards=-94.2]\u001b[A\n",
            "Training:   1%|          | 16/2000 [00:09<15:08,  2.18iteration/s, mean_rewards=-94.2]\u001b[A\n",
            "Training:   1%|          | 16/2000 [00:10<15:08,  2.18iteration/s, mean_rewards=-175] \u001b[A\n",
            "Training:   1%|          | 17/2000 [00:10<16:32,  2.00iteration/s, mean_rewards=-175]\u001b[A\n",
            "Training:   1%|          | 17/2000 [00:10<16:32,  2.00iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:   1%|          | 18/2000 [00:11<16:09,  2.04iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:   1%|          | 18/2000 [00:11<16:09,  2.04iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:   1%|          | 19/2000 [00:11<16:39,  1.98iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:   1%|          | 19/2000 [00:11<16:39,  1.98iteration/s, mean_rewards=-167]\u001b[A\n",
            "Training:   1%|          | 20/2000 [00:12<15:39,  2.11iteration/s, mean_rewards=-167]\u001b[A\n",
            "Training:   1%|          | 20/2000 [00:12<15:39,  2.11iteration/s, mean_rewards=-179]\u001b[A\n",
            "Training:   1%|          | 21/2000 [00:12<15:30,  2.13iteration/s, mean_rewards=-179]\u001b[A\n",
            "Training:   1%|          | 21/2000 [00:12<15:30,  2.13iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:   1%|          | 22/2000 [00:12<15:32,  2.12iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:   1%|          | 22/2000 [00:13<15:32,  2.12iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:   1%|          | 23/2000 [00:13<17:08,  1.92iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:   1%|          | 23/2000 [00:13<17:08,  1.92iteration/s, mean_rewards=-191]\u001b[A\n",
            "Training:   1%|          | 24/2000 [00:14<17:03,  1.93iteration/s, mean_rewards=-191]\u001b[A\n",
            "Training:   1%|          | 24/2000 [00:14<17:03,  1.93iteration/s, mean_rewards=-222]\u001b[A\n",
            "Training:   1%|▏         | 25/2000 [00:14<15:40,  2.10iteration/s, mean_rewards=-222]\u001b[A\n",
            "Training:   1%|▏         | 25/2000 [00:14<15:40,  2.10iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:   1%|▏         | 26/2000 [00:14<14:11,  2.32iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:   1%|▏         | 26/2000 [00:15<14:11,  2.32iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:   1%|▏         | 27/2000 [00:15<13:10,  2.50iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:   1%|▏         | 27/2000 [00:15<13:10,  2.50iteration/s, mean_rewards=-254]\u001b[A\n",
            "Training:   1%|▏         | 28/2000 [00:15<12:53,  2.55iteration/s, mean_rewards=-254]\u001b[A\n",
            "Training:   1%|▏         | 28/2000 [00:15<12:53,  2.55iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:   1%|▏         | 29/2000 [00:15<12:13,  2.69iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:   1%|▏         | 29/2000 [00:16<12:13,  2.69iteration/s, mean_rewards=-178]\u001b[A\n",
            "Training:   2%|▏         | 30/2000 [00:16<13:09,  2.49iteration/s, mean_rewards=-178]\u001b[A\n",
            "Training:   2%|▏         | 30/2000 [00:16<13:09,  2.49iteration/s, mean_rewards=-293]\u001b[A\n",
            "Training:   2%|▏         | 31/2000 [00:16<14:19,  2.29iteration/s, mean_rewards=-293]\u001b[A\n",
            "Training:   2%|▏         | 31/2000 [00:17<14:19,  2.29iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:   2%|▏         | 32/2000 [00:17<14:31,  2.26iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:   2%|▏         | 32/2000 [00:17<14:31,  2.26iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:   2%|▏         | 33/2000 [00:17<14:51,  2.21iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:   2%|▏         | 33/2000 [00:18<14:51,  2.21iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:   2%|▏         | 34/2000 [00:18<16:20,  2.01iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:   2%|▏         | 34/2000 [00:18<16:20,  2.01iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:   2%|▏         | 35/2000 [00:18<15:32,  2.11iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:   2%|▏         | 35/2000 [00:19<15:32,  2.11iteration/s, mean_rewards=-339]\u001b[A\n",
            "Training:   2%|▏         | 36/2000 [00:19<16:08,  2.03iteration/s, mean_rewards=-339]\u001b[A\n",
            "Training:   2%|▏         | 36/2000 [00:19<16:08,  2.03iteration/s, mean_rewards=-172]\u001b[A\n",
            "Training:   2%|▏         | 37/2000 [00:19<14:48,  2.21iteration/s, mean_rewards=-172]\u001b[A\n",
            "Training:   2%|▏         | 37/2000 [00:19<14:48,  2.21iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:   2%|▏         | 38/2000 [00:20<14:04,  2.32iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:   2%|▏         | 38/2000 [00:20<14:04,  2.32iteration/s, mean_rewards=-313]\u001b[A\n",
            "Training:   2%|▏         | 39/2000 [00:20<13:43,  2.38iteration/s, mean_rewards=-313]\u001b[A\n",
            "Training:   2%|▏         | 39/2000 [00:20<13:43,  2.38iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:   2%|▏         | 40/2000 [00:20<13:26,  2.43iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:   2%|▏         | 40/2000 [00:21<13:26,  2.43iteration/s, mean_rewards=-112]\u001b[A\n",
            "Training:   2%|▏         | 41/2000 [00:21<13:00,  2.51iteration/s, mean_rewards=-112]\u001b[A\n",
            "Training:   2%|▏         | 41/2000 [00:21<13:00,  2.51iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:   2%|▏         | 42/2000 [00:21<12:22,  2.64iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:   2%|▏         | 42/2000 [00:21<12:22,  2.64iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:   2%|▏         | 43/2000 [00:21<12:30,  2.61iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:   2%|▏         | 43/2000 [00:22<12:30,  2.61iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:   2%|▏         | 44/2000 [00:22<13:49,  2.36iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:   2%|▏         | 44/2000 [00:22<13:49,  2.36iteration/s, mean_rewards=-258]\u001b[A\n",
            "Training:   2%|▏         | 45/2000 [00:23<15:12,  2.14iteration/s, mean_rewards=-258]\u001b[A\n",
            "Training:   2%|▏         | 45/2000 [00:23<15:12,  2.14iteration/s, mean_rewards=-167]\u001b[A\n",
            "Training:   2%|▏         | 46/2000 [00:23<14:07,  2.31iteration/s, mean_rewards=-167]\u001b[A\n",
            "Training:   2%|▏         | 46/2000 [00:23<14:07,  2.31iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:   2%|▏         | 47/2000 [00:23<13:34,  2.40iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:   2%|▏         | 47/2000 [00:24<13:34,  2.40iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:   2%|▏         | 48/2000 [00:24<13:35,  2.39iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:   2%|▏         | 48/2000 [00:24<13:35,  2.39iteration/s, mean_rewards=-197]\u001b[A\n",
            "Training:   2%|▏         | 49/2000 [00:24<14:09,  2.30iteration/s, mean_rewards=-197]\u001b[A\n",
            "Training:   2%|▏         | 49/2000 [00:24<14:09,  2.30iteration/s, mean_rewards=-231]\u001b[A\n",
            "Training:   2%|▎         | 50/2000 [00:25<14:00,  2.32iteration/s, mean_rewards=-231]\u001b[A\n",
            "Training:   2%|▎         | 50/2000 [00:25<14:00,  2.32iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:   3%|▎         | 51/2000 [00:25<13:21,  2.43iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:   3%|▎         | 51/2000 [00:25<13:21,  2.43iteration/s, mean_rewards=-95.2]\u001b[A\n",
            "Training:   3%|▎         | 52/2000 [00:25<12:47,  2.54iteration/s, mean_rewards=-95.2]\u001b[A\n",
            "Training:   3%|▎         | 52/2000 [00:26<12:47,  2.54iteration/s, mean_rewards=-230] \u001b[A\n",
            "Training:   3%|▎         | 53/2000 [00:26<13:36,  2.38iteration/s, mean_rewards=-230]\u001b[A\n",
            "Training:   3%|▎         | 53/2000 [00:26<13:36,  2.38iteration/s, mean_rewards=-185]\u001b[A\n",
            "Training:   3%|▎         | 54/2000 [00:26<13:21,  2.43iteration/s, mean_rewards=-185]\u001b[A\n",
            "Training:   3%|▎         | 54/2000 [00:27<13:21,  2.43iteration/s, mean_rewards=-435]\u001b[A\n",
            "Training:   3%|▎         | 55/2000 [00:27<15:12,  2.13iteration/s, mean_rewards=-435]\u001b[A\n",
            "Training:   3%|▎         | 55/2000 [00:27<15:12,  2.13iteration/s, mean_rewards=-166]\u001b[A\n",
            "Training:   3%|▎         | 56/2000 [00:27<15:23,  2.11iteration/s, mean_rewards=-166]\u001b[A\n",
            "Training:   3%|▎         | 56/2000 [00:27<15:23,  2.11iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:   3%|▎         | 57/2000 [00:28<14:22,  2.25iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:   3%|▎         | 57/2000 [00:28<14:22,  2.25iteration/s, mean_rewards=-252]\u001b[A\n",
            "Training:   3%|▎         | 58/2000 [00:28<13:24,  2.41iteration/s, mean_rewards=-252]\u001b[A\n",
            "Training:   3%|▎         | 58/2000 [00:28<13:24,  2.41iteration/s, mean_rewards=-347]\u001b[A\n",
            "Training:   3%|▎         | 59/2000 [00:28<13:25,  2.41iteration/s, mean_rewards=-347]\u001b[A\n",
            "Training:   3%|▎         | 59/2000 [00:29<13:25,  2.41iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:   3%|▎         | 60/2000 [00:29<12:53,  2.51iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:   3%|▎         | 60/2000 [00:29<12:53,  2.51iteration/s, mean_rewards=-92.2]\u001b[A\n",
            "Training:   3%|▎         | 61/2000 [00:30<18:58,  1.70iteration/s, mean_rewards=-92.2]\u001b[A\n",
            "Training:   3%|▎         | 61/2000 [00:30<18:58,  1.70iteration/s, mean_rewards=-133] \u001b[A\n",
            "Training:   3%|▎         | 62/2000 [00:31<20:41,  1.56iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:   3%|▎         | 62/2000 [00:31<20:41,  1.56iteration/s, mean_rewards=-59.2]\u001b[A\n",
            "Training:   3%|▎         | 63/2000 [00:32<24:26,  1.32iteration/s, mean_rewards=-59.2]\u001b[A\n",
            "Training:   3%|▎         | 63/2000 [00:33<24:26,  1.32iteration/s, mean_rewards=-240] \u001b[A\n",
            "Training:   3%|▎         | 64/2000 [00:33<29:03,  1.11iteration/s, mean_rewards=-240]\u001b[A\n",
            "Training:   3%|▎         | 64/2000 [00:33<29:03,  1.11iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:   3%|▎         | 65/2000 [00:33<23:12,  1.39iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:   3%|▎         | 65/2000 [00:33<23:12,  1.39iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:   3%|▎         | 66/2000 [00:33<19:53,  1.62iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:   3%|▎         | 66/2000 [00:34<19:53,  1.62iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:   3%|▎         | 67/2000 [00:34<17:13,  1.87iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:   3%|▎         | 67/2000 [00:34<17:13,  1.87iteration/s, mean_rewards=-104]\u001b[A\n",
            "Training:   3%|▎         | 68/2000 [00:34<15:19,  2.10iteration/s, mean_rewards=-104]\u001b[A\n",
            "Training:   3%|▎         | 68/2000 [00:34<15:19,  2.10iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:   3%|▎         | 69/2000 [00:34<14:04,  2.29iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:   3%|▎         | 69/2000 [00:35<14:04,  2.29iteration/s, mean_rewards=-45.5]\u001b[A\n",
            "Training:   4%|▎         | 70/2000 [00:35<13:03,  2.46iteration/s, mean_rewards=-45.5]\u001b[A\n",
            "Training:   4%|▎         | 70/2000 [00:35<13:03,  2.46iteration/s, mean_rewards=-196] \u001b[A\n",
            "Training:   4%|▎         | 71/2000 [00:35<12:28,  2.58iteration/s, mean_rewards=-196]\u001b[A\n",
            "Training:   4%|▎         | 71/2000 [00:35<12:28,  2.58iteration/s, mean_rewards=-162]\u001b[A\n",
            "Training:   4%|▎         | 72/2000 [00:36<12:04,  2.66iteration/s, mean_rewards=-162]\u001b[A\n",
            "Training:   4%|▎         | 72/2000 [00:36<12:04,  2.66iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:   4%|▎         | 73/2000 [00:36<12:35,  2.55iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:   4%|▎         | 73/2000 [00:36<12:35,  2.55iteration/s, mean_rewards=-82.3]\u001b[A\n",
            "Training:   4%|▎         | 74/2000 [00:36<12:05,  2.66iteration/s, mean_rewards=-82.3]\u001b[A\n",
            "Training:   4%|▎         | 74/2000 [00:36<12:05,  2.66iteration/s, mean_rewards=-116] \u001b[A\n",
            "Training:   4%|▍         | 75/2000 [00:37<11:20,  2.83iteration/s, mean_rewards=-116]\u001b[A\n",
            "Training:   4%|▍         | 75/2000 [00:37<11:20,  2.83iteration/s, mean_rewards=-173]\u001b[A\n",
            "Training:   4%|▍         | 76/2000 [00:37<11:32,  2.78iteration/s, mean_rewards=-173]\u001b[A\n",
            "Training:   4%|▍         | 76/2000 [00:37<11:32,  2.78iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:   4%|▍         | 77/2000 [00:37<11:13,  2.86iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:   4%|▍         | 77/2000 [00:37<11:13,  2.86iteration/s, mean_rewards=-68.1]\u001b[A\n",
            "Training:   4%|▍         | 78/2000 [00:38<10:44,  2.98iteration/s, mean_rewards=-68.1]\u001b[A\n",
            "Training:   4%|▍         | 78/2000 [00:38<10:44,  2.98iteration/s, mean_rewards=-145] \u001b[A\n",
            "Training:   4%|▍         | 79/2000 [00:38<11:00,  2.91iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:   4%|▍         | 79/2000 [00:38<11:00,  2.91iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:   4%|▍         | 80/2000 [00:38<11:11,  2.86iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:   4%|▍         | 80/2000 [00:39<11:11,  2.86iteration/s, mean_rewards=-88.7]\u001b[A\n",
            "Training:   4%|▍         | 81/2000 [00:39<11:15,  2.84iteration/s, mean_rewards=-88.7]\u001b[A\n",
            "Training:   4%|▍         | 81/2000 [00:39<11:15,  2.84iteration/s, mean_rewards=-151] \u001b[A\n",
            "Training:   4%|▍         | 82/2000 [00:39<11:24,  2.80iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:   4%|▍         | 82/2000 [00:39<11:24,  2.80iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:   4%|▍         | 83/2000 [00:39<11:19,  2.82iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:   4%|▍         | 83/2000 [00:40<11:19,  2.82iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:   4%|▍         | 84/2000 [00:40<11:29,  2.78iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:   4%|▍         | 84/2000 [00:40<11:29,  2.78iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:   4%|▍         | 85/2000 [00:40<11:22,  2.80iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:   4%|▍         | 85/2000 [00:40<11:22,  2.80iteration/s, mean_rewards=-75.5]\u001b[A\n",
            "Training:   4%|▍         | 86/2000 [00:40<11:20,  2.81iteration/s, mean_rewards=-75.5]\u001b[A\n",
            "Training:   4%|▍         | 86/2000 [00:41<11:20,  2.81iteration/s, mean_rewards=-195] \u001b[A\n",
            "Training:   4%|▍         | 87/2000 [00:41<11:27,  2.78iteration/s, mean_rewards=-195]\u001b[A\n",
            "Training:   4%|▍         | 87/2000 [00:41<11:27,  2.78iteration/s, mean_rewards=-231]\u001b[A\n",
            "Training:   4%|▍         | 88/2000 [00:41<12:10,  2.62iteration/s, mean_rewards=-231]\u001b[A\n",
            "Training:   4%|▍         | 88/2000 [00:41<12:10,  2.62iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:   4%|▍         | 89/2000 [00:42<11:36,  2.74iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:   4%|▍         | 89/2000 [00:42<11:36,  2.74iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:   4%|▍         | 90/2000 [00:42<12:07,  2.63iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:   4%|▍         | 90/2000 [00:42<12:07,  2.63iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:   5%|▍         | 91/2000 [00:42<11:43,  2.71iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:   5%|▍         | 91/2000 [00:43<11:43,  2.71iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:   5%|▍         | 92/2000 [00:43<11:42,  2.72iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:   5%|▍         | 92/2000 [00:43<11:42,  2.72iteration/s, mean_rewards=-70.5]\u001b[A\n",
            "Training:   5%|▍         | 93/2000 [00:43<13:34,  2.34iteration/s, mean_rewards=-70.5]\u001b[A\n",
            "Training:   5%|▍         | 93/2000 [00:44<13:34,  2.34iteration/s, mean_rewards=-131] \u001b[A\n",
            "Training:   5%|▍         | 94/2000 [00:44<13:25,  2.37iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:   5%|▍         | 94/2000 [00:44<13:25,  2.37iteration/s, mean_rewards=-101]\u001b[A\n",
            "Training:   5%|▍         | 95/2000 [00:44<14:18,  2.22iteration/s, mean_rewards=-101]\u001b[A\n",
            "Training:   5%|▍         | 95/2000 [00:45<14:18,  2.22iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:   5%|▍         | 96/2000 [00:45<14:37,  2.17iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:   5%|▍         | 96/2000 [00:45<14:37,  2.17iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:   5%|▍         | 97/2000 [00:45<14:58,  2.12iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:   5%|▍         | 97/2000 [00:45<14:58,  2.12iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:   5%|▍         | 98/2000 [00:46<13:22,  2.37iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:   5%|▍         | 98/2000 [00:46<13:22,  2.37iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:   5%|▍         | 99/2000 [00:46<12:15,  2.59iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:   5%|▍         | 99/2000 [00:46<12:15,  2.59iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:   5%|▌         | 100/2000 [00:46<11:28,  2.76iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:   5%|▌         | 100/2000 [00:46<11:28,  2.76iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:   5%|▌         | 101/2000 [00:46<11:19,  2.80iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:   5%|▌         | 101/2000 [00:47<11:19,  2.80iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:   5%|▌         | 102/2000 [00:47<10:28,  3.02iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:   5%|▌         | 102/2000 [00:47<10:28,  3.02iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:   5%|▌         | 103/2000 [00:47<10:26,  3.03iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:   5%|▌         | 103/2000 [00:47<10:26,  3.03iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:   5%|▌         | 104/2000 [00:47<10:29,  3.01iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:   5%|▌         | 104/2000 [00:48<10:29,  3.01iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:   5%|▌         | 105/2000 [00:48<10:16,  3.08iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:   5%|▌         | 105/2000 [00:48<10:16,  3.08iteration/s, mean_rewards=-103]\u001b[A\n",
            "Training:   5%|▌         | 106/2000 [00:48<10:40,  2.96iteration/s, mean_rewards=-103]\u001b[A\n",
            "Training:   5%|▌         | 106/2000 [00:48<10:40,  2.96iteration/s, mean_rewards=-166]\u001b[A\n",
            "Training:   5%|▌         | 107/2000 [00:48<10:51,  2.91iteration/s, mean_rewards=-166]\u001b[A\n",
            "Training:   5%|▌         | 107/2000 [00:49<10:51,  2.91iteration/s, mean_rewards=-85.6]\u001b[A\n",
            "Training:   5%|▌         | 108/2000 [00:49<10:27,  3.02iteration/s, mean_rewards=-85.6]\u001b[A\n",
            "Training:   5%|▌         | 108/2000 [00:49<10:27,  3.02iteration/s, mean_rewards=-123] \u001b[A\n",
            "Training:   5%|▌         | 109/2000 [00:49<10:00,  3.15iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:   5%|▌         | 109/2000 [00:49<10:00,  3.15iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:   6%|▌         | 110/2000 [00:49<09:58,  3.16iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:   6%|▌         | 110/2000 [00:50<09:58,  3.16iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:   6%|▌         | 111/2000 [00:50<10:23,  3.03iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:   6%|▌         | 111/2000 [00:50<10:23,  3.03iteration/s, mean_rewards=-55.2]\u001b[A\n",
            "Training:   6%|▌         | 112/2000 [00:50<09:59,  3.15iteration/s, mean_rewards=-55.2]\u001b[A\n",
            "Training:   6%|▌         | 112/2000 [00:50<09:59,  3.15iteration/s, mean_rewards=-128] \u001b[A\n",
            "Training:   6%|▌         | 113/2000 [00:50<10:06,  3.11iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:   6%|▌         | 113/2000 [00:51<10:06,  3.11iteration/s, mean_rewards=-164]\u001b[A\n",
            "Training:   6%|▌         | 114/2000 [00:51<09:53,  3.18iteration/s, mean_rewards=-164]\u001b[A\n",
            "Training:   6%|▌         | 114/2000 [00:51<09:53,  3.18iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:   6%|▌         | 115/2000 [00:51<10:09,  3.09iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:   6%|▌         | 115/2000 [00:51<10:09,  3.09iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:   6%|▌         | 116/2000 [00:51<10:22,  3.03iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:   6%|▌         | 116/2000 [00:52<10:22,  3.03iteration/s, mean_rewards=-75.1]\u001b[A\n",
            "Training:   6%|▌         | 117/2000 [00:52<10:37,  2.95iteration/s, mean_rewards=-75.1]\u001b[A\n",
            "Training:   6%|▌         | 117/2000 [00:52<10:37,  2.95iteration/s, mean_rewards=-135] \u001b[A\n",
            "Training:   6%|▌         | 118/2000 [00:52<11:18,  2.77iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:   6%|▌         | 118/2000 [00:52<11:18,  2.77iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:   6%|▌         | 119/2000 [00:52<11:19,  2.77iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:   6%|▌         | 119/2000 [00:53<11:19,  2.77iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:   6%|▌         | 120/2000 [00:53<11:33,  2.71iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:   6%|▌         | 120/2000 [00:53<11:33,  2.71iteration/s, mean_rewards=-179]\u001b[A\n",
            "Training:   6%|▌         | 121/2000 [00:53<11:56,  2.62iteration/s, mean_rewards=-179]\u001b[A\n",
            "Training:   6%|▌         | 121/2000 [00:53<11:56,  2.62iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:   6%|▌         | 122/2000 [00:54<11:42,  2.67iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:   6%|▌         | 122/2000 [00:54<11:42,  2.67iteration/s, mean_rewards=-67.7]\u001b[A\n",
            "Training:   6%|▌         | 123/2000 [00:54<11:42,  2.67iteration/s, mean_rewards=-67.7]\u001b[A\n",
            "Training:   6%|▌         | 123/2000 [00:54<11:42,  2.67iteration/s, mean_rewards=-91.6]\u001b[A\n",
            "Training:   6%|▌         | 124/2000 [00:54<11:53,  2.63iteration/s, mean_rewards=-91.6]\u001b[A\n",
            "Training:   6%|▌         | 124/2000 [00:55<11:53,  2.63iteration/s, mean_rewards=-46.6]\u001b[A\n",
            "Training:   6%|▋         | 125/2000 [00:55<12:17,  2.54iteration/s, mean_rewards=-46.6]\u001b[A\n",
            "Training:   6%|▋         | 125/2000 [00:55<12:17,  2.54iteration/s, mean_rewards=-129] \u001b[A\n",
            "Training:   6%|▋         | 126/2000 [00:55<11:48,  2.64iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:   6%|▋         | 126/2000 [00:55<11:48,  2.64iteration/s, mean_rewards=-160]\u001b[A\n",
            "Training:   6%|▋         | 127/2000 [00:56<12:57,  2.41iteration/s, mean_rewards=-160]\u001b[A\n",
            "Training:   6%|▋         | 127/2000 [00:56<12:57,  2.41iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:   6%|▋         | 128/2000 [00:56<13:17,  2.35iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:   6%|▋         | 128/2000 [00:56<13:17,  2.35iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:   6%|▋         | 129/2000 [00:56<12:50,  2.43iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:   6%|▋         | 129/2000 [00:57<12:50,  2.43iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:   6%|▋         | 130/2000 [00:57<13:27,  2.32iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:   6%|▋         | 130/2000 [00:57<13:27,  2.32iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:   7%|▋         | 131/2000 [00:57<13:58,  2.23iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:   7%|▋         | 131/2000 [00:58<13:58,  2.23iteration/s, mean_rewards=-94.4]\u001b[A\n",
            "Training:   7%|▋         | 132/2000 [00:58<13:43,  2.27iteration/s, mean_rewards=-94.4]\u001b[A\n",
            "Training:   7%|▋         | 132/2000 [00:58<13:43,  2.27iteration/s, mean_rewards=-34.3]\u001b[A\n",
            "Training:   7%|▋         | 133/2000 [00:58<14:29,  2.15iteration/s, mean_rewards=-34.3]\u001b[A\n",
            "Training:   7%|▋         | 133/2000 [00:59<14:29,  2.15iteration/s, mean_rewards=-139] \u001b[A\n",
            "Training:   7%|▋         | 134/2000 [00:59<13:06,  2.37iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:   7%|▋         | 134/2000 [00:59<13:06,  2.37iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:   7%|▋         | 135/2000 [00:59<12:34,  2.47iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:   7%|▋         | 135/2000 [00:59<12:34,  2.47iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:   7%|▋         | 136/2000 [00:59<11:30,  2.70iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:   7%|▋         | 136/2000 [01:00<11:30,  2.70iteration/s, mean_rewards=-59.3]\u001b[A\n",
            "Training:   7%|▋         | 137/2000 [01:00<11:43,  2.65iteration/s, mean_rewards=-59.3]\u001b[A\n",
            "Training:   7%|▋         | 137/2000 [01:00<11:43,  2.65iteration/s, mean_rewards=-121] \u001b[A\n",
            "Training:   7%|▋         | 138/2000 [01:00<11:21,  2.73iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:   7%|▋         | 138/2000 [01:00<11:21,  2.73iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:   7%|▋         | 139/2000 [01:00<11:26,  2.71iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:   7%|▋         | 139/2000 [01:01<11:26,  2.71iteration/s, mean_rewards=-106]\u001b[A\n",
            "Training:   7%|▋         | 140/2000 [01:01<10:47,  2.87iteration/s, mean_rewards=-106]\u001b[A\n",
            "Training:   7%|▋         | 140/2000 [01:01<10:47,  2.87iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:   7%|▋         | 141/2000 [01:01<10:46,  2.88iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:   7%|▋         | 141/2000 [01:01<10:46,  2.88iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:   7%|▋         | 142/2000 [01:01<10:55,  2.83iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:   7%|▋         | 142/2000 [01:02<10:55,  2.83iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:   7%|▋         | 143/2000 [01:02<11:22,  2.72iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:   7%|▋         | 143/2000 [01:02<11:22,  2.72iteration/s, mean_rewards=-174]\u001b[A\n",
            "Training:   7%|▋         | 144/2000 [01:02<11:09,  2.77iteration/s, mean_rewards=-174]\u001b[A\n",
            "Training:   7%|▋         | 144/2000 [01:02<11:09,  2.77iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:   7%|▋         | 145/2000 [01:03<10:45,  2.87iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:   7%|▋         | 145/2000 [01:03<10:45,  2.87iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:   7%|▋         | 146/2000 [01:03<11:08,  2.77iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:   7%|▋         | 146/2000 [01:03<11:08,  2.77iteration/s, mean_rewards=-205]\u001b[A\n",
            "Training:   7%|▋         | 147/2000 [01:03<11:13,  2.75iteration/s, mean_rewards=-205]\u001b[A\n",
            "Training:   7%|▋         | 147/2000 [01:03<11:13,  2.75iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:   7%|▋         | 148/2000 [01:04<10:31,  2.93iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:   7%|▋         | 148/2000 [01:04<10:31,  2.93iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:   7%|▋         | 149/2000 [01:04<10:47,  2.86iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:   7%|▋         | 149/2000 [01:04<10:47,  2.86iteration/s, mean_rewards=-65] \u001b[A\n",
            "Training:   8%|▊         | 150/2000 [01:04<10:55,  2.82iteration/s, mean_rewards=-65]\u001b[A\n",
            "Training:   8%|▊         | 150/2000 [01:05<10:55,  2.82iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:   8%|▊         | 151/2000 [01:05<11:44,  2.62iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:   8%|▊         | 151/2000 [01:05<11:44,  2.62iteration/s, mean_rewards=-101]\u001b[A\n",
            "Training:   8%|▊         | 152/2000 [01:05<11:45,  2.62iteration/s, mean_rewards=-101]\u001b[A\n",
            "Training:   8%|▊         | 152/2000 [01:05<11:45,  2.62iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:   8%|▊         | 153/2000 [01:06<11:44,  2.62iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:   8%|▊         | 153/2000 [01:06<11:44,  2.62iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:   8%|▊         | 154/2000 [01:06<11:28,  2.68iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:   8%|▊         | 154/2000 [01:06<11:28,  2.68iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:   8%|▊         | 155/2000 [01:06<11:07,  2.76iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:   8%|▊         | 155/2000 [01:06<11:07,  2.76iteration/s, mean_rewards=-157]\u001b[A\n",
            "Training:   8%|▊         | 156/2000 [01:07<11:04,  2.78iteration/s, mean_rewards=-157]\u001b[A\n",
            "Training:   8%|▊         | 156/2000 [01:07<11:04,  2.78iteration/s, mean_rewards=-173]\u001b[A\n",
            "Training:   8%|▊         | 157/2000 [01:07<11:10,  2.75iteration/s, mean_rewards=-173]\u001b[A\n",
            "Training:   8%|▊         | 157/2000 [01:07<11:10,  2.75iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:   8%|▊         | 158/2000 [01:07<10:44,  2.86iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:   8%|▊         | 158/2000 [01:07<10:44,  2.86iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:   8%|▊         | 159/2000 [01:08<10:21,  2.96iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:   8%|▊         | 159/2000 [01:08<10:21,  2.96iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:   8%|▊         | 160/2000 [01:08<09:55,  3.09iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:   8%|▊         | 160/2000 [01:08<09:55,  3.09iteration/s, mean_rewards=-84.9]\u001b[A\n",
            "Training:   8%|▊         | 161/2000 [01:08<09:55,  3.09iteration/s, mean_rewards=-84.9]\u001b[A\n",
            "Training:   8%|▊         | 161/2000 [01:08<09:55,  3.09iteration/s, mean_rewards=-148] \u001b[A\n",
            "Training:   8%|▊         | 162/2000 [01:09<11:11,  2.74iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:   8%|▊         | 162/2000 [01:09<11:11,  2.74iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:   8%|▊         | 163/2000 [01:09<11:53,  2.57iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:   8%|▊         | 163/2000 [01:09<11:53,  2.57iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:   8%|▊         | 164/2000 [01:09<12:01,  2.55iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:   8%|▊         | 164/2000 [01:10<12:01,  2.55iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:   8%|▊         | 165/2000 [01:10<12:57,  2.36iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:   8%|▊         | 165/2000 [01:10<12:57,  2.36iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:   8%|▊         | 166/2000 [01:11<14:01,  2.18iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:   8%|▊         | 166/2000 [01:11<14:01,  2.18iteration/s, mean_rewards=-119]\u001b[A\n",
            "Training:   8%|▊         | 167/2000 [01:11<13:35,  2.25iteration/s, mean_rewards=-119]\u001b[A\n",
            "Training:   8%|▊         | 167/2000 [01:11<13:35,  2.25iteration/s, mean_rewards=-96.9]\u001b[A\n",
            "Training:   8%|▊         | 168/2000 [01:11<12:54,  2.37iteration/s, mean_rewards=-96.9]\u001b[A\n",
            "Training:   8%|▊         | 168/2000 [01:12<12:54,  2.37iteration/s, mean_rewards=-163] \u001b[A\n",
            "Training:   8%|▊         | 169/2000 [01:12<12:11,  2.50iteration/s, mean_rewards=-163]\u001b[A\n",
            "Training:   8%|▊         | 169/2000 [01:12<12:11,  2.50iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:   8%|▊         | 170/2000 [01:12<11:19,  2.69iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:   8%|▊         | 170/2000 [01:12<11:19,  2.69iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:   9%|▊         | 171/2000 [01:12<11:10,  2.73iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:   9%|▊         | 171/2000 [01:13<11:10,  2.73iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:   9%|▊         | 172/2000 [01:13<11:06,  2.74iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:   9%|▊         | 172/2000 [01:13<11:06,  2.74iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:   9%|▊         | 173/2000 [01:13<10:31,  2.89iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:   9%|▊         | 173/2000 [01:13<10:31,  2.89iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:   9%|▊         | 174/2000 [01:13<10:33,  2.88iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:   9%|▊         | 174/2000 [01:14<10:33,  2.88iteration/s, mean_rewards=-119]\u001b[A\n",
            "Training:   9%|▉         | 175/2000 [01:14<10:06,  3.01iteration/s, mean_rewards=-119]\u001b[A\n",
            "Training:   9%|▉         | 175/2000 [01:14<10:06,  3.01iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:   9%|▉         | 176/2000 [01:14<09:57,  3.05iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:   9%|▉         | 176/2000 [01:14<09:57,  3.05iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:   9%|▉         | 177/2000 [01:14<09:41,  3.13iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:   9%|▉         | 177/2000 [01:14<09:41,  3.13iteration/s, mean_rewards=-182]\u001b[A\n",
            "Training:   9%|▉         | 178/2000 [01:15<10:04,  3.01iteration/s, mean_rewards=-182]\u001b[A\n",
            "Training:   9%|▉         | 178/2000 [01:15<10:04,  3.01iteration/s, mean_rewards=-69.6]\u001b[A\n",
            "Training:   9%|▉         | 179/2000 [01:15<10:36,  2.86iteration/s, mean_rewards=-69.6]\u001b[A\n",
            "Training:   9%|▉         | 179/2000 [01:15<10:36,  2.86iteration/s, mean_rewards=-241] \u001b[A\n",
            "Training:   9%|▉         | 180/2000 [01:15<10:49,  2.80iteration/s, mean_rewards=-241]\u001b[A\n",
            "Training:   9%|▉         | 180/2000 [01:16<10:49,  2.80iteration/s, mean_rewards=-106]\u001b[A\n",
            "Training:   9%|▉         | 181/2000 [01:16<10:56,  2.77iteration/s, mean_rewards=-106]\u001b[A\n",
            "Training:   9%|▉         | 181/2000 [01:16<10:56,  2.77iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:   9%|▉         | 182/2000 [01:16<10:58,  2.76iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:   9%|▉         | 182/2000 [01:16<10:58,  2.76iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:   9%|▉         | 183/2000 [01:16<10:28,  2.89iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:   9%|▉         | 183/2000 [01:17<10:28,  2.89iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:   9%|▉         | 184/2000 [01:17<10:25,  2.90iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:   9%|▉         | 184/2000 [01:17<10:25,  2.90iteration/s, mean_rewards=-167]\u001b[A\n",
            "Training:   9%|▉         | 185/2000 [01:17<10:42,  2.82iteration/s, mean_rewards=-167]\u001b[A\n",
            "Training:   9%|▉         | 185/2000 [01:17<10:42,  2.82iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:   9%|▉         | 186/2000 [01:18<11:35,  2.61iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:   9%|▉         | 186/2000 [01:18<11:35,  2.61iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:   9%|▉         | 187/2000 [01:18<11:18,  2.67iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:   9%|▉         | 187/2000 [01:18<11:18,  2.67iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:   9%|▉         | 188/2000 [01:18<10:47,  2.80iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:   9%|▉         | 188/2000 [01:19<10:47,  2.80iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:   9%|▉         | 189/2000 [01:19<11:18,  2.67iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:   9%|▉         | 189/2000 [01:19<11:18,  2.67iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  10%|▉         | 190/2000 [01:19<10:30,  2.87iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  10%|▉         | 190/2000 [01:19<10:30,  2.87iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  10%|▉         | 191/2000 [01:19<10:00,  3.01iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  10%|▉         | 191/2000 [01:19<10:00,  3.01iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  10%|▉         | 192/2000 [01:20<10:22,  2.91iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  10%|▉         | 192/2000 [01:20<10:22,  2.91iteration/s, mean_rewards=-65.9]\u001b[A\n",
            "Training:  10%|▉         | 193/2000 [01:20<10:37,  2.83iteration/s, mean_rewards=-65.9]\u001b[A\n",
            "Training:  10%|▉         | 193/2000 [01:20<10:37,  2.83iteration/s, mean_rewards=-165] \u001b[A\n",
            "Training:  10%|▉         | 194/2000 [01:20<10:46,  2.79iteration/s, mean_rewards=-165]\u001b[A\n",
            "Training:  10%|▉         | 194/2000 [01:21<10:46,  2.79iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  10%|▉         | 195/2000 [01:21<10:07,  2.97iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  10%|▉         | 195/2000 [01:21<10:07,  2.97iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  10%|▉         | 196/2000 [01:21<12:03,  2.49iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  10%|▉         | 196/2000 [01:21<12:03,  2.49iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  10%|▉         | 197/2000 [01:22<12:21,  2.43iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  10%|▉         | 197/2000 [01:22<12:21,  2.43iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  10%|▉         | 198/2000 [01:22<12:04,  2.49iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  10%|▉         | 198/2000 [01:22<12:04,  2.49iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  10%|▉         | 199/2000 [01:23<12:57,  2.32iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  10%|▉         | 199/2000 [01:23<12:57,  2.32iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  10%|█         | 200/2000 [01:23<13:18,  2.25iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  10%|█         | 200/2000 [01:23<13:18,  2.25iteration/s, mean_rewards=-684]\u001b[A\n",
            "Training:  10%|█         | 201/2000 [01:24<15:11,  1.97iteration/s, mean_rewards=-684]\u001b[A\n",
            "Training:  10%|█         | 201/2000 [01:24<15:11,  1.97iteration/s, mean_rewards=-969]\u001b[A\n",
            "Training:  10%|█         | 202/2000 [01:24<17:01,  1.76iteration/s, mean_rewards=-969]\u001b[A\n",
            "Training:  10%|█         | 202/2000 [01:25<17:01,  1.76iteration/s, mean_rewards=-553]\u001b[A\n",
            "Training:  10%|█         | 203/2000 [01:25<17:16,  1.73iteration/s, mean_rewards=-553]\u001b[A\n",
            "Training:  10%|█         | 203/2000 [01:26<17:16,  1.73iteration/s, mean_rewards=-958]\u001b[A\n",
            "Training:  10%|█         | 204/2000 [01:26<19:10,  1.56iteration/s, mean_rewards=-958]\u001b[A\n",
            "Training:  10%|█         | 204/2000 [01:26<19:10,  1.56iteration/s, mean_rewards=-508]\u001b[A\n",
            "Training:  10%|█         | 205/2000 [01:26<17:19,  1.73iteration/s, mean_rewards=-508]\u001b[A\n",
            "Training:  10%|█         | 205/2000 [01:27<17:19,  1.73iteration/s, mean_rewards=-1.17e+3]\u001b[A\n",
            "Training:  10%|█         | 206/2000 [01:27<19:06,  1.57iteration/s, mean_rewards=-1.17e+3]\u001b[A\n",
            "Training:  10%|█         | 206/2000 [01:27<19:06,  1.57iteration/s, mean_rewards=-559]    \u001b[A\n",
            "Training:  10%|█         | 207/2000 [01:27<17:35,  1.70iteration/s, mean_rewards=-559]\u001b[A\n",
            "Training:  10%|█         | 207/2000 [01:28<17:35,  1.70iteration/s, mean_rewards=-1.08e+3]\u001b[A\n",
            "Training:  10%|█         | 208/2000 [01:28<20:03,  1.49iteration/s, mean_rewards=-1.08e+3]\u001b[A\n",
            "Training:  10%|█         | 208/2000 [01:29<20:03,  1.49iteration/s, mean_rewards=-1.34e+3]\u001b[A\n",
            "Training:  10%|█         | 209/2000 [01:29<22:52,  1.30iteration/s, mean_rewards=-1.34e+3]\u001b[A\n",
            "Training:  10%|█         | 209/2000 [01:30<22:52,  1.30iteration/s, mean_rewards=-1.54e+3]\u001b[A\n",
            "Training:  10%|█         | 210/2000 [01:30<25:24,  1.17iteration/s, mean_rewards=-1.54e+3]\u001b[A\n",
            "Training:  10%|█         | 210/2000 [01:31<25:24,  1.17iteration/s, mean_rewards=-818]    \u001b[A\n",
            "Training:  11%|█         | 211/2000 [01:31<22:41,  1.31iteration/s, mean_rewards=-818]\u001b[A\n",
            "Training:  11%|█         | 211/2000 [01:31<22:41,  1.31iteration/s, mean_rewards=-1.01e+3]\u001b[A\n",
            "Training:  11%|█         | 212/2000 [01:32<22:25,  1.33iteration/s, mean_rewards=-1.01e+3]\u001b[A\n",
            "Training:  11%|█         | 212/2000 [01:32<22:25,  1.33iteration/s, mean_rewards=-897]    \u001b[A\n",
            "Training:  11%|█         | 213/2000 [01:32<21:23,  1.39iteration/s, mean_rewards=-897]\u001b[A\n",
            "Training:  11%|█         | 213/2000 [01:33<21:23,  1.39iteration/s, mean_rewards=-548]\u001b[A\n",
            "Training:  11%|█         | 214/2000 [01:33<19:06,  1.56iteration/s, mean_rewards=-548]\u001b[A\n",
            "Training:  11%|█         | 214/2000 [01:33<19:06,  1.56iteration/s, mean_rewards=-979]\u001b[A\n",
            "Training:  11%|█         | 215/2000 [01:34<20:29,  1.45iteration/s, mean_rewards=-979]\u001b[A\n",
            "Training:  11%|█         | 215/2000 [01:34<20:29,  1.45iteration/s, mean_rewards=-653]\u001b[A\n",
            "Training:  11%|█         | 216/2000 [01:34<20:13,  1.47iteration/s, mean_rewards=-653]\u001b[A\n",
            "Training:  11%|█         | 216/2000 [01:35<20:13,  1.47iteration/s, mean_rewards=-562]\u001b[A\n",
            "Training:  11%|█         | 217/2000 [01:35<18:49,  1.58iteration/s, mean_rewards=-562]\u001b[A\n",
            "Training:  11%|█         | 217/2000 [01:35<18:49,  1.58iteration/s, mean_rewards=-597]\u001b[A\n",
            "Training:  11%|█         | 218/2000 [01:35<18:38,  1.59iteration/s, mean_rewards=-597]\u001b[A\n",
            "Training:  11%|█         | 218/2000 [01:36<18:38,  1.59iteration/s, mean_rewards=-621]\u001b[A\n",
            "Training:  11%|█         | 219/2000 [01:36<20:06,  1.48iteration/s, mean_rewards=-621]\u001b[A\n",
            "Training:  11%|█         | 219/2000 [01:37<20:06,  1.48iteration/s, mean_rewards=-655]\u001b[A\n",
            "Training:  11%|█         | 220/2000 [01:37<20:24,  1.45iteration/s, mean_rewards=-655]\u001b[A\n",
            "Training:  11%|█         | 220/2000 [01:37<20:24,  1.45iteration/s, mean_rewards=-1.1e+3]\u001b[A\n",
            "Training:  11%|█         | 221/2000 [01:38<22:12,  1.34iteration/s, mean_rewards=-1.1e+3]\u001b[A\n",
            "Training:  11%|█         | 221/2000 [01:38<22:12,  1.34iteration/s, mean_rewards=-468]   \u001b[A\n",
            "Training:  11%|█         | 222/2000 [01:38<21:05,  1.41iteration/s, mean_rewards=-468]\u001b[A\n",
            "Training:  11%|█         | 222/2000 [01:39<21:05,  1.41iteration/s, mean_rewards=-550]\u001b[A\n",
            "Training:  11%|█         | 223/2000 [01:39<18:45,  1.58iteration/s, mean_rewards=-550]\u001b[A\n",
            "Training:  11%|█         | 223/2000 [01:39<18:45,  1.58iteration/s, mean_rewards=-676]\u001b[A\n",
            "Training:  11%|█         | 224/2000 [01:39<18:08,  1.63iteration/s, mean_rewards=-676]\u001b[A\n",
            "Training:  11%|█         | 224/2000 [01:40<18:08,  1.63iteration/s, mean_rewards=-519]\u001b[A\n",
            "Training:  11%|█▏        | 225/2000 [01:40<16:25,  1.80iteration/s, mean_rewards=-519]\u001b[A\n",
            "Training:  11%|█▏        | 225/2000 [01:40<16:25,  1.80iteration/s, mean_rewards=-603]\u001b[A\n",
            "Training:  11%|█▏        | 226/2000 [01:40<15:37,  1.89iteration/s, mean_rewards=-603]\u001b[A\n",
            "Training:  11%|█▏        | 226/2000 [01:41<15:37,  1.89iteration/s, mean_rewards=-502]\u001b[A\n",
            "Training:  11%|█▏        | 227/2000 [01:41<15:18,  1.93iteration/s, mean_rewards=-502]\u001b[A\n",
            "Training:  11%|█▏        | 227/2000 [01:41<15:18,  1.93iteration/s, mean_rewards=-1.02e+3]\u001b[A\n",
            "Training:  11%|█▏        | 228/2000 [01:42<18:11,  1.62iteration/s, mean_rewards=-1.02e+3]\u001b[A\n",
            "Training:  11%|█▏        | 228/2000 [01:42<18:11,  1.62iteration/s, mean_rewards=-625]    \u001b[A\n",
            "Training:  11%|█▏        | 229/2000 [01:42<17:42,  1.67iteration/s, mean_rewards=-625]\u001b[A\n",
            "Training:  11%|█▏        | 229/2000 [01:42<17:42,  1.67iteration/s, mean_rewards=-623]\u001b[A\n",
            "Training:  12%|█▏        | 230/2000 [01:43<16:33,  1.78iteration/s, mean_rewards=-623]\u001b[A\n",
            "Training:  12%|█▏        | 230/2000 [01:43<16:33,  1.78iteration/s, mean_rewards=-552]\u001b[A\n",
            "Training:  12%|█▏        | 231/2000 [01:43<15:16,  1.93iteration/s, mean_rewards=-552]\u001b[A\n",
            "Training:  12%|█▏        | 231/2000 [01:43<15:16,  1.93iteration/s, mean_rewards=-903]\u001b[A\n",
            "Training:  12%|█▏        | 232/2000 [01:44<16:04,  1.83iteration/s, mean_rewards=-903]\u001b[A\n",
            "Training:  12%|█▏        | 232/2000 [01:44<16:04,  1.83iteration/s, mean_rewards=-454]\u001b[A\n",
            "Training:  12%|█▏        | 233/2000 [01:44<15:30,  1.90iteration/s, mean_rewards=-454]\u001b[A\n",
            "Training:  12%|█▏        | 233/2000 [01:45<15:30,  1.90iteration/s, mean_rewards=-800]\u001b[A\n",
            "Training:  12%|█▏        | 234/2000 [01:45<15:50,  1.86iteration/s, mean_rewards=-800]\u001b[A\n",
            "Training:  12%|█▏        | 234/2000 [01:45<15:50,  1.86iteration/s, mean_rewards=-794]\u001b[A\n",
            "Training:  12%|█▏        | 235/2000 [01:45<17:10,  1.71iteration/s, mean_rewards=-794]\u001b[A\n",
            "Training:  12%|█▏        | 235/2000 [01:46<17:10,  1.71iteration/s, mean_rewards=-746]\u001b[A\n",
            "Training:  12%|█▏        | 236/2000 [01:46<18:16,  1.61iteration/s, mean_rewards=-746]\u001b[A\n",
            "Training:  12%|█▏        | 236/2000 [01:47<18:16,  1.61iteration/s, mean_rewards=-1.25e+3]\u001b[A\n",
            "Training:  12%|█▏        | 237/2000 [01:47<22:25,  1.31iteration/s, mean_rewards=-1.25e+3]\u001b[A\n",
            "Training:  12%|█▏        | 237/2000 [01:48<22:25,  1.31iteration/s, mean_rewards=-966]    \u001b[A\n",
            "Training:  12%|█▏        | 238/2000 [01:48<23:37,  1.24iteration/s, mean_rewards=-966]\u001b[A\n",
            "Training:  12%|█▏        | 238/2000 [01:49<23:37,  1.24iteration/s, mean_rewards=-688]\u001b[A\n",
            "Training:  12%|█▏        | 239/2000 [01:49<23:31,  1.25iteration/s, mean_rewards=-688]\u001b[A\n",
            "Training:  12%|█▏        | 239/2000 [01:49<23:31,  1.25iteration/s, mean_rewards=-725]\u001b[A\n",
            "Training:  12%|█▏        | 240/2000 [01:50<23:22,  1.25iteration/s, mean_rewards=-725]\u001b[A\n",
            "Training:  12%|█▏        | 240/2000 [01:50<23:22,  1.25iteration/s, mean_rewards=-490]\u001b[A\n",
            "Training:  12%|█▏        | 241/2000 [01:50<20:30,  1.43iteration/s, mean_rewards=-490]\u001b[A\n",
            "Training:  12%|█▏        | 241/2000 [01:51<20:30,  1.43iteration/s, mean_rewards=-1.1e+3]\u001b[A\n",
            "Training:  12%|█▏        | 242/2000 [01:51<21:38,  1.35iteration/s, mean_rewards=-1.1e+3]\u001b[A\n",
            "Training:  12%|█▏        | 242/2000 [01:51<21:38,  1.35iteration/s, mean_rewards=-696]   \u001b[A\n",
            "Training:  12%|█▏        | 243/2000 [01:52<20:07,  1.46iteration/s, mean_rewards=-696]\u001b[A\n",
            "Training:  12%|█▏        | 243/2000 [01:52<20:07,  1.46iteration/s, mean_rewards=-587]\u001b[A\n",
            "Training:  12%|█▏        | 244/2000 [01:52<18:06,  1.62iteration/s, mean_rewards=-587]\u001b[A\n",
            "Training:  12%|█▏        | 244/2000 [01:52<18:06,  1.62iteration/s, mean_rewards=-590]\u001b[A\n",
            "Training:  12%|█▏        | 245/2000 [01:52<17:06,  1.71iteration/s, mean_rewards=-590]\u001b[A\n",
            "Training:  12%|█▏        | 245/2000 [01:53<17:06,  1.71iteration/s, mean_rewards=-693]\u001b[A\n",
            "Training:  12%|█▏        | 246/2000 [01:53<17:38,  1.66iteration/s, mean_rewards=-693]\u001b[A\n",
            "Training:  12%|█▏        | 246/2000 [01:53<17:38,  1.66iteration/s, mean_rewards=-473]\u001b[A\n",
            "Training:  12%|█▏        | 247/2000 [01:54<16:26,  1.78iteration/s, mean_rewards=-473]\u001b[A\n",
            "Training:  12%|█▏        | 247/2000 [01:54<16:26,  1.78iteration/s, mean_rewards=-525]\u001b[A\n",
            "Training:  12%|█▏        | 248/2000 [01:54<14:55,  1.96iteration/s, mean_rewards=-525]\u001b[A\n",
            "Training:  12%|█▏        | 248/2000 [01:54<14:55,  1.96iteration/s, mean_rewards=-657]\u001b[A\n",
            "Training:  12%|█▏        | 249/2000 [01:55<15:07,  1.93iteration/s, mean_rewards=-657]\u001b[A\n",
            "Training:  12%|█▏        | 249/2000 [01:55<15:07,  1.93iteration/s, mean_rewards=-680]\u001b[A\n",
            "Training:  12%|█▎        | 250/2000 [01:55<16:06,  1.81iteration/s, mean_rewards=-680]\u001b[A\n",
            "Training:  12%|█▎        | 250/2000 [01:56<16:06,  1.81iteration/s, mean_rewards=-482]\u001b[A\n",
            "Training:  13%|█▎        | 251/2000 [01:56<15:44,  1.85iteration/s, mean_rewards=-482]\u001b[A\n",
            "Training:  13%|█▎        | 251/2000 [01:56<15:44,  1.85iteration/s, mean_rewards=-1.05e+3]\u001b[A\n",
            "Training:  13%|█▎        | 252/2000 [01:56<18:01,  1.62iteration/s, mean_rewards=-1.05e+3]\u001b[A\n",
            "Training:  13%|█▎        | 252/2000 [01:57<18:01,  1.62iteration/s, mean_rewards=-853]    \u001b[A\n",
            "Training:  13%|█▎        | 253/2000 [01:57<18:20,  1.59iteration/s, mean_rewards=-853]\u001b[A\n",
            "Training:  13%|█▎        | 253/2000 [01:58<18:20,  1.59iteration/s, mean_rewards=-1.29e+3]\u001b[A\n",
            "Training:  13%|█▎        | 254/2000 [01:58<20:32,  1.42iteration/s, mean_rewards=-1.29e+3]\u001b[A\n",
            "Training:  13%|█▎        | 254/2000 [01:58<20:32,  1.42iteration/s, mean_rewards=-534]    \u001b[A\n",
            "Training:  13%|█▎        | 255/2000 [01:58<18:31,  1.57iteration/s, mean_rewards=-534]\u001b[A\n",
            "Training:  13%|█▎        | 255/2000 [01:59<18:31,  1.57iteration/s, mean_rewards=-1.26e+3]\u001b[A\n",
            "Training:  13%|█▎        | 256/2000 [01:59<20:57,  1.39iteration/s, mean_rewards=-1.26e+3]\u001b[A\n",
            "Training:  13%|█▎        | 256/2000 [02:00<20:57,  1.39iteration/s, mean_rewards=-939]    \u001b[A\n",
            "Training:  13%|█▎        | 257/2000 [02:00<22:54,  1.27iteration/s, mean_rewards=-939]\u001b[A\n",
            "Training:  13%|█▎        | 257/2000 [02:01<22:54,  1.27iteration/s, mean_rewards=-654]\u001b[A\n",
            "Training:  13%|█▎        | 258/2000 [02:01<21:38,  1.34iteration/s, mean_rewards=-654]\u001b[A\n",
            "Training:  13%|█▎        | 258/2000 [02:02<21:38,  1.34iteration/s, mean_rewards=-782]\u001b[A\n",
            "Training:  13%|█▎        | 259/2000 [02:02<23:01,  1.26iteration/s, mean_rewards=-782]\u001b[A\n",
            "Training:  13%|█▎        | 259/2000 [02:02<23:01,  1.26iteration/s, mean_rewards=-494]\u001b[A\n",
            "Training:  13%|█▎        | 260/2000 [02:03<21:57,  1.32iteration/s, mean_rewards=-494]\u001b[A\n",
            "Training:  13%|█▎        | 260/2000 [02:03<21:57,  1.32iteration/s, mean_rewards=-668]\u001b[A\n",
            "Training:  13%|█▎        | 261/2000 [02:03<20:06,  1.44iteration/s, mean_rewards=-668]\u001b[A\n",
            "Training:  13%|█▎        | 261/2000 [02:04<20:06,  1.44iteration/s, mean_rewards=-690]\u001b[A\n",
            "Training:  13%|█▎        | 262/2000 [02:04<19:31,  1.48iteration/s, mean_rewards=-690]\u001b[A\n",
            "Training:  13%|█▎        | 262/2000 [02:04<19:31,  1.48iteration/s, mean_rewards=-536]\u001b[A\n",
            "Training:  13%|█▎        | 263/2000 [02:04<17:40,  1.64iteration/s, mean_rewards=-536]\u001b[A\n",
            "Training:  13%|█▎        | 263/2000 [02:05<17:40,  1.64iteration/s, mean_rewards=-913]\u001b[A\n",
            "Training:  13%|█▎        | 264/2000 [02:05<17:43,  1.63iteration/s, mean_rewards=-913]\u001b[A\n",
            "Training:  13%|█▎        | 264/2000 [02:05<17:43,  1.63iteration/s, mean_rewards=-540]\u001b[A\n",
            "Training:  13%|█▎        | 265/2000 [02:05<16:41,  1.73iteration/s, mean_rewards=-540]\u001b[A\n",
            "Training:  13%|█▎        | 265/2000 [02:06<16:41,  1.73iteration/s, mean_rewards=-542]\u001b[A\n",
            "Training:  13%|█▎        | 266/2000 [02:06<16:02,  1.80iteration/s, mean_rewards=-542]\u001b[A\n",
            "Training:  13%|█▎        | 266/2000 [02:06<16:02,  1.80iteration/s, mean_rewards=-467]\u001b[A\n",
            "Training:  13%|█▎        | 267/2000 [02:06<15:19,  1.88iteration/s, mean_rewards=-467]\u001b[A\n",
            "Training:  13%|█▎        | 267/2000 [02:07<15:19,  1.88iteration/s, mean_rewards=-542]\u001b[A\n",
            "Training:  13%|█▎        | 268/2000 [02:07<15:13,  1.90iteration/s, mean_rewards=-542]\u001b[A\n",
            "Training:  13%|█▎        | 268/2000 [02:07<15:13,  1.90iteration/s, mean_rewards=-503]\u001b[A\n",
            "Training:  13%|█▎        | 269/2000 [02:07<14:36,  1.97iteration/s, mean_rewards=-503]\u001b[A\n",
            "Training:  13%|█▎        | 269/2000 [02:08<14:36,  1.97iteration/s, mean_rewards=-757]\u001b[A\n",
            "Training:  14%|█▎        | 270/2000 [02:08<15:36,  1.85iteration/s, mean_rewards=-757]\u001b[A\n",
            "Training:  14%|█▎        | 270/2000 [02:08<15:36,  1.85iteration/s, mean_rewards=-740]\u001b[A\n",
            "Training:  14%|█▎        | 271/2000 [02:08<15:59,  1.80iteration/s, mean_rewards=-740]\u001b[A\n",
            "Training:  14%|█▎        | 271/2000 [02:09<15:59,  1.80iteration/s, mean_rewards=-641]\u001b[A\n",
            "Training:  14%|█▎        | 272/2000 [02:09<16:05,  1.79iteration/s, mean_rewards=-641]\u001b[A\n",
            "Training:  14%|█▎        | 272/2000 [02:09<16:05,  1.79iteration/s, mean_rewards=-550]\u001b[A\n",
            "Training:  14%|█▎        | 273/2000 [02:09<14:56,  1.93iteration/s, mean_rewards=-550]\u001b[A\n",
            "Training:  14%|█▎        | 273/2000 [02:10<14:56,  1.93iteration/s, mean_rewards=-2.12e+3]\u001b[A\n",
            "Training:  14%|█▎        | 274/2000 [02:11<21:41,  1.33iteration/s, mean_rewards=-2.12e+3]\u001b[A\n",
            "Training:  14%|█▎        | 274/2000 [02:11<21:41,  1.33iteration/s, mean_rewards=-833]    \u001b[A\n",
            "Training:  14%|█▍        | 275/2000 [02:11<21:03,  1.37iteration/s, mean_rewards=-833]\u001b[A\n",
            "Training:  14%|█▍        | 275/2000 [02:12<21:03,  1.37iteration/s, mean_rewards=-458]\u001b[A\n",
            "Training:  14%|█▍        | 276/2000 [02:12<18:32,  1.55iteration/s, mean_rewards=-458]\u001b[A\n",
            "Training:  14%|█▍        | 276/2000 [02:12<18:32,  1.55iteration/s, mean_rewards=-1.02e+3]\u001b[A\n",
            "Training:  14%|█▍        | 277/2000 [02:13<20:07,  1.43iteration/s, mean_rewards=-1.02e+3]\u001b[A\n",
            "Training:  14%|█▍        | 277/2000 [02:13<20:07,  1.43iteration/s, mean_rewards=-935]    \u001b[A\n",
            "Training:  14%|█▍        | 278/2000 [02:14<21:16,  1.35iteration/s, mean_rewards=-935]\u001b[A\n",
            "Training:  14%|█▍        | 278/2000 [02:14<21:16,  1.35iteration/s, mean_rewards=-717]\u001b[A\n",
            "Training:  14%|█▍        | 279/2000 [02:14<22:41,  1.26iteration/s, mean_rewards=-717]\u001b[A\n",
            "Training:  14%|█▍        | 279/2000 [02:15<22:41,  1.26iteration/s, mean_rewards=-677]\u001b[A\n",
            "Training:  14%|█▍        | 280/2000 [02:15<22:06,  1.30iteration/s, mean_rewards=-677]\u001b[A\n",
            "Training:  14%|█▍        | 280/2000 [02:16<22:06,  1.30iteration/s, mean_rewards=-724]\u001b[A\n",
            "Training:  14%|█▍        | 281/2000 [02:16<20:18,  1.41iteration/s, mean_rewards=-724]\u001b[A\n",
            "Training:  14%|█▍        | 281/2000 [02:16<20:18,  1.41iteration/s, mean_rewards=-1.17e+3]\u001b[A\n",
            "Training:  14%|█▍        | 282/2000 [02:17<21:07,  1.36iteration/s, mean_rewards=-1.17e+3]\u001b[A\n",
            "Training:  14%|█▍        | 282/2000 [02:17<21:07,  1.36iteration/s, mean_rewards=-560]    \u001b[A\n",
            "Training:  14%|█▍        | 283/2000 [02:17<18:40,  1.53iteration/s, mean_rewards=-560]\u001b[A\n",
            "Training:  14%|█▍        | 283/2000 [02:18<18:40,  1.53iteration/s, mean_rewards=-716]\u001b[A\n",
            "Training:  14%|█▍        | 284/2000 [02:18<18:50,  1.52iteration/s, mean_rewards=-716]\u001b[A\n",
            "Training:  14%|█▍        | 284/2000 [02:18<18:50,  1.52iteration/s, mean_rewards=-567]\u001b[A\n",
            "Training:  14%|█▍        | 285/2000 [02:18<17:45,  1.61iteration/s, mean_rewards=-567]\u001b[A\n",
            "Training:  14%|█▍        | 285/2000 [02:19<17:45,  1.61iteration/s, mean_rewards=-728]\u001b[A\n",
            "Training:  14%|█▍        | 286/2000 [02:19<17:04,  1.67iteration/s, mean_rewards=-728]\u001b[A\n",
            "Training:  14%|█▍        | 286/2000 [02:19<17:04,  1.67iteration/s, mean_rewards=-781]\u001b[A\n",
            "Training:  14%|█▍        | 287/2000 [02:19<16:19,  1.75iteration/s, mean_rewards=-781]\u001b[A\n",
            "Training:  14%|█▍        | 287/2000 [02:20<16:19,  1.75iteration/s, mean_rewards=-712]\u001b[A\n",
            "Training:  14%|█▍        | 288/2000 [02:20<16:54,  1.69iteration/s, mean_rewards=-712]\u001b[A\n",
            "Training:  14%|█▍        | 288/2000 [02:20<16:54,  1.69iteration/s, mean_rewards=-631]\u001b[A\n",
            "Training:  14%|█▍        | 289/2000 [02:20<15:35,  1.83iteration/s, mean_rewards=-631]\u001b[A\n",
            "Training:  14%|█▍        | 289/2000 [02:21<15:35,  1.83iteration/s, mean_rewards=-630]\u001b[A\n",
            "Training:  14%|█▍        | 290/2000 [02:21<15:30,  1.84iteration/s, mean_rewards=-630]\u001b[A\n",
            "Training:  14%|█▍        | 290/2000 [02:22<15:30,  1.84iteration/s, mean_rewards=-2.09e+3]\u001b[A\n",
            "Training:  15%|█▍        | 291/2000 [02:22<21:44,  1.31iteration/s, mean_rewards=-2.09e+3]\u001b[A\n",
            "Training:  15%|█▍        | 291/2000 [02:22<21:44,  1.31iteration/s, mean_rewards=-545]    \u001b[A\n",
            "Training:  15%|█▍        | 292/2000 [02:23<19:01,  1.50iteration/s, mean_rewards=-545]\u001b[A\n",
            "Training:  15%|█▍        | 292/2000 [02:23<19:01,  1.50iteration/s, mean_rewards=-518]\u001b[A\n",
            "Training:  15%|█▍        | 293/2000 [02:23<17:26,  1.63iteration/s, mean_rewards=-518]\u001b[A\n",
            "Training:  15%|█▍        | 293/2000 [02:23<17:26,  1.63iteration/s, mean_rewards=-587]\u001b[A\n",
            "Training:  15%|█▍        | 294/2000 [02:24<15:40,  1.81iteration/s, mean_rewards=-587]\u001b[A\n",
            "Training:  15%|█▍        | 294/2000 [02:24<15:40,  1.81iteration/s, mean_rewards=-656]\u001b[A\n",
            "Training:  15%|█▍        | 295/2000 [02:24<15:49,  1.80iteration/s, mean_rewards=-656]\u001b[A\n",
            "Training:  15%|█▍        | 295/2000 [02:24<15:49,  1.80iteration/s, mean_rewards=-622]\u001b[A\n",
            "Training:  15%|█▍        | 296/2000 [02:25<14:45,  1.92iteration/s, mean_rewards=-622]\u001b[A\n",
            "Training:  15%|█▍        | 296/2000 [02:25<14:45,  1.92iteration/s, mean_rewards=-1.5e+3]\u001b[A\n",
            "Training:  15%|█▍        | 297/2000 [02:26<21:29,  1.32iteration/s, mean_rewards=-1.5e+3]\u001b[A\n",
            "Training:  15%|█▍        | 297/2000 [02:26<21:29,  1.32iteration/s, mean_rewards=-750]   \u001b[A\n",
            "Training:  15%|█▍        | 298/2000 [02:27<22:23,  1.27iteration/s, mean_rewards=-750]\u001b[A\n",
            "Training:  15%|█▍        | 298/2000 [02:27<22:23,  1.27iteration/s, mean_rewards=-968]\u001b[A\n",
            "Training:  15%|█▍        | 299/2000 [02:28<23:51,  1.19iteration/s, mean_rewards=-968]\u001b[A\n",
            "Training:  15%|█▍        | 299/2000 [02:28<23:51,  1.19iteration/s, mean_rewards=-675]\u001b[A\n",
            "Training:  15%|█▌        | 300/2000 [02:28<20:51,  1.36iteration/s, mean_rewards=-675]\u001b[A\n",
            "Training:  15%|█▌        | 300/2000 [02:28<20:51,  1.36iteration/s, mean_rewards=-572]\u001b[A\n",
            "Training:  15%|█▌        | 301/2000 [02:29<18:30,  1.53iteration/s, mean_rewards=-572]\u001b[A\n",
            "Training:  15%|█▌        | 301/2000 [02:29<18:30,  1.53iteration/s, mean_rewards=-826]\u001b[A\n",
            "Training:  15%|█▌        | 302/2000 [02:29<17:51,  1.58iteration/s, mean_rewards=-826]\u001b[A\n",
            "Training:  15%|█▌        | 302/2000 [02:30<17:51,  1.58iteration/s, mean_rewards=-554]\u001b[A\n",
            "Training:  15%|█▌        | 303/2000 [02:30<16:19,  1.73iteration/s, mean_rewards=-554]\u001b[A\n",
            "Training:  15%|█▌        | 303/2000 [02:30<16:19,  1.73iteration/s, mean_rewards=-1.09e+3]\u001b[A\n",
            "Training:  15%|█▌        | 304/2000 [02:31<19:05,  1.48iteration/s, mean_rewards=-1.09e+3]\u001b[A\n",
            "Training:  15%|█▌        | 304/2000 [02:31<19:05,  1.48iteration/s, mean_rewards=-837]    \u001b[A\n",
            "Training:  15%|█▌        | 305/2000 [02:31<18:45,  1.51iteration/s, mean_rewards=-837]\u001b[A\n",
            "Training:  15%|█▌        | 305/2000 [02:32<18:45,  1.51iteration/s, mean_rewards=-584]\u001b[A\n",
            "Training:  15%|█▌        | 306/2000 [02:32<17:53,  1.58iteration/s, mean_rewards=-584]\u001b[A\n",
            "Training:  15%|█▌        | 306/2000 [02:32<17:53,  1.58iteration/s, mean_rewards=-538]\u001b[A\n",
            "Training:  15%|█▌        | 307/2000 [02:32<17:05,  1.65iteration/s, mean_rewards=-538]\u001b[A\n",
            "Training:  15%|█▌        | 307/2000 [02:33<17:05,  1.65iteration/s, mean_rewards=-2e+3]\u001b[A\n",
            "Training:  15%|█▌        | 308/2000 [02:34<22:16,  1.27iteration/s, mean_rewards=-2e+3]\u001b[A\n",
            "Training:  15%|█▌        | 308/2000 [02:34<22:16,  1.27iteration/s, mean_rewards=-619] \u001b[A\n",
            "Training:  15%|█▌        | 309/2000 [02:34<19:50,  1.42iteration/s, mean_rewards=-619]\u001b[A\n",
            "Training:  15%|█▌        | 309/2000 [02:34<19:50,  1.42iteration/s, mean_rewards=-568]\u001b[A\n",
            "Training:  16%|█▌        | 310/2000 [02:34<17:58,  1.57iteration/s, mean_rewards=-568]\u001b[A\n",
            "Training:  16%|█▌        | 310/2000 [02:35<17:58,  1.57iteration/s, mean_rewards=-1.64e+3]\u001b[A\n",
            "Training:  16%|█▌        | 311/2000 [02:36<23:04,  1.22iteration/s, mean_rewards=-1.64e+3]\u001b[A\n",
            "Training:  16%|█▌        | 311/2000 [02:37<23:04,  1.22iteration/s, mean_rewards=-2.57e+3]\u001b[A\n",
            "Training:  16%|█▌        | 312/2000 [02:37<29:17,  1.04s/iteration, mean_rewards=-2.57e+3]\u001b[A\n",
            "Training:  16%|█▌        | 312/2000 [02:38<29:17,  1.04s/iteration, mean_rewards=-573]    \u001b[A\n",
            "Training:  16%|█▌        | 313/2000 [02:38<26:04,  1.08iteration/s, mean_rewards=-573]\u001b[A\n",
            "Training:  16%|█▌        | 313/2000 [02:38<26:04,  1.08iteration/s, mean_rewards=-634]\u001b[A\n",
            "Training:  16%|█▌        | 314/2000 [02:39<23:46,  1.18iteration/s, mean_rewards=-634]\u001b[A\n",
            "Training:  16%|█▌        | 314/2000 [02:39<23:46,  1.18iteration/s, mean_rewards=-633]\u001b[A\n",
            "Training:  16%|█▌        | 315/2000 [02:39<22:27,  1.25iteration/s, mean_rewards=-633]\u001b[A\n",
            "Training:  16%|█▌        | 315/2000 [02:40<22:27,  1.25iteration/s, mean_rewards=-858]\u001b[A\n",
            "Training:  16%|█▌        | 316/2000 [02:40<24:25,  1.15iteration/s, mean_rewards=-858]\u001b[A\n",
            "Training:  16%|█▌        | 316/2000 [02:41<24:25,  1.15iteration/s, mean_rewards=-563]\u001b[A\n",
            "Training:  16%|█▌        | 317/2000 [02:41<20:56,  1.34iteration/s, mean_rewards=-563]\u001b[A\n",
            "Training:  16%|█▌        | 317/2000 [02:42<20:56,  1.34iteration/s, mean_rewards=-1.87e+3]\u001b[A\n",
            "Training:  16%|█▌        | 318/2000 [02:42<23:37,  1.19iteration/s, mean_rewards=-1.87e+3]\u001b[A\n",
            "Training:  16%|█▌        | 318/2000 [02:42<23:37,  1.19iteration/s, mean_rewards=-668]    \u001b[A\n",
            "Training:  16%|█▌        | 319/2000 [02:42<20:53,  1.34iteration/s, mean_rewards=-668]\u001b[A\n",
            "Training:  16%|█▌        | 319/2000 [02:43<20:53,  1.34iteration/s, mean_rewards=-1.01e+3]\u001b[A\n",
            "Training:  16%|█▌        | 320/2000 [02:43<21:13,  1.32iteration/s, mean_rewards=-1.01e+3]\u001b[A\n",
            "Training:  16%|█▌        | 320/2000 [02:44<21:13,  1.32iteration/s, mean_rewards=-1.1e+3] \u001b[A\n",
            "Training:  16%|█▌        | 321/2000 [02:44<20:50,  1.34iteration/s, mean_rewards=-1.1e+3]\u001b[A\n",
            "Training:  16%|█▌        | 321/2000 [02:44<20:50,  1.34iteration/s, mean_rewards=-471]   \u001b[A\n",
            "Training:  16%|█▌        | 322/2000 [02:44<18:48,  1.49iteration/s, mean_rewards=-471]\u001b[A\n",
            "Training:  16%|█▌        | 322/2000 [02:45<18:48,  1.49iteration/s, mean_rewards=-760]\u001b[A\n",
            "Training:  16%|█▌        | 323/2000 [02:45<18:29,  1.51iteration/s, mean_rewards=-760]\u001b[A\n",
            "Training:  16%|█▌        | 323/2000 [02:46<18:29,  1.51iteration/s, mean_rewards=-852]\u001b[A\n",
            "Training:  16%|█▌        | 324/2000 [02:46<18:45,  1.49iteration/s, mean_rewards=-852]\u001b[A\n",
            "Training:  16%|█▌        | 324/2000 [02:46<18:45,  1.49iteration/s, mean_rewards=-1.63e+3]\u001b[A\n",
            "Training:  16%|█▋        | 325/2000 [02:47<20:57,  1.33iteration/s, mean_rewards=-1.63e+3]\u001b[A\n",
            "Training:  16%|█▋        | 325/2000 [02:47<20:57,  1.33iteration/s, mean_rewards=-603]    \u001b[A\n",
            "Training:  16%|█▋        | 326/2000 [02:47<18:41,  1.49iteration/s, mean_rewards=-603]\u001b[A\n",
            "Training:  16%|█▋        | 326/2000 [02:48<18:41,  1.49iteration/s, mean_rewards=-661]\u001b[A\n",
            "Training:  16%|█▋        | 327/2000 [02:48<17:51,  1.56iteration/s, mean_rewards=-661]\u001b[A\n",
            "Training:  16%|█▋        | 327/2000 [02:48<17:51,  1.56iteration/s, mean_rewards=-719]\u001b[A\n",
            "Training:  16%|█▋        | 328/2000 [02:48<17:32,  1.59iteration/s, mean_rewards=-719]\u001b[A\n",
            "Training:  16%|█▋        | 328/2000 [02:49<17:32,  1.59iteration/s, mean_rewards=-1.1e+3]\u001b[A\n",
            "Training:  16%|█▋        | 329/2000 [02:49<18:59,  1.47iteration/s, mean_rewards=-1.1e+3]\u001b[A\n",
            "Training:  16%|█▋        | 329/2000 [02:49<18:59,  1.47iteration/s, mean_rewards=-537]   \u001b[A\n",
            "Training:  16%|█▋        | 330/2000 [02:50<17:25,  1.60iteration/s, mean_rewards=-537]\u001b[A\n",
            "Training:  16%|█▋        | 330/2000 [02:50<17:25,  1.60iteration/s, mean_rewards=-712]\u001b[A\n",
            "Training:  17%|█▋        | 331/2000 [02:50<17:30,  1.59iteration/s, mean_rewards=-712]\u001b[A\n",
            "Training:  17%|█▋        | 331/2000 [02:51<17:30,  1.59iteration/s, mean_rewards=-870]\u001b[A\n",
            "Training:  17%|█▋        | 332/2000 [02:51<20:11,  1.38iteration/s, mean_rewards=-870]\u001b[A\n",
            "Training:  17%|█▋        | 332/2000 [02:52<20:11,  1.38iteration/s, mean_rewards=-627]\u001b[A\n",
            "Training:  17%|█▋        | 333/2000 [02:52<19:47,  1.40iteration/s, mean_rewards=-627]\u001b[A\n",
            "Training:  17%|█▋        | 333/2000 [02:52<19:47,  1.40iteration/s, mean_rewards=-665]\u001b[A\n",
            "Training:  17%|█▋        | 334/2000 [02:53<19:27,  1.43iteration/s, mean_rewards=-665]\u001b[A\n",
            "Training:  17%|█▋        | 334/2000 [02:53<19:27,  1.43iteration/s, mean_rewards=-1.55e+3]\u001b[A\n",
            "Training:  17%|█▋        | 335/2000 [02:54<22:18,  1.24iteration/s, mean_rewards=-1.55e+3]\u001b[A\n",
            "Training:  17%|█▋        | 335/2000 [02:54<22:18,  1.24iteration/s, mean_rewards=-1.04e+3]\u001b[A\n",
            "Training:  17%|█▋        | 336/2000 [02:55<23:12,  1.19iteration/s, mean_rewards=-1.04e+3]\u001b[A\n",
            "Training:  17%|█▋        | 336/2000 [02:55<23:12,  1.19iteration/s, mean_rewards=-591]    \u001b[A\n",
            "Training:  17%|█▋        | 337/2000 [02:55<21:01,  1.32iteration/s, mean_rewards=-591]\u001b[A\n",
            "Training:  17%|█▋        | 337/2000 [02:56<21:01,  1.32iteration/s, mean_rewards=-822]\u001b[A\n",
            "Training:  17%|█▋        | 338/2000 [02:56<20:23,  1.36iteration/s, mean_rewards=-822]\u001b[A\n",
            "Training:  17%|█▋        | 338/2000 [02:56<20:23,  1.36iteration/s, mean_rewards=-911]\u001b[A\n",
            "Training:  17%|█▋        | 339/2000 [02:56<20:12,  1.37iteration/s, mean_rewards=-911]\u001b[A\n",
            "Training:  17%|█▋        | 339/2000 [02:57<20:12,  1.37iteration/s, mean_rewards=-797]\u001b[A\n",
            "Training:  17%|█▋        | 340/2000 [02:57<19:08,  1.44iteration/s, mean_rewards=-797]\u001b[A\n",
            "Training:  17%|█▋        | 340/2000 [02:57<19:08,  1.44iteration/s, mean_rewards=-732]\u001b[A\n",
            "Training:  17%|█▋        | 341/2000 [02:58<17:49,  1.55iteration/s, mean_rewards=-732]\u001b[A\n",
            "Training:  17%|█▋        | 341/2000 [02:58<17:49,  1.55iteration/s, mean_rewards=-1.09e+3]\u001b[A\n",
            "Training:  17%|█▋        | 342/2000 [02:58<19:22,  1.43iteration/s, mean_rewards=-1.09e+3]\u001b[A\n",
            "Training:  17%|█▋        | 342/2000 [02:59<19:22,  1.43iteration/s, mean_rewards=-703]    \u001b[A\n",
            "Training:  17%|█▋        | 343/2000 [02:59<18:03,  1.53iteration/s, mean_rewards=-703]\u001b[A\n",
            "Training:  17%|█▋        | 343/2000 [02:59<18:03,  1.53iteration/s, mean_rewards=-536]\u001b[A\n",
            "Training:  17%|█▋        | 344/2000 [02:59<16:22,  1.69iteration/s, mean_rewards=-536]\u001b[A\n",
            "Training:  17%|█▋        | 344/2000 [03:00<16:22,  1.69iteration/s, mean_rewards=-645]\u001b[A\n",
            "Training:  17%|█▋        | 345/2000 [03:00<16:05,  1.71iteration/s, mean_rewards=-645]\u001b[A\n",
            "Training:  17%|█▋        | 345/2000 [03:01<16:05,  1.71iteration/s, mean_rewards=-1.03e+3]\u001b[A\n",
            "Training:  17%|█▋        | 346/2000 [03:01<17:08,  1.61iteration/s, mean_rewards=-1.03e+3]\u001b[A\n",
            "Training:  17%|█▋        | 346/2000 [03:01<17:08,  1.61iteration/s, mean_rewards=-808]    \u001b[A\n",
            "Training:  17%|█▋        | 347/2000 [03:01<16:40,  1.65iteration/s, mean_rewards=-808]\u001b[A\n",
            "Training:  17%|█▋        | 347/2000 [03:02<16:40,  1.65iteration/s, mean_rewards=-797]\u001b[A\n",
            "Training:  17%|█▋        | 348/2000 [03:02<17:02,  1.62iteration/s, mean_rewards=-797]\u001b[A\n",
            "Training:  17%|█▋        | 348/2000 [03:02<17:02,  1.62iteration/s, mean_rewards=-632]\u001b[A\n",
            "Training:  17%|█▋        | 349/2000 [03:02<16:11,  1.70iteration/s, mean_rewards=-632]\u001b[A\n",
            "Training:  17%|█▋        | 349/2000 [03:03<16:11,  1.70iteration/s, mean_rewards=-726]\u001b[A\n",
            "Training:  18%|█▊        | 350/2000 [03:03<17:37,  1.56iteration/s, mean_rewards=-726]\u001b[A\n",
            "Training:  18%|█▊        | 350/2000 [03:04<17:37,  1.56iteration/s, mean_rewards=-1.3e+3]\u001b[A\n",
            "Training:  18%|█▊        | 351/2000 [03:04<22:14,  1.24iteration/s, mean_rewards=-1.3e+3]\u001b[A\n",
            "Training:  18%|█▊        | 351/2000 [03:06<22:14,  1.24iteration/s, mean_rewards=-2.54e+3]\u001b[A\n",
            "Training:  18%|█▊        | 352/2000 [03:06<30:50,  1.12s/iteration, mean_rewards=-2.54e+3]\u001b[A\n",
            "Training:  18%|█▊        | 352/2000 [03:07<30:50,  1.12s/iteration, mean_rewards=-734]    \u001b[A\n",
            "Training:  18%|█▊        | 353/2000 [03:07<26:31,  1.03iteration/s, mean_rewards=-734]\u001b[A\n",
            "Training:  18%|█▊        | 353/2000 [03:07<26:31,  1.03iteration/s, mean_rewards=-673]\u001b[A\n",
            "Training:  18%|█▊        | 354/2000 [03:08<23:45,  1.16iteration/s, mean_rewards=-673]\u001b[A\n",
            "Training:  18%|█▊        | 354/2000 [03:08<23:45,  1.16iteration/s, mean_rewards=-1.31e+3]\u001b[A\n",
            "Training:  18%|█▊        | 355/2000 [03:08<23:59,  1.14iteration/s, mean_rewards=-1.31e+3]\u001b[A\n",
            "Training:  18%|█▊        | 355/2000 [03:09<23:59,  1.14iteration/s, mean_rewards=-1.7e+3] \u001b[A\n",
            "Training:  18%|█▊        | 356/2000 [03:10<27:02,  1.01iteration/s, mean_rewards=-1.7e+3]\u001b[A\n",
            "Training:  18%|█▊        | 356/2000 [03:10<27:02,  1.01iteration/s, mean_rewards=-1.01e+3]\u001b[A\n",
            "Training:  18%|█▊        | 357/2000 [03:10<25:33,  1.07iteration/s, mean_rewards=-1.01e+3]\u001b[A\n",
            "Training:  18%|█▊        | 357/2000 [03:11<25:33,  1.07iteration/s, mean_rewards=-498]    \u001b[A\n",
            "Training:  18%|█▊        | 358/2000 [03:11<21:41,  1.26iteration/s, mean_rewards=-498]\u001b[A\n",
            "Training:  18%|█▊        | 358/2000 [03:12<21:41,  1.26iteration/s, mean_rewards=-1.24e+3]\u001b[A\n",
            "Training:  18%|█▊        | 359/2000 [03:12<23:15,  1.18iteration/s, mean_rewards=-1.24e+3]\u001b[A\n",
            "Training:  18%|█▊        | 359/2000 [03:12<23:15,  1.18iteration/s, mean_rewards=-668]    \u001b[A\n",
            "Training:  18%|█▊        | 360/2000 [03:12<20:43,  1.32iteration/s, mean_rewards=-668]\u001b[A\n",
            "Training:  18%|█▊        | 360/2000 [03:13<20:43,  1.32iteration/s, mean_rewards=-585]\u001b[A\n",
            "Training:  18%|█▊        | 361/2000 [03:13<18:59,  1.44iteration/s, mean_rewards=-585]\u001b[A\n",
            "Training:  18%|█▊        | 361/2000 [03:13<18:59,  1.44iteration/s, mean_rewards=-719]\u001b[A\n",
            "Training:  18%|█▊        | 362/2000 [03:14<17:54,  1.52iteration/s, mean_rewards=-719]\u001b[A\n",
            "Training:  18%|█▊        | 362/2000 [03:14<17:54,  1.52iteration/s, mean_rewards=-627]\u001b[A\n",
            "Training:  18%|█▊        | 363/2000 [03:14<16:57,  1.61iteration/s, mean_rewards=-627]\u001b[A\n",
            "Training:  18%|█▊        | 363/2000 [03:14<16:57,  1.61iteration/s, mean_rewards=-514]\u001b[A\n",
            "Training:  18%|█▊        | 364/2000 [03:15<15:45,  1.73iteration/s, mean_rewards=-514]\u001b[A\n",
            "Training:  18%|█▊        | 364/2000 [03:15<15:45,  1.73iteration/s, mean_rewards=-991]\u001b[A\n",
            "Training:  18%|█▊        | 365/2000 [03:16<19:47,  1.38iteration/s, mean_rewards=-991]\u001b[A\n",
            "Training:  18%|█▊        | 365/2000 [03:16<19:47,  1.38iteration/s, mean_rewards=-618]\u001b[A\n",
            "Training:  18%|█▊        | 366/2000 [03:16<18:38,  1.46iteration/s, mean_rewards=-618]\u001b[A\n",
            "Training:  18%|█▊        | 366/2000 [03:17<18:38,  1.46iteration/s, mean_rewards=-595]\u001b[A\n",
            "Training:  18%|█▊        | 367/2000 [03:17<17:50,  1.53iteration/s, mean_rewards=-595]\u001b[A\n",
            "Training:  18%|█▊        | 367/2000 [03:17<17:50,  1.53iteration/s, mean_rewards=-583]\u001b[A\n",
            "Training:  18%|█▊        | 368/2000 [03:18<18:30,  1.47iteration/s, mean_rewards=-583]\u001b[A\n",
            "Training:  18%|█▊        | 368/2000 [03:18<18:30,  1.47iteration/s, mean_rewards=-605]\u001b[A\n",
            "Training:  18%|█▊        | 369/2000 [03:18<17:53,  1.52iteration/s, mean_rewards=-605]\u001b[A\n",
            "Training:  18%|█▊        | 369/2000 [03:19<17:53,  1.52iteration/s, mean_rewards=-677]\u001b[A\n",
            "Training:  18%|█▊        | 370/2000 [03:19<17:04,  1.59iteration/s, mean_rewards=-677]\u001b[A\n",
            "Training:  18%|█▊        | 370/2000 [03:20<17:04,  1.59iteration/s, mean_rewards=-2.54e+3]\u001b[A\n",
            "Training:  19%|█▊        | 371/2000 [03:20<23:44,  1.14iteration/s, mean_rewards=-2.54e+3]\u001b[A\n",
            "Training:  19%|█▊        | 371/2000 [03:21<23:44,  1.14iteration/s, mean_rewards=-590]    \u001b[A\n",
            "Training:  19%|█▊        | 372/2000 [03:21<21:44,  1.25iteration/s, mean_rewards=-590]\u001b[A\n",
            "Training:  19%|█▊        | 372/2000 [03:21<21:44,  1.25iteration/s, mean_rewards=-425]\u001b[A\n",
            "Training:  19%|█▊        | 373/2000 [03:21<18:48,  1.44iteration/s, mean_rewards=-425]\u001b[A\n",
            "Training:  19%|█▊        | 373/2000 [03:22<18:48,  1.44iteration/s, mean_rewards=-773]\u001b[A\n",
            "Training:  19%|█▊        | 374/2000 [03:22<17:46,  1.52iteration/s, mean_rewards=-773]\u001b[A\n",
            "Training:  19%|█▊        | 374/2000 [03:22<17:46,  1.52iteration/s, mean_rewards=-835]\u001b[A\n",
            "Training:  19%|█▉        | 375/2000 [03:23<18:46,  1.44iteration/s, mean_rewards=-835]\u001b[A\n",
            "Training:  19%|█▉        | 375/2000 [03:23<18:46,  1.44iteration/s, mean_rewards=-510]\u001b[A\n",
            "Training:  19%|█▉        | 376/2000 [03:23<16:42,  1.62iteration/s, mean_rewards=-510]\u001b[A\n",
            "Training:  19%|█▉        | 376/2000 [03:23<16:42,  1.62iteration/s, mean_rewards=-740]\u001b[A\n",
            "Training:  19%|█▉        | 377/2000 [03:24<15:55,  1.70iteration/s, mean_rewards=-740]\u001b[A\n",
            "Training:  19%|█▉        | 377/2000 [03:24<15:55,  1.70iteration/s, mean_rewards=-887]\u001b[A\n",
            "Training:  19%|█▉        | 378/2000 [03:24<16:34,  1.63iteration/s, mean_rewards=-887]\u001b[A\n",
            "Training:  19%|█▉        | 378/2000 [03:25<16:34,  1.63iteration/s, mean_rewards=-724]\u001b[A\n",
            "Training:  19%|█▉        | 379/2000 [03:25<15:31,  1.74iteration/s, mean_rewards=-724]\u001b[A\n",
            "Training:  19%|█▉        | 379/2000 [03:25<15:31,  1.74iteration/s, mean_rewards=-924]\u001b[A\n",
            "Training:  19%|█▉        | 380/2000 [03:26<17:14,  1.57iteration/s, mean_rewards=-924]\u001b[A\n",
            "Training:  19%|█▉        | 380/2000 [03:26<17:14,  1.57iteration/s, mean_rewards=-710]\u001b[A\n",
            "Training:  19%|█▉        | 381/2000 [03:26<16:00,  1.69iteration/s, mean_rewards=-710]\u001b[A\n",
            "Training:  19%|█▉        | 381/2000 [03:27<16:00,  1.69iteration/s, mean_rewards=-1.43e+3]\u001b[A\n",
            "Training:  19%|█▉        | 382/2000 [03:27<19:09,  1.41iteration/s, mean_rewards=-1.43e+3]\u001b[A\n",
            "Training:  19%|█▉        | 382/2000 [03:27<19:09,  1.41iteration/s, mean_rewards=-775]    \u001b[A\n",
            "Training:  19%|█▉        | 383/2000 [03:28<19:30,  1.38iteration/s, mean_rewards=-775]\u001b[A\n",
            "Training:  19%|█▉        | 383/2000 [03:28<19:30,  1.38iteration/s, mean_rewards=-575]\u001b[A\n",
            "Training:  19%|█▉        | 384/2000 [03:28<19:21,  1.39iteration/s, mean_rewards=-575]\u001b[A\n",
            "Training:  19%|█▉        | 384/2000 [03:29<19:21,  1.39iteration/s, mean_rewards=-574]\u001b[A\n",
            "Training:  19%|█▉        | 385/2000 [03:29<19:37,  1.37iteration/s, mean_rewards=-574]\u001b[A\n",
            "Training:  19%|█▉        | 385/2000 [03:30<19:37,  1.37iteration/s, mean_rewards=-635]\u001b[A\n",
            "Training:  19%|█▉        | 386/2000 [03:30<19:55,  1.35iteration/s, mean_rewards=-635]\u001b[A\n",
            "Training:  19%|█▉        | 386/2000 [03:30<19:55,  1.35iteration/s, mean_rewards=-663]\u001b[A\n",
            "Training:  19%|█▉        | 387/2000 [03:31<18:41,  1.44iteration/s, mean_rewards=-663]\u001b[A\n",
            "Training:  19%|█▉        | 387/2000 [03:31<18:41,  1.44iteration/s, mean_rewards=-660]\u001b[A\n",
            "Training:  19%|█▉        | 388/2000 [03:31<17:36,  1.53iteration/s, mean_rewards=-660]\u001b[A\n",
            "Training:  19%|█▉        | 388/2000 [03:31<17:36,  1.53iteration/s, mean_rewards=-489]\u001b[A\n",
            "Training:  19%|█▉        | 389/2000 [03:32<15:32,  1.73iteration/s, mean_rewards=-489]\u001b[A\n",
            "Training:  19%|█▉        | 389/2000 [03:32<15:32,  1.73iteration/s, mean_rewards=-562]\u001b[A\n",
            "Training:  20%|█▉        | 390/2000 [03:32<15:10,  1.77iteration/s, mean_rewards=-562]\u001b[A\n",
            "Training:  20%|█▉        | 390/2000 [03:32<15:10,  1.77iteration/s, mean_rewards=-504]\u001b[A\n",
            "Training:  20%|█▉        | 391/2000 [03:33<14:20,  1.87iteration/s, mean_rewards=-504]\u001b[A\n",
            "Training:  20%|█▉        | 391/2000 [03:33<14:20,  1.87iteration/s, mean_rewards=-836]\u001b[A\n",
            "Training:  20%|█▉        | 392/2000 [03:33<15:46,  1.70iteration/s, mean_rewards=-836]\u001b[A\n",
            "Training:  20%|█▉        | 392/2000 [03:34<15:46,  1.70iteration/s, mean_rewards=-544]\u001b[A\n",
            "Training:  20%|█▉        | 393/2000 [03:34<15:37,  1.71iteration/s, mean_rewards=-544]\u001b[A\n",
            "Training:  20%|█▉        | 393/2000 [03:34<15:37,  1.71iteration/s, mean_rewards=-797]\u001b[A\n",
            "Training:  20%|█▉        | 394/2000 [03:34<16:23,  1.63iteration/s, mean_rewards=-797]\u001b[A\n",
            "Training:  20%|█▉        | 394/2000 [03:35<16:23,  1.63iteration/s, mean_rewards=-551]\u001b[A\n",
            "Training:  20%|█▉        | 395/2000 [03:35<15:47,  1.69iteration/s, mean_rewards=-551]\u001b[A\n",
            "Training:  20%|█▉        | 395/2000 [03:35<15:47,  1.69iteration/s, mean_rewards=-661]\u001b[A\n",
            "Training:  20%|█▉        | 396/2000 [03:36<15:54,  1.68iteration/s, mean_rewards=-661]\u001b[A\n",
            "Training:  20%|█▉        | 396/2000 [03:36<15:54,  1.68iteration/s, mean_rewards=-555]\u001b[A\n",
            "Training:  20%|█▉        | 397/2000 [03:36<14:39,  1.82iteration/s, mean_rewards=-555]\u001b[A\n",
            "Training:  20%|█▉        | 397/2000 [03:36<14:39,  1.82iteration/s, mean_rewards=-566]\u001b[A\n",
            "Training:  20%|█▉        | 398/2000 [03:37<14:27,  1.85iteration/s, mean_rewards=-566]\u001b[A\n",
            "Training:  20%|█▉        | 398/2000 [03:37<14:27,  1.85iteration/s, mean_rewards=-515]\u001b[A\n",
            "Training:  20%|█▉        | 399/2000 [03:37<14:06,  1.89iteration/s, mean_rewards=-515]\u001b[A\n",
            "Training:  20%|█▉        | 399/2000 [03:38<14:06,  1.89iteration/s, mean_rewards=-2.33e+3]\u001b[A\n",
            "Training:  20%|██        | 400/2000 [03:38<20:15,  1.32iteration/s, mean_rewards=-2.33e+3]\u001b[A\n",
            "Training:  20%|██        | 400/2000 [03:39<20:15,  1.32iteration/s, mean_rewards=-763]    \u001b[A\n",
            "Training:  20%|██        | 401/2000 [03:39<18:33,  1.44iteration/s, mean_rewards=-763]\u001b[A\n",
            "Training:  20%|██        | 401/2000 [03:39<18:33,  1.44iteration/s, mean_rewards=-929]\u001b[A\n",
            "Training:  20%|██        | 402/2000 [03:40<19:11,  1.39iteration/s, mean_rewards=-929]\u001b[A\n",
            "Training:  20%|██        | 402/2000 [03:40<19:11,  1.39iteration/s, mean_rewards=-978]\u001b[A\n",
            "Training:  20%|██        | 403/2000 [03:41<21:24,  1.24iteration/s, mean_rewards=-978]\u001b[A\n",
            "Training:  20%|██        | 403/2000 [03:41<21:24,  1.24iteration/s, mean_rewards=-671]\u001b[A\n",
            "Training:  20%|██        | 404/2000 [03:41<21:00,  1.27iteration/s, mean_rewards=-671]\u001b[A\n",
            "Training:  20%|██        | 404/2000 [03:42<21:00,  1.27iteration/s, mean_rewards=-805]\u001b[A\n",
            "Training:  20%|██        | 405/2000 [03:42<22:25,  1.19iteration/s, mean_rewards=-805]\u001b[A\n",
            "Training:  20%|██        | 405/2000 [03:43<22:25,  1.19iteration/s, mean_rewards=-776]\u001b[A\n",
            "Training:  20%|██        | 406/2000 [03:43<21:16,  1.25iteration/s, mean_rewards=-776]\u001b[A\n",
            "Training:  20%|██        | 406/2000 [03:44<21:16,  1.25iteration/s, mean_rewards=-1.16e+3]\u001b[A\n",
            "Training:  20%|██        | 407/2000 [03:44<21:25,  1.24iteration/s, mean_rewards=-1.16e+3]\u001b[A\n",
            "Training:  20%|██        | 407/2000 [03:45<21:25,  1.24iteration/s, mean_rewards=-935]    \u001b[A\n",
            "Training:  20%|██        | 408/2000 [03:45<21:26,  1.24iteration/s, mean_rewards=-935]\u001b[A\n",
            "Training:  20%|██        | 408/2000 [03:45<21:26,  1.24iteration/s, mean_rewards=-509]\u001b[A\n",
            "Training:  20%|██        | 409/2000 [03:45<18:53,  1.40iteration/s, mean_rewards=-509]\u001b[A\n",
            "Training:  20%|██        | 409/2000 [03:46<18:53,  1.40iteration/s, mean_rewards=-425]\u001b[A\n",
            "Training:  20%|██        | 410/2000 [03:46<16:38,  1.59iteration/s, mean_rewards=-425]\u001b[A\n",
            "Training:  20%|██        | 410/2000 [03:46<16:38,  1.59iteration/s, mean_rewards=-1.48e+3]\u001b[A\n",
            "Training:  21%|██        | 411/2000 [03:47<19:32,  1.36iteration/s, mean_rewards=-1.48e+3]\u001b[A\n",
            "Training:  21%|██        | 411/2000 [03:48<19:32,  1.36iteration/s, mean_rewards=-1.93e+3]\u001b[A\n",
            "Training:  21%|██        | 412/2000 [03:48<23:51,  1.11iteration/s, mean_rewards=-1.93e+3]\u001b[A\n",
            "Training:  21%|██        | 412/2000 [03:48<23:51,  1.11iteration/s, mean_rewards=-880]    \u001b[A\n",
            "Training:  21%|██        | 413/2000 [03:49<21:46,  1.21iteration/s, mean_rewards=-880]\u001b[A\n",
            "Training:  21%|██        | 413/2000 [03:49<21:46,  1.21iteration/s, mean_rewards=-900]\u001b[A\n",
            "Training:  21%|██        | 414/2000 [03:49<21:15,  1.24iteration/s, mean_rewards=-900]\u001b[A\n",
            "Training:  21%|██        | 414/2000 [03:50<21:15,  1.24iteration/s, mean_rewards=-714]\u001b[A\n",
            "Training:  21%|██        | 415/2000 [03:50<20:07,  1.31iteration/s, mean_rewards=-714]\u001b[A\n",
            "Training:  21%|██        | 415/2000 [03:51<20:07,  1.31iteration/s, mean_rewards=-2.09e+3]\u001b[A\n",
            "Training:  21%|██        | 416/2000 [03:51<24:16,  1.09iteration/s, mean_rewards=-2.09e+3]\u001b[A\n",
            "Training:  21%|██        | 416/2000 [03:52<24:16,  1.09iteration/s, mean_rewards=-1.14e+3]\u001b[A\n",
            "Training:  21%|██        | 417/2000 [03:52<22:49,  1.16iteration/s, mean_rewards=-1.14e+3]\u001b[A\n",
            "Training:  21%|██        | 417/2000 [03:52<22:49,  1.16iteration/s, mean_rewards=-762]    \u001b[A\n",
            "Training:  21%|██        | 418/2000 [03:53<20:31,  1.28iteration/s, mean_rewards=-762]\u001b[A\n",
            "Training:  21%|██        | 418/2000 [03:53<20:31,  1.28iteration/s, mean_rewards=-956]\u001b[A\n",
            "Training:  21%|██        | 419/2000 [03:54<21:23,  1.23iteration/s, mean_rewards=-956]\u001b[A\n",
            "Training:  21%|██        | 419/2000 [03:54<21:23,  1.23iteration/s, mean_rewards=-1.14e+3]\u001b[A\n",
            "Training:  21%|██        | 420/2000 [03:55<23:32,  1.12iteration/s, mean_rewards=-1.14e+3]\u001b[A\n",
            "Training:  21%|██        | 420/2000 [03:55<23:32,  1.12iteration/s, mean_rewards=-641]    \u001b[A\n",
            "Training:  21%|██        | 421/2000 [03:55<23:09,  1.14iteration/s, mean_rewards=-641]\u001b[A\n",
            "Training:  21%|██        | 421/2000 [03:56<23:09,  1.14iteration/s, mean_rewards=-572]\u001b[A\n",
            "Training:  21%|██        | 422/2000 [03:56<21:14,  1.24iteration/s, mean_rewards=-572]\u001b[A\n",
            "Training:  21%|██        | 422/2000 [03:56<21:14,  1.24iteration/s, mean_rewards=-601]\u001b[A\n",
            "Training:  21%|██        | 423/2000 [03:57<18:31,  1.42iteration/s, mean_rewards=-601]\u001b[A\n",
            "Training:  21%|██        | 423/2000 [03:57<18:31,  1.42iteration/s, mean_rewards=-625]\u001b[A\n",
            "Training:  21%|██        | 424/2000 [03:57<17:33,  1.50iteration/s, mean_rewards=-625]\u001b[A\n",
            "Training:  21%|██        | 424/2000 [03:58<17:33,  1.50iteration/s, mean_rewards=-772]\u001b[A\n",
            "Training:  21%|██▏       | 425/2000 [03:58<17:21,  1.51iteration/s, mean_rewards=-772]\u001b[A\n",
            "Training:  21%|██▏       | 425/2000 [03:58<17:21,  1.51iteration/s, mean_rewards=-621]\u001b[A\n",
            "Training:  21%|██▏       | 426/2000 [03:58<16:17,  1.61iteration/s, mean_rewards=-621]\u001b[A\n",
            "Training:  21%|██▏       | 426/2000 [03:59<16:17,  1.61iteration/s, mean_rewards=-750]\u001b[A\n",
            "Training:  21%|██▏       | 427/2000 [03:59<16:11,  1.62iteration/s, mean_rewards=-750]\u001b[A\n",
            "Training:  21%|██▏       | 427/2000 [03:59<16:11,  1.62iteration/s, mean_rewards=-678]\u001b[A\n",
            "Training:  21%|██▏       | 428/2000 [03:59<15:32,  1.69iteration/s, mean_rewards=-678]\u001b[A\n",
            "Training:  21%|██▏       | 428/2000 [04:00<15:32,  1.69iteration/s, mean_rewards=-744]\u001b[A\n",
            "Training:  21%|██▏       | 429/2000 [04:00<15:46,  1.66iteration/s, mean_rewards=-744]\u001b[A\n",
            "Training:  21%|██▏       | 429/2000 [04:01<15:46,  1.66iteration/s, mean_rewards=-694]\u001b[A\n",
            "Training:  22%|██▏       | 430/2000 [04:01<16:00,  1.63iteration/s, mean_rewards=-694]\u001b[A\n",
            "Training:  22%|██▏       | 430/2000 [04:02<16:00,  1.63iteration/s, mean_rewards=-2.87e+3]\u001b[A\n",
            "Training:  22%|██▏       | 431/2000 [04:02<23:11,  1.13iteration/s, mean_rewards=-2.87e+3]\u001b[A\n",
            "Training:  22%|██▏       | 431/2000 [04:03<23:11,  1.13iteration/s, mean_rewards=-1.49e+3]\u001b[A\n",
            "Training:  22%|██▏       | 432/2000 [04:03<24:09,  1.08iteration/s, mean_rewards=-1.49e+3]\u001b[A\n",
            "Training:  22%|██▏       | 432/2000 [04:04<24:09,  1.08iteration/s, mean_rewards=-1.18e+3]\u001b[A\n",
            "Training:  22%|██▏       | 433/2000 [04:04<23:01,  1.13iteration/s, mean_rewards=-1.18e+3]\u001b[A\n",
            "Training:  22%|██▏       | 433/2000 [04:05<23:01,  1.13iteration/s, mean_rewards=-3.27e+3]\u001b[A\n",
            "Training:  22%|██▏       | 434/2000 [04:06<31:20,  1.20s/iteration, mean_rewards=-3.27e+3]\u001b[A\n",
            "Training:  22%|██▏       | 434/2000 [04:07<31:20,  1.20s/iteration, mean_rewards=-775]    \u001b[A\n",
            "Training:  22%|██▏       | 435/2000 [04:07<28:10,  1.08s/iteration, mean_rewards=-775]\u001b[A\n",
            "Training:  22%|██▏       | 435/2000 [04:08<28:10,  1.08s/iteration, mean_rewards=-1.28e+3]\u001b[A\n",
            "Training:  22%|██▏       | 436/2000 [04:08<30:13,  1.16s/iteration, mean_rewards=-1.28e+3]\u001b[A\n",
            "Training:  22%|██▏       | 436/2000 [04:09<30:13,  1.16s/iteration, mean_rewards=-992]    \u001b[A\n",
            "Training:  22%|██▏       | 437/2000 [04:09<27:43,  1.06s/iteration, mean_rewards=-992]\u001b[A\n",
            "Training:  22%|██▏       | 437/2000 [04:09<27:43,  1.06s/iteration, mean_rewards=-894]\u001b[A\n",
            "Training:  22%|██▏       | 438/2000 [04:10<24:37,  1.06iteration/s, mean_rewards=-894]\u001b[A\n",
            "Training:  22%|██▏       | 438/2000 [04:10<24:37,  1.06iteration/s, mean_rewards=-686]\u001b[A\n",
            "Training:  22%|██▏       | 439/2000 [04:10<22:16,  1.17iteration/s, mean_rewards=-686]\u001b[A\n",
            "Training:  22%|██▏       | 439/2000 [04:11<22:16,  1.17iteration/s, mean_rewards=-564]\u001b[A\n",
            "Training:  22%|██▏       | 440/2000 [04:11<19:42,  1.32iteration/s, mean_rewards=-564]\u001b[A\n",
            "Training:  22%|██▏       | 440/2000 [04:11<19:42,  1.32iteration/s, mean_rewards=-1.19e+3]\u001b[A\n",
            "Training:  22%|██▏       | 441/2000 [04:12<20:45,  1.25iteration/s, mean_rewards=-1.19e+3]\u001b[A\n",
            "Training:  22%|██▏       | 441/2000 [04:12<20:45,  1.25iteration/s, mean_rewards=-980]    \u001b[A\n",
            "Training:  22%|██▏       | 442/2000 [04:12<20:02,  1.30iteration/s, mean_rewards=-980]\u001b[A\n",
            "Training:  22%|██▏       | 442/2000 [04:13<20:02,  1.30iteration/s, mean_rewards=-607]\u001b[A\n",
            "Training:  22%|██▏       | 443/2000 [04:13<18:23,  1.41iteration/s, mean_rewards=-607]\u001b[A\n",
            "Training:  22%|██▏       | 443/2000 [04:14<18:23,  1.41iteration/s, mean_rewards=-1.18e+3]\u001b[A\n",
            "Training:  22%|██▏       | 444/2000 [04:14<19:08,  1.35iteration/s, mean_rewards=-1.18e+3]\u001b[A\n",
            "Training:  22%|██▏       | 444/2000 [04:14<19:08,  1.35iteration/s, mean_rewards=-1.35e+3]\u001b[A\n",
            "Training:  22%|██▏       | 445/2000 [04:15<20:13,  1.28iteration/s, mean_rewards=-1.35e+3]\u001b[A\n",
            "Training:  22%|██▏       | 445/2000 [04:15<20:13,  1.28iteration/s, mean_rewards=-571]    \u001b[A\n",
            "Training:  22%|██▏       | 446/2000 [04:15<17:52,  1.45iteration/s, mean_rewards=-571]\u001b[A\n",
            "Training:  22%|██▏       | 446/2000 [04:15<17:52,  1.45iteration/s, mean_rewards=-662]\u001b[A\n",
            "Training:  22%|██▏       | 447/2000 [04:16<16:17,  1.59iteration/s, mean_rewards=-662]\u001b[A\n",
            "Training:  22%|██▏       | 447/2000 [04:16<16:17,  1.59iteration/s, mean_rewards=-640]\u001b[A\n",
            "Training:  22%|██▏       | 448/2000 [04:16<14:58,  1.73iteration/s, mean_rewards=-640]\u001b[A\n",
            "Training:  22%|██▏       | 448/2000 [04:17<14:58,  1.73iteration/s, mean_rewards=-725]\u001b[A\n",
            "Training:  22%|██▏       | 449/2000 [04:17<15:17,  1.69iteration/s, mean_rewards=-725]\u001b[A\n",
            "Training:  22%|██▏       | 449/2000 [04:17<15:17,  1.69iteration/s, mean_rewards=-818]\u001b[A\n",
            "Training:  22%|██▎       | 450/2000 [04:17<15:50,  1.63iteration/s, mean_rewards=-818]\u001b[A\n",
            "Training:  22%|██▎       | 450/2000 [04:18<15:50,  1.63iteration/s, mean_rewards=-880]\u001b[A\n",
            "Training:  23%|██▎       | 451/2000 [04:18<17:11,  1.50iteration/s, mean_rewards=-880]\u001b[A\n",
            "Training:  23%|██▎       | 451/2000 [04:19<17:11,  1.50iteration/s, mean_rewards=-1.25e+3]\u001b[A\n",
            "Training:  23%|██▎       | 452/2000 [04:19<21:12,  1.22iteration/s, mean_rewards=-1.25e+3]\u001b[A\n",
            "Training:  23%|██▎       | 452/2000 [04:21<21:12,  1.22iteration/s, mean_rewards=-1.93e+3]\u001b[A\n",
            "Training:  23%|██▎       | 453/2000 [04:21<28:33,  1.11s/iteration, mean_rewards=-1.93e+3]\u001b[A\n",
            "Training:  23%|██▎       | 453/2000 [04:22<28:33,  1.11s/iteration, mean_rewards=-851]    \u001b[A\n",
            "Training:  23%|██▎       | 454/2000 [04:22<25:26,  1.01iteration/s, mean_rewards=-851]\u001b[A\n",
            "Training:  23%|██▎       | 454/2000 [04:22<25:26,  1.01iteration/s, mean_rewards=-486]\u001b[A\n",
            "Training:  23%|██▎       | 455/2000 [04:22<21:12,  1.21iteration/s, mean_rewards=-486]\u001b[A\n",
            "Training:  23%|██▎       | 455/2000 [04:23<21:12,  1.21iteration/s, mean_rewards=-642]\u001b[A\n",
            "Training:  23%|██▎       | 456/2000 [04:23<18:28,  1.39iteration/s, mean_rewards=-642]\u001b[A\n",
            "Training:  23%|██▎       | 456/2000 [04:23<18:28,  1.39iteration/s, mean_rewards=-906]\u001b[A\n",
            "Training:  23%|██▎       | 457/2000 [04:23<17:45,  1.45iteration/s, mean_rewards=-906]\u001b[A\n",
            "Training:  23%|██▎       | 457/2000 [04:24<17:45,  1.45iteration/s, mean_rewards=-2.01e+3]\u001b[A\n",
            "Training:  23%|██▎       | 458/2000 [04:25<22:49,  1.13iteration/s, mean_rewards=-2.01e+3]\u001b[A\n",
            "Training:  23%|██▎       | 458/2000 [04:25<22:49,  1.13iteration/s, mean_rewards=-588]    \u001b[A\n",
            "Training:  23%|██▎       | 459/2000 [04:25<19:28,  1.32iteration/s, mean_rewards=-588]\u001b[A\n",
            "Training:  23%|██▎       | 459/2000 [04:26<19:28,  1.32iteration/s, mean_rewards=-618]\u001b[A\n",
            "Training:  23%|██▎       | 460/2000 [04:26<17:51,  1.44iteration/s, mean_rewards=-618]\u001b[A\n",
            "Training:  23%|██▎       | 460/2000 [04:26<17:51,  1.44iteration/s, mean_rewards=-486]\u001b[A\n",
            "Training:  23%|██▎       | 461/2000 [04:26<16:26,  1.56iteration/s, mean_rewards=-486]\u001b[A\n",
            "Training:  23%|██▎       | 461/2000 [04:27<16:26,  1.56iteration/s, mean_rewards=-1.39e+3]\u001b[A\n",
            "Training:  23%|██▎       | 462/2000 [04:27<19:07,  1.34iteration/s, mean_rewards=-1.39e+3]\u001b[A\n",
            "Training:  23%|██▎       | 462/2000 [04:28<19:07,  1.34iteration/s, mean_rewards=-574]    \u001b[A\n",
            "Training:  23%|██▎       | 463/2000 [04:28<16:58,  1.51iteration/s, mean_rewards=-574]\u001b[A\n",
            "Training:  23%|██▎       | 463/2000 [04:28<16:58,  1.51iteration/s, mean_rewards=-609]\u001b[A\n",
            "Training:  23%|██▎       | 464/2000 [04:28<15:32,  1.65iteration/s, mean_rewards=-609]\u001b[A\n",
            "Training:  23%|██▎       | 464/2000 [04:29<15:32,  1.65iteration/s, mean_rewards=-891]\u001b[A\n",
            "Training:  23%|██▎       | 465/2000 [04:29<15:39,  1.63iteration/s, mean_rewards=-891]\u001b[A\n",
            "Training:  23%|██▎       | 465/2000 [04:29<15:39,  1.63iteration/s, mean_rewards=-810]\u001b[A\n",
            "Training:  23%|██▎       | 466/2000 [04:29<15:50,  1.61iteration/s, mean_rewards=-810]\u001b[A\n",
            "Training:  23%|██▎       | 466/2000 [04:30<15:50,  1.61iteration/s, mean_rewards=-531]\u001b[A\n",
            "Training:  23%|██▎       | 467/2000 [04:30<14:07,  1.81iteration/s, mean_rewards=-531]\u001b[A\n",
            "Training:  23%|██▎       | 467/2000 [04:30<14:07,  1.81iteration/s, mean_rewards=-1.08e+3]\u001b[A\n",
            "Training:  23%|██▎       | 468/2000 [04:31<16:38,  1.53iteration/s, mean_rewards=-1.08e+3]\u001b[A\n",
            "Training:  23%|██▎       | 468/2000 [04:31<16:38,  1.53iteration/s, mean_rewards=-488]    \u001b[A\n",
            "Training:  23%|██▎       | 469/2000 [04:31<15:51,  1.61iteration/s, mean_rewards=-488]\u001b[A\n",
            "Training:  23%|██▎       | 469/2000 [04:32<15:51,  1.61iteration/s, mean_rewards=-605]\u001b[A\n",
            "Training:  24%|██▎       | 470/2000 [04:32<15:33,  1.64iteration/s, mean_rewards=-605]\u001b[A\n",
            "Training:  24%|██▎       | 470/2000 [04:32<15:33,  1.64iteration/s, mean_rewards=-607]\u001b[A\n",
            "Training:  24%|██▎       | 471/2000 [04:33<16:30,  1.54iteration/s, mean_rewards=-607]\u001b[A\n",
            "Training:  24%|██▎       | 471/2000 [04:33<16:30,  1.54iteration/s, mean_rewards=-667]\u001b[A\n",
            "Training:  24%|██▎       | 472/2000 [04:33<17:42,  1.44iteration/s, mean_rewards=-667]\u001b[A\n",
            "Training:  24%|██▎       | 472/2000 [04:34<17:42,  1.44iteration/s, mean_rewards=-632]\u001b[A\n",
            "Training:  24%|██▎       | 473/2000 [04:34<17:07,  1.49iteration/s, mean_rewards=-632]\u001b[A\n",
            "Training:  24%|██▎       | 473/2000 [04:35<17:07,  1.49iteration/s, mean_rewards=-2.74e+3]\u001b[A\n",
            "Training:  24%|██▎       | 474/2000 [04:36<24:50,  1.02iteration/s, mean_rewards=-2.74e+3]\u001b[A\n",
            "Training:  24%|██▎       | 474/2000 [04:36<24:50,  1.02iteration/s, mean_rewards=-546]    \u001b[A\n",
            "Training:  24%|██▍       | 475/2000 [04:36<21:30,  1.18iteration/s, mean_rewards=-546]\u001b[A\n",
            "Training:  24%|██▍       | 475/2000 [04:37<21:30,  1.18iteration/s, mean_rewards=-477]\u001b[A\n",
            "Training:  24%|██▍       | 476/2000 [04:37<18:40,  1.36iteration/s, mean_rewards=-477]\u001b[A\n",
            "Training:  24%|██▍       | 476/2000 [04:37<18:40,  1.36iteration/s, mean_rewards=-1.37e+3]\u001b[A\n",
            "Training:  24%|██▍       | 477/2000 [04:38<20:05,  1.26iteration/s, mean_rewards=-1.37e+3]\u001b[A\n",
            "Training:  24%|██▍       | 477/2000 [04:38<20:05,  1.26iteration/s, mean_rewards=-1.09e+3]\u001b[A\n",
            "Training:  24%|██▍       | 478/2000 [04:38<20:21,  1.25iteration/s, mean_rewards=-1.09e+3]\u001b[A\n",
            "Training:  24%|██▍       | 478/2000 [04:39<20:21,  1.25iteration/s, mean_rewards=-1.11e+3]\u001b[A\n",
            "Training:  24%|██▍       | 479/2000 [04:39<20:23,  1.24iteration/s, mean_rewards=-1.11e+3]\u001b[A\n",
            "Training:  24%|██▍       | 479/2000 [04:40<20:23,  1.24iteration/s, mean_rewards=-727]    \u001b[A\n",
            "Training:  24%|██▍       | 480/2000 [04:40<19:03,  1.33iteration/s, mean_rewards=-727]\u001b[A\n",
            "Training:  24%|██▍       | 480/2000 [04:40<19:03,  1.33iteration/s, mean_rewards=-539]\u001b[A\n",
            "Training:  24%|██▍       | 481/2000 [04:40<16:41,  1.52iteration/s, mean_rewards=-539]\u001b[A\n",
            "Training:  24%|██▍       | 481/2000 [04:41<16:41,  1.52iteration/s, mean_rewards=-512]\u001b[A\n",
            "Training:  24%|██▍       | 482/2000 [04:41<14:46,  1.71iteration/s, mean_rewards=-512]\u001b[A\n",
            "Training:  24%|██▍       | 482/2000 [04:41<14:46,  1.71iteration/s, mean_rewards=-721]\u001b[A\n",
            "Training:  24%|██▍       | 483/2000 [04:41<14:36,  1.73iteration/s, mean_rewards=-721]\u001b[A\n",
            "Training:  24%|██▍       | 483/2000 [04:42<14:36,  1.73iteration/s, mean_rewards=-652]\u001b[A\n",
            "Training:  24%|██▍       | 484/2000 [04:42<14:07,  1.79iteration/s, mean_rewards=-652]\u001b[A\n",
            "Training:  24%|██▍       | 484/2000 [04:42<14:07,  1.79iteration/s, mean_rewards=-706]\u001b[A\n",
            "Training:  24%|██▍       | 485/2000 [04:43<14:50,  1.70iteration/s, mean_rewards=-706]\u001b[A\n",
            "Training:  24%|██▍       | 485/2000 [04:43<14:50,  1.70iteration/s, mean_rewards=-893]\u001b[A\n",
            "Training:  24%|██▍       | 486/2000 [04:43<16:24,  1.54iteration/s, mean_rewards=-893]\u001b[A\n",
            "Training:  24%|██▍       | 486/2000 [04:44<16:24,  1.54iteration/s, mean_rewards=-985]\u001b[A\n",
            "Training:  24%|██▍       | 487/2000 [04:44<17:26,  1.45iteration/s, mean_rewards=-985]\u001b[A\n",
            "Training:  24%|██▍       | 487/2000 [04:45<17:26,  1.45iteration/s, mean_rewards=-796]\u001b[A\n",
            "Training:  24%|██▍       | 488/2000 [04:45<18:30,  1.36iteration/s, mean_rewards=-796]\u001b[A\n",
            "Training:  24%|██▍       | 488/2000 [04:45<18:30,  1.36iteration/s, mean_rewards=-674]\u001b[A\n",
            "Training:  24%|██▍       | 489/2000 [04:46<18:36,  1.35iteration/s, mean_rewards=-674]\u001b[A\n",
            "Training:  24%|██▍       | 489/2000 [04:46<18:36,  1.35iteration/s, mean_rewards=-665]\u001b[A\n",
            "Training:  24%|██▍       | 490/2000 [04:46<18:47,  1.34iteration/s, mean_rewards=-665]\u001b[A\n",
            "Training:  24%|██▍       | 490/2000 [04:47<18:47,  1.34iteration/s, mean_rewards=-633]\u001b[A\n",
            "Training:  25%|██▍       | 491/2000 [04:47<18:07,  1.39iteration/s, mean_rewards=-633]\u001b[A\n",
            "Training:  25%|██▍       | 491/2000 [04:47<18:07,  1.39iteration/s, mean_rewards=-527]\u001b[A\n",
            "Training:  25%|██▍       | 492/2000 [04:48<15:47,  1.59iteration/s, mean_rewards=-527]\u001b[A\n",
            "Training:  25%|██▍       | 492/2000 [04:48<15:47,  1.59iteration/s, mean_rewards=-1.71e+3]\u001b[A\n",
            "Training:  25%|██▍       | 493/2000 [04:49<18:43,  1.34iteration/s, mean_rewards=-1.71e+3]\u001b[A\n",
            "Training:  25%|██▍       | 493/2000 [04:49<18:43,  1.34iteration/s, mean_rewards=-557]    \u001b[A\n",
            "Training:  25%|██▍       | 494/2000 [04:49<17:44,  1.42iteration/s, mean_rewards=-557]\u001b[A\n",
            "Training:  25%|██▍       | 494/2000 [04:49<17:44,  1.42iteration/s, mean_rewards=-668]\u001b[A\n",
            "Training:  25%|██▍       | 495/2000 [04:50<16:02,  1.56iteration/s, mean_rewards=-668]\u001b[A\n",
            "Training:  25%|██▍       | 495/2000 [04:50<16:02,  1.56iteration/s, mean_rewards=-840]\u001b[A\n",
            "Training:  25%|██▍       | 496/2000 [04:50<15:51,  1.58iteration/s, mean_rewards=-840]\u001b[A\n",
            "Training:  25%|██▍       | 496/2000 [04:51<15:51,  1.58iteration/s, mean_rewards=-1.83e+3]\u001b[A\n",
            "Training:  25%|██▍       | 497/2000 [04:51<19:58,  1.25iteration/s, mean_rewards=-1.83e+3]\u001b[A\n",
            "Training:  25%|██▍       | 497/2000 [04:52<19:58,  1.25iteration/s, mean_rewards=-627]    \u001b[A\n",
            "Training:  25%|██▍       | 498/2000 [04:52<17:50,  1.40iteration/s, mean_rewards=-627]\u001b[A\n",
            "Training:  25%|██▍       | 498/2000 [04:52<17:50,  1.40iteration/s, mean_rewards=-695]\u001b[A\n",
            "Training:  25%|██▍       | 499/2000 [04:53<16:42,  1.50iteration/s, mean_rewards=-695]\u001b[A\n",
            "Training:  25%|██▍       | 499/2000 [04:53<16:42,  1.50iteration/s, mean_rewards=-1.06e+3]\u001b[A\n",
            "Training:  25%|██▌       | 500/2000 [04:53<17:51,  1.40iteration/s, mean_rewards=-1.06e+3]\u001b[A\n",
            "Training:  25%|██▌       | 500/2000 [04:54<17:51,  1.40iteration/s, mean_rewards=-485]    \u001b[A\n",
            "Training:  25%|██▌       | 501/2000 [04:54<15:57,  1.57iteration/s, mean_rewards=-485]\u001b[A\n",
            "Training:  25%|██▌       | 501/2000 [04:54<15:57,  1.57iteration/s, mean_rewards=-1.48e+3]\u001b[A\n",
            "Training:  25%|██▌       | 502/2000 [04:55<18:30,  1.35iteration/s, mean_rewards=-1.48e+3]\u001b[A\n",
            "Training:  25%|██▌       | 502/2000 [04:55<18:30,  1.35iteration/s, mean_rewards=-663]    \u001b[A\n",
            "Training:  25%|██▌       | 503/2000 [04:55<17:09,  1.45iteration/s, mean_rewards=-663]\u001b[A\n",
            "Training:  25%|██▌       | 503/2000 [04:56<17:09,  1.45iteration/s, mean_rewards=-739]\u001b[A\n",
            "Training:  25%|██▌       | 504/2000 [04:56<17:26,  1.43iteration/s, mean_rewards=-739]\u001b[A\n",
            "Training:  25%|██▌       | 504/2000 [04:57<17:26,  1.43iteration/s, mean_rewards=-786]\u001b[A\n",
            "Training:  25%|██▌       | 505/2000 [04:57<17:35,  1.42iteration/s, mean_rewards=-786]\u001b[A\n",
            "Training:  25%|██▌       | 505/2000 [04:57<17:35,  1.42iteration/s, mean_rewards=-630]\u001b[A\n",
            "Training:  25%|██▌       | 506/2000 [04:58<18:37,  1.34iteration/s, mean_rewards=-630]\u001b[A\n",
            "Training:  25%|██▌       | 506/2000 [04:59<18:37,  1.34iteration/s, mean_rewards=-3.12e+3]\u001b[A\n",
            "Training:  25%|██▌       | 507/2000 [05:00<29:39,  1.19s/iteration, mean_rewards=-3.12e+3]\u001b[A\n",
            "Training:  25%|██▌       | 507/2000 [05:00<29:39,  1.19s/iteration, mean_rewards=-674]    \u001b[A\n",
            "Training:  25%|██▌       | 508/2000 [05:01<25:37,  1.03s/iteration, mean_rewards=-674]\u001b[A\n",
            "Training:  25%|██▌       | 508/2000 [05:01<25:37,  1.03s/iteration, mean_rewards=-547]\u001b[A\n",
            "Training:  25%|██▌       | 509/2000 [05:01<20:53,  1.19iteration/s, mean_rewards=-547]\u001b[A\n",
            "Training:  25%|██▌       | 509/2000 [05:01<20:53,  1.19iteration/s, mean_rewards=-892]\u001b[A\n",
            "Training:  26%|██▌       | 510/2000 [05:02<19:25,  1.28iteration/s, mean_rewards=-892]\u001b[A\n",
            "Training:  26%|██▌       | 510/2000 [05:02<19:25,  1.28iteration/s, mean_rewards=-646]\u001b[A\n",
            "Training:  26%|██▌       | 511/2000 [05:02<17:42,  1.40iteration/s, mean_rewards=-646]\u001b[A\n",
            "Training:  26%|██▌       | 511/2000 [05:03<17:42,  1.40iteration/s, mean_rewards=-1.08e+3]\u001b[A\n",
            "Training:  26%|██▌       | 512/2000 [05:03<19:38,  1.26iteration/s, mean_rewards=-1.08e+3]\u001b[A\n",
            "Training:  26%|██▌       | 512/2000 [05:03<19:38,  1.26iteration/s, mean_rewards=-644]    \u001b[A\n",
            "Training:  26%|██▌       | 513/2000 [05:04<17:19,  1.43iteration/s, mean_rewards=-644]\u001b[A\n",
            "Training:  26%|██▌       | 513/2000 [05:04<17:19,  1.43iteration/s, mean_rewards=-733]\u001b[A\n",
            "Training:  26%|██▌       | 514/2000 [05:04<16:41,  1.48iteration/s, mean_rewards=-733]\u001b[A\n",
            "Training:  26%|██▌       | 514/2000 [05:05<16:41,  1.48iteration/s, mean_rewards=-636]\u001b[A\n",
            "Training:  26%|██▌       | 515/2000 [05:05<16:29,  1.50iteration/s, mean_rewards=-636]\u001b[A\n",
            "Training:  26%|██▌       | 515/2000 [05:05<16:29,  1.50iteration/s, mean_rewards=-613]\u001b[A\n",
            "Training:  26%|██▌       | 516/2000 [05:05<15:12,  1.63iteration/s, mean_rewards=-613]\u001b[A\n",
            "Training:  26%|██▌       | 516/2000 [05:06<15:12,  1.63iteration/s, mean_rewards=-1.54e+3]\u001b[A\n",
            "Training:  26%|██▌       | 517/2000 [05:06<18:05,  1.37iteration/s, mean_rewards=-1.54e+3]\u001b[A\n",
            "Training:  26%|██▌       | 517/2000 [05:07<18:05,  1.37iteration/s, mean_rewards=-497]    \u001b[A\n",
            "Training:  26%|██▌       | 518/2000 [05:07<16:11,  1.53iteration/s, mean_rewards=-497]\u001b[A\n",
            "Training:  26%|██▌       | 518/2000 [05:07<16:11,  1.53iteration/s, mean_rewards=-899]\u001b[A\n",
            "Training:  26%|██▌       | 519/2000 [05:08<16:37,  1.48iteration/s, mean_rewards=-899]\u001b[A\n",
            "Training:  26%|██▌       | 519/2000 [05:08<16:37,  1.48iteration/s, mean_rewards=-1.2e+3]\u001b[A\n",
            "Training:  26%|██▌       | 520/2000 [05:08<17:29,  1.41iteration/s, mean_rewards=-1.2e+3]\u001b[A\n",
            "Training:  26%|██▌       | 520/2000 [05:09<17:29,  1.41iteration/s, mean_rewards=-765]   \u001b[A\n",
            "Training:  26%|██▌       | 521/2000 [05:09<16:13,  1.52iteration/s, mean_rewards=-765]\u001b[A\n",
            "Training:  26%|██▌       | 521/2000 [05:09<16:13,  1.52iteration/s, mean_rewards=-1.06e+3]\u001b[A\n",
            "Training:  26%|██▌       | 522/2000 [05:10<16:44,  1.47iteration/s, mean_rewards=-1.06e+3]\u001b[A\n",
            "Training:  26%|██▌       | 522/2000 [05:10<16:44,  1.47iteration/s, mean_rewards=-720]    \u001b[A\n",
            "Training:  26%|██▌       | 523/2000 [05:10<16:32,  1.49iteration/s, mean_rewards=-720]\u001b[A\n",
            "Training:  26%|██▌       | 523/2000 [05:11<16:32,  1.49iteration/s, mean_rewards=-609]\u001b[A\n",
            "Training:  26%|██▌       | 524/2000 [05:11<16:26,  1.50iteration/s, mean_rewards=-609]\u001b[A\n",
            "Training:  26%|██▌       | 524/2000 [05:11<16:26,  1.50iteration/s, mean_rewards=-558]\u001b[A\n",
            "Training:  26%|██▋       | 525/2000 [05:12<16:14,  1.51iteration/s, mean_rewards=-558]\u001b[A\n",
            "Training:  26%|██▋       | 525/2000 [05:12<16:14,  1.51iteration/s, mean_rewards=-669]\u001b[A\n",
            "Training:  26%|██▋       | 526/2000 [05:12<16:46,  1.47iteration/s, mean_rewards=-669]\u001b[A\n",
            "Training:  26%|██▋       | 526/2000 [05:13<16:46,  1.47iteration/s, mean_rewards=-602]\u001b[A\n",
            "Training:  26%|██▋       | 527/2000 [05:13<15:47,  1.55iteration/s, mean_rewards=-602]\u001b[A\n",
            "Training:  26%|██▋       | 527/2000 [05:13<15:47,  1.55iteration/s, mean_rewards=-586]\u001b[A\n",
            "Training:  26%|██▋       | 528/2000 [05:13<14:27,  1.70iteration/s, mean_rewards=-586]\u001b[A\n",
            "Training:  26%|██▋       | 528/2000 [05:14<14:27,  1.70iteration/s, mean_rewards=-707]\u001b[A\n",
            "Training:  26%|██▋       | 529/2000 [05:14<14:03,  1.74iteration/s, mean_rewards=-707]\u001b[A\n",
            "Training:  26%|██▋       | 529/2000 [05:14<14:03,  1.74iteration/s, mean_rewards=-690]\u001b[A\n",
            "Training:  26%|██▋       | 530/2000 [05:14<13:43,  1.79iteration/s, mean_rewards=-690]\u001b[A\n",
            "Training:  26%|██▋       | 530/2000 [05:15<13:43,  1.79iteration/s, mean_rewards=-697]\u001b[A\n",
            "Training:  27%|██▋       | 531/2000 [05:15<13:36,  1.80iteration/s, mean_rewards=-697]\u001b[A\n",
            "Training:  27%|██▋       | 531/2000 [05:15<13:36,  1.80iteration/s, mean_rewards=-604]\u001b[A\n",
            "Training:  27%|██▋       | 532/2000 [05:15<12:30,  1.96iteration/s, mean_rewards=-604]\u001b[A\n",
            "Training:  27%|██▋       | 532/2000 [05:16<12:30,  1.96iteration/s, mean_rewards=-567]\u001b[A\n",
            "Training:  27%|██▋       | 533/2000 [05:16<12:10,  2.01iteration/s, mean_rewards=-567]\u001b[A\n",
            "Training:  27%|██▋       | 533/2000 [05:16<12:10,  2.01iteration/s, mean_rewards=-981]\u001b[A\n",
            "Training:  27%|██▋       | 534/2000 [05:16<13:39,  1.79iteration/s, mean_rewards=-981]\u001b[A\n",
            "Training:  27%|██▋       | 534/2000 [05:17<13:39,  1.79iteration/s, mean_rewards=-613]\u001b[A\n",
            "Training:  27%|██▋       | 535/2000 [05:17<13:46,  1.77iteration/s, mean_rewards=-613]\u001b[A\n",
            "Training:  27%|██▋       | 535/2000 [05:17<13:46,  1.77iteration/s, mean_rewards=-680]\u001b[A\n",
            "Training:  27%|██▋       | 536/2000 [05:18<14:14,  1.71iteration/s, mean_rewards=-680]\u001b[A\n",
            "Training:  27%|██▋       | 536/2000 [05:18<14:14,  1.71iteration/s, mean_rewards=-588]\u001b[A\n",
            "Training:  27%|██▋       | 537/2000 [05:18<13:32,  1.80iteration/s, mean_rewards=-588]\u001b[A\n",
            "Training:  27%|██▋       | 537/2000 [05:19<13:32,  1.80iteration/s, mean_rewards=-1.82e+3]\u001b[A\n",
            "Training:  27%|██▋       | 538/2000 [05:19<18:00,  1.35iteration/s, mean_rewards=-1.82e+3]\u001b[A\n",
            "Training:  27%|██▋       | 538/2000 [05:20<18:00,  1.35iteration/s, mean_rewards=-615]    \u001b[A\n",
            "Training:  27%|██▋       | 539/2000 [05:20<16:26,  1.48iteration/s, mean_rewards=-615]\u001b[A\n",
            "Training:  27%|██▋       | 539/2000 [05:20<16:26,  1.48iteration/s, mean_rewards=-535]\u001b[A\n",
            "Training:  27%|██▋       | 540/2000 [05:20<14:49,  1.64iteration/s, mean_rewards=-535]\u001b[A\n",
            "Training:  27%|██▋       | 540/2000 [05:21<14:49,  1.64iteration/s, mean_rewards=-1.7e+3]\u001b[A\n",
            "Training:  27%|██▋       | 541/2000 [05:21<18:04,  1.34iteration/s, mean_rewards=-1.7e+3]\u001b[A\n",
            "Training:  27%|██▋       | 541/2000 [05:22<18:04,  1.34iteration/s, mean_rewards=-549]   \u001b[A\n",
            "Training:  27%|██▋       | 542/2000 [05:22<15:38,  1.55iteration/s, mean_rewards=-549]\u001b[A\n",
            "Training:  27%|██▋       | 542/2000 [05:22<15:38,  1.55iteration/s, mean_rewards=-638]\u001b[A\n",
            "Training:  27%|██▋       | 543/2000 [05:22<15:21,  1.58iteration/s, mean_rewards=-638]\u001b[A\n",
            "Training:  27%|██▋       | 543/2000 [05:23<15:21,  1.58iteration/s, mean_rewards=-659]\u001b[A\n",
            "Training:  27%|██▋       | 544/2000 [05:23<14:45,  1.64iteration/s, mean_rewards=-659]\u001b[A\n",
            "Training:  27%|██▋       | 544/2000 [05:24<14:45,  1.64iteration/s, mean_rewards=-943]\u001b[A\n",
            "Training:  27%|██▋       | 545/2000 [05:24<16:57,  1.43iteration/s, mean_rewards=-943]\u001b[A\n",
            "Training:  27%|██▋       | 545/2000 [05:24<16:57,  1.43iteration/s, mean_rewards=-581]\u001b[A\n",
            "Training:  27%|██▋       | 546/2000 [05:25<16:45,  1.45iteration/s, mean_rewards=-581]\u001b[A\n",
            "Training:  27%|██▋       | 546/2000 [05:26<16:45,  1.45iteration/s, mean_rewards=-1.66e+3]\u001b[A\n",
            "Training:  27%|██▋       | 547/2000 [05:26<22:53,  1.06iteration/s, mean_rewards=-1.66e+3]\u001b[A\n",
            "Training:  27%|██▋       | 547/2000 [05:27<22:53,  1.06iteration/s, mean_rewards=-1.31e+3]\u001b[A\n",
            "Training:  27%|██▋       | 548/2000 [05:27<22:10,  1.09iteration/s, mean_rewards=-1.31e+3]\u001b[A\n",
            "Training:  27%|██▋       | 548/2000 [05:27<22:10,  1.09iteration/s, mean_rewards=-528]    \u001b[A\n",
            "Training:  27%|██▋       | 549/2000 [05:27<18:29,  1.31iteration/s, mean_rewards=-528]\u001b[A\n",
            "Training:  27%|██▋       | 549/2000 [05:28<18:29,  1.31iteration/s, mean_rewards=-1.16e+3]\u001b[A\n",
            "Training:  28%|██▊       | 550/2000 [05:28<19:21,  1.25iteration/s, mean_rewards=-1.16e+3]\u001b[A\n",
            "Training:  28%|██▊       | 550/2000 [05:29<19:21,  1.25iteration/s, mean_rewards=-558]    \u001b[A\n",
            "Training:  28%|██▊       | 551/2000 [05:29<17:36,  1.37iteration/s, mean_rewards=-558]\u001b[A\n",
            "Training:  28%|██▊       | 551/2000 [05:30<17:36,  1.37iteration/s, mean_rewards=-1.86e+3]\u001b[A\n",
            "Training:  28%|██▊       | 552/2000 [05:30<21:12,  1.14iteration/s, mean_rewards=-1.86e+3]\u001b[A\n",
            "Training:  28%|██▊       | 552/2000 [05:30<21:12,  1.14iteration/s, mean_rewards=-764]    \u001b[A\n",
            "Training:  28%|██▊       | 553/2000 [05:31<19:17,  1.25iteration/s, mean_rewards=-764]\u001b[A\n",
            "Training:  28%|██▊       | 553/2000 [05:31<19:17,  1.25iteration/s, mean_rewards=-820]\u001b[A\n",
            "Training:  28%|██▊       | 554/2000 [05:31<18:08,  1.33iteration/s, mean_rewards=-820]\u001b[A\n",
            "Training:  28%|██▊       | 554/2000 [05:32<18:08,  1.33iteration/s, mean_rewards=-637]\u001b[A\n",
            "Training:  28%|██▊       | 555/2000 [05:32<17:18,  1.39iteration/s, mean_rewards=-637]\u001b[A\n",
            "Training:  28%|██▊       | 555/2000 [05:32<17:18,  1.39iteration/s, mean_rewards=-690]\u001b[A\n",
            "Training:  28%|██▊       | 556/2000 [05:32<16:12,  1.48iteration/s, mean_rewards=-690]\u001b[A\n",
            "Training:  28%|██▊       | 556/2000 [05:33<16:12,  1.48iteration/s, mean_rewards=-560]\u001b[A\n",
            "Training:  28%|██▊       | 557/2000 [05:33<14:56,  1.61iteration/s, mean_rewards=-560]\u001b[A\n",
            "Training:  28%|██▊       | 557/2000 [05:33<14:56,  1.61iteration/s, mean_rewards=-1.01e+3]\u001b[A\n",
            "Training:  28%|██▊       | 558/2000 [05:34<15:41,  1.53iteration/s, mean_rewards=-1.01e+3]\u001b[A\n",
            "Training:  28%|██▊       | 558/2000 [05:34<15:41,  1.53iteration/s, mean_rewards=-467]    \u001b[A\n",
            "Training:  28%|██▊       | 559/2000 [05:34<13:55,  1.72iteration/s, mean_rewards=-467]\u001b[A\n",
            "Training:  28%|██▊       | 559/2000 [05:34<13:55,  1.72iteration/s, mean_rewards=-631]\u001b[A\n",
            "Training:  28%|██▊       | 560/2000 [05:35<13:33,  1.77iteration/s, mean_rewards=-631]\u001b[A\n",
            "Training:  28%|██▊       | 560/2000 [05:35<13:33,  1.77iteration/s, mean_rewards=-587]\u001b[A\n",
            "Training:  28%|██▊       | 561/2000 [05:35<12:23,  1.93iteration/s, mean_rewards=-587]\u001b[A\n",
            "Training:  28%|██▊       | 561/2000 [05:35<12:23,  1.93iteration/s, mean_rewards=-542]\u001b[A\n",
            "Training:  28%|██▊       | 562/2000 [05:36<12:16,  1.95iteration/s, mean_rewards=-542]\u001b[A\n",
            "Training:  28%|██▊       | 562/2000 [05:36<12:16,  1.95iteration/s, mean_rewards=-824]\u001b[A\n",
            "Training:  28%|██▊       | 563/2000 [05:36<14:58,  1.60iteration/s, mean_rewards=-824]\u001b[A\n",
            "Training:  28%|██▊       | 563/2000 [05:38<14:58,  1.60iteration/s, mean_rewards=-2.15e+3]\u001b[A\n",
            "Training:  28%|██▊       | 564/2000 [05:38<22:00,  1.09iteration/s, mean_rewards=-2.15e+3]\u001b[A\n",
            "Training:  28%|██▊       | 564/2000 [05:39<22:00,  1.09iteration/s, mean_rewards=-919]    \u001b[A\n",
            "Training:  28%|██▊       | 565/2000 [05:39<20:23,  1.17iteration/s, mean_rewards=-919]\u001b[A\n",
            "Training:  28%|██▊       | 565/2000 [05:39<20:23,  1.17iteration/s, mean_rewards=-973]\u001b[A\n",
            "Training:  28%|██▊       | 566/2000 [05:39<18:51,  1.27iteration/s, mean_rewards=-973]\u001b[A\n",
            "Training:  28%|██▊       | 566/2000 [05:41<18:51,  1.27iteration/s, mean_rewards=-2.55e+3]\u001b[A\n",
            "Training:  28%|██▊       | 567/2000 [05:41<24:39,  1.03s/iteration, mean_rewards=-2.55e+3]\u001b[A\n",
            "Training:  28%|██▊       | 567/2000 [05:41<24:39,  1.03s/iteration, mean_rewards=-808]    \u001b[A\n",
            "Training:  28%|██▊       | 568/2000 [05:42<21:45,  1.10iteration/s, mean_rewards=-808]\u001b[A\n",
            "Training:  28%|██▊       | 568/2000 [05:42<21:45,  1.10iteration/s, mean_rewards=-919]\u001b[A\n",
            "Training:  28%|██▊       | 569/2000 [05:42<20:29,  1.16iteration/s, mean_rewards=-919]\u001b[A\n",
            "Training:  28%|██▊       | 569/2000 [05:43<20:29,  1.16iteration/s, mean_rewards=-454]\u001b[A\n",
            "Training:  28%|██▊       | 570/2000 [05:43<17:32,  1.36iteration/s, mean_rewards=-454]\u001b[A\n",
            "Training:  28%|██▊       | 570/2000 [05:43<17:32,  1.36iteration/s, mean_rewards=-543]\u001b[A\n",
            "Training:  29%|██▊       | 571/2000 [05:43<15:15,  1.56iteration/s, mean_rewards=-543]\u001b[A\n",
            "Training:  29%|██▊       | 571/2000 [05:44<15:15,  1.56iteration/s, mean_rewards=-976]\u001b[A\n",
            "Training:  29%|██▊       | 572/2000 [05:44<15:52,  1.50iteration/s, mean_rewards=-976]\u001b[A\n",
            "Training:  29%|██▊       | 572/2000 [05:45<15:52,  1.50iteration/s, mean_rewards=-1.26e+3]\u001b[A\n",
            "Training:  29%|██▊       | 573/2000 [05:45<17:28,  1.36iteration/s, mean_rewards=-1.26e+3]\u001b[A\n",
            "Training:  29%|██▊       | 573/2000 [05:46<17:28,  1.36iteration/s, mean_rewards=-1.55e+3]\u001b[A\n",
            "Training:  29%|██▊       | 574/2000 [05:46<20:14,  1.17iteration/s, mean_rewards=-1.55e+3]\u001b[A\n",
            "Training:  29%|██▊       | 574/2000 [05:46<20:14,  1.17iteration/s, mean_rewards=-518]    \u001b[A\n",
            "Training:  29%|██▉       | 575/2000 [05:46<17:18,  1.37iteration/s, mean_rewards=-518]\u001b[A\n",
            "Training:  29%|██▉       | 575/2000 [05:47<17:18,  1.37iteration/s, mean_rewards=-727]\u001b[A\n",
            "Training:  29%|██▉       | 576/2000 [05:47<15:36,  1.52iteration/s, mean_rewards=-727]\u001b[A\n",
            "Training:  29%|██▉       | 576/2000 [05:47<15:36,  1.52iteration/s, mean_rewards=-793]\u001b[A\n",
            "Training:  29%|██▉       | 577/2000 [05:48<15:50,  1.50iteration/s, mean_rewards=-793]\u001b[A\n",
            "Training:  29%|██▉       | 577/2000 [05:48<15:50,  1.50iteration/s, mean_rewards=-1.04e+3]\u001b[A\n",
            "Training:  29%|██▉       | 578/2000 [05:49<19:14,  1.23iteration/s, mean_rewards=-1.04e+3]\u001b[A\n",
            "Training:  29%|██▉       | 578/2000 [05:49<19:14,  1.23iteration/s, mean_rewards=-597]    \u001b[A\n",
            "Training:  29%|██▉       | 579/2000 [05:49<17:47,  1.33iteration/s, mean_rewards=-597]\u001b[A\n",
            "Training:  29%|██▉       | 579/2000 [05:50<17:47,  1.33iteration/s, mean_rewards=-627]\u001b[A\n",
            "Training:  29%|██▉       | 580/2000 [05:50<18:18,  1.29iteration/s, mean_rewards=-627]\u001b[A\n",
            "Training:  29%|██▉       | 580/2000 [05:51<18:18,  1.29iteration/s, mean_rewards=-2.39e+3]\u001b[A\n",
            "Training:  29%|██▉       | 581/2000 [05:52<22:20,  1.06iteration/s, mean_rewards=-2.39e+3]\u001b[A\n",
            "Training:  29%|██▉       | 581/2000 [05:52<22:20,  1.06iteration/s, mean_rewards=-466]    \u001b[A\n",
            "Training:  29%|██▉       | 582/2000 [05:52<19:10,  1.23iteration/s, mean_rewards=-466]\u001b[A\n",
            "Training:  29%|██▉       | 582/2000 [05:53<19:10,  1.23iteration/s, mean_rewards=-909]\u001b[A\n",
            "Training:  29%|██▉       | 583/2000 [05:53<18:30,  1.28iteration/s, mean_rewards=-909]\u001b[A\n",
            "Training:  29%|██▉       | 583/2000 [05:53<18:30,  1.28iteration/s, mean_rewards=-873]\u001b[A\n",
            "Training:  29%|██▉       | 584/2000 [05:53<17:55,  1.32iteration/s, mean_rewards=-873]\u001b[A\n",
            "Training:  29%|██▉       | 584/2000 [05:54<17:55,  1.32iteration/s, mean_rewards=-737]\u001b[A\n",
            "Training:  29%|██▉       | 585/2000 [05:54<16:58,  1.39iteration/s, mean_rewards=-737]\u001b[A\n",
            "Training:  29%|██▉       | 585/2000 [05:54<16:58,  1.39iteration/s, mean_rewards=-515]\u001b[A\n",
            "Training:  29%|██▉       | 586/2000 [05:55<15:16,  1.54iteration/s, mean_rewards=-515]\u001b[A\n",
            "Training:  29%|██▉       | 586/2000 [05:55<15:16,  1.54iteration/s, mean_rewards=-667]\u001b[A\n",
            "Training:  29%|██▉       | 587/2000 [05:55<15:08,  1.56iteration/s, mean_rewards=-667]\u001b[A\n",
            "Training:  29%|██▉       | 587/2000 [05:56<15:08,  1.56iteration/s, mean_rewards=-582]\u001b[A\n",
            "Training:  29%|██▉       | 588/2000 [05:56<14:22,  1.64iteration/s, mean_rewards=-582]\u001b[A\n",
            "Training:  29%|██▉       | 588/2000 [05:56<14:22,  1.64iteration/s, mean_rewards=-450]\u001b[A\n",
            "Training:  29%|██▉       | 589/2000 [05:56<12:57,  1.82iteration/s, mean_rewards=-450]\u001b[A\n",
            "Training:  29%|██▉       | 589/2000 [05:57<12:57,  1.82iteration/s, mean_rewards=-770]\u001b[A\n",
            "Training:  30%|██▉       | 590/2000 [05:57<13:37,  1.72iteration/s, mean_rewards=-770]\u001b[A\n",
            "Training:  30%|██▉       | 590/2000 [05:57<13:37,  1.72iteration/s, mean_rewards=-1.06e+3]\u001b[A\n",
            "Training:  30%|██▉       | 591/2000 [05:58<15:11,  1.55iteration/s, mean_rewards=-1.06e+3]\u001b[A\n",
            "Training:  30%|██▉       | 591/2000 [05:58<15:11,  1.55iteration/s, mean_rewards=-784]    \u001b[A\n",
            "Training:  30%|██▉       | 592/2000 [05:58<14:45,  1.59iteration/s, mean_rewards=-784]\u001b[A\n",
            "Training:  30%|██▉       | 592/2000 [05:59<14:45,  1.59iteration/s, mean_rewards=-1.23e+3]\u001b[A\n",
            "Training:  30%|██▉       | 593/2000 [05:59<17:39,  1.33iteration/s, mean_rewards=-1.23e+3]\u001b[A\n",
            "Training:  30%|██▉       | 593/2000 [06:00<17:39,  1.33iteration/s, mean_rewards=-1.84e+3]\u001b[A\n",
            "Training:  30%|██▉       | 594/2000 [06:00<20:10,  1.16iteration/s, mean_rewards=-1.84e+3]\u001b[A\n",
            "Training:  30%|██▉       | 594/2000 [06:01<20:10,  1.16iteration/s, mean_rewards=-844]    \u001b[A\n",
            "Training:  30%|██▉       | 595/2000 [06:01<20:39,  1.13iteration/s, mean_rewards=-844]\u001b[A\n",
            "Training:  30%|██▉       | 595/2000 [06:02<20:39,  1.13iteration/s, mean_rewards=-860]\u001b[A\n",
            "Training:  30%|██▉       | 596/2000 [06:02<20:01,  1.17iteration/s, mean_rewards=-860]\u001b[A\n",
            "Training:  30%|██▉       | 596/2000 [06:03<20:01,  1.17iteration/s, mean_rewards=-869]\u001b[A\n",
            "Training:  30%|██▉       | 597/2000 [06:03<20:49,  1.12iteration/s, mean_rewards=-869]\u001b[A\n",
            "Training:  30%|██▉       | 597/2000 [06:04<20:49,  1.12iteration/s, mean_rewards=-2.23e+3]\u001b[A\n",
            "Training:  30%|██▉       | 598/2000 [06:04<24:55,  1.07s/iteration, mean_rewards=-2.23e+3]\u001b[A\n",
            "Training:  30%|██▉       | 598/2000 [06:05<24:55,  1.07s/iteration, mean_rewards=-723]    \u001b[A\n",
            "Training:  30%|██▉       | 599/2000 [06:05<21:21,  1.09iteration/s, mean_rewards=-723]\u001b[A\n",
            "Training:  30%|██▉       | 599/2000 [06:05<21:21,  1.09iteration/s, mean_rewards=-618]\u001b[A\n",
            "Training:  30%|███       | 600/2000 [06:06<18:51,  1.24iteration/s, mean_rewards=-618]\u001b[A\n",
            "Training:  30%|███       | 600/2000 [06:06<18:51,  1.24iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  30%|███       | 601/2000 [06:06<16:07,  1.45iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  30%|███       | 601/2000 [06:06<16:07,  1.45iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  30%|███       | 602/2000 [06:06<13:33,  1.72iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  30%|███       | 602/2000 [06:07<13:33,  1.72iteration/s, mean_rewards=-168]\u001b[A\n",
            "Training:  30%|███       | 603/2000 [06:07<12:32,  1.86iteration/s, mean_rewards=-168]\u001b[A\n",
            "Training:  30%|███       | 603/2000 [06:07<12:32,  1.86iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  30%|███       | 604/2000 [06:07<11:15,  2.07iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  30%|███       | 604/2000 [06:07<11:15,  2.07iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  30%|███       | 605/2000 [06:07<10:03,  2.31iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  30%|███       | 605/2000 [06:08<10:03,  2.31iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  30%|███       | 606/2000 [06:08<09:33,  2.43iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  30%|███       | 606/2000 [06:08<09:33,  2.43iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  30%|███       | 607/2000 [06:08<09:10,  2.53iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  30%|███       | 607/2000 [06:08<09:10,  2.53iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  30%|███       | 608/2000 [06:08<08:34,  2.71iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  30%|███       | 608/2000 [06:09<08:34,  2.71iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  30%|███       | 609/2000 [06:09<08:08,  2.85iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  30%|███       | 609/2000 [06:09<08:08,  2.85iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  30%|███       | 610/2000 [06:09<08:17,  2.80iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  30%|███       | 610/2000 [06:09<08:17,  2.80iteration/s, mean_rewards=-116]\u001b[A\n",
            "Training:  31%|███       | 611/2000 [06:10<08:28,  2.73iteration/s, mean_rewards=-116]\u001b[A\n",
            "Training:  31%|███       | 611/2000 [06:10<08:28,  2.73iteration/s, mean_rewards=-52.1]\u001b[A\n",
            "Training:  31%|███       | 612/2000 [06:10<08:23,  2.76iteration/s, mean_rewards=-52.1]\u001b[A\n",
            "Training:  31%|███       | 612/2000 [06:10<08:23,  2.76iteration/s, mean_rewards=-149] \u001b[A\n",
            "Training:  31%|███       | 613/2000 [06:10<08:22,  2.76iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  31%|███       | 613/2000 [06:11<08:22,  2.76iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  31%|███       | 614/2000 [06:11<08:31,  2.71iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  31%|███       | 614/2000 [06:11<08:31,  2.71iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  31%|███       | 615/2000 [06:11<08:01,  2.88iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  31%|███       | 615/2000 [06:11<08:01,  2.88iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  31%|███       | 616/2000 [06:11<07:43,  2.99iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  31%|███       | 616/2000 [06:11<07:43,  2.99iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  31%|███       | 617/2000 [06:12<07:57,  2.90iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  31%|███       | 617/2000 [06:12<07:57,  2.90iteration/s, mean_rewards=-169]\u001b[A\n",
            "Training:  31%|███       | 618/2000 [06:12<08:25,  2.73iteration/s, mean_rewards=-169]\u001b[A\n",
            "Training:  31%|███       | 618/2000 [06:12<08:25,  2.73iteration/s, mean_rewards=-79.2]\u001b[A\n",
            "Training:  31%|███       | 619/2000 [06:12<08:58,  2.57iteration/s, mean_rewards=-79.2]\u001b[A\n",
            "Training:  31%|███       | 619/2000 [06:13<08:58,  2.57iteration/s, mean_rewards=-121] \u001b[A\n",
            "Training:  31%|███       | 620/2000 [06:13<09:21,  2.46iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  31%|███       | 620/2000 [06:13<09:21,  2.46iteration/s, mean_rewards=-91.3]\u001b[A\n",
            "Training:  31%|███       | 621/2000 [06:13<08:52,  2.59iteration/s, mean_rewards=-91.3]\u001b[A\n",
            "Training:  31%|███       | 621/2000 [06:13<08:52,  2.59iteration/s, mean_rewards=-122] \u001b[A\n",
            "Training:  31%|███       | 622/2000 [06:14<08:32,  2.69iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  31%|███       | 622/2000 [06:14<08:32,  2.69iteration/s, mean_rewards=-97.7]\u001b[A\n",
            "Training:  31%|███       | 623/2000 [06:14<09:24,  2.44iteration/s, mean_rewards=-97.7]\u001b[A\n",
            "Training:  31%|███       | 623/2000 [06:14<09:24,  2.44iteration/s, mean_rewards=-139] \u001b[A\n",
            "Training:  31%|███       | 624/2000 [06:14<09:12,  2.49iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:  31%|███       | 624/2000 [06:15<09:12,  2.49iteration/s, mean_rewards=-165]\u001b[A\n",
            "Training:  31%|███▏      | 625/2000 [06:15<09:53,  2.32iteration/s, mean_rewards=-165]\u001b[A\n",
            "Training:  31%|███▏      | 625/2000 [06:15<09:53,  2.32iteration/s, mean_rewards=-87.2]\u001b[A\n",
            "Training:  31%|███▏      | 626/2000 [06:15<10:15,  2.23iteration/s, mean_rewards=-87.2]\u001b[A\n",
            "Training:  31%|███▏      | 626/2000 [06:16<10:15,  2.23iteration/s, mean_rewards=-127] \u001b[A\n",
            "Training:  31%|███▏      | 627/2000 [06:16<10:35,  2.16iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  31%|███▏      | 627/2000 [06:16<10:35,  2.16iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  31%|███▏      | 628/2000 [06:16<10:31,  2.17iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  31%|███▏      | 628/2000 [06:17<10:31,  2.17iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  31%|███▏      | 629/2000 [06:17<10:19,  2.21iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  31%|███▏      | 629/2000 [06:17<10:19,  2.21iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  32%|███▏      | 630/2000 [06:17<09:26,  2.42iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  32%|███▏      | 630/2000 [06:17<09:26,  2.42iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  32%|███▏      | 631/2000 [06:18<09:21,  2.44iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  32%|███▏      | 631/2000 [06:18<09:21,  2.44iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  32%|███▏      | 632/2000 [06:18<09:08,  2.49iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  32%|███▏      | 632/2000 [06:18<09:08,  2.49iteration/s, mean_rewards=-54] \u001b[A\n",
            "Training:  32%|███▏      | 633/2000 [06:18<09:18,  2.45iteration/s, mean_rewards=-54]\u001b[A\n",
            "Training:  32%|███▏      | 633/2000 [06:19<09:18,  2.45iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:  32%|███▏      | 634/2000 [06:19<08:57,  2.54iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:  32%|███▏      | 634/2000 [06:19<08:57,  2.54iteration/s, mean_rewards=-45.9]\u001b[A\n",
            "Training:  32%|███▏      | 635/2000 [06:19<08:56,  2.55iteration/s, mean_rewards=-45.9]\u001b[A\n",
            "Training:  32%|███▏      | 635/2000 [06:19<08:56,  2.55iteration/s, mean_rewards=-149] \u001b[A\n",
            "Training:  32%|███▏      | 636/2000 [06:20<08:53,  2.56iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  32%|███▏      | 636/2000 [06:20<08:53,  2.56iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  32%|███▏      | 637/2000 [06:20<08:45,  2.59iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  32%|███▏      | 637/2000 [06:20<08:45,  2.59iteration/s, mean_rewards=-216]\u001b[A\n",
            "Training:  32%|███▏      | 638/2000 [06:20<09:06,  2.49iteration/s, mean_rewards=-216]\u001b[A\n",
            "Training:  32%|███▏      | 638/2000 [06:21<09:06,  2.49iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  32%|███▏      | 639/2000 [06:21<08:46,  2.58iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  32%|███▏      | 639/2000 [06:21<08:46,  2.58iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  32%|███▏      | 640/2000 [06:21<09:05,  2.50iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  32%|███▏      | 640/2000 [06:21<09:05,  2.50iteration/s, mean_rewards=-73.3]\u001b[A\n",
            "Training:  32%|███▏      | 641/2000 [06:22<09:00,  2.51iteration/s, mean_rewards=-73.3]\u001b[A\n",
            "Training:  32%|███▏      | 641/2000 [06:22<09:00,  2.51iteration/s, mean_rewards=-128] \u001b[A\n",
            "Training:  32%|███▏      | 642/2000 [06:22<08:51,  2.55iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  32%|███▏      | 642/2000 [06:22<08:51,  2.55iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  32%|███▏      | 643/2000 [06:22<08:24,  2.69iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  32%|███▏      | 643/2000 [06:22<08:24,  2.69iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  32%|███▏      | 644/2000 [06:23<08:26,  2.68iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  32%|███▏      | 644/2000 [06:23<08:26,  2.68iteration/s, mean_rewards=-105]\u001b[A\n",
            "Training:  32%|███▏      | 645/2000 [06:23<08:37,  2.62iteration/s, mean_rewards=-105]\u001b[A\n",
            "Training:  32%|███▏      | 645/2000 [06:23<08:37,  2.62iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  32%|███▏      | 646/2000 [06:23<08:51,  2.55iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  32%|███▏      | 646/2000 [06:24<08:51,  2.55iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  32%|███▏      | 647/2000 [06:24<08:34,  2.63iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  32%|███▏      | 647/2000 [06:24<08:34,  2.63iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  32%|███▏      | 648/2000 [06:24<08:17,  2.72iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  32%|███▏      | 648/2000 [06:24<08:17,  2.72iteration/s, mean_rewards=-162]\u001b[A\n",
            "Training:  32%|███▏      | 649/2000 [06:24<08:10,  2.75iteration/s, mean_rewards=-162]\u001b[A\n",
            "Training:  32%|███▏      | 649/2000 [06:25<08:10,  2.75iteration/s, mean_rewards=-174]\u001b[A\n",
            "Training:  32%|███▎      | 650/2000 [06:25<08:16,  2.72iteration/s, mean_rewards=-174]\u001b[A\n",
            "Training:  32%|███▎      | 650/2000 [06:25<08:16,  2.72iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  33%|███▎      | 651/2000 [06:25<08:16,  2.72iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  33%|███▎      | 651/2000 [06:25<08:16,  2.72iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  33%|███▎      | 652/2000 [06:26<08:17,  2.71iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  33%|███▎      | 652/2000 [06:26<08:17,  2.71iteration/s, mean_rewards=-55.2]\u001b[A\n",
            "Training:  33%|███▎      | 653/2000 [06:26<08:49,  2.54iteration/s, mean_rewards=-55.2]\u001b[A\n",
            "Training:  33%|███▎      | 653/2000 [06:26<08:49,  2.54iteration/s, mean_rewards=-129] \u001b[A\n",
            "Training:  33%|███▎      | 654/2000 [06:26<09:05,  2.47iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  33%|███▎      | 654/2000 [06:27<09:05,  2.47iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  33%|███▎      | 655/2000 [06:27<09:00,  2.49iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  33%|███▎      | 655/2000 [06:27<09:00,  2.49iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  33%|███▎      | 656/2000 [06:27<08:52,  2.52iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  33%|███▎      | 656/2000 [06:28<08:52,  2.52iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  33%|███▎      | 657/2000 [06:28<09:58,  2.24iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  33%|███▎      | 657/2000 [06:28<09:58,  2.24iteration/s, mean_rewards=-165]\u001b[A\n",
            "Training:  33%|███▎      | 658/2000 [06:28<10:32,  2.12iteration/s, mean_rewards=-165]\u001b[A\n",
            "Training:  33%|███▎      | 658/2000 [06:29<10:32,  2.12iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  33%|███▎      | 659/2000 [06:29<10:57,  2.04iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  33%|███▎      | 659/2000 [06:29<10:57,  2.04iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  33%|███▎      | 660/2000 [06:29<10:28,  2.13iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  33%|███▎      | 660/2000 [06:29<10:28,  2.13iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  33%|███▎      | 661/2000 [06:30<09:26,  2.36iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  33%|███▎      | 661/2000 [06:30<09:26,  2.36iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  33%|███▎      | 662/2000 [06:30<08:57,  2.49iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  33%|███▎      | 662/2000 [06:30<08:57,  2.49iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:  33%|███▎      | 663/2000 [06:30<08:41,  2.56iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:  33%|███▎      | 663/2000 [06:31<08:41,  2.56iteration/s, mean_rewards=-119]\u001b[A\n",
            "Training:  33%|███▎      | 664/2000 [06:31<08:29,  2.62iteration/s, mean_rewards=-119]\u001b[A\n",
            "Training:  33%|███▎      | 664/2000 [06:31<08:29,  2.62iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  33%|███▎      | 665/2000 [06:31<08:31,  2.61iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  33%|███▎      | 665/2000 [06:31<08:31,  2.61iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  33%|███▎      | 666/2000 [06:31<08:03,  2.76iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  33%|███▎      | 666/2000 [06:32<08:03,  2.76iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  33%|███▎      | 667/2000 [06:32<07:39,  2.90iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  33%|███▎      | 667/2000 [06:32<07:39,  2.90iteration/s, mean_rewards=-112]\u001b[A\n",
            "Training:  33%|███▎      | 668/2000 [06:32<07:47,  2.85iteration/s, mean_rewards=-112]\u001b[A\n",
            "Training:  33%|███▎      | 668/2000 [06:32<07:47,  2.85iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  33%|███▎      | 669/2000 [06:32<07:51,  2.82iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  33%|███▎      | 669/2000 [06:33<07:51,  2.82iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  34%|███▎      | 670/2000 [06:33<07:32,  2.94iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  34%|███▎      | 670/2000 [06:33<07:32,  2.94iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  34%|███▎      | 671/2000 [06:33<07:27,  2.97iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  34%|███▎      | 671/2000 [06:33<07:27,  2.97iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  34%|███▎      | 672/2000 [06:33<07:41,  2.88iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  34%|███▎      | 672/2000 [06:34<07:41,  2.88iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  34%|███▎      | 673/2000 [06:34<07:43,  2.86iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  34%|███▎      | 673/2000 [06:34<07:43,  2.86iteration/s, mean_rewards=-182]\u001b[A\n",
            "Training:  34%|███▎      | 674/2000 [06:34<08:00,  2.76iteration/s, mean_rewards=-182]\u001b[A\n",
            "Training:  34%|███▎      | 674/2000 [06:34<08:00,  2.76iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  34%|███▍      | 675/2000 [06:34<07:46,  2.84iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  34%|███▍      | 675/2000 [06:35<07:46,  2.84iteration/s, mean_rewards=-213]\u001b[A\n",
            "Training:  34%|███▍      | 676/2000 [06:35<08:20,  2.65iteration/s, mean_rewards=-213]\u001b[A\n",
            "Training:  34%|███▍      | 676/2000 [06:35<08:20,  2.65iteration/s, mean_rewards=-173]\u001b[A\n",
            "Training:  34%|███▍      | 677/2000 [06:35<08:39,  2.55iteration/s, mean_rewards=-173]\u001b[A\n",
            "Training:  34%|███▍      | 677/2000 [06:36<08:39,  2.55iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  34%|███▍      | 678/2000 [06:36<08:09,  2.70iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  34%|███▍      | 678/2000 [06:36<08:09,  2.70iteration/s, mean_rewards=-167]\u001b[A\n",
            "Training:  34%|███▍      | 679/2000 [06:36<08:17,  2.66iteration/s, mean_rewards=-167]\u001b[A\n",
            "Training:  34%|███▍      | 679/2000 [06:36<08:17,  2.66iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  34%|███▍      | 680/2000 [06:36<08:24,  2.62iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  34%|███▍      | 680/2000 [06:37<08:24,  2.62iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  34%|███▍      | 681/2000 [06:37<08:23,  2.62iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  34%|███▍      | 681/2000 [06:37<08:23,  2.62iteration/s, mean_rewards=-157]\u001b[A\n",
            "Training:  34%|███▍      | 682/2000 [06:37<08:27,  2.60iteration/s, mean_rewards=-157]\u001b[A\n",
            "Training:  34%|███▍      | 682/2000 [06:37<08:27,  2.60iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  34%|███▍      | 683/2000 [06:38<08:15,  2.66iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  34%|███▍      | 683/2000 [06:38<08:15,  2.66iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  34%|███▍      | 684/2000 [06:38<08:06,  2.70iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  34%|███▍      | 684/2000 [06:38<08:06,  2.70iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  34%|███▍      | 685/2000 [06:38<08:11,  2.67iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  34%|███▍      | 685/2000 [06:39<08:11,  2.67iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  34%|███▍      | 686/2000 [06:39<08:04,  2.71iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  34%|███▍      | 686/2000 [06:39<08:04,  2.71iteration/s, mean_rewards=-62.2]\u001b[A\n",
            "Training:  34%|███▍      | 687/2000 [06:39<07:56,  2.76iteration/s, mean_rewards=-62.2]\u001b[A\n",
            "Training:  34%|███▍      | 687/2000 [06:39<07:56,  2.76iteration/s, mean_rewards=-138] \u001b[A\n",
            "Training:  34%|███▍      | 688/2000 [06:40<08:40,  2.52iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:  34%|███▍      | 688/2000 [06:40<08:40,  2.52iteration/s, mean_rewards=-78.8]\u001b[A\n",
            "Training:  34%|███▍      | 689/2000 [06:40<08:31,  2.56iteration/s, mean_rewards=-78.8]\u001b[A\n",
            "Training:  34%|███▍      | 689/2000 [06:40<08:31,  2.56iteration/s, mean_rewards=-146] \u001b[A\n",
            "Training:  34%|███▍      | 690/2000 [06:40<08:31,  2.56iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  34%|███▍      | 690/2000 [06:41<08:31,  2.56iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  35%|███▍      | 691/2000 [06:41<09:08,  2.39iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  35%|███▍      | 691/2000 [06:41<09:08,  2.39iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  35%|███▍      | 692/2000 [06:41<09:11,  2.37iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  35%|███▍      | 692/2000 [06:42<09:11,  2.37iteration/s, mean_rewards=-52] \u001b[A\n",
            "Training:  35%|███▍      | 693/2000 [06:42<09:36,  2.27iteration/s, mean_rewards=-52]\u001b[A\n",
            "Training:  35%|███▍      | 693/2000 [06:42<09:36,  2.27iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  35%|███▍      | 694/2000 [06:42<09:10,  2.37iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  35%|███▍      | 694/2000 [06:42<09:10,  2.37iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  35%|███▍      | 695/2000 [06:42<09:13,  2.36iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  35%|███▍      | 695/2000 [06:43<09:13,  2.36iteration/s, mean_rewards=-115]\u001b[A\n",
            "Training:  35%|███▍      | 696/2000 [06:43<08:50,  2.46iteration/s, mean_rewards=-115]\u001b[A\n",
            "Training:  35%|███▍      | 696/2000 [06:43<08:50,  2.46iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  35%|███▍      | 697/2000 [06:43<08:39,  2.51iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  35%|███▍      | 697/2000 [06:43<08:39,  2.51iteration/s, mean_rewards=-76.3]\u001b[A\n",
            "Training:  35%|███▍      | 698/2000 [06:44<08:29,  2.56iteration/s, mean_rewards=-76.3]\u001b[A\n",
            "Training:  35%|███▍      | 698/2000 [06:44<08:29,  2.56iteration/s, mean_rewards=-165] \u001b[A\n",
            "Training:  35%|███▍      | 699/2000 [06:44<08:24,  2.58iteration/s, mean_rewards=-165]\u001b[A\n",
            "Training:  35%|███▍      | 699/2000 [06:44<08:24,  2.58iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  35%|███▌      | 700/2000 [06:44<08:13,  2.64iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  35%|███▌      | 700/2000 [06:45<08:13,  2.64iteration/s, mean_rewards=-152]\u001b[A\n",
            "Training:  35%|███▌      | 701/2000 [06:45<08:05,  2.67iteration/s, mean_rewards=-152]\u001b[A\n",
            "Training:  35%|███▌      | 701/2000 [06:45<08:05,  2.67iteration/s, mean_rewards=-116]\u001b[A\n",
            "Training:  35%|███▌      | 702/2000 [06:45<07:47,  2.78iteration/s, mean_rewards=-116]\u001b[A\n",
            "Training:  35%|███▌      | 702/2000 [06:45<07:47,  2.78iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  35%|███▌      | 703/2000 [06:45<07:57,  2.72iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  35%|███▌      | 703/2000 [06:46<07:57,  2.72iteration/s, mean_rewards=-119]\u001b[A\n",
            "Training:  35%|███▌      | 704/2000 [06:46<08:07,  2.66iteration/s, mean_rewards=-119]\u001b[A\n",
            "Training:  35%|███▌      | 704/2000 [06:46<08:07,  2.66iteration/s, mean_rewards=-56.5]\u001b[A\n",
            "Training:  35%|███▌      | 705/2000 [06:46<08:03,  2.68iteration/s, mean_rewards=-56.5]\u001b[A\n",
            "Training:  35%|███▌      | 705/2000 [06:46<08:03,  2.68iteration/s, mean_rewards=-144] \u001b[A\n",
            "Training:  35%|███▌      | 706/2000 [06:47<08:12,  2.63iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  35%|███▌      | 706/2000 [06:47<08:12,  2.63iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  35%|███▌      | 707/2000 [06:47<08:08,  2.65iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  35%|███▌      | 707/2000 [06:47<08:08,  2.65iteration/s, mean_rewards=-58.7]\u001b[A\n",
            "Training:  35%|███▌      | 708/2000 [06:47<08:19,  2.58iteration/s, mean_rewards=-58.7]\u001b[A\n",
            "Training:  35%|███▌      | 708/2000 [06:48<08:19,  2.58iteration/s, mean_rewards=-150] \u001b[A\n",
            "Training:  35%|███▌      | 709/2000 [06:48<08:07,  2.65iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  35%|███▌      | 709/2000 [06:48<08:07,  2.65iteration/s, mean_rewards=-171]\u001b[A\n",
            "Training:  36%|███▌      | 710/2000 [06:48<08:24,  2.55iteration/s, mean_rewards=-171]\u001b[A\n",
            "Training:  36%|███▌      | 710/2000 [06:48<08:24,  2.55iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  36%|███▌      | 711/2000 [06:48<07:55,  2.71iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  36%|███▌      | 711/2000 [06:49<07:55,  2.71iteration/s, mean_rewards=-152]\u001b[A\n",
            "Training:  36%|███▌      | 712/2000 [06:49<07:40,  2.79iteration/s, mean_rewards=-152]\u001b[A\n",
            "Training:  36%|███▌      | 712/2000 [06:49<07:40,  2.79iteration/s, mean_rewards=-68.7]\u001b[A\n",
            "Training:  36%|███▌      | 713/2000 [06:49<08:13,  2.61iteration/s, mean_rewards=-68.7]\u001b[A\n",
            "Training:  36%|███▌      | 713/2000 [06:49<08:13,  2.61iteration/s, mean_rewards=-91.2]\u001b[A\n",
            "Training:  36%|███▌      | 714/2000 [06:50<08:05,  2.65iteration/s, mean_rewards=-91.2]\u001b[A\n",
            "Training:  36%|███▌      | 714/2000 [06:50<08:05,  2.65iteration/s, mean_rewards=-90.5]\u001b[A\n",
            "Training:  36%|███▌      | 715/2000 [06:50<08:28,  2.53iteration/s, mean_rewards=-90.5]\u001b[A\n",
            "Training:  36%|███▌      | 715/2000 [06:50<08:28,  2.53iteration/s, mean_rewards=-140] \u001b[A\n",
            "Training:  36%|███▌      | 716/2000 [06:50<08:18,  2.58iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  36%|███▌      | 716/2000 [06:51<08:18,  2.58iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  36%|███▌      | 717/2000 [06:51<08:22,  2.55iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  36%|███▌      | 717/2000 [06:51<08:22,  2.55iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  36%|███▌      | 718/2000 [06:51<08:10,  2.61iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  36%|███▌      | 718/2000 [06:51<08:10,  2.61iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  36%|███▌      | 719/2000 [06:51<07:48,  2.74iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  36%|███▌      | 719/2000 [06:52<07:48,  2.74iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  36%|███▌      | 720/2000 [06:52<08:34,  2.49iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  36%|███▌      | 720/2000 [06:52<08:34,  2.49iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  36%|███▌      | 721/2000 [06:52<08:55,  2.39iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  36%|███▌      | 721/2000 [06:53<08:55,  2.39iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  36%|███▌      | 722/2000 [06:53<08:45,  2.43iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  36%|███▌      | 722/2000 [06:53<08:45,  2.43iteration/s, mean_rewards=-106]\u001b[A\n",
            "Training:  36%|███▌      | 723/2000 [06:53<09:16,  2.30iteration/s, mean_rewards=-106]\u001b[A\n",
            "Training:  36%|███▌      | 723/2000 [06:54<09:16,  2.30iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  36%|███▌      | 724/2000 [06:54<09:05,  2.34iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  36%|███▌      | 724/2000 [06:54<09:05,  2.34iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  36%|███▋      | 725/2000 [06:54<10:01,  2.12iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  36%|███▋      | 725/2000 [06:55<10:01,  2.12iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  36%|███▋      | 726/2000 [06:55<09:31,  2.23iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  36%|███▋      | 726/2000 [06:55<09:31,  2.23iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  36%|███▋      | 727/2000 [06:55<09:25,  2.25iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  36%|███▋      | 727/2000 [06:55<09:25,  2.25iteration/s, mean_rewards=-159]\u001b[A\n",
            "Training:  36%|███▋      | 728/2000 [06:55<08:42,  2.44iteration/s, mean_rewards=-159]\u001b[A\n",
            "Training:  36%|███▋      | 728/2000 [06:56<08:42,  2.44iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:  36%|███▋      | 729/2000 [06:56<08:21,  2.54iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:  36%|███▋      | 729/2000 [06:56<08:21,  2.54iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  36%|███▋      | 730/2000 [06:56<08:20,  2.54iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  36%|███▋      | 730/2000 [06:56<08:20,  2.54iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  37%|███▋      | 731/2000 [06:57<07:46,  2.72iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  37%|███▋      | 731/2000 [06:57<07:46,  2.72iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  37%|███▋      | 732/2000 [06:57<07:49,  2.70iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  37%|███▋      | 732/2000 [06:57<07:49,  2.70iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:  37%|███▋      | 733/2000 [06:57<08:10,  2.59iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:  37%|███▋      | 733/2000 [06:58<08:10,  2.59iteration/s, mean_rewards=-63.9]\u001b[A\n",
            "Training:  37%|███▋      | 734/2000 [06:58<08:25,  2.51iteration/s, mean_rewards=-63.9]\u001b[A\n",
            "Training:  37%|███▋      | 734/2000 [06:58<08:25,  2.51iteration/s, mean_rewards=-131] \u001b[A\n",
            "Training:  37%|███▋      | 735/2000 [06:58<08:24,  2.51iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  37%|███▋      | 735/2000 [06:58<08:24,  2.51iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  37%|███▋      | 736/2000 [06:59<08:11,  2.57iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  37%|███▋      | 736/2000 [06:59<08:11,  2.57iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  37%|███▋      | 737/2000 [06:59<07:42,  2.73iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  37%|███▋      | 737/2000 [06:59<07:42,  2.73iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  37%|███▋      | 738/2000 [06:59<08:09,  2.58iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  37%|███▋      | 738/2000 [06:59<08:09,  2.58iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  37%|███▋      | 739/2000 [07:00<07:42,  2.72iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  37%|███▋      | 739/2000 [07:00<07:42,  2.72iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  37%|███▋      | 740/2000 [07:00<07:36,  2.76iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  37%|███▋      | 740/2000 [07:00<07:36,  2.76iteration/s, mean_rewards=-173]\u001b[A\n",
            "Training:  37%|███▋      | 741/2000 [07:00<07:50,  2.68iteration/s, mean_rewards=-173]\u001b[A\n",
            "Training:  37%|███▋      | 741/2000 [07:01<07:50,  2.68iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  37%|███▋      | 742/2000 [07:01<07:52,  2.66iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  37%|███▋      | 742/2000 [07:01<07:52,  2.66iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  37%|███▋      | 743/2000 [07:01<07:35,  2.76iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  37%|███▋      | 743/2000 [07:01<07:35,  2.76iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  37%|███▋      | 744/2000 [07:01<07:41,  2.72iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  37%|███▋      | 744/2000 [07:02<07:41,  2.72iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  37%|███▋      | 745/2000 [07:02<07:41,  2.72iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  37%|███▋      | 745/2000 [07:02<07:41,  2.72iteration/s, mean_rewards=-163]\u001b[A\n",
            "Training:  37%|███▋      | 746/2000 [07:02<08:07,  2.57iteration/s, mean_rewards=-163]\u001b[A\n",
            "Training:  37%|███▋      | 746/2000 [07:02<08:07,  2.57iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  37%|███▋      | 747/2000 [07:03<07:44,  2.70iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  37%|███▋      | 747/2000 [07:03<07:44,  2.70iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  37%|███▋      | 748/2000 [07:03<07:36,  2.75iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  37%|███▋      | 748/2000 [07:03<07:36,  2.75iteration/s, mean_rewards=-164]\u001b[A\n",
            "Training:  37%|███▋      | 749/2000 [07:03<07:48,  2.67iteration/s, mean_rewards=-164]\u001b[A\n",
            "Training:  37%|███▋      | 749/2000 [07:04<07:48,  2.67iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  38%|███▊      | 750/2000 [07:04<07:46,  2.68iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  38%|███▊      | 750/2000 [07:04<07:46,  2.68iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  38%|███▊      | 751/2000 [07:04<07:23,  2.81iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  38%|███▊      | 751/2000 [07:04<07:23,  2.81iteration/s, mean_rewards=-119]\u001b[A\n",
            "Training:  38%|███▊      | 752/2000 [07:04<07:35,  2.74iteration/s, mean_rewards=-119]\u001b[A\n",
            "Training:  38%|███▊      | 752/2000 [07:05<07:35,  2.74iteration/s, mean_rewards=-163]\u001b[A\n",
            "Training:  38%|███▊      | 753/2000 [07:05<07:41,  2.70iteration/s, mean_rewards=-163]\u001b[A\n",
            "Training:  38%|███▊      | 753/2000 [07:05<07:41,  2.70iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  38%|███▊      | 754/2000 [07:05<07:48,  2.66iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  38%|███▊      | 754/2000 [07:06<07:48,  2.66iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  38%|███▊      | 755/2000 [07:06<08:35,  2.41iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  38%|███▊      | 755/2000 [07:06<08:35,  2.41iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  38%|███▊      | 756/2000 [07:06<08:17,  2.50iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  38%|███▊      | 756/2000 [07:06<08:17,  2.50iteration/s, mean_rewards=-164]\u001b[A\n",
            "Training:  38%|███▊      | 757/2000 [07:07<08:53,  2.33iteration/s, mean_rewards=-164]\u001b[A\n",
            "Training:  38%|███▊      | 757/2000 [07:07<08:53,  2.33iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  38%|███▊      | 758/2000 [07:07<09:23,  2.20iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  38%|███▊      | 758/2000 [07:07<09:23,  2.20iteration/s, mean_rewards=-166]\u001b[A\n",
            "Training:  38%|███▊      | 759/2000 [07:08<09:56,  2.08iteration/s, mean_rewards=-166]\u001b[A\n",
            "Training:  38%|███▊      | 759/2000 [07:08<09:56,  2.08iteration/s, mean_rewards=-170]\u001b[A\n",
            "Training:  38%|███▊      | 760/2000 [07:08<09:46,  2.11iteration/s, mean_rewards=-170]\u001b[A\n",
            "Training:  38%|███▊      | 760/2000 [07:08<09:46,  2.11iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  38%|███▊      | 761/2000 [07:08<09:18,  2.22iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  38%|███▊      | 761/2000 [07:09<09:18,  2.22iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  38%|███▊      | 762/2000 [07:09<08:46,  2.35iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  38%|███▊      | 762/2000 [07:09<08:46,  2.35iteration/s, mean_rewards=-105]\u001b[A\n",
            "Training:  38%|███▊      | 763/2000 [07:09<08:29,  2.43iteration/s, mean_rewards=-105]\u001b[A\n",
            "Training:  38%|███▊      | 763/2000 [07:09<08:29,  2.43iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  38%|███▊      | 764/2000 [07:10<08:42,  2.37iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  38%|███▊      | 764/2000 [07:10<08:42,  2.37iteration/s, mean_rewards=-78.2]\u001b[A\n",
            "Training:  38%|███▊      | 765/2000 [07:10<08:19,  2.47iteration/s, mean_rewards=-78.2]\u001b[A\n",
            "Training:  38%|███▊      | 765/2000 [07:10<08:19,  2.47iteration/s, mean_rewards=-167] \u001b[A\n",
            "Training:  38%|███▊      | 766/2000 [07:10<08:05,  2.54iteration/s, mean_rewards=-167]\u001b[A\n",
            "Training:  38%|███▊      | 766/2000 [07:11<08:05,  2.54iteration/s, mean_rewards=-171]\u001b[A\n",
            "Training:  38%|███▊      | 767/2000 [07:11<08:02,  2.56iteration/s, mean_rewards=-171]\u001b[A\n",
            "Training:  38%|███▊      | 767/2000 [07:11<08:02,  2.56iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  38%|███▊      | 768/2000 [07:11<07:55,  2.59iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  38%|███▊      | 768/2000 [07:11<07:55,  2.59iteration/s, mean_rewards=-116]\u001b[A\n",
            "Training:  38%|███▊      | 769/2000 [07:11<07:25,  2.76iteration/s, mean_rewards=-116]\u001b[A\n",
            "Training:  38%|███▊      | 769/2000 [07:12<07:25,  2.76iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  38%|███▊      | 770/2000 [07:12<07:15,  2.83iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  38%|███▊      | 770/2000 [07:12<07:15,  2.83iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  39%|███▊      | 771/2000 [07:12<07:52,  2.60iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  39%|███▊      | 771/2000 [07:12<07:52,  2.60iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  39%|███▊      | 772/2000 [07:13<07:46,  2.63iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  39%|███▊      | 772/2000 [07:13<07:46,  2.63iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  39%|███▊      | 773/2000 [07:13<07:40,  2.66iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  39%|███▊      | 773/2000 [07:13<07:40,  2.66iteration/s, mean_rewards=-163]\u001b[A\n",
            "Training:  39%|███▊      | 774/2000 [07:13<07:41,  2.65iteration/s, mean_rewards=-163]\u001b[A\n",
            "Training:  39%|███▊      | 774/2000 [07:14<07:41,  2.65iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  39%|███▉      | 775/2000 [07:14<07:20,  2.78iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  39%|███▉      | 775/2000 [07:14<07:20,  2.78iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:  39%|███▉      | 776/2000 [07:14<07:07,  2.86iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:  39%|███▉      | 776/2000 [07:14<07:07,  2.86iteration/s, mean_rewards=-75] \u001b[A\n",
            "Training:  39%|███▉      | 777/2000 [07:14<07:38,  2.66iteration/s, mean_rewards=-75]\u001b[A\n",
            "Training:  39%|███▉      | 777/2000 [07:15<07:38,  2.66iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  39%|███▉      | 778/2000 [07:15<07:13,  2.82iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  39%|███▉      | 778/2000 [07:15<07:13,  2.82iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  39%|███▉      | 779/2000 [07:15<07:09,  2.84iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  39%|███▉      | 779/2000 [07:15<07:09,  2.84iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  39%|███▉      | 780/2000 [07:15<06:47,  2.99iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  39%|███▉      | 780/2000 [07:16<06:47,  2.99iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  39%|███▉      | 781/2000 [07:16<07:10,  2.83iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  39%|███▉      | 781/2000 [07:16<07:10,  2.83iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  39%|███▉      | 782/2000 [07:16<06:55,  2.93iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  39%|███▉      | 782/2000 [07:16<06:55,  2.93iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  39%|███▉      | 783/2000 [07:16<06:47,  2.98iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  39%|███▉      | 783/2000 [07:17<06:47,  2.98iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  39%|███▉      | 784/2000 [07:17<06:57,  2.92iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  39%|███▉      | 784/2000 [07:17<06:57,  2.92iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  39%|███▉      | 785/2000 [07:17<07:23,  2.74iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  39%|███▉      | 785/2000 [07:17<07:23,  2.74iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  39%|███▉      | 786/2000 [07:18<07:27,  2.71iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  39%|███▉      | 786/2000 [07:18<07:27,  2.71iteration/s, mean_rewards=-25.2]\u001b[A\n",
            "Training:  39%|███▉      | 787/2000 [07:18<08:43,  2.32iteration/s, mean_rewards=-25.2]\u001b[A\n",
            "Training:  39%|███▉      | 787/2000 [07:18<08:43,  2.32iteration/s, mean_rewards=-144] \u001b[A\n",
            "Training:  39%|███▉      | 788/2000 [07:19<08:44,  2.31iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  39%|███▉      | 788/2000 [07:19<08:44,  2.31iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  39%|███▉      | 789/2000 [07:19<08:19,  2.43iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  39%|███▉      | 789/2000 [07:19<08:19,  2.43iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  40%|███▉      | 790/2000 [07:19<08:27,  2.39iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  40%|███▉      | 790/2000 [07:20<08:27,  2.39iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  40%|███▉      | 791/2000 [07:20<08:21,  2.41iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  40%|███▉      | 791/2000 [07:20<08:21,  2.41iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  40%|███▉      | 792/2000 [07:20<08:51,  2.27iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  40%|███▉      | 792/2000 [07:21<08:51,  2.27iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  40%|███▉      | 793/2000 [07:21<08:30,  2.36iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  40%|███▉      | 793/2000 [07:21<08:30,  2.36iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  40%|███▉      | 794/2000 [07:21<08:08,  2.47iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  40%|███▉      | 794/2000 [07:21<08:08,  2.47iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  40%|███▉      | 795/2000 [07:21<07:32,  2.66iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  40%|███▉      | 795/2000 [07:22<07:32,  2.66iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  40%|███▉      | 796/2000 [07:22<07:40,  2.62iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  40%|███▉      | 796/2000 [07:22<07:40,  2.62iteration/s, mean_rewards=-105]\u001b[A\n",
            "Training:  40%|███▉      | 797/2000 [07:22<07:34,  2.65iteration/s, mean_rewards=-105]\u001b[A\n",
            "Training:  40%|███▉      | 797/2000 [07:22<07:34,  2.65iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  40%|███▉      | 798/2000 [07:22<07:10,  2.79iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  40%|███▉      | 798/2000 [07:23<07:10,  2.79iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  40%|███▉      | 799/2000 [07:23<06:57,  2.87iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  40%|███▉      | 799/2000 [07:23<06:57,  2.87iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  40%|████      | 800/2000 [07:23<06:56,  2.88iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  40%|████      | 800/2000 [07:23<06:56,  2.88iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  40%|████      | 801/2000 [07:23<06:59,  2.86iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  40%|████      | 801/2000 [07:24<06:59,  2.86iteration/s, mean_rewards=-58.3]\u001b[A\n",
            "Training:  40%|████      | 802/2000 [07:24<07:03,  2.83iteration/s, mean_rewards=-58.3]\u001b[A\n",
            "Training:  40%|████      | 802/2000 [07:24<07:03,  2.83iteration/s, mean_rewards=-99.6]\u001b[A\n",
            "Training:  40%|████      | 803/2000 [07:24<07:07,  2.80iteration/s, mean_rewards=-99.6]\u001b[A\n",
            "Training:  40%|████      | 803/2000 [07:24<07:07,  2.80iteration/s, mean_rewards=-120] \u001b[A\n",
            "Training:  40%|████      | 804/2000 [07:24<07:09,  2.78iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  40%|████      | 804/2000 [07:25<07:09,  2.78iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  40%|████      | 805/2000 [07:25<06:57,  2.86iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  40%|████      | 805/2000 [07:25<06:57,  2.86iteration/s, mean_rewards=-166]\u001b[A\n",
            "Training:  40%|████      | 806/2000 [07:25<07:09,  2.78iteration/s, mean_rewards=-166]\u001b[A\n",
            "Training:  40%|████      | 806/2000 [07:25<07:09,  2.78iteration/s, mean_rewards=-157]\u001b[A\n",
            "Training:  40%|████      | 807/2000 [07:26<07:29,  2.66iteration/s, mean_rewards=-157]\u001b[A\n",
            "Training:  40%|████      | 807/2000 [07:26<07:29,  2.66iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  40%|████      | 808/2000 [07:26<07:10,  2.77iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  40%|████      | 808/2000 [07:26<07:10,  2.77iteration/s, mean_rewards=-42.4]\u001b[A\n",
            "Training:  40%|████      | 809/2000 [07:26<07:09,  2.77iteration/s, mean_rewards=-42.4]\u001b[A\n",
            "Training:  40%|████      | 809/2000 [07:27<07:09,  2.77iteration/s, mean_rewards=-117] \u001b[A\n",
            "Training:  40%|████      | 810/2000 [07:27<06:52,  2.89iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  40%|████      | 810/2000 [07:27<06:52,  2.89iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  41%|████      | 811/2000 [07:27<07:08,  2.77iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  41%|████      | 811/2000 [07:27<07:08,  2.77iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:  41%|████      | 812/2000 [07:27<07:10,  2.76iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:  41%|████      | 812/2000 [07:28<07:10,  2.76iteration/s, mean_rewards=-65] \u001b[A\n",
            "Training:  41%|████      | 813/2000 [07:28<07:25,  2.67iteration/s, mean_rewards=-65]\u001b[A\n",
            "Training:  41%|████      | 813/2000 [07:28<07:25,  2.67iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  41%|████      | 814/2000 [07:28<06:54,  2.86iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  41%|████      | 814/2000 [07:28<06:54,  2.86iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  41%|████      | 815/2000 [07:28<07:02,  2.80iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  41%|████      | 815/2000 [07:29<07:02,  2.80iteration/s, mean_rewards=-223]\u001b[A\n",
            "Training:  41%|████      | 816/2000 [07:29<07:26,  2.65iteration/s, mean_rewards=-223]\u001b[A\n",
            "Training:  41%|████      | 816/2000 [07:29<07:26,  2.65iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  41%|████      | 817/2000 [07:29<07:14,  2.72iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  41%|████      | 817/2000 [07:29<07:14,  2.72iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  41%|████      | 818/2000 [07:30<06:54,  2.85iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  41%|████      | 818/2000 [07:30<06:54,  2.85iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  41%|████      | 819/2000 [07:30<07:19,  2.69iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  41%|████      | 819/2000 [07:30<07:19,  2.69iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  41%|████      | 820/2000 [07:30<07:21,  2.67iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  41%|████      | 820/2000 [07:31<07:21,  2.67iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:  41%|████      | 821/2000 [07:31<07:43,  2.54iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:  41%|████      | 821/2000 [07:31<07:43,  2.54iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  41%|████      | 822/2000 [07:31<07:50,  2.51iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  41%|████      | 822/2000 [07:31<07:50,  2.51iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  41%|████      | 823/2000 [07:32<08:06,  2.42iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  41%|████      | 823/2000 [07:32<08:06,  2.42iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  41%|████      | 824/2000 [07:32<09:13,  2.13iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  41%|████      | 824/2000 [07:33<09:13,  2.13iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  41%|████▏     | 825/2000 [07:33<09:24,  2.08iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  41%|████▏     | 825/2000 [07:33<09:24,  2.08iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  41%|████▏     | 826/2000 [07:33<09:06,  2.15iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  41%|████▏     | 826/2000 [07:33<09:06,  2.15iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  41%|████▏     | 827/2000 [07:34<08:45,  2.23iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  41%|████▏     | 827/2000 [07:34<08:45,  2.23iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  41%|████▏     | 828/2000 [07:34<08:11,  2.38iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  41%|████▏     | 828/2000 [07:34<08:11,  2.38iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:  41%|████▏     | 829/2000 [07:34<07:53,  2.47iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:  41%|████▏     | 829/2000 [07:35<07:53,  2.47iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  42%|████▏     | 830/2000 [07:35<07:36,  2.56iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  42%|████▏     | 830/2000 [07:35<07:36,  2.56iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  42%|████▏     | 831/2000 [07:35<07:10,  2.72iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  42%|████▏     | 831/2000 [07:35<07:10,  2.72iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  42%|████▏     | 832/2000 [07:35<06:45,  2.88iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  42%|████▏     | 832/2000 [07:35<06:45,  2.88iteration/s, mean_rewards=-101]\u001b[A\n",
            "Training:  42%|████▏     | 833/2000 [07:36<06:46,  2.87iteration/s, mean_rewards=-101]\u001b[A\n",
            "Training:  42%|████▏     | 833/2000 [07:36<06:46,  2.87iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  42%|████▏     | 834/2000 [07:36<07:16,  2.67iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  42%|████▏     | 834/2000 [07:36<07:16,  2.67iteration/s, mean_rewards=-106]\u001b[A\n",
            "Training:  42%|████▏     | 835/2000 [07:36<07:13,  2.69iteration/s, mean_rewards=-106]\u001b[A\n",
            "Training:  42%|████▏     | 835/2000 [07:37<07:13,  2.69iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  42%|████▏     | 836/2000 [07:37<07:04,  2.74iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  42%|████▏     | 836/2000 [07:37<07:04,  2.74iteration/s, mean_rewards=-205]\u001b[A\n",
            "Training:  42%|████▏     | 837/2000 [07:37<07:21,  2.63iteration/s, mean_rewards=-205]\u001b[A\n",
            "Training:  42%|████▏     | 837/2000 [07:37<07:21,  2.63iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  42%|████▏     | 838/2000 [07:38<07:23,  2.62iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  42%|████▏     | 838/2000 [07:38<07:23,  2.62iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  42%|████▏     | 839/2000 [07:38<07:04,  2.74iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  42%|████▏     | 839/2000 [07:38<07:04,  2.74iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  42%|████▏     | 840/2000 [07:38<07:05,  2.72iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  42%|████▏     | 840/2000 [07:38<07:05,  2.72iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  42%|████▏     | 841/2000 [07:39<06:57,  2.78iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  42%|████▏     | 841/2000 [07:39<06:57,  2.78iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  42%|████▏     | 842/2000 [07:39<06:56,  2.78iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  42%|████▏     | 842/2000 [07:39<06:56,  2.78iteration/s, mean_rewards=-58.3]\u001b[A\n",
            "Training:  42%|████▏     | 843/2000 [07:39<06:40,  2.89iteration/s, mean_rewards=-58.3]\u001b[A\n",
            "Training:  42%|████▏     | 843/2000 [07:39<06:40,  2.89iteration/s, mean_rewards=-138] \u001b[A\n",
            "Training:  42%|████▏     | 844/2000 [07:40<06:26,  2.99iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:  42%|████▏     | 844/2000 [07:40<06:26,  2.99iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  42%|████▏     | 845/2000 [07:40<06:34,  2.93iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  42%|████▏     | 845/2000 [07:40<06:34,  2.93iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:  42%|████▏     | 846/2000 [07:40<06:51,  2.80iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:  42%|████▏     | 846/2000 [07:41<06:51,  2.80iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  42%|████▏     | 847/2000 [07:41<06:54,  2.78iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  42%|████▏     | 847/2000 [07:41<06:54,  2.78iteration/s, mean_rewards=-96.6]\u001b[A\n",
            "Training:  42%|████▏     | 848/2000 [07:41<06:50,  2.81iteration/s, mean_rewards=-96.6]\u001b[A\n",
            "Training:  42%|████▏     | 848/2000 [07:41<06:50,  2.81iteration/s, mean_rewards=-63.9]\u001b[A\n",
            "Training:  42%|████▏     | 849/2000 [07:41<06:48,  2.81iteration/s, mean_rewards=-63.9]\u001b[A\n",
            "Training:  42%|████▏     | 849/2000 [07:42<06:48,  2.81iteration/s, mean_rewards=-120] \u001b[A\n",
            "Training:  42%|████▎     | 850/2000 [07:42<06:55,  2.77iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  42%|████▎     | 850/2000 [07:42<06:55,  2.77iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  43%|████▎     | 851/2000 [07:42<06:54,  2.77iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  43%|████▎     | 851/2000 [07:42<06:54,  2.77iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:  43%|████▎     | 852/2000 [07:42<06:49,  2.81iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:  43%|████▎     | 852/2000 [07:43<06:49,  2.81iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:  43%|████▎     | 853/2000 [07:43<06:29,  2.94iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:  43%|████▎     | 853/2000 [07:43<06:29,  2.94iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  43%|████▎     | 854/2000 [07:43<06:16,  3.05iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  43%|████▎     | 854/2000 [07:43<06:16,  3.05iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  43%|████▎     | 855/2000 [07:43<06:09,  3.10iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  43%|████▎     | 855/2000 [07:44<06:09,  3.10iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  43%|████▎     | 856/2000 [07:44<06:34,  2.90iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  43%|████▎     | 856/2000 [07:44<06:34,  2.90iteration/s, mean_rewards=-74.8]\u001b[A\n",
            "Training:  43%|████▎     | 857/2000 [07:44<06:49,  2.79iteration/s, mean_rewards=-74.8]\u001b[A\n",
            "Training:  43%|████▎     | 857/2000 [07:44<06:49,  2.79iteration/s, mean_rewards=-162] \u001b[A\n",
            "Training:  43%|████▎     | 858/2000 [07:45<07:15,  2.62iteration/s, mean_rewards=-162]\u001b[A\n",
            "Training:  43%|████▎     | 858/2000 [07:45<07:15,  2.62iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  43%|████▎     | 859/2000 [07:45<07:09,  2.66iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  43%|████▎     | 859/2000 [07:45<07:09,  2.66iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  43%|████▎     | 860/2000 [07:45<07:51,  2.42iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  43%|████▎     | 860/2000 [07:46<07:51,  2.42iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:  43%|████▎     | 861/2000 [07:46<08:19,  2.28iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:  43%|████▎     | 861/2000 [07:46<08:19,  2.28iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  43%|████▎     | 862/2000 [07:46<08:41,  2.18iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  43%|████▎     | 862/2000 [07:47<08:41,  2.18iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  43%|████▎     | 863/2000 [07:47<08:24,  2.26iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  43%|████▎     | 863/2000 [07:47<08:24,  2.26iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  43%|████▎     | 864/2000 [07:47<08:05,  2.34iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  43%|████▎     | 864/2000 [07:48<08:05,  2.34iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  43%|████▎     | 865/2000 [07:48<07:51,  2.41iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  43%|████▎     | 865/2000 [07:48<07:51,  2.41iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:  43%|████▎     | 866/2000 [07:48<07:17,  2.59iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:  43%|████▎     | 866/2000 [07:48<07:17,  2.59iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  43%|████▎     | 867/2000 [07:48<07:14,  2.61iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  43%|████▎     | 867/2000 [07:49<07:14,  2.61iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  43%|████▎     | 868/2000 [07:49<07:16,  2.59iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  43%|████▎     | 868/2000 [07:49<07:16,  2.59iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  43%|████▎     | 869/2000 [07:49<07:33,  2.49iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  43%|████▎     | 869/2000 [07:49<07:33,  2.49iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  44%|████▎     | 870/2000 [07:50<07:01,  2.68iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  44%|████▎     | 870/2000 [07:50<07:01,  2.68iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  44%|████▎     | 871/2000 [07:50<06:51,  2.74iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  44%|████▎     | 871/2000 [07:50<06:51,  2.74iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:  44%|████▎     | 872/2000 [07:50<06:57,  2.70iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:  44%|████▎     | 872/2000 [07:50<06:57,  2.70iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  44%|████▎     | 873/2000 [07:51<07:02,  2.67iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  44%|████▎     | 873/2000 [07:51<07:02,  2.67iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  44%|████▎     | 874/2000 [07:51<06:52,  2.73iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  44%|████▎     | 874/2000 [07:51<06:52,  2.73iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  44%|████▍     | 875/2000 [07:51<06:55,  2.71iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  44%|████▍     | 875/2000 [07:52<06:55,  2.71iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  44%|████▍     | 876/2000 [07:52<06:37,  2.82iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  44%|████▍     | 876/2000 [07:52<06:37,  2.82iteration/s, mean_rewards=-204]\u001b[A\n",
            "Training:  44%|████▍     | 877/2000 [07:52<07:11,  2.60iteration/s, mean_rewards=-204]\u001b[A\n",
            "Training:  44%|████▍     | 877/2000 [07:52<07:11,  2.60iteration/s, mean_rewards=-80.4]\u001b[A\n",
            "Training:  44%|████▍     | 878/2000 [07:52<07:05,  2.63iteration/s, mean_rewards=-80.4]\u001b[A\n",
            "Training:  44%|████▍     | 878/2000 [07:53<07:05,  2.63iteration/s, mean_rewards=-154] \u001b[A\n",
            "Training:  44%|████▍     | 879/2000 [07:53<07:07,  2.62iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  44%|████▍     | 879/2000 [07:53<07:07,  2.62iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  44%|████▍     | 880/2000 [07:53<07:23,  2.52iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  44%|████▍     | 880/2000 [07:54<07:23,  2.52iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  44%|████▍     | 881/2000 [07:54<07:06,  2.62iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  44%|████▍     | 881/2000 [07:54<07:06,  2.62iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  44%|████▍     | 882/2000 [07:54<06:41,  2.79iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  44%|████▍     | 882/2000 [07:54<06:41,  2.79iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  44%|████▍     | 883/2000 [07:54<06:41,  2.78iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  44%|████▍     | 883/2000 [07:54<06:41,  2.78iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  44%|████▍     | 884/2000 [07:55<06:17,  2.96iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  44%|████▍     | 884/2000 [07:55<06:17,  2.96iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  44%|████▍     | 885/2000 [07:55<06:34,  2.83iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  44%|████▍     | 885/2000 [07:55<06:34,  2.83iteration/s, mean_rewards=-10.7]\u001b[A\n",
            "Training:  44%|████▍     | 886/2000 [07:55<06:45,  2.75iteration/s, mean_rewards=-10.7]\u001b[A\n",
            "Training:  44%|████▍     | 886/2000 [07:56<06:45,  2.75iteration/s, mean_rewards=-168] \u001b[A\n",
            "Training:  44%|████▍     | 887/2000 [07:56<06:45,  2.74iteration/s, mean_rewards=-168]\u001b[A\n",
            "Training:  44%|████▍     | 887/2000 [07:56<06:45,  2.74iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  44%|████▍     | 888/2000 [07:56<06:50,  2.71iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  44%|████▍     | 888/2000 [07:56<06:50,  2.71iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  44%|████▍     | 889/2000 [07:56<06:43,  2.75iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  44%|████▍     | 889/2000 [07:57<06:43,  2.75iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  44%|████▍     | 890/2000 [07:57<06:49,  2.71iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  44%|████▍     | 890/2000 [07:57<06:49,  2.71iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  45%|████▍     | 891/2000 [07:57<07:27,  2.48iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  45%|████▍     | 891/2000 [07:58<07:27,  2.48iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  45%|████▍     | 892/2000 [07:58<08:22,  2.21iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  45%|████▍     | 892/2000 [07:58<08:22,  2.21iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  45%|████▍     | 893/2000 [07:58<08:02,  2.29iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  45%|████▍     | 893/2000 [07:59<08:02,  2.29iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  45%|████▍     | 894/2000 [07:59<08:13,  2.24iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  45%|████▍     | 894/2000 [07:59<08:13,  2.24iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  45%|████▍     | 895/2000 [07:59<08:19,  2.21iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  45%|████▍     | 895/2000 [08:00<08:19,  2.21iteration/s, mean_rewards=-211]\u001b[A\n",
            "Training:  45%|████▍     | 896/2000 [08:00<09:12,  2.00iteration/s, mean_rewards=-211]\u001b[A\n",
            "Training:  45%|████▍     | 896/2000 [08:00<09:12,  2.00iteration/s, mean_rewards=-119]\u001b[A\n",
            "Training:  45%|████▍     | 897/2000 [08:00<09:08,  2.01iteration/s, mean_rewards=-119]\u001b[A\n",
            "Training:  45%|████▍     | 897/2000 [08:01<09:08,  2.01iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  45%|████▍     | 898/2000 [08:01<08:01,  2.29iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  45%|████▍     | 898/2000 [08:01<08:01,  2.29iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:  45%|████▍     | 899/2000 [08:01<07:40,  2.39iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:  45%|████▍     | 899/2000 [08:01<07:40,  2.39iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  45%|████▌     | 900/2000 [08:01<07:20,  2.50iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  45%|████▌     | 900/2000 [08:02<07:20,  2.50iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  45%|████▌     | 901/2000 [08:02<07:32,  2.43iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  45%|████▌     | 901/2000 [08:02<07:32,  2.43iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  45%|████▌     | 902/2000 [08:02<07:23,  2.47iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  45%|████▌     | 902/2000 [08:02<07:23,  2.47iteration/s, mean_rewards=-168]\u001b[A\n",
            "Training:  45%|████▌     | 903/2000 [08:03<07:29,  2.44iteration/s, mean_rewards=-168]\u001b[A\n",
            "Training:  45%|████▌     | 903/2000 [08:03<07:29,  2.44iteration/s, mean_rewards=-60.5]\u001b[A\n",
            "Training:  45%|████▌     | 904/2000 [08:03<07:16,  2.51iteration/s, mean_rewards=-60.5]\u001b[A\n",
            "Training:  45%|████▌     | 904/2000 [08:03<07:16,  2.51iteration/s, mean_rewards=-111] \u001b[A\n",
            "Training:  45%|████▌     | 905/2000 [08:03<06:38,  2.75iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  45%|████▌     | 905/2000 [08:03<06:38,  2.75iteration/s, mean_rewards=-72.6]\u001b[A\n",
            "Training:  45%|████▌     | 906/2000 [08:04<06:22,  2.86iteration/s, mean_rewards=-72.6]\u001b[A\n",
            "Training:  45%|████▌     | 906/2000 [08:04<06:22,  2.86iteration/s, mean_rewards=-150] \u001b[A\n",
            "Training:  45%|████▌     | 907/2000 [08:04<06:23,  2.85iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  45%|████▌     | 907/2000 [08:04<06:23,  2.85iteration/s, mean_rewards=-102]\u001b[A\n",
            "Training:  45%|████▌     | 908/2000 [08:04<06:05,  2.99iteration/s, mean_rewards=-102]\u001b[A\n",
            "Training:  45%|████▌     | 908/2000 [08:04<06:05,  2.99iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:  45%|████▌     | 909/2000 [08:05<06:19,  2.87iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:  45%|████▌     | 909/2000 [08:05<06:19,  2.87iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  46%|████▌     | 910/2000 [08:05<06:19,  2.87iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  46%|████▌     | 910/2000 [08:05<06:19,  2.87iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  46%|████▌     | 911/2000 [08:05<06:24,  2.83iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  46%|████▌     | 911/2000 [08:06<06:24,  2.83iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  46%|████▌     | 912/2000 [08:06<06:07,  2.96iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  46%|████▌     | 912/2000 [08:06<06:07,  2.96iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  46%|████▌     | 913/2000 [08:06<06:21,  2.85iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  46%|████▌     | 913/2000 [08:06<06:21,  2.85iteration/s, mean_rewards=-152]\u001b[A\n",
            "Training:  46%|████▌     | 914/2000 [08:06<06:20,  2.85iteration/s, mean_rewards=-152]\u001b[A\n",
            "Training:  46%|████▌     | 914/2000 [08:07<06:20,  2.85iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  46%|████▌     | 915/2000 [08:07<06:01,  3.00iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  46%|████▌     | 915/2000 [08:07<06:01,  3.00iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  46%|████▌     | 916/2000 [08:07<06:14,  2.89iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  46%|████▌     | 916/2000 [08:07<06:14,  2.89iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  46%|████▌     | 917/2000 [08:07<06:03,  2.98iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  46%|████▌     | 917/2000 [08:08<06:03,  2.98iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  46%|████▌     | 918/2000 [08:08<05:58,  3.02iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  46%|████▌     | 918/2000 [08:08<05:58,  3.02iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  46%|████▌     | 919/2000 [08:08<05:55,  3.04iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  46%|████▌     | 919/2000 [08:08<05:55,  3.04iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  46%|████▌     | 920/2000 [08:08<06:06,  2.95iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  46%|████▌     | 920/2000 [08:09<06:06,  2.95iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  46%|████▌     | 921/2000 [08:09<06:06,  2.94iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  46%|████▌     | 921/2000 [08:09<06:06,  2.94iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  46%|████▌     | 922/2000 [08:09<06:30,  2.76iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  46%|████▌     | 922/2000 [08:09<06:30,  2.76iteration/s, mean_rewards=-5.75]\u001b[A\n",
            "Training:  46%|████▌     | 923/2000 [08:10<06:48,  2.64iteration/s, mean_rewards=-5.75]\u001b[A\n",
            "Training:  46%|████▌     | 923/2000 [08:10<06:48,  2.64iteration/s, mean_rewards=-155] \u001b[A\n",
            "Training:  46%|████▌     | 924/2000 [08:10<06:56,  2.58iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  46%|████▌     | 924/2000 [08:10<06:56,  2.58iteration/s, mean_rewards=-63.1]\u001b[A\n",
            "Training:  46%|████▋     | 925/2000 [08:11<07:54,  2.27iteration/s, mean_rewards=-63.1]\u001b[A\n",
            "Training:  46%|████▋     | 925/2000 [08:11<07:54,  2.27iteration/s, mean_rewards=-126] \u001b[A\n",
            "Training:  46%|████▋     | 926/2000 [08:11<08:07,  2.21iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  46%|████▋     | 926/2000 [08:11<08:07,  2.21iteration/s, mean_rewards=-163]\u001b[A\n",
            "Training:  46%|████▋     | 927/2000 [08:11<08:25,  2.12iteration/s, mean_rewards=-163]\u001b[A\n",
            "Training:  46%|████▋     | 927/2000 [08:12<08:25,  2.12iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  46%|████▋     | 928/2000 [08:12<08:11,  2.18iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  46%|████▋     | 928/2000 [08:12<08:11,  2.18iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:  46%|████▋     | 929/2000 [08:13<08:51,  2.02iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:  46%|████▋     | 929/2000 [08:13<08:51,  2.02iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  46%|████▋     | 930/2000 [08:13<08:22,  2.13iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  46%|████▋     | 930/2000 [08:13<08:22,  2.13iteration/s, mean_rewards=-173]\u001b[A\n",
            "Training:  47%|████▋     | 931/2000 [08:13<08:28,  2.10iteration/s, mean_rewards=-173]\u001b[A\n",
            "Training:  47%|████▋     | 931/2000 [08:14<08:28,  2.10iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  47%|████▋     | 932/2000 [08:14<08:07,  2.19iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  47%|████▋     | 932/2000 [08:14<08:07,  2.19iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  47%|████▋     | 933/2000 [08:14<07:40,  2.32iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  47%|████▋     | 933/2000 [08:14<07:40,  2.32iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  47%|████▋     | 934/2000 [08:15<07:00,  2.53iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  47%|████▋     | 934/2000 [08:15<07:00,  2.53iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  47%|████▋     | 935/2000 [08:15<06:48,  2.61iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  47%|████▋     | 935/2000 [08:15<06:48,  2.61iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  47%|████▋     | 936/2000 [08:15<06:19,  2.80iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  47%|████▋     | 936/2000 [08:15<06:19,  2.80iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  47%|████▋     | 937/2000 [08:16<06:29,  2.73iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  47%|████▋     | 937/2000 [08:16<06:29,  2.73iteration/s, mean_rewards=-168]\u001b[A\n",
            "Training:  47%|████▋     | 938/2000 [08:16<06:31,  2.71iteration/s, mean_rewards=-168]\u001b[A\n",
            "Training:  47%|████▋     | 938/2000 [08:16<06:31,  2.71iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  47%|████▋     | 939/2000 [08:16<06:14,  2.83iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  47%|████▋     | 939/2000 [08:16<06:14,  2.83iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  47%|████▋     | 940/2000 [08:17<06:14,  2.83iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  47%|████▋     | 940/2000 [08:17<06:14,  2.83iteration/s, mean_rewards=-112]\u001b[A\n",
            "Training:  47%|████▋     | 941/2000 [08:17<06:39,  2.65iteration/s, mean_rewards=-112]\u001b[A\n",
            "Training:  47%|████▋     | 941/2000 [08:17<06:39,  2.65iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  47%|████▋     | 942/2000 [08:17<06:45,  2.61iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  47%|████▋     | 942/2000 [08:18<06:45,  2.61iteration/s, mean_rewards=-63.6]\u001b[A\n",
            "Training:  47%|████▋     | 943/2000 [08:18<06:52,  2.56iteration/s, mean_rewards=-63.6]\u001b[A\n",
            "Training:  47%|████▋     | 943/2000 [08:18<06:52,  2.56iteration/s, mean_rewards=-153] \u001b[A\n",
            "Training:  47%|████▋     | 944/2000 [08:18<06:49,  2.58iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  47%|████▋     | 944/2000 [08:18<06:49,  2.58iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  47%|████▋     | 945/2000 [08:19<06:39,  2.64iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  47%|████▋     | 945/2000 [08:19<06:39,  2.64iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  47%|████▋     | 946/2000 [08:19<06:34,  2.67iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  47%|████▋     | 946/2000 [08:19<06:34,  2.67iteration/s, mean_rewards=-119]\u001b[A\n",
            "Training:  47%|████▋     | 947/2000 [08:19<06:40,  2.63iteration/s, mean_rewards=-119]\u001b[A\n",
            "Training:  47%|████▋     | 947/2000 [08:20<06:40,  2.63iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  47%|████▋     | 948/2000 [08:20<06:18,  2.78iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  47%|████▋     | 948/2000 [08:20<06:18,  2.78iteration/s, mean_rewards=-116]\u001b[A\n",
            "Training:  47%|████▋     | 949/2000 [08:20<05:52,  2.98iteration/s, mean_rewards=-116]\u001b[A\n",
            "Training:  47%|████▋     | 949/2000 [08:20<05:52,  2.98iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  48%|████▊     | 950/2000 [08:20<05:57,  2.94iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  48%|████▊     | 950/2000 [08:21<05:57,  2.94iteration/s, mean_rewards=-60.1]\u001b[A\n",
            "Training:  48%|████▊     | 951/2000 [08:21<06:25,  2.72iteration/s, mean_rewards=-60.1]\u001b[A\n",
            "Training:  48%|████▊     | 951/2000 [08:21<06:25,  2.72iteration/s, mean_rewards=-161] \u001b[A\n",
            "Training:  48%|████▊     | 952/2000 [08:21<06:27,  2.70iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:  48%|████▊     | 952/2000 [08:21<06:27,  2.70iteration/s, mean_rewards=-214]\u001b[A\n",
            "Training:  48%|████▊     | 953/2000 [08:21<06:36,  2.64iteration/s, mean_rewards=-214]\u001b[A\n",
            "Training:  48%|████▊     | 953/2000 [08:22<06:36,  2.64iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  48%|████▊     | 954/2000 [08:22<06:52,  2.54iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  48%|████▊     | 954/2000 [08:22<06:52,  2.54iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  48%|████▊     | 955/2000 [08:22<06:39,  2.61iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  48%|████▊     | 955/2000 [08:22<06:39,  2.61iteration/s, mean_rewards=-106]\u001b[A\n",
            "Training:  48%|████▊     | 956/2000 [08:23<06:29,  2.68iteration/s, mean_rewards=-106]\u001b[A\n",
            "Training:  48%|████▊     | 956/2000 [08:23<06:29,  2.68iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  48%|████▊     | 957/2000 [08:23<06:43,  2.59iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  48%|████▊     | 957/2000 [08:23<06:43,  2.59iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  48%|████▊     | 958/2000 [08:23<06:48,  2.55iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  48%|████▊     | 958/2000 [08:24<06:48,  2.55iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  48%|████▊     | 959/2000 [08:24<07:08,  2.43iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  48%|████▊     | 959/2000 [08:24<07:08,  2.43iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  48%|████▊     | 960/2000 [08:24<06:59,  2.48iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  48%|████▊     | 960/2000 [08:25<06:59,  2.48iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  48%|████▊     | 961/2000 [08:25<07:37,  2.27iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  48%|████▊     | 961/2000 [08:25<07:37,  2.27iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  48%|████▊     | 962/2000 [08:25<07:59,  2.16iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  48%|████▊     | 962/2000 [08:26<07:59,  2.16iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:  48%|████▊     | 963/2000 [08:26<08:01,  2.15iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:  48%|████▊     | 963/2000 [08:26<08:01,  2.15iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  48%|████▊     | 964/2000 [08:26<08:33,  2.02iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  48%|████▊     | 964/2000 [08:27<08:33,  2.02iteration/s, mean_rewards=-91.4]\u001b[A\n",
            "Training:  48%|████▊     | 965/2000 [08:27<07:31,  2.29iteration/s, mean_rewards=-91.4]\u001b[A\n",
            "Training:  48%|████▊     | 965/2000 [08:27<07:31,  2.29iteration/s, mean_rewards=-129] \u001b[A\n",
            "Training:  48%|████▊     | 966/2000 [08:27<07:08,  2.41iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  48%|████▊     | 966/2000 [08:27<07:08,  2.41iteration/s, mean_rewards=-81] \u001b[A\n",
            "Training:  48%|████▊     | 967/2000 [08:27<06:49,  2.52iteration/s, mean_rewards=-81]\u001b[A\n",
            "Training:  48%|████▊     | 967/2000 [08:28<06:49,  2.52iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  48%|████▊     | 968/2000 [08:28<07:01,  2.45iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  48%|████▊     | 968/2000 [08:28<07:01,  2.45iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  48%|████▊     | 969/2000 [08:28<06:54,  2.49iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  48%|████▊     | 969/2000 [08:28<06:54,  2.49iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  48%|████▊     | 970/2000 [08:29<06:56,  2.47iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  48%|████▊     | 970/2000 [08:29<06:56,  2.47iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:  49%|████▊     | 971/2000 [08:29<06:46,  2.53iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:  49%|████▊     | 971/2000 [08:29<06:46,  2.53iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  49%|████▊     | 972/2000 [08:29<06:35,  2.60iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  49%|████▊     | 972/2000 [08:30<06:35,  2.60iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  49%|████▊     | 973/2000 [08:30<06:08,  2.79iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  49%|████▊     | 973/2000 [08:30<06:08,  2.79iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  49%|████▊     | 974/2000 [08:30<05:49,  2.94iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  49%|████▊     | 974/2000 [08:30<05:49,  2.94iteration/s, mean_rewards=-228]\u001b[A\n",
            "Training:  49%|████▉     | 975/2000 [08:30<06:02,  2.83iteration/s, mean_rewards=-228]\u001b[A\n",
            "Training:  49%|████▉     | 975/2000 [08:31<06:02,  2.83iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  49%|████▉     | 976/2000 [08:31<05:59,  2.85iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  49%|████▉     | 976/2000 [08:31<05:59,  2.85iteration/s, mean_rewards=-116]\u001b[A\n",
            "Training:  49%|████▉     | 977/2000 [08:31<06:02,  2.82iteration/s, mean_rewards=-116]\u001b[A\n",
            "Training:  49%|████▉     | 977/2000 [08:31<06:02,  2.82iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  49%|████▉     | 978/2000 [08:31<06:09,  2.77iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  49%|████▉     | 978/2000 [08:32<06:09,  2.77iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  49%|████▉     | 979/2000 [08:32<06:10,  2.76iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  49%|████▉     | 979/2000 [08:32<06:10,  2.76iteration/s, mean_rewards=-66.4]\u001b[A\n",
            "Training:  49%|████▉     | 980/2000 [08:32<06:07,  2.78iteration/s, mean_rewards=-66.4]\u001b[A\n",
            "Training:  49%|████▉     | 980/2000 [08:32<06:07,  2.78iteration/s, mean_rewards=-113] \u001b[A\n",
            "Training:  49%|████▉     | 981/2000 [08:33<06:16,  2.71iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  49%|████▉     | 981/2000 [08:33<06:16,  2.71iteration/s, mean_rewards=-58.6]\u001b[A\n",
            "Training:  49%|████▉     | 982/2000 [08:33<06:21,  2.67iteration/s, mean_rewards=-58.6]\u001b[A\n",
            "Training:  49%|████▉     | 982/2000 [08:33<06:21,  2.67iteration/s, mean_rewards=-109] \u001b[A\n",
            "Training:  49%|████▉     | 983/2000 [08:33<06:18,  2.69iteration/s, mean_rewards=-109]\u001b[A\n",
            "Training:  49%|████▉     | 983/2000 [08:33<06:18,  2.69iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  49%|████▉     | 984/2000 [08:34<05:56,  2.85iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  49%|████▉     | 984/2000 [08:34<05:56,  2.85iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  49%|████▉     | 985/2000 [08:34<05:44,  2.94iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  49%|████▉     | 985/2000 [08:34<05:44,  2.94iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:  49%|████▉     | 986/2000 [08:34<05:40,  2.98iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:  49%|████▉     | 986/2000 [08:34<05:40,  2.98iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:  49%|████▉     | 987/2000 [08:35<06:00,  2.81iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:  49%|████▉     | 987/2000 [08:35<06:00,  2.81iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  49%|████▉     | 988/2000 [08:35<05:46,  2.92iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  49%|████▉     | 988/2000 [08:35<05:46,  2.92iteration/s, mean_rewards=-43.5]\u001b[A\n",
            "Training:  49%|████▉     | 989/2000 [08:35<05:53,  2.86iteration/s, mean_rewards=-43.5]\u001b[A\n",
            "Training:  49%|████▉     | 989/2000 [08:36<05:53,  2.86iteration/s, mean_rewards=-154] \u001b[A\n",
            "Training:  50%|████▉     | 990/2000 [08:36<06:01,  2.79iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  50%|████▉     | 990/2000 [08:36<06:01,  2.79iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  50%|████▉     | 991/2000 [08:36<06:07,  2.74iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  50%|████▉     | 991/2000 [08:36<06:07,  2.74iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:  50%|████▉     | 992/2000 [08:36<06:24,  2.62iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:  50%|████▉     | 992/2000 [08:37<06:24,  2.62iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  50%|████▉     | 993/2000 [08:37<06:52,  2.44iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  50%|████▉     | 993/2000 [08:37<06:52,  2.44iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  50%|████▉     | 994/2000 [08:37<07:14,  2.32iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  50%|████▉     | 994/2000 [08:38<07:14,  2.32iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  50%|████▉     | 995/2000 [08:38<07:06,  2.36iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  50%|████▉     | 995/2000 [08:38<07:06,  2.36iteration/s, mean_rewards=-168]\u001b[A\n",
            "Training:  50%|████▉     | 996/2000 [08:38<07:35,  2.20iteration/s, mean_rewards=-168]\u001b[A\n",
            "Training:  50%|████▉     | 996/2000 [08:39<07:35,  2.20iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  50%|████▉     | 997/2000 [08:39<08:03,  2.08iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  50%|████▉     | 997/2000 [08:39<08:03,  2.08iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  50%|████▉     | 998/2000 [08:39<07:25,  2.25iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  50%|████▉     | 998/2000 [08:39<07:25,  2.25iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  50%|████▉     | 999/2000 [08:40<07:02,  2.37iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  50%|████▉     | 999/2000 [08:40<07:02,  2.37iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  50%|█████     | 1000/2000 [08:40<06:48,  2.45iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  50%|█████     | 1000/2000 [08:40<06:48,  2.45iteration/s, mean_rewards=-535]\u001b[A\n",
            "Training:  50%|█████     | 1001/2000 [08:41<07:25,  2.24iteration/s, mean_rewards=-535]\u001b[A\n",
            "Training:  50%|█████     | 1001/2000 [08:41<07:25,  2.24iteration/s, mean_rewards=-557]\u001b[A\n",
            "Training:  50%|█████     | 1002/2000 [08:41<07:40,  2.17iteration/s, mean_rewards=-557]\u001b[A\n",
            "Training:  50%|█████     | 1002/2000 [08:42<07:40,  2.17iteration/s, mean_rewards=-996]\u001b[A\n",
            "Training:  50%|█████     | 1003/2000 [08:42<08:59,  1.85iteration/s, mean_rewards=-996]\u001b[A\n",
            "Training:  50%|█████     | 1003/2000 [08:42<08:59,  1.85iteration/s, mean_rewards=-756]\u001b[A\n",
            "Training:  50%|█████     | 1004/2000 [08:42<09:08,  1.82iteration/s, mean_rewards=-756]\u001b[A\n",
            "Training:  50%|█████     | 1004/2000 [08:43<09:08,  1.82iteration/s, mean_rewards=-652]\u001b[A\n",
            "Training:  50%|█████     | 1005/2000 [08:43<08:49,  1.88iteration/s, mean_rewards=-652]\u001b[A\n",
            "Training:  50%|█████     | 1005/2000 [08:43<08:49,  1.88iteration/s, mean_rewards=-593]\u001b[A\n",
            "Training:  50%|█████     | 1006/2000 [08:43<08:27,  1.96iteration/s, mean_rewards=-593]\u001b[A\n",
            "Training:  50%|█████     | 1006/2000 [08:44<08:27,  1.96iteration/s, mean_rewards=-679]\u001b[A\n",
            "Training:  50%|█████     | 1007/2000 [08:44<08:52,  1.86iteration/s, mean_rewards=-679]\u001b[A\n",
            "Training:  50%|█████     | 1007/2000 [08:44<08:52,  1.86iteration/s, mean_rewards=-945]\u001b[A\n",
            "Training:  50%|█████     | 1008/2000 [08:45<10:05,  1.64iteration/s, mean_rewards=-945]\u001b[A\n",
            "Training:  50%|█████     | 1008/2000 [08:45<10:05,  1.64iteration/s, mean_rewards=-519]\u001b[A\n",
            "Training:  50%|█████     | 1009/2000 [08:45<09:18,  1.78iteration/s, mean_rewards=-519]\u001b[A\n",
            "Training:  50%|█████     | 1009/2000 [08:46<09:18,  1.78iteration/s, mean_rewards=-677]\u001b[A\n",
            "Training:  50%|█████     | 1010/2000 [08:46<09:33,  1.73iteration/s, mean_rewards=-677]\u001b[A\n",
            "Training:  50%|█████     | 1010/2000 [08:46<09:33,  1.73iteration/s, mean_rewards=-892]\u001b[A\n",
            "Training:  51%|█████     | 1011/2000 [08:46<09:51,  1.67iteration/s, mean_rewards=-892]\u001b[A\n",
            "Training:  51%|█████     | 1011/2000 [08:47<09:51,  1.67iteration/s, mean_rewards=-1.02e+3]\u001b[A\n",
            "Training:  51%|█████     | 1012/2000 [08:47<10:21,  1.59iteration/s, mean_rewards=-1.02e+3]\u001b[A\n",
            "Training:  51%|█████     | 1012/2000 [08:48<10:21,  1.59iteration/s, mean_rewards=-585]    \u001b[A\n",
            "Training:  51%|█████     | 1013/2000 [08:48<10:24,  1.58iteration/s, mean_rewards=-585]\u001b[A\n",
            "Training:  51%|█████     | 1013/2000 [08:48<10:24,  1.58iteration/s, mean_rewards=-768]\u001b[A\n",
            "Training:  51%|█████     | 1014/2000 [08:48<10:31,  1.56iteration/s, mean_rewards=-768]\u001b[A\n",
            "Training:  51%|█████     | 1014/2000 [08:49<10:31,  1.56iteration/s, mean_rewards=-554]\u001b[A\n",
            "Training:  51%|█████     | 1015/2000 [08:49<09:31,  1.72iteration/s, mean_rewards=-554]\u001b[A\n",
            "Training:  51%|█████     | 1015/2000 [08:50<09:31,  1.72iteration/s, mean_rewards=-1.41e+3]\u001b[A\n",
            "Training:  51%|█████     | 1016/2000 [08:50<12:24,  1.32iteration/s, mean_rewards=-1.41e+3]\u001b[A\n",
            "Training:  51%|█████     | 1016/2000 [08:51<12:24,  1.32iteration/s, mean_rewards=-943]    \u001b[A\n",
            "Training:  51%|█████     | 1017/2000 [08:51<13:21,  1.23iteration/s, mean_rewards=-943]\u001b[A\n",
            "Training:  51%|█████     | 1017/2000 [08:51<13:21,  1.23iteration/s, mean_rewards=-617]\u001b[A\n",
            "Training:  51%|█████     | 1018/2000 [08:52<12:22,  1.32iteration/s, mean_rewards=-617]\u001b[A\n",
            "Training:  51%|█████     | 1018/2000 [08:52<12:22,  1.32iteration/s, mean_rewards=-614]\u001b[A\n",
            "Training:  51%|█████     | 1019/2000 [08:52<11:36,  1.41iteration/s, mean_rewards=-614]\u001b[A\n",
            "Training:  51%|█████     | 1019/2000 [08:53<11:36,  1.41iteration/s, mean_rewards=-613]\u001b[A\n",
            "Training:  51%|█████     | 1020/2000 [08:53<11:09,  1.46iteration/s, mean_rewards=-613]\u001b[A\n",
            "Training:  51%|█████     | 1020/2000 [08:53<11:09,  1.46iteration/s, mean_rewards=-1.01e+3]\u001b[A\n",
            "Training:  51%|█████     | 1021/2000 [08:54<11:45,  1.39iteration/s, mean_rewards=-1.01e+3]\u001b[A\n",
            "Training:  51%|█████     | 1021/2000 [08:54<11:45,  1.39iteration/s, mean_rewards=-929]    \u001b[A\n",
            "Training:  51%|█████     | 1022/2000 [08:54<11:44,  1.39iteration/s, mean_rewards=-929]\u001b[A\n",
            "Training:  51%|█████     | 1022/2000 [08:55<11:44,  1.39iteration/s, mean_rewards=-593]\u001b[A\n",
            "Training:  51%|█████     | 1023/2000 [08:55<11:11,  1.46iteration/s, mean_rewards=-593]\u001b[A\n",
            "Training:  51%|█████     | 1023/2000 [08:56<11:11,  1.46iteration/s, mean_rewards=-1.3e+3]\u001b[A\n",
            "Training:  51%|█████     | 1024/2000 [08:56<12:01,  1.35iteration/s, mean_rewards=-1.3e+3]\u001b[A\n",
            "Training:  51%|█████     | 1024/2000 [08:56<12:01,  1.35iteration/s, mean_rewards=-563]   \u001b[A\n",
            "Training:  51%|█████▏    | 1025/2000 [08:56<10:23,  1.56iteration/s, mean_rewards=-563]\u001b[A\n",
            "Training:  51%|█████▏    | 1025/2000 [08:57<10:23,  1.56iteration/s, mean_rewards=-783]\u001b[A\n",
            "Training:  51%|█████▏    | 1026/2000 [08:57<10:33,  1.54iteration/s, mean_rewards=-783]\u001b[A\n",
            "Training:  51%|█████▏    | 1026/2000 [08:57<10:33,  1.54iteration/s, mean_rewards=-1.3e+3]\u001b[A\n",
            "Training:  51%|█████▏    | 1027/2000 [08:58<11:46,  1.38iteration/s, mean_rewards=-1.3e+3]\u001b[A\n",
            "Training:  51%|█████▏    | 1027/2000 [08:58<11:46,  1.38iteration/s, mean_rewards=-717]   \u001b[A\n",
            "Training:  51%|█████▏    | 1028/2000 [08:58<10:56,  1.48iteration/s, mean_rewards=-717]\u001b[A\n",
            "Training:  51%|█████▏    | 1028/2000 [08:59<10:56,  1.48iteration/s, mean_rewards=-690]\u001b[A\n",
            "Training:  51%|█████▏    | 1029/2000 [08:59<10:58,  1.47iteration/s, mean_rewards=-690]\u001b[A\n",
            "Training:  51%|█████▏    | 1029/2000 [08:59<10:58,  1.47iteration/s, mean_rewards=-474]\u001b[A\n",
            "Training:  52%|█████▏    | 1030/2000 [08:59<09:56,  1.63iteration/s, mean_rewards=-474]\u001b[A\n",
            "Training:  52%|█████▏    | 1030/2000 [09:00<09:56,  1.63iteration/s, mean_rewards=-796]\u001b[A\n",
            "Training:  52%|█████▏    | 1031/2000 [09:00<09:53,  1.63iteration/s, mean_rewards=-796]\u001b[A\n",
            "Training:  52%|█████▏    | 1031/2000 [09:01<09:53,  1.63iteration/s, mean_rewards=-958]\u001b[A\n",
            "Training:  52%|█████▏    | 1032/2000 [09:01<10:47,  1.49iteration/s, mean_rewards=-958]\u001b[A\n",
            "Training:  52%|█████▏    | 1032/2000 [09:01<10:47,  1.49iteration/s, mean_rewards=-1.03e+3]\u001b[A\n",
            "Training:  52%|█████▏    | 1033/2000 [09:02<11:22,  1.42iteration/s, mean_rewards=-1.03e+3]\u001b[A\n",
            "Training:  52%|█████▏    | 1033/2000 [09:02<11:22,  1.42iteration/s, mean_rewards=-515]    \u001b[A\n",
            "Training:  52%|█████▏    | 1034/2000 [09:02<10:51,  1.48iteration/s, mean_rewards=-515]\u001b[A\n",
            "Training:  52%|█████▏    | 1034/2000 [09:03<10:51,  1.48iteration/s, mean_rewards=-594]\u001b[A\n",
            "Training:  52%|█████▏    | 1035/2000 [09:03<10:56,  1.47iteration/s, mean_rewards=-594]\u001b[A\n",
            "Training:  52%|█████▏    | 1035/2000 [09:04<10:56,  1.47iteration/s, mean_rewards=-664]\u001b[A\n",
            "Training:  52%|█████▏    | 1036/2000 [09:04<11:44,  1.37iteration/s, mean_rewards=-664]\u001b[A\n",
            "Training:  52%|█████▏    | 1036/2000 [09:04<11:44,  1.37iteration/s, mean_rewards=-627]\u001b[A\n",
            "Training:  52%|█████▏    | 1037/2000 [09:05<11:40,  1.38iteration/s, mean_rewards=-627]\u001b[A\n",
            "Training:  52%|█████▏    | 1037/2000 [09:05<11:40,  1.38iteration/s, mean_rewards=-618]\u001b[A\n",
            "Training:  52%|█████▏    | 1038/2000 [09:05<10:33,  1.52iteration/s, mean_rewards=-618]\u001b[A\n",
            "Training:  52%|█████▏    | 1038/2000 [09:06<10:33,  1.52iteration/s, mean_rewards=-928]\u001b[A\n",
            "Training:  52%|█████▏    | 1039/2000 [09:06<10:46,  1.49iteration/s, mean_rewards=-928]\u001b[A\n",
            "Training:  52%|█████▏    | 1039/2000 [09:06<10:46,  1.49iteration/s, mean_rewards=-508]\u001b[A\n",
            "Training:  52%|█████▏    | 1040/2000 [09:06<09:45,  1.64iteration/s, mean_rewards=-508]\u001b[A\n",
            "Training:  52%|█████▏    | 1040/2000 [09:07<09:45,  1.64iteration/s, mean_rewards=-537]\u001b[A\n",
            "Training:  52%|█████▏    | 1041/2000 [09:07<09:26,  1.69iteration/s, mean_rewards=-537]\u001b[A\n",
            "Training:  52%|█████▏    | 1041/2000 [09:07<09:26,  1.69iteration/s, mean_rewards=-662]\u001b[A\n",
            "Training:  52%|█████▏    | 1042/2000 [09:07<08:48,  1.81iteration/s, mean_rewards=-662]\u001b[A\n",
            "Training:  52%|█████▏    | 1042/2000 [09:07<08:48,  1.81iteration/s, mean_rewards=-569]\u001b[A\n",
            "Training:  52%|█████▏    | 1043/2000 [09:08<08:17,  1.93iteration/s, mean_rewards=-569]\u001b[A\n",
            "Training:  52%|█████▏    | 1043/2000 [09:08<08:17,  1.93iteration/s, mean_rewards=-534]\u001b[A\n",
            "Training:  52%|█████▏    | 1044/2000 [09:08<08:10,  1.95iteration/s, mean_rewards=-534]\u001b[A\n",
            "Training:  52%|█████▏    | 1044/2000 [09:08<08:10,  1.95iteration/s, mean_rewards=-595]\u001b[A\n",
            "Training:  52%|█████▏    | 1045/2000 [09:09<07:58,  2.00iteration/s, mean_rewards=-595]\u001b[A\n",
            "Training:  52%|█████▏    | 1045/2000 [09:09<07:58,  2.00iteration/s, mean_rewards=-530]\u001b[A\n",
            "Training:  52%|█████▏    | 1046/2000 [09:09<07:33,  2.10iteration/s, mean_rewards=-530]\u001b[A\n",
            "Training:  52%|█████▏    | 1046/2000 [09:09<07:33,  2.10iteration/s, mean_rewards=-735]\u001b[A\n",
            "Training:  52%|█████▏    | 1047/2000 [09:10<08:05,  1.96iteration/s, mean_rewards=-735]\u001b[A\n",
            "Training:  52%|█████▏    | 1047/2000 [09:10<08:05,  1.96iteration/s, mean_rewards=-602]\u001b[A\n",
            "Training:  52%|█████▏    | 1048/2000 [09:10<08:13,  1.93iteration/s, mean_rewards=-602]\u001b[A\n",
            "Training:  52%|█████▏    | 1048/2000 [09:11<08:13,  1.93iteration/s, mean_rewards=-671]\u001b[A\n",
            "Training:  52%|█████▏    | 1049/2000 [09:11<08:19,  1.91iteration/s, mean_rewards=-671]\u001b[A\n",
            "Training:  52%|█████▏    | 1049/2000 [09:11<08:19,  1.91iteration/s, mean_rewards=-666]\u001b[A\n",
            "Training:  52%|█████▎    | 1050/2000 [09:11<08:47,  1.80iteration/s, mean_rewards=-666]\u001b[A\n",
            "Training:  52%|█████▎    | 1050/2000 [09:12<08:47,  1.80iteration/s, mean_rewards=-2.21e+3]\u001b[A\n",
            "Training:  53%|█████▎    | 1051/2000 [09:13<12:15,  1.29iteration/s, mean_rewards=-2.21e+3]\u001b[A\n",
            "Training:  53%|█████▎    | 1051/2000 [09:13<12:15,  1.29iteration/s, mean_rewards=-947]    \u001b[A\n",
            "Training:  53%|█████▎    | 1052/2000 [09:13<12:18,  1.28iteration/s, mean_rewards=-947]\u001b[A\n",
            "Training:  53%|█████▎    | 1052/2000 [09:14<12:18,  1.28iteration/s, mean_rewards=-850]\u001b[A\n",
            "Training:  53%|█████▎    | 1053/2000 [09:14<11:50,  1.33iteration/s, mean_rewards=-850]\u001b[A\n",
            "Training:  53%|█████▎    | 1053/2000 [09:14<11:50,  1.33iteration/s, mean_rewards=-687]\u001b[A\n",
            "Training:  53%|█████▎    | 1054/2000 [09:15<11:08,  1.41iteration/s, mean_rewards=-687]\u001b[A\n",
            "Training:  53%|█████▎    | 1054/2000 [09:15<11:08,  1.41iteration/s, mean_rewards=-589]\u001b[A\n",
            "Training:  53%|█████▎    | 1055/2000 [09:15<10:40,  1.48iteration/s, mean_rewards=-589]\u001b[A\n",
            "Training:  53%|█████▎    | 1055/2000 [09:16<10:40,  1.48iteration/s, mean_rewards=-489]\u001b[A\n",
            "Training:  53%|█████▎    | 1056/2000 [09:16<10:28,  1.50iteration/s, mean_rewards=-489]\u001b[A\n",
            "Training:  53%|█████▎    | 1056/2000 [09:16<10:28,  1.50iteration/s, mean_rewards=-644]\u001b[A\n",
            "Training:  53%|█████▎    | 1057/2000 [09:17<10:36,  1.48iteration/s, mean_rewards=-644]\u001b[A\n",
            "Training:  53%|█████▎    | 1057/2000 [09:17<10:36,  1.48iteration/s, mean_rewards=-1.1e+3]\u001b[A\n",
            "Training:  53%|█████▎    | 1058/2000 [09:18<12:08,  1.29iteration/s, mean_rewards=-1.1e+3]\u001b[A\n",
            "Training:  53%|█████▎    | 1058/2000 [09:18<12:08,  1.29iteration/s, mean_rewards=-674]   \u001b[A\n",
            "Training:  53%|█████▎    | 1059/2000 [09:18<11:27,  1.37iteration/s, mean_rewards=-674]\u001b[A\n",
            "Training:  53%|█████▎    | 1059/2000 [09:19<11:27,  1.37iteration/s, mean_rewards=-511]\u001b[A\n",
            "Training:  53%|█████▎    | 1060/2000 [09:19<10:12,  1.53iteration/s, mean_rewards=-511]\u001b[A\n",
            "Training:  53%|█████▎    | 1060/2000 [09:19<10:12,  1.53iteration/s, mean_rewards=-780]\u001b[A\n",
            "Training:  53%|█████▎    | 1061/2000 [09:19<09:45,  1.60iteration/s, mean_rewards=-780]\u001b[A\n",
            "Training:  53%|█████▎    | 1061/2000 [09:20<09:45,  1.60iteration/s, mean_rewards=-705]\u001b[A\n",
            "Training:  53%|█████▎    | 1062/2000 [09:20<09:09,  1.71iteration/s, mean_rewards=-705]\u001b[A\n",
            "Training:  53%|█████▎    | 1062/2000 [09:20<09:09,  1.71iteration/s, mean_rewards=-634]\u001b[A\n",
            "Training:  53%|█████▎    | 1063/2000 [09:20<09:22,  1.67iteration/s, mean_rewards=-634]\u001b[A\n",
            "Training:  53%|█████▎    | 1063/2000 [09:21<09:22,  1.67iteration/s, mean_rewards=-641]\u001b[A\n",
            "Training:  53%|█████▎    | 1064/2000 [09:21<08:45,  1.78iteration/s, mean_rewards=-641]\u001b[A\n",
            "Training:  53%|█████▎    | 1064/2000 [09:21<08:45,  1.78iteration/s, mean_rewards=-598]\u001b[A\n",
            "Training:  53%|█████▎    | 1065/2000 [09:21<08:39,  1.80iteration/s, mean_rewards=-598]\u001b[A\n",
            "Training:  53%|█████▎    | 1065/2000 [09:22<08:39,  1.80iteration/s, mean_rewards=-554]\u001b[A\n",
            "Training:  53%|█████▎    | 1066/2000 [09:22<08:19,  1.87iteration/s, mean_rewards=-554]\u001b[A\n",
            "Training:  53%|█████▎    | 1066/2000 [09:22<08:19,  1.87iteration/s, mean_rewards=-822]\u001b[A\n",
            "Training:  53%|█████▎    | 1067/2000 [09:23<08:56,  1.74iteration/s, mean_rewards=-822]\u001b[A\n",
            "Training:  53%|█████▎    | 1067/2000 [09:23<08:56,  1.74iteration/s, mean_rewards=-673]\u001b[A\n",
            "Training:  53%|█████▎    | 1068/2000 [09:23<09:05,  1.71iteration/s, mean_rewards=-673]\u001b[A\n",
            "Training:  53%|█████▎    | 1068/2000 [09:24<09:05,  1.71iteration/s, mean_rewards=-800]\u001b[A\n",
            "Training:  53%|█████▎    | 1069/2000 [09:24<09:18,  1.67iteration/s, mean_rewards=-800]\u001b[A\n",
            "Training:  53%|█████▎    | 1069/2000 [09:24<09:18,  1.67iteration/s, mean_rewards=-960]\u001b[A\n",
            "Training:  54%|█████▎    | 1070/2000 [09:24<09:32,  1.62iteration/s, mean_rewards=-960]\u001b[A\n",
            "Training:  54%|█████▎    | 1070/2000 [09:25<09:32,  1.62iteration/s, mean_rewards=-1.04e+3]\u001b[A\n",
            "Training:  54%|█████▎    | 1071/2000 [09:25<10:23,  1.49iteration/s, mean_rewards=-1.04e+3]\u001b[A\n",
            "Training:  54%|█████▎    | 1071/2000 [09:26<10:23,  1.49iteration/s, mean_rewards=-1.21e+3]\u001b[A\n",
            "Training:  54%|█████▎    | 1072/2000 [09:26<10:57,  1.41iteration/s, mean_rewards=-1.21e+3]\u001b[A\n",
            "Training:  54%|█████▎    | 1072/2000 [09:27<10:57,  1.41iteration/s, mean_rewards=-531]    \u001b[A\n",
            "Training:  54%|█████▎    | 1073/2000 [09:27<10:23,  1.49iteration/s, mean_rewards=-531]\u001b[A\n",
            "Training:  54%|█████▎    | 1073/2000 [09:27<10:23,  1.49iteration/s, mean_rewards=-1.04e+3]\u001b[A\n",
            "Training:  54%|█████▎    | 1074/2000 [09:27<10:57,  1.41iteration/s, mean_rewards=-1.04e+3]\u001b[A\n",
            "Training:  54%|█████▎    | 1074/2000 [09:29<10:57,  1.41iteration/s, mean_rewards=-1.87e+3]\u001b[A\n",
            "Training:  54%|█████▍    | 1075/2000 [09:29<15:25,  1.00s/iteration, mean_rewards=-1.87e+3]\u001b[A\n",
            "Training:  54%|█████▍    | 1075/2000 [09:30<15:25,  1.00s/iteration, mean_rewards=-483]    \u001b[A\n",
            "Training:  54%|█████▍    | 1076/2000 [09:30<13:58,  1.10iteration/s, mean_rewards=-483]\u001b[A\n",
            "Training:  54%|█████▍    | 1076/2000 [09:30<13:58,  1.10iteration/s, mean_rewards=-812]\u001b[A\n",
            "Training:  54%|█████▍    | 1077/2000 [09:31<13:29,  1.14iteration/s, mean_rewards=-812]\u001b[A\n",
            "Training:  54%|█████▍    | 1077/2000 [09:31<13:29,  1.14iteration/s, mean_rewards=-540]\u001b[A\n",
            "Training:  54%|█████▍    | 1078/2000 [09:31<11:25,  1.34iteration/s, mean_rewards=-540]\u001b[A\n",
            "Training:  54%|█████▍    | 1078/2000 [09:32<11:25,  1.34iteration/s, mean_rewards=-1.04e+3]\u001b[A\n",
            "Training:  54%|█████▍    | 1079/2000 [09:32<12:47,  1.20iteration/s, mean_rewards=-1.04e+3]\u001b[A\n",
            "Training:  54%|█████▍    | 1079/2000 [09:33<12:47,  1.20iteration/s, mean_rewards=-763]    \u001b[A\n",
            "Training:  54%|█████▍    | 1080/2000 [09:33<12:05,  1.27iteration/s, mean_rewards=-763]\u001b[A\n",
            "Training:  54%|█████▍    | 1080/2000 [09:33<12:05,  1.27iteration/s, mean_rewards=-869]\u001b[A\n",
            "Training:  54%|█████▍    | 1081/2000 [09:33<11:35,  1.32iteration/s, mean_rewards=-869]\u001b[A\n",
            "Training:  54%|█████▍    | 1081/2000 [09:34<11:35,  1.32iteration/s, mean_rewards=-999]\u001b[A\n",
            "Training:  54%|█████▍    | 1082/2000 [09:34<11:28,  1.33iteration/s, mean_rewards=-999]\u001b[A\n",
            "Training:  54%|█████▍    | 1082/2000 [09:35<11:28,  1.33iteration/s, mean_rewards=-649]\u001b[A\n",
            "Training:  54%|█████▍    | 1083/2000 [09:35<10:41,  1.43iteration/s, mean_rewards=-649]\u001b[A\n",
            "Training:  54%|█████▍    | 1083/2000 [09:35<10:41,  1.43iteration/s, mean_rewards=-639]\u001b[A\n",
            "Training:  54%|█████▍    | 1084/2000 [09:35<09:21,  1.63iteration/s, mean_rewards=-639]\u001b[A\n",
            "Training:  54%|█████▍    | 1084/2000 [09:36<09:21,  1.63iteration/s, mean_rewards=-1.56e+3]\u001b[A\n",
            "Training:  54%|█████▍    | 1085/2000 [09:36<10:46,  1.42iteration/s, mean_rewards=-1.56e+3]\u001b[A\n",
            "Training:  54%|█████▍    | 1085/2000 [09:37<10:46,  1.42iteration/s, mean_rewards=-842]    \u001b[A\n",
            "Training:  54%|█████▍    | 1086/2000 [09:37<10:24,  1.46iteration/s, mean_rewards=-842]\u001b[A\n",
            "Training:  54%|█████▍    | 1086/2000 [09:37<10:24,  1.46iteration/s, mean_rewards=-835]\u001b[A\n",
            "Training:  54%|█████▍    | 1087/2000 [09:37<10:21,  1.47iteration/s, mean_rewards=-835]\u001b[A\n",
            "Training:  54%|█████▍    | 1087/2000 [09:38<10:21,  1.47iteration/s, mean_rewards=-908]\u001b[A\n",
            "Training:  54%|█████▍    | 1088/2000 [09:38<10:44,  1.41iteration/s, mean_rewards=-908]\u001b[A\n",
            "Training:  54%|█████▍    | 1088/2000 [09:39<10:44,  1.41iteration/s, mean_rewards=-681]\u001b[A\n",
            "Training:  54%|█████▍    | 1089/2000 [09:39<10:09,  1.49iteration/s, mean_rewards=-681]\u001b[A\n",
            "Training:  54%|█████▍    | 1089/2000 [09:39<10:09,  1.49iteration/s, mean_rewards=-1.19e+3]\u001b[A\n",
            "Training:  55%|█████▍    | 1090/2000 [09:40<10:43,  1.41iteration/s, mean_rewards=-1.19e+3]\u001b[A\n",
            "Training:  55%|█████▍    | 1090/2000 [09:40<10:43,  1.41iteration/s, mean_rewards=-970]    \u001b[A\n",
            "Training:  55%|█████▍    | 1091/2000 [09:40<11:03,  1.37iteration/s, mean_rewards=-970]\u001b[A\n",
            "Training:  55%|█████▍    | 1091/2000 [09:41<11:03,  1.37iteration/s, mean_rewards=-561]\u001b[A\n",
            "Training:  55%|█████▍    | 1092/2000 [09:41<11:18,  1.34iteration/s, mean_rewards=-561]\u001b[A\n",
            "Training:  55%|█████▍    | 1092/2000 [09:42<11:18,  1.34iteration/s, mean_rewards=-998]\u001b[A\n",
            "Training:  55%|█████▍    | 1093/2000 [09:42<12:22,  1.22iteration/s, mean_rewards=-998]\u001b[A\n",
            "Training:  55%|█████▍    | 1093/2000 [09:43<12:22,  1.22iteration/s, mean_rewards=-660]\u001b[A\n",
            "Training:  55%|█████▍    | 1094/2000 [09:43<12:12,  1.24iteration/s, mean_rewards=-660]\u001b[A\n",
            "Training:  55%|█████▍    | 1094/2000 [09:44<12:12,  1.24iteration/s, mean_rewards=-907]\u001b[A\n",
            "Training:  55%|█████▍    | 1095/2000 [09:44<12:08,  1.24iteration/s, mean_rewards=-907]\u001b[A\n",
            "Training:  55%|█████▍    | 1095/2000 [09:44<12:08,  1.24iteration/s, mean_rewards=-823]\u001b[A\n",
            "Training:  55%|█████▍    | 1096/2000 [09:44<11:06,  1.36iteration/s, mean_rewards=-823]\u001b[A\n",
            "Training:  55%|█████▍    | 1096/2000 [09:45<11:06,  1.36iteration/s, mean_rewards=-769]\u001b[A\n",
            "Training:  55%|█████▍    | 1097/2000 [09:45<10:23,  1.45iteration/s, mean_rewards=-769]\u001b[A\n",
            "Training:  55%|█████▍    | 1097/2000 [09:45<10:23,  1.45iteration/s, mean_rewards=-594]\u001b[A\n",
            "Training:  55%|█████▍    | 1098/2000 [09:45<09:34,  1.57iteration/s, mean_rewards=-594]\u001b[A\n",
            "Training:  55%|█████▍    | 1098/2000 [09:46<09:34,  1.57iteration/s, mean_rewards=-608]\u001b[A\n",
            "Training:  55%|█████▍    | 1099/2000 [09:46<09:05,  1.65iteration/s, mean_rewards=-608]\u001b[A\n",
            "Training:  55%|█████▍    | 1099/2000 [09:47<09:05,  1.65iteration/s, mean_rewards=-1.62e+3]\u001b[A\n",
            "Training:  55%|█████▌    | 1100/2000 [09:47<11:22,  1.32iteration/s, mean_rewards=-1.62e+3]\u001b[A\n",
            "Training:  55%|█████▌    | 1100/2000 [09:48<11:22,  1.32iteration/s, mean_rewards=-839]    \u001b[A\n",
            "Training:  55%|█████▌    | 1101/2000 [09:48<10:54,  1.37iteration/s, mean_rewards=-839]\u001b[A\n",
            "Training:  55%|█████▌    | 1101/2000 [09:48<10:54,  1.37iteration/s, mean_rewards=-854]\u001b[A\n",
            "Training:  55%|█████▌    | 1102/2000 [09:48<10:49,  1.38iteration/s, mean_rewards=-854]\u001b[A\n",
            "Training:  55%|█████▌    | 1102/2000 [09:49<10:49,  1.38iteration/s, mean_rewards=-681]\u001b[A\n",
            "Training:  55%|█████▌    | 1103/2000 [09:49<09:41,  1.54iteration/s, mean_rewards=-681]\u001b[A\n",
            "Training:  55%|█████▌    | 1103/2000 [09:49<09:41,  1.54iteration/s, mean_rewards=-517]\u001b[A\n",
            "Training:  55%|█████▌    | 1104/2000 [09:49<08:36,  1.74iteration/s, mean_rewards=-517]\u001b[A\n",
            "Training:  55%|█████▌    | 1104/2000 [09:50<08:36,  1.74iteration/s, mean_rewards=-540]\u001b[A\n",
            "Training:  55%|█████▌    | 1105/2000 [09:50<08:30,  1.75iteration/s, mean_rewards=-540]\u001b[A\n",
            "Training:  55%|█████▌    | 1105/2000 [09:51<08:30,  1.75iteration/s, mean_rewards=-2.08e+3]\u001b[A\n",
            "Training:  55%|█████▌    | 1106/2000 [09:51<11:34,  1.29iteration/s, mean_rewards=-2.08e+3]\u001b[A\n",
            "Training:  55%|█████▌    | 1106/2000 [09:51<11:34,  1.29iteration/s, mean_rewards=-621]    \u001b[A\n",
            "Training:  55%|█████▌    | 1107/2000 [09:52<10:09,  1.47iteration/s, mean_rewards=-621]\u001b[A\n",
            "Training:  55%|█████▌    | 1107/2000 [09:52<10:09,  1.47iteration/s, mean_rewards=-484]\u001b[A\n",
            "Training:  55%|█████▌    | 1108/2000 [09:52<08:59,  1.65iteration/s, mean_rewards=-484]\u001b[A\n",
            "Training:  55%|█████▌    | 1108/2000 [09:52<08:59,  1.65iteration/s, mean_rewards=-801]\u001b[A\n",
            "Training:  55%|█████▌    | 1109/2000 [09:53<08:55,  1.66iteration/s, mean_rewards=-801]\u001b[A\n",
            "Training:  55%|█████▌    | 1109/2000 [09:53<08:55,  1.66iteration/s, mean_rewards=-1.21e+3]\u001b[A\n",
            "Training:  56%|█████▌    | 1110/2000 [09:54<11:03,  1.34iteration/s, mean_rewards=-1.21e+3]\u001b[A\n",
            "Training:  56%|█████▌    | 1110/2000 [09:54<11:03,  1.34iteration/s, mean_rewards=-732]    \u001b[A\n",
            "Training:  56%|█████▌    | 1111/2000 [09:54<10:51,  1.36iteration/s, mean_rewards=-732]\u001b[A\n",
            "Training:  56%|█████▌    | 1111/2000 [09:55<10:51,  1.36iteration/s, mean_rewards=-806]\u001b[A\n",
            "Training:  56%|█████▌    | 1112/2000 [09:55<11:58,  1.24iteration/s, mean_rewards=-806]\u001b[A\n",
            "Training:  56%|█████▌    | 1112/2000 [09:56<11:58,  1.24iteration/s, mean_rewards=-787]\u001b[A\n",
            "Training:  56%|█████▌    | 1113/2000 [09:56<12:55,  1.14iteration/s, mean_rewards=-787]\u001b[A\n",
            "Training:  56%|█████▌    | 1113/2000 [09:57<12:55,  1.14iteration/s, mean_rewards=-723]\u001b[A\n",
            "Training:  56%|█████▌    | 1114/2000 [09:57<11:46,  1.25iteration/s, mean_rewards=-723]\u001b[A\n",
            "Training:  56%|█████▌    | 1114/2000 [09:58<11:46,  1.25iteration/s, mean_rewards=-990]\u001b[A\n",
            "Training:  56%|█████▌    | 1115/2000 [09:58<11:55,  1.24iteration/s, mean_rewards=-990]\u001b[A\n",
            "Training:  56%|█████▌    | 1115/2000 [09:58<11:55,  1.24iteration/s, mean_rewards=-631]\u001b[A\n",
            "Training:  56%|█████▌    | 1116/2000 [09:58<10:18,  1.43iteration/s, mean_rewards=-631]\u001b[A\n",
            "Training:  56%|█████▌    | 1116/2000 [09:59<10:18,  1.43iteration/s, mean_rewards=-971]\u001b[A\n",
            "Training:  56%|█████▌    | 1117/2000 [09:59<10:43,  1.37iteration/s, mean_rewards=-971]\u001b[A\n",
            "Training:  56%|█████▌    | 1117/2000 [09:59<10:43,  1.37iteration/s, mean_rewards=-636]\u001b[A\n",
            "Training:  56%|█████▌    | 1118/2000 [10:00<09:56,  1.48iteration/s, mean_rewards=-636]\u001b[A\n",
            "Training:  56%|█████▌    | 1118/2000 [10:00<09:56,  1.48iteration/s, mean_rewards=-443]\u001b[A\n",
            "Training:  56%|█████▌    | 1119/2000 [10:00<09:04,  1.62iteration/s, mean_rewards=-443]\u001b[A\n",
            "Training:  56%|█████▌    | 1119/2000 [10:01<09:04,  1.62iteration/s, mean_rewards=-786]\u001b[A\n",
            "Training:  56%|█████▌    | 1120/2000 [10:01<09:28,  1.55iteration/s, mean_rewards=-786]\u001b[A\n",
            "Training:  56%|█████▌    | 1120/2000 [10:01<09:28,  1.55iteration/s, mean_rewards=-625]\u001b[A\n",
            "Training:  56%|█████▌    | 1121/2000 [10:01<08:45,  1.67iteration/s, mean_rewards=-625]\u001b[A\n",
            "Training:  56%|█████▌    | 1121/2000 [10:02<08:45,  1.67iteration/s, mean_rewards=-1.63e+3]\u001b[A\n",
            "Training:  56%|█████▌    | 1122/2000 [10:02<11:02,  1.32iteration/s, mean_rewards=-1.63e+3]\u001b[A\n",
            "Training:  56%|█████▌    | 1122/2000 [10:03<11:02,  1.32iteration/s, mean_rewards=-1.51e+3]\u001b[A\n",
            "Training:  56%|█████▌    | 1123/2000 [10:04<12:56,  1.13iteration/s, mean_rewards=-1.51e+3]\u001b[A\n",
            "Training:  56%|█████▌    | 1123/2000 [10:04<12:56,  1.13iteration/s, mean_rewards=-1.09e+3]\u001b[A\n",
            "Training:  56%|█████▌    | 1124/2000 [10:04<12:43,  1.15iteration/s, mean_rewards=-1.09e+3]\u001b[A\n",
            "Training:  56%|█████▌    | 1124/2000 [10:05<12:43,  1.15iteration/s, mean_rewards=-580]    \u001b[A\n",
            "Training:  56%|█████▋    | 1125/2000 [10:05<10:54,  1.34iteration/s, mean_rewards=-580]\u001b[A\n",
            "Training:  56%|█████▋    | 1125/2000 [10:05<10:54,  1.34iteration/s, mean_rewards=-1.11e+3]\u001b[A\n",
            "Training:  56%|█████▋    | 1126/2000 [10:06<10:55,  1.33iteration/s, mean_rewards=-1.11e+3]\u001b[A\n",
            "Training:  56%|█████▋    | 1126/2000 [10:06<10:55,  1.33iteration/s, mean_rewards=-853]    \u001b[A\n",
            "Training:  56%|█████▋    | 1127/2000 [10:06<10:39,  1.36iteration/s, mean_rewards=-853]\u001b[A\n",
            "Training:  56%|█████▋    | 1127/2000 [10:07<10:39,  1.36iteration/s, mean_rewards=-648]\u001b[A\n",
            "Training:  56%|█████▋    | 1128/2000 [10:07<11:00,  1.32iteration/s, mean_rewards=-648]\u001b[A\n",
            "Training:  56%|█████▋    | 1128/2000 [10:08<11:00,  1.32iteration/s, mean_rewards=-601]\u001b[A\n",
            "Training:  56%|█████▋    | 1129/2000 [10:08<10:44,  1.35iteration/s, mean_rewards=-601]\u001b[A\n",
            "Training:  56%|█████▋    | 1129/2000 [10:09<10:44,  1.35iteration/s, mean_rewards=-1.51e+3]\u001b[A\n",
            "Training:  56%|█████▋    | 1130/2000 [10:09<13:17,  1.09iteration/s, mean_rewards=-1.51e+3]\u001b[A\n",
            "Training:  56%|█████▋    | 1130/2000 [10:10<13:17,  1.09iteration/s, mean_rewards=-592]    \u001b[A\n",
            "Training:  57%|█████▋    | 1131/2000 [10:10<11:40,  1.24iteration/s, mean_rewards=-592]\u001b[A\n",
            "Training:  57%|█████▋    | 1131/2000 [10:10<11:40,  1.24iteration/s, mean_rewards=-699]\u001b[A\n",
            "Training:  57%|█████▋    | 1132/2000 [10:10<10:19,  1.40iteration/s, mean_rewards=-699]\u001b[A\n",
            "Training:  57%|█████▋    | 1132/2000 [10:11<10:19,  1.40iteration/s, mean_rewards=-999]\u001b[A\n",
            "Training:  57%|█████▋    | 1133/2000 [10:11<10:38,  1.36iteration/s, mean_rewards=-999]\u001b[A\n",
            "Training:  57%|█████▋    | 1133/2000 [10:11<10:38,  1.36iteration/s, mean_rewards=-588]\u001b[A\n",
            "Training:  57%|█████▋    | 1134/2000 [10:12<09:42,  1.49iteration/s, mean_rewards=-588]\u001b[A\n",
            "Training:  57%|█████▋    | 1134/2000 [10:12<09:42,  1.49iteration/s, mean_rewards=-777]\u001b[A\n",
            "Training:  57%|█████▋    | 1135/2000 [10:12<09:37,  1.50iteration/s, mean_rewards=-777]\u001b[A\n",
            "Training:  57%|█████▋    | 1135/2000 [10:13<09:37,  1.50iteration/s, mean_rewards=-566]\u001b[A\n",
            "Training:  57%|█████▋    | 1136/2000 [10:13<08:49,  1.63iteration/s, mean_rewards=-566]\u001b[A\n",
            "Training:  57%|█████▋    | 1136/2000 [10:13<08:49,  1.63iteration/s, mean_rewards=-515]\u001b[A\n",
            "Training:  57%|█████▋    | 1137/2000 [10:13<08:29,  1.69iteration/s, mean_rewards=-515]\u001b[A\n",
            "Training:  57%|█████▋    | 1137/2000 [10:14<08:29,  1.69iteration/s, mean_rewards=-664]\u001b[A\n",
            "Training:  57%|█████▋    | 1138/2000 [10:14<08:21,  1.72iteration/s, mean_rewards=-664]\u001b[A\n",
            "Training:  57%|█████▋    | 1138/2000 [10:14<08:21,  1.72iteration/s, mean_rewards=-562]\u001b[A\n",
            "Training:  57%|█████▋    | 1139/2000 [10:14<07:52,  1.82iteration/s, mean_rewards=-562]\u001b[A\n",
            "Training:  57%|█████▋    | 1139/2000 [10:15<07:52,  1.82iteration/s, mean_rewards=-890]\u001b[A\n",
            "Training:  57%|█████▋    | 1140/2000 [10:15<08:16,  1.73iteration/s, mean_rewards=-890]\u001b[A\n",
            "Training:  57%|█████▋    | 1140/2000 [10:15<08:16,  1.73iteration/s, mean_rewards=-549]\u001b[A\n",
            "Training:  57%|█████▋    | 1141/2000 [10:15<07:47,  1.84iteration/s, mean_rewards=-549]\u001b[A\n",
            "Training:  57%|█████▋    | 1141/2000 [10:16<07:47,  1.84iteration/s, mean_rewards=-488]\u001b[A\n",
            "Training:  57%|█████▋    | 1142/2000 [10:16<07:32,  1.90iteration/s, mean_rewards=-488]\u001b[A\n",
            "Training:  57%|█████▋    | 1142/2000 [10:16<07:32,  1.90iteration/s, mean_rewards=-490]\u001b[A\n",
            "Training:  57%|█████▋    | 1143/2000 [10:16<07:18,  1.96iteration/s, mean_rewards=-490]\u001b[A\n",
            "Training:  57%|█████▋    | 1143/2000 [10:17<07:18,  1.96iteration/s, mean_rewards=-537]\u001b[A\n",
            "Training:  57%|█████▋    | 1144/2000 [10:17<07:03,  2.02iteration/s, mean_rewards=-537]\u001b[A\n",
            "Training:  57%|█████▋    | 1144/2000 [10:17<07:03,  2.02iteration/s, mean_rewards=-600]\u001b[A\n",
            "Training:  57%|█████▋    | 1145/2000 [10:17<07:06,  2.01iteration/s, mean_rewards=-600]\u001b[A\n",
            "Training:  57%|█████▋    | 1145/2000 [10:18<07:06,  2.01iteration/s, mean_rewards=-826]\u001b[A\n",
            "Training:  57%|█████▋    | 1146/2000 [10:18<07:29,  1.90iteration/s, mean_rewards=-826]\u001b[A\n",
            "Training:  57%|█████▋    | 1146/2000 [10:18<07:29,  1.90iteration/s, mean_rewards=-727]\u001b[A\n",
            "Training:  57%|█████▋    | 1147/2000 [10:19<08:06,  1.75iteration/s, mean_rewards=-727]\u001b[A\n",
            "Training:  57%|█████▋    | 1147/2000 [10:19<08:06,  1.75iteration/s, mean_rewards=-828]\u001b[A\n",
            "Training:  57%|█████▋    | 1148/2000 [10:19<09:11,  1.55iteration/s, mean_rewards=-828]\u001b[A\n",
            "Training:  57%|█████▋    | 1148/2000 [10:20<09:11,  1.55iteration/s, mean_rewards=-625]\u001b[A\n",
            "Training:  57%|█████▋    | 1149/2000 [10:20<09:04,  1.56iteration/s, mean_rewards=-625]\u001b[A\n",
            "Training:  57%|█████▋    | 1149/2000 [10:21<09:04,  1.56iteration/s, mean_rewards=-587]\u001b[A\n",
            "Training:  57%|█████▊    | 1150/2000 [10:21<09:22,  1.51iteration/s, mean_rewards=-587]\u001b[A\n",
            "Training:  57%|█████▊    | 1150/2000 [10:21<09:22,  1.51iteration/s, mean_rewards=-906]\u001b[A\n",
            "Training:  58%|█████▊    | 1151/2000 [10:22<10:22,  1.36iteration/s, mean_rewards=-906]\u001b[A\n",
            "Training:  58%|█████▊    | 1151/2000 [10:22<10:22,  1.36iteration/s, mean_rewards=-491]\u001b[A\n",
            "Training:  58%|█████▊    | 1152/2000 [10:22<09:17,  1.52iteration/s, mean_rewards=-491]\u001b[A\n",
            "Training:  58%|█████▊    | 1152/2000 [10:23<09:17,  1.52iteration/s, mean_rewards=-2.32e+3]\u001b[A\n",
            "Training:  58%|█████▊    | 1153/2000 [10:24<12:52,  1.10iteration/s, mean_rewards=-2.32e+3]\u001b[A\n",
            "Training:  58%|█████▊    | 1153/2000 [10:24<12:52,  1.10iteration/s, mean_rewards=-713]    \u001b[A\n",
            "Training:  58%|█████▊    | 1154/2000 [10:24<11:57,  1.18iteration/s, mean_rewards=-713]\u001b[A\n",
            "Training:  58%|█████▊    | 1154/2000 [10:25<11:57,  1.18iteration/s, mean_rewards=-472]\u001b[A\n",
            "Training:  58%|█████▊    | 1155/2000 [10:25<10:05,  1.40iteration/s, mean_rewards=-472]\u001b[A\n",
            "Training:  58%|█████▊    | 1155/2000 [10:25<10:05,  1.40iteration/s, mean_rewards=-701]\u001b[A\n",
            "Training:  58%|█████▊    | 1156/2000 [10:25<10:02,  1.40iteration/s, mean_rewards=-701]\u001b[A\n",
            "Training:  58%|█████▊    | 1156/2000 [10:26<10:02,  1.40iteration/s, mean_rewards=-592]\u001b[A\n",
            "Training:  58%|█████▊    | 1157/2000 [10:26<09:03,  1.55iteration/s, mean_rewards=-592]\u001b[A\n",
            "Training:  58%|█████▊    | 1157/2000 [10:26<09:03,  1.55iteration/s, mean_rewards=-609]\u001b[A\n",
            "Training:  58%|█████▊    | 1158/2000 [10:26<08:18,  1.69iteration/s, mean_rewards=-609]\u001b[A\n",
            "Training:  58%|█████▊    | 1158/2000 [10:27<08:18,  1.69iteration/s, mean_rewards=-522]\u001b[A\n",
            "Training:  58%|█████▊    | 1159/2000 [10:27<08:10,  1.71iteration/s, mean_rewards=-522]\u001b[A\n",
            "Training:  58%|█████▊    | 1159/2000 [10:27<08:10,  1.71iteration/s, mean_rewards=-578]\u001b[A\n",
            "Training:  58%|█████▊    | 1160/2000 [10:28<07:59,  1.75iteration/s, mean_rewards=-578]\u001b[A\n",
            "Training:  58%|█████▊    | 1160/2000 [10:28<07:59,  1.75iteration/s, mean_rewards=-1.05e+3]\u001b[A\n",
            "Training:  58%|█████▊    | 1161/2000 [10:28<08:37,  1.62iteration/s, mean_rewards=-1.05e+3]\u001b[A\n",
            "Training:  58%|█████▊    | 1161/2000 [10:29<08:37,  1.62iteration/s, mean_rewards=-979]    \u001b[A\n",
            "Training:  58%|█████▊    | 1162/2000 [10:29<09:00,  1.55iteration/s, mean_rewards=-979]\u001b[A\n",
            "Training:  58%|█████▊    | 1162/2000 [10:29<09:00,  1.55iteration/s, mean_rewards=-625]\u001b[A\n",
            "Training:  58%|█████▊    | 1163/2000 [10:29<08:19,  1.68iteration/s, mean_rewards=-625]\u001b[A\n",
            "Training:  58%|█████▊    | 1163/2000 [10:30<08:19,  1.68iteration/s, mean_rewards=-511]\u001b[A\n",
            "Training:  58%|█████▊    | 1164/2000 [10:30<08:12,  1.70iteration/s, mean_rewards=-511]\u001b[A\n",
            "Training:  58%|█████▊    | 1164/2000 [10:31<08:12,  1.70iteration/s, mean_rewards=-1.71e+3]\u001b[A\n",
            "Training:  58%|█████▊    | 1165/2000 [10:31<10:00,  1.39iteration/s, mean_rewards=-1.71e+3]\u001b[A\n",
            "Training:  58%|█████▊    | 1165/2000 [10:31<10:00,  1.39iteration/s, mean_rewards=-593]    \u001b[A\n",
            "Training:  58%|█████▊    | 1166/2000 [10:32<09:12,  1.51iteration/s, mean_rewards=-593]\u001b[A\n",
            "Training:  58%|█████▊    | 1166/2000 [10:32<09:12,  1.51iteration/s, mean_rewards=-559]\u001b[A\n",
            "Training:  58%|█████▊    | 1167/2000 [10:32<08:27,  1.64iteration/s, mean_rewards=-559]\u001b[A\n",
            "Training:  58%|█████▊    | 1167/2000 [10:33<08:27,  1.64iteration/s, mean_rewards=-656]\u001b[A\n",
            "Training:  58%|█████▊    | 1168/2000 [10:33<08:52,  1.56iteration/s, mean_rewards=-656]\u001b[A\n",
            "Training:  58%|█████▊    | 1168/2000 [10:33<08:52,  1.56iteration/s, mean_rewards=-677]\u001b[A\n",
            "Training:  58%|█████▊    | 1169/2000 [10:33<08:59,  1.54iteration/s, mean_rewards=-677]\u001b[A\n",
            "Training:  58%|█████▊    | 1169/2000 [10:34<08:59,  1.54iteration/s, mean_rewards=-634]\u001b[A\n",
            "Training:  58%|█████▊    | 1170/2000 [10:34<09:22,  1.48iteration/s, mean_rewards=-634]\u001b[A\n",
            "Training:  58%|█████▊    | 1170/2000 [10:35<09:22,  1.48iteration/s, mean_rewards=-510]\u001b[A\n",
            "Training:  59%|█████▊    | 1171/2000 [10:35<09:02,  1.53iteration/s, mean_rewards=-510]\u001b[A\n",
            "Training:  59%|█████▊    | 1171/2000 [10:35<09:02,  1.53iteration/s, mean_rewards=-579]\u001b[A\n",
            "Training:  59%|█████▊    | 1172/2000 [10:35<08:31,  1.62iteration/s, mean_rewards=-579]\u001b[A\n",
            "Training:  59%|█████▊    | 1172/2000 [10:36<08:31,  1.62iteration/s, mean_rewards=-748]\u001b[A\n",
            "Training:  59%|█████▊    | 1173/2000 [10:36<08:36,  1.60iteration/s, mean_rewards=-748]\u001b[A\n",
            "Training:  59%|█████▊    | 1173/2000 [10:36<08:36,  1.60iteration/s, mean_rewards=-901]\u001b[A\n",
            "Training:  59%|█████▊    | 1174/2000 [10:37<09:01,  1.53iteration/s, mean_rewards=-901]\u001b[A\n",
            "Training:  59%|█████▊    | 1174/2000 [10:37<09:01,  1.53iteration/s, mean_rewards=-921]\u001b[A\n",
            "Training:  59%|█████▉    | 1175/2000 [10:37<09:05,  1.51iteration/s, mean_rewards=-921]\u001b[A\n",
            "Training:  59%|█████▉    | 1175/2000 [10:38<09:05,  1.51iteration/s, mean_rewards=-940]\u001b[A\n",
            "Training:  59%|█████▉    | 1176/2000 [10:38<09:33,  1.44iteration/s, mean_rewards=-940]\u001b[A\n",
            "Training:  59%|█████▉    | 1176/2000 [10:39<09:33,  1.44iteration/s, mean_rewards=-1.45e+3]\u001b[A\n",
            "Training:  59%|█████▉    | 1177/2000 [10:39<10:48,  1.27iteration/s, mean_rewards=-1.45e+3]\u001b[A\n",
            "Training:  59%|█████▉    | 1177/2000 [10:39<10:48,  1.27iteration/s, mean_rewards=-482]    \u001b[A\n",
            "Training:  59%|█████▉    | 1178/2000 [10:40<09:30,  1.44iteration/s, mean_rewards=-482]\u001b[A\n",
            "Training:  59%|█████▉    | 1178/2000 [10:40<09:30,  1.44iteration/s, mean_rewards=-651]\u001b[A\n",
            "Training:  59%|█████▉    | 1179/2000 [10:40<08:31,  1.60iteration/s, mean_rewards=-651]\u001b[A\n",
            "Training:  59%|█████▉    | 1179/2000 [10:40<08:31,  1.60iteration/s, mean_rewards=-564]\u001b[A\n",
            "Training:  59%|█████▉    | 1180/2000 [10:41<07:49,  1.75iteration/s, mean_rewards=-564]\u001b[A\n",
            "Training:  59%|█████▉    | 1180/2000 [10:41<07:49,  1.75iteration/s, mean_rewards=-976]\u001b[A\n",
            "Training:  59%|█████▉    | 1181/2000 [10:41<09:05,  1.50iteration/s, mean_rewards=-976]\u001b[A\n",
            "Training:  59%|█████▉    | 1181/2000 [10:42<09:05,  1.50iteration/s, mean_rewards=-741]\u001b[A\n",
            "Training:  59%|█████▉    | 1182/2000 [10:42<08:38,  1.58iteration/s, mean_rewards=-741]\u001b[A\n",
            "Training:  59%|█████▉    | 1182/2000 [10:42<08:38,  1.58iteration/s, mean_rewards=-538]\u001b[A\n",
            "Training:  59%|█████▉    | 1183/2000 [10:42<07:57,  1.71iteration/s, mean_rewards=-538]\u001b[A\n",
            "Training:  59%|█████▉    | 1183/2000 [10:43<07:57,  1.71iteration/s, mean_rewards=-412]\u001b[A\n",
            "Training:  59%|█████▉    | 1184/2000 [10:43<07:51,  1.73iteration/s, mean_rewards=-412]\u001b[A\n",
            "Training:  59%|█████▉    | 1184/2000 [10:43<07:51,  1.73iteration/s, mean_rewards=-634]\u001b[A\n",
            "Training:  59%|█████▉    | 1185/2000 [10:44<07:59,  1.70iteration/s, mean_rewards=-634]\u001b[A\n",
            "Training:  59%|█████▉    | 1185/2000 [10:44<07:59,  1.70iteration/s, mean_rewards=-685]\u001b[A\n",
            "Training:  59%|█████▉    | 1186/2000 [10:44<08:10,  1.66iteration/s, mean_rewards=-685]\u001b[A\n",
            "Training:  59%|█████▉    | 1186/2000 [10:45<08:10,  1.66iteration/s, mean_rewards=-551]\u001b[A\n",
            "Training:  59%|█████▉    | 1187/2000 [10:45<07:52,  1.72iteration/s, mean_rewards=-551]\u001b[A\n",
            "Training:  59%|█████▉    | 1187/2000 [10:46<07:52,  1.72iteration/s, mean_rewards=-1.89e+3]\u001b[A\n",
            "Training:  59%|█████▉    | 1188/2000 [10:46<12:10,  1.11iteration/s, mean_rewards=-1.89e+3]\u001b[A\n",
            "Training:  59%|█████▉    | 1188/2000 [10:47<12:10,  1.11iteration/s, mean_rewards=-582]    \u001b[A\n",
            "Training:  59%|█████▉    | 1189/2000 [10:47<11:10,  1.21iteration/s, mean_rewards=-582]\u001b[A\n",
            "Training:  59%|█████▉    | 1189/2000 [10:47<11:10,  1.21iteration/s, mean_rewards=-562]\u001b[A\n",
            "Training:  60%|█████▉    | 1190/2000 [10:48<09:54,  1.36iteration/s, mean_rewards=-562]\u001b[A\n",
            "Training:  60%|█████▉    | 1190/2000 [10:48<09:54,  1.36iteration/s, mean_rewards=-656]\u001b[A\n",
            "Training:  60%|█████▉    | 1191/2000 [10:48<09:03,  1.49iteration/s, mean_rewards=-656]\u001b[A\n",
            "Training:  60%|█████▉    | 1191/2000 [10:48<09:03,  1.49iteration/s, mean_rewards=-451]\u001b[A\n",
            "Training:  60%|█████▉    | 1192/2000 [10:49<08:17,  1.62iteration/s, mean_rewards=-451]\u001b[A\n",
            "Training:  60%|█████▉    | 1192/2000 [10:49<08:17,  1.62iteration/s, mean_rewards=-596]\u001b[A\n",
            "Training:  60%|█████▉    | 1193/2000 [10:49<07:42,  1.75iteration/s, mean_rewards=-596]\u001b[A\n",
            "Training:  60%|█████▉    | 1193/2000 [10:49<07:42,  1.75iteration/s, mean_rewards=-558]\u001b[A\n",
            "Training:  60%|█████▉    | 1194/2000 [10:50<07:46,  1.73iteration/s, mean_rewards=-558]\u001b[A\n",
            "Training:  60%|█████▉    | 1194/2000 [10:50<07:46,  1.73iteration/s, mean_rewards=-1.25e+3]\u001b[A\n",
            "Training:  60%|█████▉    | 1195/2000 [10:51<09:05,  1.47iteration/s, mean_rewards=-1.25e+3]\u001b[A\n",
            "Training:  60%|█████▉    | 1195/2000 [10:51<09:05,  1.47iteration/s, mean_rewards=-565]    \u001b[A\n",
            "Training:  60%|█████▉    | 1196/2000 [10:51<08:53,  1.51iteration/s, mean_rewards=-565]\u001b[A\n",
            "Training:  60%|█████▉    | 1196/2000 [10:52<08:53,  1.51iteration/s, mean_rewards=-1.75e+3]\u001b[A\n",
            "Training:  60%|█████▉    | 1197/2000 [10:52<10:46,  1.24iteration/s, mean_rewards=-1.75e+3]\u001b[A\n",
            "Training:  60%|█████▉    | 1197/2000 [10:53<10:46,  1.24iteration/s, mean_rewards=-755]    \u001b[A\n",
            "Training:  60%|█████▉    | 1198/2000 [10:53<10:03,  1.33iteration/s, mean_rewards=-755]\u001b[A\n",
            "Training:  60%|█████▉    | 1198/2000 [10:54<10:03,  1.33iteration/s, mean_rewards=-1.61e+3]\u001b[A\n",
            "Training:  60%|█████▉    | 1199/2000 [10:54<11:20,  1.18iteration/s, mean_rewards=-1.61e+3]\u001b[A\n",
            "Training:  60%|█████▉    | 1199/2000 [10:54<11:20,  1.18iteration/s, mean_rewards=-691]    \u001b[A\n",
            "Training:  60%|██████    | 1200/2000 [10:55<10:08,  1.31iteration/s, mean_rewards=-691]\u001b[A\n",
            "Training:  60%|██████    | 1200/2000 [10:55<10:08,  1.31iteration/s, mean_rewards=-397]\u001b[A\n",
            "Training:  60%|██████    | 1201/2000 [10:55<08:54,  1.50iteration/s, mean_rewards=-397]\u001b[A\n",
            "Training:  60%|██████    | 1201/2000 [10:55<08:54,  1.50iteration/s, mean_rewards=-732]\u001b[A\n",
            "Training:  60%|██████    | 1202/2000 [10:56<08:26,  1.58iteration/s, mean_rewards=-732]\u001b[A\n",
            "Training:  60%|██████    | 1202/2000 [10:56<08:26,  1.58iteration/s, mean_rewards=-99.3]\u001b[A\n",
            "Training:  60%|██████    | 1203/2000 [10:56<07:06,  1.87iteration/s, mean_rewards=-99.3]\u001b[A\n",
            "Training:  60%|██████    | 1203/2000 [10:56<07:06,  1.87iteration/s, mean_rewards=-639] \u001b[A\n",
            "Training:  60%|██████    | 1204/2000 [10:56<07:04,  1.87iteration/s, mean_rewards=-639]\u001b[A\n",
            "Training:  60%|██████    | 1204/2000 [10:57<07:04,  1.87iteration/s, mean_rewards=-356]\u001b[A\n",
            "Training:  60%|██████    | 1205/2000 [10:57<06:25,  2.06iteration/s, mean_rewards=-356]\u001b[A\n",
            "Training:  60%|██████    | 1205/2000 [10:57<06:25,  2.06iteration/s, mean_rewards=-788]\u001b[A\n",
            "Training:  60%|██████    | 1206/2000 [10:57<06:47,  1.95iteration/s, mean_rewards=-788]\u001b[A\n",
            "Training:  60%|██████    | 1206/2000 [10:58<06:47,  1.95iteration/s, mean_rewards=-512]\u001b[A\n",
            "Training:  60%|██████    | 1207/2000 [10:58<07:17,  1.81iteration/s, mean_rewards=-512]\u001b[A\n",
            "Training:  60%|██████    | 1207/2000 [10:59<07:17,  1.81iteration/s, mean_rewards=-577]\u001b[A\n",
            "Training:  60%|██████    | 1208/2000 [10:59<07:56,  1.66iteration/s, mean_rewards=-577]\u001b[A\n",
            "Training:  60%|██████    | 1208/2000 [11:00<07:56,  1.66iteration/s, mean_rewards=-1.25e+3]\u001b[A\n",
            "Training:  60%|██████    | 1209/2000 [11:00<09:52,  1.34iteration/s, mean_rewards=-1.25e+3]\u001b[A\n",
            "Training:  60%|██████    | 1209/2000 [11:01<09:52,  1.34iteration/s, mean_rewards=-891]    \u001b[A\n",
            "Training:  60%|██████    | 1210/2000 [11:01<10:45,  1.22iteration/s, mean_rewards=-891]\u001b[A\n",
            "Training:  60%|██████    | 1210/2000 [11:01<10:45,  1.22iteration/s, mean_rewards=-904]\u001b[A\n",
            "Training:  61%|██████    | 1211/2000 [11:02<10:26,  1.26iteration/s, mean_rewards=-904]\u001b[A\n",
            "Training:  61%|██████    | 1211/2000 [11:02<10:26,  1.26iteration/s, mean_rewards=-753]\u001b[A\n",
            "Training:  61%|██████    | 1212/2000 [11:02<09:27,  1.39iteration/s, mean_rewards=-753]\u001b[A\n",
            "Training:  61%|██████    | 1212/2000 [11:03<09:27,  1.39iteration/s, mean_rewards=-728]\u001b[A\n",
            "Training:  61%|██████    | 1213/2000 [11:03<08:57,  1.46iteration/s, mean_rewards=-728]\u001b[A\n",
            "Training:  61%|██████    | 1213/2000 [11:03<08:57,  1.46iteration/s, mean_rewards=-1.69e+3]\u001b[A\n",
            "Training:  61%|██████    | 1214/2000 [11:04<10:16,  1.28iteration/s, mean_rewards=-1.69e+3]\u001b[A\n",
            "Training:  61%|██████    | 1214/2000 [11:04<10:16,  1.28iteration/s, mean_rewards=-789]    \u001b[A\n",
            "Training:  61%|██████    | 1215/2000 [11:04<09:55,  1.32iteration/s, mean_rewards=-789]\u001b[A\n",
            "Training:  61%|██████    | 1215/2000 [11:05<09:55,  1.32iteration/s, mean_rewards=-1.08e+3]\u001b[A\n",
            "Training:  61%|██████    | 1216/2000 [11:05<10:15,  1.27iteration/s, mean_rewards=-1.08e+3]\u001b[A\n",
            "Training:  61%|██████    | 1216/2000 [11:06<10:15,  1.27iteration/s, mean_rewards=-1.25e+3]\u001b[A\n",
            "Training:  61%|██████    | 1217/2000 [11:06<10:26,  1.25iteration/s, mean_rewards=-1.25e+3]\u001b[A\n",
            "Training:  61%|██████    | 1217/2000 [11:06<10:26,  1.25iteration/s, mean_rewards=-89.4]   \u001b[A\n",
            "Training:  61%|██████    | 1218/2000 [11:06<08:35,  1.52iteration/s, mean_rewards=-89.4]\u001b[A\n",
            "Training:  61%|██████    | 1218/2000 [11:07<08:35,  1.52iteration/s, mean_rewards=-432] \u001b[A\n",
            "Training:  61%|██████    | 1219/2000 [11:07<07:45,  1.68iteration/s, mean_rewards=-432]\u001b[A\n",
            "Training:  61%|██████    | 1219/2000 [11:07<07:45,  1.68iteration/s, mean_rewards=-605]\u001b[A\n",
            "Training:  61%|██████    | 1220/2000 [11:07<07:17,  1.78iteration/s, mean_rewards=-605]\u001b[A\n",
            "Training:  61%|██████    | 1220/2000 [11:08<07:17,  1.78iteration/s, mean_rewards=-541]\u001b[A\n",
            "Training:  61%|██████    | 1221/2000 [11:08<06:58,  1.86iteration/s, mean_rewards=-541]\u001b[A\n",
            "Training:  61%|██████    | 1221/2000 [11:08<06:58,  1.86iteration/s, mean_rewards=-1.32e+3]\u001b[A\n",
            "Training:  61%|██████    | 1222/2000 [11:09<08:25,  1.54iteration/s, mean_rewards=-1.32e+3]\u001b[A\n",
            "Training:  61%|██████    | 1222/2000 [11:09<08:25,  1.54iteration/s, mean_rewards=-576]    \u001b[A\n",
            "Training:  61%|██████    | 1223/2000 [11:09<07:31,  1.72iteration/s, mean_rewards=-576]\u001b[A\n",
            "Training:  61%|██████    | 1223/2000 [11:10<07:31,  1.72iteration/s, mean_rewards=-673]\u001b[A\n",
            "Training:  61%|██████    | 1224/2000 [11:10<07:26,  1.74iteration/s, mean_rewards=-673]\u001b[A\n",
            "Training:  61%|██████    | 1224/2000 [11:11<07:26,  1.74iteration/s, mean_rewards=-1.35e+3]\u001b[A\n",
            "Training:  61%|██████▏   | 1225/2000 [11:11<09:42,  1.33iteration/s, mean_rewards=-1.35e+3]\u001b[A\n",
            "Training:  61%|██████▏   | 1225/2000 [11:11<09:42,  1.33iteration/s, mean_rewards=-541]    \u001b[A\n",
            "Training:  61%|██████▏   | 1226/2000 [11:12<09:31,  1.35iteration/s, mean_rewards=-541]\u001b[A\n",
            "Training:  61%|██████▏   | 1226/2000 [11:12<09:31,  1.35iteration/s, mean_rewards=-314]\u001b[A\n",
            "Training:  61%|██████▏   | 1227/2000 [11:12<09:22,  1.38iteration/s, mean_rewards=-314]\u001b[A\n",
            "Training:  61%|██████▏   | 1227/2000 [11:13<09:22,  1.38iteration/s, mean_rewards=-591]\u001b[A\n",
            "Training:  61%|██████▏   | 1228/2000 [11:13<09:07,  1.41iteration/s, mean_rewards=-591]\u001b[A\n",
            "Training:  61%|██████▏   | 1228/2000 [11:13<09:07,  1.41iteration/s, mean_rewards=-269]\u001b[A\n",
            "Training:  61%|██████▏   | 1229/2000 [11:13<08:06,  1.59iteration/s, mean_rewards=-269]\u001b[A\n",
            "Training:  61%|██████▏   | 1229/2000 [11:14<08:06,  1.59iteration/s, mean_rewards=-528]\u001b[A\n",
            "Training:  62%|██████▏   | 1230/2000 [11:14<07:43,  1.66iteration/s, mean_rewards=-528]\u001b[A\n",
            "Training:  62%|██████▏   | 1230/2000 [11:14<07:43,  1.66iteration/s, mean_rewards=-725]\u001b[A\n",
            "Training:  62%|██████▏   | 1231/2000 [11:15<07:29,  1.71iteration/s, mean_rewards=-725]\u001b[A\n",
            "Training:  62%|██████▏   | 1231/2000 [11:15<07:29,  1.71iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  62%|██████▏   | 1232/2000 [11:15<06:26,  1.99iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  62%|██████▏   | 1232/2000 [11:15<06:26,  1.99iteration/s, mean_rewards=-765]\u001b[A\n",
            "Training:  62%|██████▏   | 1233/2000 [11:15<06:49,  1.87iteration/s, mean_rewards=-765]\u001b[A\n",
            "Training:  62%|██████▏   | 1233/2000 [11:16<06:49,  1.87iteration/s, mean_rewards=-549]\u001b[A\n",
            "Training:  62%|██████▏   | 1234/2000 [11:16<06:35,  1.94iteration/s, mean_rewards=-549]\u001b[A\n",
            "Training:  62%|██████▏   | 1234/2000 [11:16<06:35,  1.94iteration/s, mean_rewards=-349]\u001b[A\n",
            "Training:  62%|██████▏   | 1235/2000 [11:16<06:19,  2.01iteration/s, mean_rewards=-349]\u001b[A\n",
            "Training:  62%|██████▏   | 1235/2000 [11:17<06:19,  2.01iteration/s, mean_rewards=-753]\u001b[A\n",
            "Training:  62%|██████▏   | 1236/2000 [11:17<06:50,  1.86iteration/s, mean_rewards=-753]\u001b[A\n",
            "Training:  62%|██████▏   | 1236/2000 [11:17<06:50,  1.86iteration/s, mean_rewards=-591]\u001b[A\n",
            "Training:  62%|██████▏   | 1237/2000 [11:18<06:47,  1.87iteration/s, mean_rewards=-591]\u001b[A\n",
            "Training:  62%|██████▏   | 1237/2000 [11:18<06:47,  1.87iteration/s, mean_rewards=-744]\u001b[A\n",
            "Training:  62%|██████▏   | 1238/2000 [11:18<07:02,  1.80iteration/s, mean_rewards=-744]\u001b[A\n",
            "Training:  62%|██████▏   | 1238/2000 [11:18<07:02,  1.80iteration/s, mean_rewards=-637]\u001b[A\n",
            "Training:  62%|██████▏   | 1239/2000 [11:19<06:50,  1.85iteration/s, mean_rewards=-637]\u001b[A\n",
            "Training:  62%|██████▏   | 1239/2000 [11:19<06:50,  1.85iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  62%|██████▏   | 1240/2000 [11:19<06:01,  2.10iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  62%|██████▏   | 1240/2000 [11:19<06:01,  2.10iteration/s, mean_rewards=-567]\u001b[A\n",
            "Training:  62%|██████▏   | 1241/2000 [11:19<06:00,  2.11iteration/s, mean_rewards=-567]\u001b[A\n",
            "Training:  62%|██████▏   | 1241/2000 [11:20<06:00,  2.11iteration/s, mean_rewards=-666]\u001b[A\n",
            "Training:  62%|██████▏   | 1242/2000 [11:20<06:02,  2.09iteration/s, mean_rewards=-666]\u001b[A\n",
            "Training:  62%|██████▏   | 1242/2000 [11:20<06:02,  2.09iteration/s, mean_rewards=-759]\u001b[A\n",
            "Training:  62%|██████▏   | 1243/2000 [11:21<06:39,  1.90iteration/s, mean_rewards=-759]\u001b[A\n",
            "Training:  62%|██████▏   | 1243/2000 [11:21<06:39,  1.90iteration/s, mean_rewards=-297]\u001b[A\n",
            "Training:  62%|██████▏   | 1244/2000 [11:21<06:02,  2.09iteration/s, mean_rewards=-297]\u001b[A\n",
            "Training:  62%|██████▏   | 1244/2000 [11:21<06:02,  2.09iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  62%|██████▏   | 1245/2000 [11:21<05:23,  2.33iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  62%|██████▏   | 1245/2000 [11:21<05:23,  2.33iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:  62%|██████▏   | 1246/2000 [11:22<05:07,  2.46iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:  62%|██████▏   | 1246/2000 [11:22<05:07,  2.46iteration/s, mean_rewards=-693]\u001b[A\n",
            "Training:  62%|██████▏   | 1247/2000 [11:22<05:35,  2.24iteration/s, mean_rewards=-693]\u001b[A\n",
            "Training:  62%|██████▏   | 1247/2000 [11:23<05:35,  2.24iteration/s, mean_rewards=-811]\u001b[A\n",
            "Training:  62%|██████▏   | 1248/2000 [11:23<06:20,  1.98iteration/s, mean_rewards=-811]\u001b[A\n",
            "Training:  62%|██████▏   | 1248/2000 [11:23<06:20,  1.98iteration/s, mean_rewards=-554]\u001b[A\n",
            "Training:  62%|██████▏   | 1249/2000 [11:23<06:38,  1.88iteration/s, mean_rewards=-554]\u001b[A\n",
            "Training:  62%|██████▏   | 1249/2000 [11:24<06:38,  1.88iteration/s, mean_rewards=-389]\u001b[A\n",
            "Training:  62%|██████▎   | 1250/2000 [11:24<06:53,  1.81iteration/s, mean_rewards=-389]\u001b[A\n",
            "Training:  62%|██████▎   | 1250/2000 [11:26<06:53,  1.81iteration/s, mean_rewards=-2.89e+3]\u001b[A\n",
            "Training:  63%|██████▎   | 1251/2000 [11:26<12:56,  1.04s/iteration, mean_rewards=-2.89e+3]\u001b[A\n",
            "Training:  63%|██████▎   | 1251/2000 [11:26<12:56,  1.04s/iteration, mean_rewards=-703]    \u001b[A\n",
            "Training:  63%|██████▎   | 1252/2000 [11:27<11:03,  1.13iteration/s, mean_rewards=-703]\u001b[A\n",
            "Training:  63%|██████▎   | 1252/2000 [11:27<11:03,  1.13iteration/s, mean_rewards=-429]\u001b[A\n",
            "Training:  63%|██████▎   | 1253/2000 [11:27<09:45,  1.28iteration/s, mean_rewards=-429]\u001b[A\n",
            "Training:  63%|██████▎   | 1253/2000 [11:27<09:45,  1.28iteration/s, mean_rewards=-382]\u001b[A\n",
            "Training:  63%|██████▎   | 1254/2000 [11:28<08:17,  1.50iteration/s, mean_rewards=-382]\u001b[A\n",
            "Training:  63%|██████▎   | 1254/2000 [11:28<08:17,  1.50iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  63%|██████▎   | 1255/2000 [11:28<06:58,  1.78iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  63%|██████▎   | 1255/2000 [11:28<06:58,  1.78iteration/s, mean_rewards=-797]\u001b[A\n",
            "Training:  63%|██████▎   | 1256/2000 [11:29<07:17,  1.70iteration/s, mean_rewards=-797]\u001b[A\n",
            "Training:  63%|██████▎   | 1256/2000 [11:29<07:17,  1.70iteration/s, mean_rewards=-521]\u001b[A\n",
            "Training:  63%|██████▎   | 1257/2000 [11:29<06:49,  1.82iteration/s, mean_rewards=-521]\u001b[A\n",
            "Training:  63%|██████▎   | 1257/2000 [11:29<06:49,  1.82iteration/s, mean_rewards=-317]\u001b[A\n",
            "Training:  63%|██████▎   | 1258/2000 [11:29<06:10,  2.00iteration/s, mean_rewards=-317]\u001b[A\n",
            "Training:  63%|██████▎   | 1258/2000 [11:30<06:10,  2.00iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  63%|██████▎   | 1259/2000 [11:30<05:27,  2.26iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  63%|██████▎   | 1259/2000 [11:30<05:27,  2.26iteration/s, mean_rewards=-483]\u001b[A\n",
            "Training:  63%|██████▎   | 1260/2000 [11:30<05:43,  2.15iteration/s, mean_rewards=-483]\u001b[A\n",
            "Training:  63%|██████▎   | 1260/2000 [11:31<05:43,  2.15iteration/s, mean_rewards=-707]\u001b[A\n",
            "Training:  63%|██████▎   | 1261/2000 [11:31<06:04,  2.03iteration/s, mean_rewards=-707]\u001b[A\n",
            "Training:  63%|██████▎   | 1261/2000 [11:31<06:04,  2.03iteration/s, mean_rewards=-455]\u001b[A\n",
            "Training:  63%|██████▎   | 1262/2000 [11:31<05:47,  2.12iteration/s, mean_rewards=-455]\u001b[A\n",
            "Training:  63%|██████▎   | 1262/2000 [11:32<05:47,  2.12iteration/s, mean_rewards=-1.06e+3]\u001b[A\n",
            "Training:  63%|██████▎   | 1263/2000 [11:32<06:56,  1.77iteration/s, mean_rewards=-1.06e+3]\u001b[A\n",
            "Training:  63%|██████▎   | 1263/2000 [11:32<06:56,  1.77iteration/s, mean_rewards=-283]    \u001b[A\n",
            "Training:  63%|██████▎   | 1264/2000 [11:32<06:18,  1.94iteration/s, mean_rewards=-283]\u001b[A\n",
            "Training:  63%|██████▎   | 1264/2000 [11:33<06:18,  1.94iteration/s, mean_rewards=-361]\u001b[A\n",
            "Training:  63%|██████▎   | 1265/2000 [11:33<05:48,  2.11iteration/s, mean_rewards=-361]\u001b[A\n",
            "Training:  63%|██████▎   | 1265/2000 [11:33<05:48,  2.11iteration/s, mean_rewards=-1.16e+3]\u001b[A\n",
            "Training:  63%|██████▎   | 1266/2000 [11:34<07:09,  1.71iteration/s, mean_rewards=-1.16e+3]\u001b[A\n",
            "Training:  63%|██████▎   | 1266/2000 [11:34<07:09,  1.71iteration/s, mean_rewards=-617]    \u001b[A\n",
            "Training:  63%|██████▎   | 1267/2000 [11:34<06:32,  1.87iteration/s, mean_rewards=-617]\u001b[A\n",
            "Training:  63%|██████▎   | 1267/2000 [11:34<06:32,  1.87iteration/s, mean_rewards=-624]\u001b[A\n",
            "Training:  63%|██████▎   | 1268/2000 [11:35<06:34,  1.86iteration/s, mean_rewards=-624]\u001b[A\n",
            "Training:  63%|██████▎   | 1268/2000 [11:35<06:34,  1.86iteration/s, mean_rewards=-41.8]\u001b[A\n",
            "Training:  63%|██████▎   | 1269/2000 [11:35<05:43,  2.13iteration/s, mean_rewards=-41.8]\u001b[A\n",
            "Training:  63%|██████▎   | 1269/2000 [11:35<05:43,  2.13iteration/s, mean_rewards=-637] \u001b[A\n",
            "Training:  64%|██████▎   | 1270/2000 [11:35<05:47,  2.10iteration/s, mean_rewards=-637]\u001b[A\n",
            "Training:  64%|██████▎   | 1270/2000 [11:36<05:47,  2.10iteration/s, mean_rewards=-774]\u001b[A\n",
            "Training:  64%|██████▎   | 1271/2000 [11:36<05:57,  2.04iteration/s, mean_rewards=-774]\u001b[A\n",
            "Training:  64%|██████▎   | 1271/2000 [11:36<05:57,  2.04iteration/s, mean_rewards=-648]\u001b[A\n",
            "Training:  64%|██████▎   | 1272/2000 [11:37<06:45,  1.80iteration/s, mean_rewards=-648]\u001b[A\n",
            "Training:  64%|██████▎   | 1272/2000 [11:37<06:45,  1.80iteration/s, mean_rewards=-429]\u001b[A\n",
            "Training:  64%|██████▎   | 1273/2000 [11:37<06:35,  1.84iteration/s, mean_rewards=-429]\u001b[A\n",
            "Training:  64%|██████▎   | 1273/2000 [11:38<06:35,  1.84iteration/s, mean_rewards=-822]\u001b[A\n",
            "Training:  64%|██████▎   | 1274/2000 [11:38<07:23,  1.64iteration/s, mean_rewards=-822]\u001b[A\n",
            "Training:  64%|██████▎   | 1274/2000 [11:38<07:23,  1.64iteration/s, mean_rewards=-498]\u001b[A\n",
            "Training:  64%|██████▍   | 1275/2000 [11:39<07:47,  1.55iteration/s, mean_rewards=-498]\u001b[A\n",
            "Training:  64%|██████▍   | 1275/2000 [11:39<07:47,  1.55iteration/s, mean_rewards=-1.01e+3]\u001b[A\n",
            "Training:  64%|██████▍   | 1276/2000 [11:39<08:26,  1.43iteration/s, mean_rewards=-1.01e+3]\u001b[A\n",
            "Training:  64%|██████▍   | 1276/2000 [11:40<08:26,  1.43iteration/s, mean_rewards=-308]    \u001b[A\n",
            "Training:  64%|██████▍   | 1277/2000 [11:40<07:20,  1.64iteration/s, mean_rewards=-308]\u001b[A\n",
            "Training:  64%|██████▍   | 1277/2000 [11:40<07:20,  1.64iteration/s, mean_rewards=-89] \u001b[A\n",
            "Training:  64%|██████▍   | 1278/2000 [11:40<06:11,  1.94iteration/s, mean_rewards=-89]\u001b[A\n",
            "Training:  64%|██████▍   | 1278/2000 [11:40<06:11,  1.94iteration/s, mean_rewards=-356]\u001b[A\n",
            "Training:  64%|██████▍   | 1279/2000 [11:41<05:46,  2.08iteration/s, mean_rewards=-356]\u001b[A\n",
            "Training:  64%|██████▍   | 1279/2000 [11:41<05:46,  2.08iteration/s, mean_rewards=-693]\u001b[A\n",
            "Training:  64%|██████▍   | 1280/2000 [11:41<05:47,  2.07iteration/s, mean_rewards=-693]\u001b[A\n",
            "Training:  64%|██████▍   | 1280/2000 [11:42<05:47,  2.07iteration/s, mean_rewards=-1.38e+3]\u001b[A\n",
            "Training:  64%|██████▍   | 1281/2000 [11:42<07:40,  1.56iteration/s, mean_rewards=-1.38e+3]\u001b[A\n",
            "Training:  64%|██████▍   | 1281/2000 [11:43<07:40,  1.56iteration/s, mean_rewards=-2.82e+3]\u001b[A\n",
            "Training:  64%|██████▍   | 1282/2000 [11:44<11:07,  1.08iteration/s, mean_rewards=-2.82e+3]\u001b[A\n",
            "Training:  64%|██████▍   | 1282/2000 [11:44<11:07,  1.08iteration/s, mean_rewards=-826]    \u001b[A\n",
            "Training:  64%|██████▍   | 1283/2000 [11:44<10:09,  1.18iteration/s, mean_rewards=-826]\u001b[A\n",
            "Training:  64%|██████▍   | 1283/2000 [11:45<10:09,  1.18iteration/s, mean_rewards=-453]\u001b[A\n",
            "Training:  64%|██████▍   | 1284/2000 [11:45<08:44,  1.36iteration/s, mean_rewards=-453]\u001b[A\n",
            "Training:  64%|██████▍   | 1284/2000 [11:45<08:44,  1.36iteration/s, mean_rewards=-498]\u001b[A\n",
            "Training:  64%|██████▍   | 1285/2000 [11:45<07:55,  1.50iteration/s, mean_rewards=-498]\u001b[A\n",
            "Training:  64%|██████▍   | 1285/2000 [11:46<07:55,  1.50iteration/s, mean_rewards=-557]\u001b[A\n",
            "Training:  64%|██████▍   | 1286/2000 [11:46<07:19,  1.62iteration/s, mean_rewards=-557]\u001b[A\n",
            "Training:  64%|██████▍   | 1286/2000 [11:46<07:19,  1.62iteration/s, mean_rewards=-349]\u001b[A\n",
            "Training:  64%|██████▍   | 1287/2000 [11:46<06:52,  1.73iteration/s, mean_rewards=-349]\u001b[A\n",
            "Training:  64%|██████▍   | 1287/2000 [11:46<06:52,  1.73iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  64%|██████▍   | 1288/2000 [11:47<05:59,  1.98iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  64%|██████▍   | 1288/2000 [11:47<05:59,  1.98iteration/s, mean_rewards=-644]\u001b[A\n",
            "Training:  64%|██████▍   | 1289/2000 [11:47<06:12,  1.91iteration/s, mean_rewards=-644]\u001b[A\n",
            "Training:  64%|██████▍   | 1289/2000 [11:48<06:12,  1.91iteration/s, mean_rewards=-542]\u001b[A\n",
            "Training:  64%|██████▍   | 1290/2000 [11:48<06:20,  1.87iteration/s, mean_rewards=-542]\u001b[A\n",
            "Training:  64%|██████▍   | 1290/2000 [11:48<06:20,  1.87iteration/s, mean_rewards=-306]\u001b[A\n",
            "Training:  65%|██████▍   | 1291/2000 [11:48<05:54,  2.00iteration/s, mean_rewards=-306]\u001b[A\n",
            "Training:  65%|██████▍   | 1291/2000 [11:48<05:54,  2.00iteration/s, mean_rewards=-340]\u001b[A\n",
            "Training:  65%|██████▍   | 1292/2000 [11:49<05:30,  2.14iteration/s, mean_rewards=-340]\u001b[A\n",
            "Training:  65%|██████▍   | 1292/2000 [11:50<05:30,  2.14iteration/s, mean_rewards=-1.51e+3]\u001b[A\n",
            "Training:  65%|██████▍   | 1293/2000 [11:50<08:50,  1.33iteration/s, mean_rewards=-1.51e+3]\u001b[A\n",
            "Training:  65%|██████▍   | 1293/2000 [11:51<08:50,  1.33iteration/s, mean_rewards=-931]    \u001b[A\n",
            "Training:  65%|██████▍   | 1294/2000 [11:51<09:52,  1.19iteration/s, mean_rewards=-931]\u001b[A\n",
            "Training:  65%|██████▍   | 1294/2000 [11:52<09:52,  1.19iteration/s, mean_rewards=-1.51e+3]\u001b[A\n",
            "Training:  65%|██████▍   | 1295/2000 [11:52<10:50,  1.08iteration/s, mean_rewards=-1.51e+3]\u001b[A\n",
            "Training:  65%|██████▍   | 1295/2000 [11:52<10:50,  1.08iteration/s, mean_rewards=-596]    \u001b[A\n",
            "Training:  65%|██████▍   | 1296/2000 [11:53<09:09,  1.28iteration/s, mean_rewards=-596]\u001b[A\n",
            "Training:  65%|██████▍   | 1296/2000 [11:53<09:09,  1.28iteration/s, mean_rewards=-400]\u001b[A\n",
            "Training:  65%|██████▍   | 1297/2000 [11:53<07:49,  1.50iteration/s, mean_rewards=-400]\u001b[A\n",
            "Training:  65%|██████▍   | 1297/2000 [11:53<07:49,  1.50iteration/s, mean_rewards=-300]\u001b[A\n",
            "Training:  65%|██████▍   | 1298/2000 [11:53<06:52,  1.70iteration/s, mean_rewards=-300]\u001b[A\n",
            "Training:  65%|██████▍   | 1298/2000 [11:54<06:52,  1.70iteration/s, mean_rewards=-667]\u001b[A\n",
            "Training:  65%|██████▍   | 1299/2000 [11:54<07:02,  1.66iteration/s, mean_rewards=-667]\u001b[A\n",
            "Training:  65%|██████▍   | 1299/2000 [11:55<07:02,  1.66iteration/s, mean_rewards=-848]\u001b[A\n",
            "Training:  65%|██████▌   | 1300/2000 [11:55<07:43,  1.51iteration/s, mean_rewards=-848]\u001b[A\n",
            "Training:  65%|██████▌   | 1300/2000 [11:55<07:43,  1.51iteration/s, mean_rewards=-393]\u001b[A\n",
            "Training:  65%|██████▌   | 1301/2000 [11:55<06:51,  1.70iteration/s, mean_rewards=-393]\u001b[A\n",
            "Training:  65%|██████▌   | 1301/2000 [11:55<06:51,  1.70iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  65%|██████▌   | 1302/2000 [11:56<05:53,  1.98iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  65%|██████▌   | 1302/2000 [11:56<05:53,  1.98iteration/s, mean_rewards=-472]\u001b[A\n",
            "Training:  65%|██████▌   | 1303/2000 [11:56<05:40,  2.05iteration/s, mean_rewards=-472]\u001b[A\n",
            "Training:  65%|██████▌   | 1303/2000 [11:56<05:40,  2.05iteration/s, mean_rewards=-326]\u001b[A\n",
            "Training:  65%|██████▌   | 1304/2000 [11:56<05:33,  2.09iteration/s, mean_rewards=-326]\u001b[A\n",
            "Training:  65%|██████▌   | 1304/2000 [11:57<05:33,  2.09iteration/s, mean_rewards=-444]\u001b[A\n",
            "Training:  65%|██████▌   | 1305/2000 [11:57<05:27,  2.12iteration/s, mean_rewards=-444]\u001b[A\n",
            "Training:  65%|██████▌   | 1305/2000 [11:57<05:27,  2.12iteration/s, mean_rewards=-419]\u001b[A\n",
            "Training:  65%|██████▌   | 1306/2000 [11:57<05:34,  2.07iteration/s, mean_rewards=-419]\u001b[A\n",
            "Training:  65%|██████▌   | 1306/2000 [11:58<05:34,  2.07iteration/s, mean_rewards=-640]\u001b[A\n",
            "Training:  65%|██████▌   | 1307/2000 [11:58<05:58,  1.93iteration/s, mean_rewards=-640]\u001b[A\n",
            "Training:  65%|██████▌   | 1307/2000 [11:58<05:58,  1.93iteration/s, mean_rewards=-99.2]\u001b[A\n",
            "Training:  65%|██████▌   | 1308/2000 [11:58<05:15,  2.19iteration/s, mean_rewards=-99.2]\u001b[A\n",
            "Training:  65%|██████▌   | 1308/2000 [11:59<05:15,  2.19iteration/s, mean_rewards=-287] \u001b[A\n",
            "Training:  65%|██████▌   | 1309/2000 [11:59<05:00,  2.30iteration/s, mean_rewards=-287]\u001b[A\n",
            "Training:  65%|██████▌   | 1309/2000 [11:59<05:00,  2.30iteration/s, mean_rewards=-730]\u001b[A\n",
            "Training:  66%|██████▌   | 1310/2000 [11:59<05:23,  2.13iteration/s, mean_rewards=-730]\u001b[A\n",
            "Training:  66%|██████▌   | 1310/2000 [11:59<05:23,  2.13iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  66%|██████▌   | 1311/2000 [12:00<05:06,  2.25iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  66%|██████▌   | 1311/2000 [12:00<05:06,  2.25iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  66%|██████▌   | 1312/2000 [12:00<04:54,  2.34iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  66%|██████▌   | 1312/2000 [12:00<04:54,  2.34iteration/s, mean_rewards=-490]\u001b[A\n",
            "Training:  66%|██████▌   | 1313/2000 [12:01<05:27,  2.10iteration/s, mean_rewards=-490]\u001b[A\n",
            "Training:  66%|██████▌   | 1313/2000 [12:01<05:27,  2.10iteration/s, mean_rewards=-390]\u001b[A\n",
            "Training:  66%|██████▌   | 1314/2000 [12:01<05:30,  2.07iteration/s, mean_rewards=-390]\u001b[A\n",
            "Training:  66%|██████▌   | 1314/2000 [12:02<05:30,  2.07iteration/s, mean_rewards=-542]\u001b[A\n",
            "Training:  66%|██████▌   | 1315/2000 [12:02<06:24,  1.78iteration/s, mean_rewards=-542]\u001b[A\n",
            "Training:  66%|██████▌   | 1315/2000 [12:03<06:24,  1.78iteration/s, mean_rewards=-924]\u001b[A\n",
            "Training:  66%|██████▌   | 1316/2000 [12:03<08:03,  1.42iteration/s, mean_rewards=-924]\u001b[A\n",
            "Training:  66%|██████▌   | 1316/2000 [12:03<08:03,  1.42iteration/s, mean_rewards=-340]\u001b[A\n",
            "Training:  66%|██████▌   | 1317/2000 [12:03<07:24,  1.54iteration/s, mean_rewards=-340]\u001b[A\n",
            "Training:  66%|██████▌   | 1317/2000 [12:04<07:24,  1.54iteration/s, mean_rewards=-331]\u001b[A\n",
            "Training:  66%|██████▌   | 1318/2000 [12:04<06:54,  1.65iteration/s, mean_rewards=-331]\u001b[A\n",
            "Training:  66%|██████▌   | 1318/2000 [12:04<06:54,  1.65iteration/s, mean_rewards=-349]\u001b[A\n",
            "Training:  66%|██████▌   | 1319/2000 [12:04<06:40,  1.70iteration/s, mean_rewards=-349]\u001b[A\n",
            "Training:  66%|██████▌   | 1319/2000 [12:05<06:40,  1.70iteration/s, mean_rewards=-1.08e+3]\u001b[A\n",
            "Training:  66%|██████▌   | 1320/2000 [12:05<07:08,  1.59iteration/s, mean_rewards=-1.08e+3]\u001b[A\n",
            "Training:  66%|██████▌   | 1320/2000 [12:06<07:08,  1.59iteration/s, mean_rewards=-673]    \u001b[A\n",
            "Training:  66%|██████▌   | 1321/2000 [12:06<06:51,  1.65iteration/s, mean_rewards=-673]\u001b[A\n",
            "Training:  66%|██████▌   | 1321/2000 [12:06<06:51,  1.65iteration/s, mean_rewards=-605]\u001b[A\n",
            "Training:  66%|██████▌   | 1322/2000 [12:06<06:29,  1.74iteration/s, mean_rewards=-605]\u001b[A\n",
            "Training:  66%|██████▌   | 1322/2000 [12:07<06:29,  1.74iteration/s, mean_rewards=-1.12e+3]\u001b[A\n",
            "Training:  66%|██████▌   | 1323/2000 [12:07<07:08,  1.58iteration/s, mean_rewards=-1.12e+3]\u001b[A\n",
            "Training:  66%|██████▌   | 1323/2000 [12:07<07:08,  1.58iteration/s, mean_rewards=-120]    \u001b[A\n",
            "Training:  66%|██████▌   | 1324/2000 [12:07<06:00,  1.87iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  66%|██████▌   | 1324/2000 [12:08<06:00,  1.87iteration/s, mean_rewards=-342]\u001b[A\n",
            "Training:  66%|██████▋   | 1325/2000 [12:08<05:32,  2.03iteration/s, mean_rewards=-342]\u001b[A\n",
            "Training:  66%|██████▋   | 1325/2000 [12:08<05:32,  2.03iteration/s, mean_rewards=-589]\u001b[A\n",
            "Training:  66%|██████▋   | 1326/2000 [12:08<05:40,  1.98iteration/s, mean_rewards=-589]\u001b[A\n",
            "Training:  66%|██████▋   | 1326/2000 [12:09<05:40,  1.98iteration/s, mean_rewards=-331]\u001b[A\n",
            "Training:  66%|██████▋   | 1327/2000 [12:09<05:19,  2.10iteration/s, mean_rewards=-331]\u001b[A\n",
            "Training:  66%|██████▋   | 1327/2000 [12:09<05:19,  2.10iteration/s, mean_rewards=-1.1e+3]\u001b[A\n",
            "Training:  66%|██████▋   | 1328/2000 [12:09<06:27,  1.73iteration/s, mean_rewards=-1.1e+3]\u001b[A\n",
            "Training:  66%|██████▋   | 1328/2000 [12:10<06:27,  1.73iteration/s, mean_rewards=-376]   \u001b[A\n",
            "Training:  66%|██████▋   | 1329/2000 [12:10<06:02,  1.85iteration/s, mean_rewards=-376]\u001b[A\n",
            "Training:  66%|██████▋   | 1329/2000 [12:10<06:02,  1.85iteration/s, mean_rewards=-322]\u001b[A\n",
            "Training:  66%|██████▋   | 1330/2000 [12:10<05:32,  2.01iteration/s, mean_rewards=-322]\u001b[A\n",
            "Training:  66%|██████▋   | 1330/2000 [12:11<05:32,  2.01iteration/s, mean_rewards=-699]\u001b[A\n",
            "Training:  67%|██████▋   | 1331/2000 [12:11<05:52,  1.90iteration/s, mean_rewards=-699]\u001b[A\n",
            "Training:  67%|██████▋   | 1331/2000 [12:12<05:52,  1.90iteration/s, mean_rewards=-1.18e+3]\u001b[A\n",
            "Training:  67%|██████▋   | 1332/2000 [12:12<07:02,  1.58iteration/s, mean_rewards=-1.18e+3]\u001b[A\n",
            "Training:  67%|██████▋   | 1332/2000 [12:12<07:02,  1.58iteration/s, mean_rewards=-675]    \u001b[A\n",
            "Training:  67%|██████▋   | 1333/2000 [12:12<07:08,  1.56iteration/s, mean_rewards=-675]\u001b[A\n",
            "Training:  67%|██████▋   | 1333/2000 [12:13<07:08,  1.56iteration/s, mean_rewards=-557]\u001b[A\n",
            "Training:  67%|██████▋   | 1334/2000 [12:13<06:52,  1.61iteration/s, mean_rewards=-557]\u001b[A\n",
            "Training:  67%|██████▋   | 1334/2000 [12:13<06:52,  1.61iteration/s, mean_rewards=-619]\u001b[A\n",
            "Training:  67%|██████▋   | 1335/2000 [12:14<06:36,  1.68iteration/s, mean_rewards=-619]\u001b[A\n",
            "Training:  67%|██████▋   | 1335/2000 [12:14<06:36,  1.68iteration/s, mean_rewards=-1.34e+3]\u001b[A\n",
            "Training:  67%|██████▋   | 1336/2000 [12:14<07:33,  1.46iteration/s, mean_rewards=-1.34e+3]\u001b[A\n",
            "Training:  67%|██████▋   | 1336/2000 [12:15<07:33,  1.46iteration/s, mean_rewards=-342]    \u001b[A\n",
            "Training:  67%|██████▋   | 1337/2000 [12:15<06:58,  1.58iteration/s, mean_rewards=-342]\u001b[A\n",
            "Training:  67%|██████▋   | 1337/2000 [12:15<06:58,  1.58iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  67%|██████▋   | 1338/2000 [12:15<06:19,  1.74iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  67%|██████▋   | 1338/2000 [12:16<06:19,  1.74iteration/s, mean_rewards=-595]\u001b[A\n",
            "Training:  67%|██████▋   | 1339/2000 [12:16<06:19,  1.74iteration/s, mean_rewards=-595]\u001b[A\n",
            "Training:  67%|██████▋   | 1339/2000 [12:16<06:19,  1.74iteration/s, mean_rewards=-381]\u001b[A\n",
            "Training:  67%|██████▋   | 1340/2000 [12:17<06:45,  1.63iteration/s, mean_rewards=-381]\u001b[A\n",
            "Training:  67%|██████▋   | 1340/2000 [12:17<06:45,  1.63iteration/s, mean_rewards=-553]\u001b[A\n",
            "Training:  67%|██████▋   | 1341/2000 [12:17<06:55,  1.59iteration/s, mean_rewards=-553]\u001b[A\n",
            "Training:  67%|██████▋   | 1341/2000 [12:18<06:55,  1.59iteration/s, mean_rewards=-507]\u001b[A\n",
            "Training:  67%|██████▋   | 1342/2000 [12:18<06:13,  1.76iteration/s, mean_rewards=-507]\u001b[A\n",
            "Training:  67%|██████▋   | 1342/2000 [12:18<06:13,  1.76iteration/s, mean_rewards=-542]\u001b[A\n",
            "Training:  67%|██████▋   | 1343/2000 [12:18<06:07,  1.79iteration/s, mean_rewards=-542]\u001b[A\n",
            "Training:  67%|██████▋   | 1343/2000 [12:19<06:07,  1.79iteration/s, mean_rewards=-425]\u001b[A\n",
            "Training:  67%|██████▋   | 1344/2000 [12:19<05:38,  1.94iteration/s, mean_rewards=-425]\u001b[A\n",
            "Training:  67%|██████▋   | 1344/2000 [12:19<05:38,  1.94iteration/s, mean_rewards=-1.1e+3]\u001b[A\n",
            "Training:  67%|██████▋   | 1345/2000 [12:20<06:38,  1.64iteration/s, mean_rewards=-1.1e+3]\u001b[A\n",
            "Training:  67%|██████▋   | 1345/2000 [12:20<06:38,  1.64iteration/s, mean_rewards=-716]   \u001b[A\n",
            "Training:  67%|██████▋   | 1346/2000 [12:20<06:44,  1.62iteration/s, mean_rewards=-716]\u001b[A\n",
            "Training:  67%|██████▋   | 1346/2000 [12:21<06:44,  1.62iteration/s, mean_rewards=-549]\u001b[A\n",
            "Training:  67%|██████▋   | 1347/2000 [12:21<06:57,  1.57iteration/s, mean_rewards=-549]\u001b[A\n",
            "Training:  67%|██████▋   | 1347/2000 [12:21<06:57,  1.57iteration/s, mean_rewards=-885]\u001b[A\n",
            "Training:  67%|██████▋   | 1348/2000 [12:22<07:00,  1.55iteration/s, mean_rewards=-885]\u001b[A\n",
            "Training:  67%|██████▋   | 1348/2000 [12:22<07:00,  1.55iteration/s, mean_rewards=-385]\u001b[A\n",
            "Training:  67%|██████▋   | 1349/2000 [12:22<06:19,  1.72iteration/s, mean_rewards=-385]\u001b[A\n",
            "Training:  67%|██████▋   | 1349/2000 [12:22<06:19,  1.72iteration/s, mean_rewards=-336]\u001b[A\n",
            "Training:  68%|██████▊   | 1350/2000 [12:22<05:42,  1.90iteration/s, mean_rewards=-336]\u001b[A\n",
            "Training:  68%|██████▊   | 1350/2000 [12:23<05:42,  1.90iteration/s, mean_rewards=-457]\u001b[A\n",
            "Training:  68%|██████▊   | 1351/2000 [12:23<05:28,  1.98iteration/s, mean_rewards=-457]\u001b[A\n",
            "Training:  68%|██████▊   | 1351/2000 [12:23<05:28,  1.98iteration/s, mean_rewards=-711]\u001b[A\n",
            "Training:  68%|██████▊   | 1352/2000 [12:24<06:04,  1.78iteration/s, mean_rewards=-711]\u001b[A\n",
            "Training:  68%|██████▊   | 1352/2000 [12:24<06:04,  1.78iteration/s, mean_rewards=-633]\u001b[A\n",
            "Training:  68%|██████▊   | 1353/2000 [12:24<06:09,  1.75iteration/s, mean_rewards=-633]\u001b[A\n",
            "Training:  68%|██████▊   | 1353/2000 [12:25<06:09,  1.75iteration/s, mean_rewards=-742]\u001b[A\n",
            "Training:  68%|██████▊   | 1354/2000 [12:25<06:19,  1.70iteration/s, mean_rewards=-742]\u001b[A\n",
            "Training:  68%|██████▊   | 1354/2000 [12:25<06:19,  1.70iteration/s, mean_rewards=-465]\u001b[A\n",
            "Training:  68%|██████▊   | 1355/2000 [12:25<06:11,  1.73iteration/s, mean_rewards=-465]\u001b[A\n",
            "Training:  68%|██████▊   | 1355/2000 [12:26<06:11,  1.73iteration/s, mean_rewards=-477]\u001b[A\n",
            "Training:  68%|██████▊   | 1356/2000 [12:26<05:52,  1.83iteration/s, mean_rewards=-477]\u001b[A\n",
            "Training:  68%|██████▊   | 1356/2000 [12:26<05:52,  1.83iteration/s, mean_rewards=-748]\u001b[A\n",
            "Training:  68%|██████▊   | 1357/2000 [12:27<06:28,  1.66iteration/s, mean_rewards=-748]\u001b[A\n",
            "Training:  68%|██████▊   | 1357/2000 [12:27<06:28,  1.66iteration/s, mean_rewards=-416]\u001b[A\n",
            "Training:  68%|██████▊   | 1358/2000 [12:27<05:58,  1.79iteration/s, mean_rewards=-416]\u001b[A\n",
            "Training:  68%|██████▊   | 1358/2000 [12:27<05:58,  1.79iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  68%|██████▊   | 1359/2000 [12:27<05:12,  2.05iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  68%|██████▊   | 1359/2000 [12:28<05:12,  2.05iteration/s, mean_rewards=-320]\u001b[A\n",
            "Training:  68%|██████▊   | 1360/2000 [12:28<05:15,  2.03iteration/s, mean_rewards=-320]\u001b[A\n",
            "Training:  68%|██████▊   | 1360/2000 [12:28<05:15,  2.03iteration/s, mean_rewards=-604]\u001b[A\n",
            "Training:  68%|██████▊   | 1361/2000 [12:28<05:28,  1.94iteration/s, mean_rewards=-604]\u001b[A\n",
            "Training:  68%|██████▊   | 1361/2000 [12:29<05:28,  1.94iteration/s, mean_rewards=-732]\u001b[A\n",
            "Training:  68%|██████▊   | 1362/2000 [12:29<06:31,  1.63iteration/s, mean_rewards=-732]\u001b[A\n",
            "Training:  68%|██████▊   | 1362/2000 [12:30<06:31,  1.63iteration/s, mean_rewards=-523]\u001b[A\n",
            "Training:  68%|██████▊   | 1363/2000 [12:30<06:48,  1.56iteration/s, mean_rewards=-523]\u001b[A\n",
            "Training:  68%|██████▊   | 1363/2000 [12:30<06:48,  1.56iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  68%|██████▊   | 1364/2000 [12:30<05:51,  1.81iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  68%|██████▊   | 1364/2000 [12:31<05:51,  1.81iteration/s, mean_rewards=-334]\u001b[A\n",
            "Training:  68%|██████▊   | 1365/2000 [12:31<05:30,  1.92iteration/s, mean_rewards=-334]\u001b[A\n",
            "Training:  68%|██████▊   | 1365/2000 [12:31<05:30,  1.92iteration/s, mean_rewards=-377]\u001b[A\n",
            "Training:  68%|██████▊   | 1366/2000 [12:31<05:11,  2.04iteration/s, mean_rewards=-377]\u001b[A\n",
            "Training:  68%|██████▊   | 1366/2000 [12:32<05:11,  2.04iteration/s, mean_rewards=-2e+3]\u001b[A\n",
            "Training:  68%|██████▊   | 1367/2000 [12:32<07:50,  1.35iteration/s, mean_rewards=-2e+3]\u001b[A\n",
            "Training:  68%|██████▊   | 1367/2000 [12:33<07:50,  1.35iteration/s, mean_rewards=-981] \u001b[A\n",
            "Training:  68%|██████▊   | 1368/2000 [12:33<08:13,  1.28iteration/s, mean_rewards=-981]\u001b[A\n",
            "Training:  68%|██████▊   | 1368/2000 [12:34<08:13,  1.28iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  68%|██████▊   | 1369/2000 [12:34<07:08,  1.47iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  68%|██████▊   | 1369/2000 [12:34<07:08,  1.47iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  68%|██████▊   | 1370/2000 [12:34<06:00,  1.75iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  68%|██████▊   | 1370/2000 [12:34<06:00,  1.75iteration/s, mean_rewards=-81.1]\u001b[A\n",
            "Training:  69%|██████▊   | 1371/2000 [12:34<05:24,  1.94iteration/s, mean_rewards=-81.1]\u001b[A\n",
            "Training:  69%|██████▊   | 1371/2000 [12:35<05:24,  1.94iteration/s, mean_rewards=-162] \u001b[A\n",
            "Training:  69%|██████▊   | 1372/2000 [12:35<04:54,  2.13iteration/s, mean_rewards=-162]\u001b[A\n",
            "Training:  69%|██████▊   | 1372/2000 [12:35<04:54,  2.13iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  69%|██████▊   | 1373/2000 [12:35<04:36,  2.27iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  69%|██████▊   | 1373/2000 [12:35<04:36,  2.27iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  69%|██████▊   | 1374/2000 [12:36<04:33,  2.29iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  69%|██████▊   | 1374/2000 [12:36<04:33,  2.29iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  69%|██████▉   | 1375/2000 [12:36<04:27,  2.34iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  69%|██████▉   | 1375/2000 [12:36<04:27,  2.34iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  69%|██████▉   | 1376/2000 [12:36<04:20,  2.39iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  69%|██████▉   | 1376/2000 [12:37<04:20,  2.39iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  69%|██████▉   | 1377/2000 [12:37<04:11,  2.48iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  69%|██████▉   | 1377/2000 [12:37<04:11,  2.48iteration/s, mean_rewards=-100]\u001b[A\n",
            "Training:  69%|██████▉   | 1378/2000 [12:37<03:55,  2.65iteration/s, mean_rewards=-100]\u001b[A\n",
            "Training:  69%|██████▉   | 1378/2000 [12:37<03:55,  2.65iteration/s, mean_rewards=-218]\u001b[A\n",
            "Training:  69%|██████▉   | 1379/2000 [12:38<04:07,  2.51iteration/s, mean_rewards=-218]\u001b[A\n",
            "Training:  69%|██████▉   | 1379/2000 [12:38<04:07,  2.51iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  69%|██████▉   | 1380/2000 [12:38<03:50,  2.68iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  69%|██████▉   | 1380/2000 [12:38<03:50,  2.68iteration/s, mean_rewards=-188]\u001b[A\n",
            "Training:  69%|██████▉   | 1381/2000 [12:38<03:55,  2.63iteration/s, mean_rewards=-188]\u001b[A\n",
            "Training:  69%|██████▉   | 1381/2000 [12:39<03:55,  2.63iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  69%|██████▉   | 1382/2000 [12:39<03:57,  2.60iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  69%|██████▉   | 1382/2000 [12:39<03:57,  2.60iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  69%|██████▉   | 1383/2000 [12:39<03:51,  2.66iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  69%|██████▉   | 1383/2000 [12:39<03:51,  2.66iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  69%|██████▉   | 1384/2000 [12:39<03:40,  2.80iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  69%|██████▉   | 1384/2000 [12:40<03:40,  2.80iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  69%|██████▉   | 1385/2000 [12:40<03:33,  2.89iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  69%|██████▉   | 1385/2000 [12:40<03:33,  2.89iteration/s, mean_rewards=-79.8]\u001b[A\n",
            "Training:  69%|██████▉   | 1386/2000 [12:40<04:00,  2.55iteration/s, mean_rewards=-79.8]\u001b[A\n",
            "Training:  69%|██████▉   | 1386/2000 [12:40<04:00,  2.55iteration/s, mean_rewards=-149] \u001b[A\n",
            "Training:  69%|██████▉   | 1387/2000 [12:41<04:08,  2.46iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  69%|██████▉   | 1387/2000 [12:41<04:08,  2.46iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  69%|██████▉   | 1388/2000 [12:41<04:23,  2.32iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  69%|██████▉   | 1388/2000 [12:41<04:23,  2.32iteration/s, mean_rewards=-162]\u001b[A\n",
            "Training:  69%|██████▉   | 1389/2000 [12:42<04:35,  2.22iteration/s, mean_rewards=-162]\u001b[A\n",
            "Training:  69%|██████▉   | 1389/2000 [12:42<04:35,  2.22iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  70%|██████▉   | 1390/2000 [12:42<04:34,  2.22iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  70%|██████▉   | 1390/2000 [12:42<04:34,  2.22iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  70%|██████▉   | 1391/2000 [12:42<04:29,  2.26iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  70%|██████▉   | 1391/2000 [12:43<04:29,  2.26iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  70%|██████▉   | 1392/2000 [12:43<04:26,  2.28iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  70%|██████▉   | 1392/2000 [12:43<04:26,  2.28iteration/s, mean_rewards=-105]\u001b[A\n",
            "Training:  70%|██████▉   | 1393/2000 [12:43<04:17,  2.35iteration/s, mean_rewards=-105]\u001b[A\n",
            "Training:  70%|██████▉   | 1393/2000 [12:44<04:17,  2.35iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  70%|██████▉   | 1394/2000 [12:44<04:09,  2.42iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  70%|██████▉   | 1394/2000 [12:44<04:09,  2.42iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  70%|██████▉   | 1395/2000 [12:44<03:58,  2.53iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  70%|██████▉   | 1395/2000 [12:44<03:58,  2.53iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  70%|██████▉   | 1396/2000 [12:44<03:44,  2.69iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  70%|██████▉   | 1396/2000 [12:45<03:44,  2.69iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:  70%|██████▉   | 1397/2000 [12:45<03:48,  2.64iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:  70%|██████▉   | 1397/2000 [12:45<03:48,  2.64iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  70%|██████▉   | 1398/2000 [12:45<03:36,  2.78iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  70%|██████▉   | 1398/2000 [12:45<03:36,  2.78iteration/s, mean_rewards=-184]\u001b[A\n",
            "Training:  70%|██████▉   | 1399/2000 [12:45<03:39,  2.74iteration/s, mean_rewards=-184]\u001b[A\n",
            "Training:  70%|██████▉   | 1399/2000 [12:46<03:39,  2.74iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  70%|███████   | 1400/2000 [12:46<03:40,  2.73iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  70%|███████   | 1400/2000 [12:46<03:40,  2.73iteration/s, mean_rewards=-218]\u001b[A\n",
            "Training:  70%|███████   | 1401/2000 [12:47<05:11,  1.92iteration/s, mean_rewards=-218]\u001b[A\n",
            "Training:  70%|███████   | 1401/2000 [12:47<05:11,  1.92iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  70%|███████   | 1402/2000 [12:47<04:49,  2.06iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  70%|███████   | 1402/2000 [12:47<04:49,  2.06iteration/s, mean_rewards=-314]\u001b[A\n",
            "Training:  70%|███████   | 1403/2000 [12:48<04:46,  2.08iteration/s, mean_rewards=-314]\u001b[A\n",
            "Training:  70%|███████   | 1403/2000 [12:48<04:46,  2.08iteration/s, mean_rewards=-87.3]\u001b[A\n",
            "Training:  70%|███████   | 1404/2000 [12:48<04:19,  2.30iteration/s, mean_rewards=-87.3]\u001b[A\n",
            "Training:  70%|███████   | 1404/2000 [12:48<04:19,  2.30iteration/s, mean_rewards=-109] \u001b[A\n",
            "Training:  70%|███████   | 1405/2000 [12:48<04:14,  2.34iteration/s, mean_rewards=-109]\u001b[A\n",
            "Training:  70%|███████   | 1405/2000 [12:49<04:14,  2.34iteration/s, mean_rewards=-340]\u001b[A\n",
            "Training:  70%|███████   | 1406/2000 [12:49<04:59,  1.99iteration/s, mean_rewards=-340]\u001b[A\n",
            "Training:  70%|███████   | 1406/2000 [12:49<04:59,  1.99iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  70%|███████   | 1407/2000 [12:49<04:36,  2.15iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  70%|███████   | 1407/2000 [12:50<04:36,  2.15iteration/s, mean_rewards=-254]\u001b[A\n",
            "Training:  70%|███████   | 1408/2000 [12:50<04:26,  2.22iteration/s, mean_rewards=-254]\u001b[A\n",
            "Training:  70%|███████   | 1408/2000 [12:50<04:26,  2.22iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  70%|███████   | 1409/2000 [12:50<04:23,  2.24iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  70%|███████   | 1409/2000 [12:50<04:23,  2.24iteration/s, mean_rewards=-251]\u001b[A\n",
            "Training:  70%|███████   | 1410/2000 [12:51<04:23,  2.24iteration/s, mean_rewards=-251]\u001b[A\n",
            "Training:  70%|███████   | 1410/2000 [12:51<04:23,  2.24iteration/s, mean_rewards=-308]\u001b[A\n",
            "Training:  71%|███████   | 1411/2000 [12:51<05:06,  1.92iteration/s, mean_rewards=-308]\u001b[A\n",
            "Training:  71%|███████   | 1411/2000 [12:52<05:06,  1.92iteration/s, mean_rewards=-225]\u001b[A\n",
            "Training:  71%|███████   | 1412/2000 [12:52<04:54,  2.00iteration/s, mean_rewards=-225]\u001b[A\n",
            "Training:  71%|███████   | 1412/2000 [12:52<04:54,  2.00iteration/s, mean_rewards=-188]\u001b[A\n",
            "Training:  71%|███████   | 1413/2000 [12:52<04:46,  2.05iteration/s, mean_rewards=-188]\u001b[A\n",
            "Training:  71%|███████   | 1413/2000 [12:53<04:46,  2.05iteration/s, mean_rewards=-283]\u001b[A\n",
            "Training:  71%|███████   | 1414/2000 [12:53<05:22,  1.82iteration/s, mean_rewards=-283]\u001b[A\n",
            "Training:  71%|███████   | 1414/2000 [12:53<05:22,  1.82iteration/s, mean_rewards=-160]\u001b[A\n",
            "Training:  71%|███████   | 1415/2000 [12:53<05:03,  1.93iteration/s, mean_rewards=-160]\u001b[A\n",
            "Training:  71%|███████   | 1415/2000 [12:54<05:03,  1.93iteration/s, mean_rewards=-367]\u001b[A\n",
            "Training:  71%|███████   | 1416/2000 [12:54<05:19,  1.83iteration/s, mean_rewards=-367]\u001b[A\n",
            "Training:  71%|███████   | 1416/2000 [12:54<05:19,  1.83iteration/s, mean_rewards=-166]\u001b[A\n",
            "Training:  71%|███████   | 1417/2000 [12:55<05:26,  1.79iteration/s, mean_rewards=-166]\u001b[A\n",
            "Training:  71%|███████   | 1417/2000 [12:55<05:26,  1.79iteration/s, mean_rewards=-290]\u001b[A\n",
            "Training:  71%|███████   | 1418/2000 [12:55<05:47,  1.67iteration/s, mean_rewards=-290]\u001b[A\n",
            "Training:  71%|███████   | 1418/2000 [12:56<05:47,  1.67iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  71%|███████   | 1419/2000 [12:56<05:26,  1.78iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  71%|███████   | 1419/2000 [12:56<05:26,  1.78iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  71%|███████   | 1420/2000 [12:56<04:44,  2.04iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  71%|███████   | 1420/2000 [12:56<04:44,  2.04iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  71%|███████   | 1421/2000 [12:56<04:12,  2.29iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  71%|███████   | 1421/2000 [12:57<04:12,  2.29iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  71%|███████   | 1422/2000 [12:57<03:52,  2.49iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  71%|███████   | 1422/2000 [12:57<03:52,  2.49iteration/s, mean_rewards=-71.8]\u001b[A\n",
            "Training:  71%|███████   | 1423/2000 [12:57<03:50,  2.51iteration/s, mean_rewards=-71.8]\u001b[A\n",
            "Training:  71%|███████   | 1423/2000 [12:57<03:50,  2.51iteration/s, mean_rewards=-134] \u001b[A\n",
            "Training:  71%|███████   | 1424/2000 [12:57<03:41,  2.59iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  71%|███████   | 1424/2000 [12:58<03:41,  2.59iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  71%|███████▏  | 1425/2000 [12:58<03:38,  2.63iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  71%|███████▏  | 1425/2000 [12:58<03:38,  2.63iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  71%|███████▏  | 1426/2000 [12:58<03:36,  2.65iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  71%|███████▏  | 1426/2000 [12:58<03:36,  2.65iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  71%|███████▏  | 1427/2000 [12:59<03:34,  2.68iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  71%|███████▏  | 1427/2000 [12:59<03:34,  2.68iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  71%|███████▏  | 1428/2000 [12:59<03:44,  2.55iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  71%|███████▏  | 1428/2000 [12:59<03:44,  2.55iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  71%|███████▏  | 1429/2000 [12:59<03:30,  2.71iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  71%|███████▏  | 1429/2000 [13:00<03:30,  2.71iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  72%|███████▏  | 1430/2000 [13:00<03:20,  2.85iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  72%|███████▏  | 1430/2000 [13:00<03:20,  2.85iteration/s, mean_rewards=-194]\u001b[A\n",
            "Training:  72%|███████▏  | 1431/2000 [13:00<03:26,  2.76iteration/s, mean_rewards=-194]\u001b[A\n",
            "Training:  72%|███████▏  | 1431/2000 [13:00<03:26,  2.76iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  72%|███████▏  | 1432/2000 [13:00<03:24,  2.77iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  72%|███████▏  | 1432/2000 [13:01<03:24,  2.77iteration/s, mean_rewards=-115]\u001b[A\n",
            "Training:  72%|███████▏  | 1433/2000 [13:01<03:24,  2.77iteration/s, mean_rewards=-115]\u001b[A\n",
            "Training:  72%|███████▏  | 1433/2000 [13:01<03:24,  2.77iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:  72%|███████▏  | 1434/2000 [13:01<03:18,  2.85iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:  72%|███████▏  | 1434/2000 [13:01<03:18,  2.85iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  72%|███████▏  | 1435/2000 [13:01<03:13,  2.92iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  72%|███████▏  | 1435/2000 [13:02<03:13,  2.92iteration/s, mean_rewards=-179]\u001b[A\n",
            "Training:  72%|███████▏  | 1436/2000 [13:02<03:20,  2.81iteration/s, mean_rewards=-179]\u001b[A\n",
            "Training:  72%|███████▏  | 1436/2000 [13:02<03:20,  2.81iteration/s, mean_rewards=-52.4]\u001b[A\n",
            "Training:  72%|███████▏  | 1437/2000 [13:02<03:28,  2.70iteration/s, mean_rewards=-52.4]\u001b[A\n",
            "Training:  72%|███████▏  | 1437/2000 [13:02<03:28,  2.70iteration/s, mean_rewards=-123] \u001b[A\n",
            "Training:  72%|███████▏  | 1438/2000 [13:03<03:26,  2.72iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  72%|███████▏  | 1438/2000 [13:03<03:26,  2.72iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  72%|███████▏  | 1439/2000 [13:03<03:33,  2.63iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  72%|███████▏  | 1439/2000 [13:03<03:33,  2.63iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  72%|███████▏  | 1440/2000 [13:03<03:21,  2.79iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  72%|███████▏  | 1440/2000 [13:03<03:21,  2.79iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:  72%|███████▏  | 1441/2000 [13:04<03:14,  2.88iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:  72%|███████▏  | 1441/2000 [13:04<03:14,  2.88iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  72%|███████▏  | 1442/2000 [13:04<03:19,  2.79iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  72%|███████▏  | 1442/2000 [13:04<03:19,  2.79iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:  72%|███████▏  | 1443/2000 [13:04<03:22,  2.75iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:  72%|███████▏  | 1443/2000 [13:05<03:22,  2.75iteration/s, mean_rewards=-71.1]\u001b[A\n",
            "Training:  72%|███████▏  | 1444/2000 [13:05<03:33,  2.60iteration/s, mean_rewards=-71.1]\u001b[A\n",
            "Training:  72%|███████▏  | 1444/2000 [13:05<03:33,  2.60iteration/s, mean_rewards=-154] \u001b[A\n",
            "Training:  72%|███████▏  | 1445/2000 [13:05<03:42,  2.50iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  72%|███████▏  | 1445/2000 [13:05<03:42,  2.50iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  72%|███████▏  | 1446/2000 [13:06<03:28,  2.65iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  72%|███████▏  | 1446/2000 [13:06<03:28,  2.65iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  72%|███████▏  | 1447/2000 [13:06<03:24,  2.70iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  72%|███████▏  | 1447/2000 [13:06<03:24,  2.70iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  72%|███████▏  | 1448/2000 [13:06<03:45,  2.44iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  72%|███████▏  | 1448/2000 [13:07<03:45,  2.44iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  72%|███████▏  | 1449/2000 [13:07<03:44,  2.46iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  72%|███████▏  | 1449/2000 [13:07<03:44,  2.46iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  72%|███████▎  | 1450/2000 [13:07<04:03,  2.26iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  72%|███████▎  | 1450/2000 [13:08<04:03,  2.26iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  73%|███████▎  | 1451/2000 [13:08<04:13,  2.17iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  73%|███████▎  | 1451/2000 [13:08<04:13,  2.17iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  73%|███████▎  | 1452/2000 [13:08<04:22,  2.09iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  73%|███████▎  | 1452/2000 [13:09<04:22,  2.09iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:  73%|███████▎  | 1453/2000 [13:09<04:25,  2.06iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:  73%|███████▎  | 1453/2000 [13:09<04:25,  2.06iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  73%|███████▎  | 1454/2000 [13:09<03:57,  2.30iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  73%|███████▎  | 1454/2000 [13:09<03:57,  2.30iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  73%|███████▎  | 1455/2000 [13:09<03:36,  2.52iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  73%|███████▎  | 1455/2000 [13:10<03:36,  2.52iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  73%|███████▎  | 1456/2000 [13:10<03:31,  2.57iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  73%|███████▎  | 1456/2000 [13:10<03:31,  2.57iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  73%|███████▎  | 1457/2000 [13:10<03:26,  2.63iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  73%|███████▎  | 1457/2000 [13:10<03:26,  2.63iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  73%|███████▎  | 1458/2000 [13:11<03:26,  2.62iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  73%|███████▎  | 1458/2000 [13:11<03:26,  2.62iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  73%|███████▎  | 1459/2000 [13:11<03:28,  2.60iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  73%|███████▎  | 1459/2000 [13:11<03:28,  2.60iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  73%|███████▎  | 1460/2000 [13:11<03:34,  2.51iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  73%|███████▎  | 1460/2000 [13:12<03:34,  2.51iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  73%|███████▎  | 1461/2000 [13:12<03:19,  2.70iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  73%|███████▎  | 1461/2000 [13:12<03:19,  2.70iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  73%|███████▎  | 1462/2000 [13:12<03:18,  2.71iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  73%|███████▎  | 1462/2000 [13:12<03:18,  2.71iteration/s, mean_rewards=-214]\u001b[A\n",
            "Training:  73%|███████▎  | 1463/2000 [13:12<03:22,  2.65iteration/s, mean_rewards=-214]\u001b[A\n",
            "Training:  73%|███████▎  | 1463/2000 [13:13<03:22,  2.65iteration/s, mean_rewards=-105]\u001b[A\n",
            "Training:  73%|███████▎  | 1464/2000 [13:13<03:10,  2.81iteration/s, mean_rewards=-105]\u001b[A\n",
            "Training:  73%|███████▎  | 1464/2000 [13:13<03:10,  2.81iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  73%|███████▎  | 1465/2000 [13:13<03:09,  2.83iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  73%|███████▎  | 1465/2000 [13:13<03:09,  2.83iteration/s, mean_rewards=-64.8]\u001b[A\n",
            "Training:  73%|███████▎  | 1466/2000 [13:14<03:28,  2.57iteration/s, mean_rewards=-64.8]\u001b[A\n",
            "Training:  73%|███████▎  | 1466/2000 [13:14<03:28,  2.57iteration/s, mean_rewards=-137] \u001b[A\n",
            "Training:  73%|███████▎  | 1467/2000 [13:14<03:27,  2.57iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  73%|███████▎  | 1467/2000 [13:14<03:27,  2.57iteration/s, mean_rewards=-162]\u001b[A\n",
            "Training:  73%|███████▎  | 1468/2000 [13:14<03:29,  2.54iteration/s, mean_rewards=-162]\u001b[A\n",
            "Training:  73%|███████▎  | 1468/2000 [13:15<03:29,  2.54iteration/s, mean_rewards=-88.8]\u001b[A\n",
            "Training:  73%|███████▎  | 1469/2000 [13:15<03:39,  2.42iteration/s, mean_rewards=-88.8]\u001b[A\n",
            "Training:  73%|███████▎  | 1469/2000 [13:15<03:39,  2.42iteration/s, mean_rewards=-115] \u001b[A\n",
            "Training:  74%|███████▎  | 1470/2000 [13:15<03:44,  2.36iteration/s, mean_rewards=-115]\u001b[A\n",
            "Training:  74%|███████▎  | 1470/2000 [13:16<03:44,  2.36iteration/s, mean_rewards=-172]\u001b[A\n",
            "Training:  74%|███████▎  | 1471/2000 [13:16<03:46,  2.33iteration/s, mean_rewards=-172]\u001b[A\n",
            "Training:  74%|███████▎  | 1471/2000 [13:16<03:46,  2.33iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  74%|███████▎  | 1472/2000 [13:16<03:28,  2.53iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  74%|███████▎  | 1472/2000 [13:16<03:28,  2.53iteration/s, mean_rewards=-159]\u001b[A\n",
            "Training:  74%|███████▎  | 1473/2000 [13:16<03:20,  2.63iteration/s, mean_rewards=-159]\u001b[A\n",
            "Training:  74%|███████▎  | 1473/2000 [13:17<03:20,  2.63iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  74%|███████▎  | 1474/2000 [13:17<03:18,  2.65iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  74%|███████▎  | 1474/2000 [13:17<03:18,  2.65iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  74%|███████▍  | 1475/2000 [13:17<03:09,  2.77iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  74%|███████▍  | 1475/2000 [13:17<03:09,  2.77iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  74%|███████▍  | 1476/2000 [13:17<03:02,  2.87iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  74%|███████▍  | 1476/2000 [13:18<03:02,  2.87iteration/s, mean_rewards=-109]\u001b[A\n",
            "Training:  74%|███████▍  | 1477/2000 [13:18<03:07,  2.78iteration/s, mean_rewards=-109]\u001b[A\n",
            "Training:  74%|███████▍  | 1477/2000 [13:18<03:07,  2.78iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  74%|███████▍  | 1478/2000 [13:18<03:06,  2.79iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  74%|███████▍  | 1478/2000 [13:18<03:06,  2.79iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  74%|███████▍  | 1479/2000 [13:19<03:13,  2.69iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  74%|███████▍  | 1479/2000 [13:19<03:13,  2.69iteration/s, mean_rewards=-240]\u001b[A\n",
            "Training:  74%|███████▍  | 1480/2000 [13:19<03:33,  2.44iteration/s, mean_rewards=-240]\u001b[A\n",
            "Training:  74%|███████▍  | 1480/2000 [13:19<03:33,  2.44iteration/s, mean_rewards=-91.4]\u001b[A\n",
            "Training:  74%|███████▍  | 1481/2000 [13:20<03:55,  2.20iteration/s, mean_rewards=-91.4]\u001b[A\n",
            "Training:  74%|███████▍  | 1481/2000 [13:20<03:55,  2.20iteration/s, mean_rewards=-128] \u001b[A\n",
            "Training:  74%|███████▍  | 1482/2000 [13:20<03:55,  2.20iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  74%|███████▍  | 1482/2000 [13:20<03:55,  2.20iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  74%|███████▍  | 1483/2000 [13:21<04:02,  2.13iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  74%|███████▍  | 1483/2000 [13:21<04:02,  2.13iteration/s, mean_rewards=-99.2]\u001b[A\n",
            "Training:  74%|███████▍  | 1484/2000 [13:21<03:55,  2.19iteration/s, mean_rewards=-99.2]\u001b[A\n",
            "Training:  74%|███████▍  | 1484/2000 [13:21<03:55,  2.19iteration/s, mean_rewards=-118] \u001b[A\n",
            "Training:  74%|███████▍  | 1485/2000 [13:22<04:08,  2.07iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  74%|███████▍  | 1485/2000 [13:22<04:08,  2.07iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  74%|███████▍  | 1486/2000 [13:22<04:07,  2.08iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  74%|███████▍  | 1486/2000 [13:22<04:07,  2.08iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  74%|███████▍  | 1487/2000 [13:22<03:49,  2.24iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  74%|███████▍  | 1487/2000 [13:23<03:49,  2.24iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  74%|███████▍  | 1488/2000 [13:23<03:42,  2.30iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  74%|███████▍  | 1488/2000 [13:23<03:42,  2.30iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  74%|███████▍  | 1489/2000 [13:23<03:24,  2.50iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  74%|███████▍  | 1489/2000 [13:23<03:24,  2.50iteration/s, mean_rewards=-62] \u001b[A\n",
            "Training:  74%|███████▍  | 1490/2000 [13:23<03:12,  2.65iteration/s, mean_rewards=-62]\u001b[A\n",
            "Training:  74%|███████▍  | 1490/2000 [13:24<03:12,  2.65iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  75%|███████▍  | 1491/2000 [13:24<03:04,  2.76iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  75%|███████▍  | 1491/2000 [13:24<03:04,  2.76iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  75%|███████▍  | 1492/2000 [13:24<03:06,  2.72iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  75%|███████▍  | 1492/2000 [13:24<03:06,  2.72iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  75%|███████▍  | 1493/2000 [13:25<03:11,  2.65iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  75%|███████▍  | 1493/2000 [13:25<03:11,  2.65iteration/s, mean_rewards=-170]\u001b[A\n",
            "Training:  75%|███████▍  | 1494/2000 [13:25<03:15,  2.59iteration/s, mean_rewards=-170]\u001b[A\n",
            "Training:  75%|███████▍  | 1494/2000 [13:25<03:15,  2.59iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:  75%|███████▍  | 1495/2000 [13:25<03:06,  2.70iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:  75%|███████▍  | 1495/2000 [13:25<03:06,  2.70iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  75%|███████▍  | 1496/2000 [13:26<02:58,  2.83iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  75%|███████▍  | 1496/2000 [13:26<02:58,  2.83iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  75%|███████▍  | 1497/2000 [13:26<03:00,  2.78iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  75%|███████▍  | 1497/2000 [13:26<03:00,  2.78iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  75%|███████▍  | 1498/2000 [13:26<03:04,  2.73iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  75%|███████▍  | 1498/2000 [13:27<03:04,  2.73iteration/s, mean_rewards=-65.5]\u001b[A\n",
            "Training:  75%|███████▍  | 1499/2000 [13:27<03:03,  2.73iteration/s, mean_rewards=-65.5]\u001b[A\n",
            "Training:  75%|███████▍  | 1499/2000 [13:27<03:03,  2.73iteration/s, mean_rewards=-127] \u001b[A\n",
            "Training:  75%|███████▌  | 1500/2000 [13:27<03:02,  2.74iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  75%|███████▌  | 1500/2000 [13:27<03:02,  2.74iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  75%|███████▌  | 1501/2000 [13:27<02:53,  2.88iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  75%|███████▌  | 1501/2000 [13:28<02:53,  2.88iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:  75%|███████▌  | 1502/2000 [13:28<02:50,  2.93iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:  75%|███████▌  | 1502/2000 [13:28<02:50,  2.93iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  75%|███████▌  | 1503/2000 [13:28<02:48,  2.95iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  75%|███████▌  | 1503/2000 [13:28<02:48,  2.95iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  75%|███████▌  | 1504/2000 [13:28<02:45,  3.00iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  75%|███████▌  | 1504/2000 [13:29<02:45,  3.00iteration/s, mean_rewards=-116]\u001b[A\n",
            "Training:  75%|███████▌  | 1505/2000 [13:29<02:52,  2.87iteration/s, mean_rewards=-116]\u001b[A\n",
            "Training:  75%|███████▌  | 1505/2000 [13:29<02:52,  2.87iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  75%|███████▌  | 1506/2000 [13:29<03:07,  2.63iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  75%|███████▌  | 1506/2000 [13:29<03:07,  2.63iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  75%|███████▌  | 1507/2000 [13:30<03:07,  2.63iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  75%|███████▌  | 1507/2000 [13:30<03:07,  2.63iteration/s, mean_rewards=-168]\u001b[A\n",
            "Training:  75%|███████▌  | 1508/2000 [13:30<03:10,  2.58iteration/s, mean_rewards=-168]\u001b[A\n",
            "Training:  75%|███████▌  | 1508/2000 [13:30<03:10,  2.58iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  75%|███████▌  | 1509/2000 [13:30<03:06,  2.63iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  75%|███████▌  | 1509/2000 [13:31<03:06,  2.63iteration/s, mean_rewards=-68.2]\u001b[A\n",
            "Training:  76%|███████▌  | 1510/2000 [13:31<03:05,  2.64iteration/s, mean_rewards=-68.2]\u001b[A\n",
            "Training:  76%|███████▌  | 1510/2000 [13:31<03:05,  2.64iteration/s, mean_rewards=-144] \u001b[A\n",
            "Training:  76%|███████▌  | 1511/2000 [13:31<03:10,  2.57iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  76%|███████▌  | 1511/2000 [13:31<03:10,  2.57iteration/s, mean_rewards=-94.1]\u001b[A\n",
            "Training:  76%|███████▌  | 1512/2000 [13:31<02:56,  2.76iteration/s, mean_rewards=-94.1]\u001b[A\n",
            "Training:  76%|███████▌  | 1512/2000 [13:32<02:56,  2.76iteration/s, mean_rewards=-134] \u001b[A\n",
            "Training:  76%|███████▌  | 1513/2000 [13:32<03:02,  2.66iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  76%|███████▌  | 1513/2000 [13:32<03:02,  2.66iteration/s, mean_rewards=-119]\u001b[A\n",
            "Training:  76%|███████▌  | 1514/2000 [13:32<03:30,  2.31iteration/s, mean_rewards=-119]\u001b[A\n",
            "Training:  76%|███████▌  | 1514/2000 [13:33<03:30,  2.31iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  76%|███████▌  | 1515/2000 [13:33<03:22,  2.40iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  76%|███████▌  | 1515/2000 [13:33<03:22,  2.40iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  76%|███████▌  | 1516/2000 [13:33<03:31,  2.29iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  76%|███████▌  | 1516/2000 [13:34<03:31,  2.29iteration/s, mean_rewards=-152]\u001b[A\n",
            "Training:  76%|███████▌  | 1517/2000 [13:34<03:40,  2.19iteration/s, mean_rewards=-152]\u001b[A\n",
            "Training:  76%|███████▌  | 1517/2000 [13:34<03:40,  2.19iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  76%|███████▌  | 1518/2000 [13:34<03:44,  2.14iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  76%|███████▌  | 1518/2000 [13:35<03:44,  2.14iteration/s, mean_rewards=-116]\u001b[A\n",
            "Training:  76%|███████▌  | 1519/2000 [13:35<03:55,  2.05iteration/s, mean_rewards=-116]\u001b[A\n",
            "Training:  76%|███████▌  | 1519/2000 [13:35<03:55,  2.05iteration/s, mean_rewards=-157]\u001b[A\n",
            "Training:  76%|███████▌  | 1520/2000 [13:35<03:40,  2.17iteration/s, mean_rewards=-157]\u001b[A\n",
            "Training:  76%|███████▌  | 1520/2000 [13:35<03:40,  2.17iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  76%|███████▌  | 1521/2000 [13:36<03:26,  2.32iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  76%|███████▌  | 1521/2000 [13:36<03:26,  2.32iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  76%|███████▌  | 1522/2000 [13:36<03:07,  2.55iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  76%|███████▌  | 1522/2000 [13:36<03:07,  2.55iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  76%|███████▌  | 1523/2000 [13:36<03:08,  2.52iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  76%|███████▌  | 1523/2000 [13:37<03:08,  2.52iteration/s, mean_rewards=-92.3]\u001b[A\n",
            "Training:  76%|███████▌  | 1524/2000 [13:37<03:07,  2.53iteration/s, mean_rewards=-92.3]\u001b[A\n",
            "Training:  76%|███████▌  | 1524/2000 [13:37<03:07,  2.53iteration/s, mean_rewards=-137] \u001b[A\n",
            "Training:  76%|███████▋  | 1525/2000 [13:37<03:14,  2.44iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  76%|███████▋  | 1525/2000 [13:37<03:14,  2.44iteration/s, mean_rewards=-184]\u001b[A\n",
            "Training:  76%|███████▋  | 1526/2000 [13:38<03:13,  2.45iteration/s, mean_rewards=-184]\u001b[A\n",
            "Training:  76%|███████▋  | 1526/2000 [13:38<03:13,  2.45iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  76%|███████▋  | 1527/2000 [13:38<02:58,  2.65iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  76%|███████▋  | 1527/2000 [13:38<02:58,  2.65iteration/s, mean_rewards=-115]\u001b[A\n",
            "Training:  76%|███████▋  | 1528/2000 [13:38<02:58,  2.64iteration/s, mean_rewards=-115]\u001b[A\n",
            "Training:  76%|███████▋  | 1528/2000 [13:38<02:58,  2.64iteration/s, mean_rewards=-104]\u001b[A\n",
            "Training:  76%|███████▋  | 1529/2000 [13:39<02:49,  2.78iteration/s, mean_rewards=-104]\u001b[A\n",
            "Training:  76%|███████▋  | 1529/2000 [13:39<02:49,  2.78iteration/s, mean_rewards=-75.2]\u001b[A\n",
            "Training:  76%|███████▋  | 1530/2000 [13:39<02:41,  2.91iteration/s, mean_rewards=-75.2]\u001b[A\n",
            "Training:  76%|███████▋  | 1530/2000 [13:39<02:41,  2.91iteration/s, mean_rewards=-139] \u001b[A\n",
            "Training:  77%|███████▋  | 1531/2000 [13:39<02:45,  2.84iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:  77%|███████▋  | 1531/2000 [13:39<02:45,  2.84iteration/s, mean_rewards=-104]\u001b[A\n",
            "Training:  77%|███████▋  | 1532/2000 [13:40<02:41,  2.90iteration/s, mean_rewards=-104]\u001b[A\n",
            "Training:  77%|███████▋  | 1532/2000 [13:40<02:41,  2.90iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  77%|███████▋  | 1533/2000 [13:40<02:36,  2.99iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  77%|███████▋  | 1533/2000 [13:40<02:36,  2.99iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  77%|███████▋  | 1534/2000 [13:40<02:38,  2.93iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  77%|███████▋  | 1534/2000 [13:40<02:38,  2.93iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  77%|███████▋  | 1535/2000 [13:41<02:47,  2.78iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  77%|███████▋  | 1535/2000 [13:41<02:47,  2.78iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  77%|███████▋  | 1536/2000 [13:41<02:47,  2.77iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  77%|███████▋  | 1536/2000 [13:41<02:47,  2.77iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  77%|███████▋  | 1537/2000 [13:41<02:59,  2.58iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  77%|███████▋  | 1537/2000 [13:42<02:59,  2.58iteration/s, mean_rewards=-164]\u001b[A\n",
            "Training:  77%|███████▋  | 1538/2000 [13:42<03:05,  2.49iteration/s, mean_rewards=-164]\u001b[A\n",
            "Training:  77%|███████▋  | 1538/2000 [13:42<03:05,  2.49iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  77%|███████▋  | 1539/2000 [13:42<03:03,  2.51iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  77%|███████▋  | 1539/2000 [13:42<03:03,  2.51iteration/s, mean_rewards=-119]\u001b[A\n",
            "Training:  77%|███████▋  | 1540/2000 [13:43<03:02,  2.52iteration/s, mean_rewards=-119]\u001b[A\n",
            "Training:  77%|███████▋  | 1540/2000 [13:43<03:02,  2.52iteration/s, mean_rewards=-109]\u001b[A\n",
            "Training:  77%|███████▋  | 1541/2000 [13:43<03:02,  2.51iteration/s, mean_rewards=-109]\u001b[A\n",
            "Training:  77%|███████▋  | 1541/2000 [13:43<03:02,  2.51iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:  77%|███████▋  | 1542/2000 [13:43<02:50,  2.69iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:  77%|███████▋  | 1542/2000 [13:44<02:50,  2.69iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  77%|███████▋  | 1543/2000 [13:44<02:51,  2.66iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  77%|███████▋  | 1543/2000 [13:44<02:51,  2.66iteration/s, mean_rewards=-168]\u001b[A\n",
            "Training:  77%|███████▋  | 1544/2000 [13:44<02:58,  2.55iteration/s, mean_rewards=-168]\u001b[A\n",
            "Training:  77%|███████▋  | 1544/2000 [13:44<02:58,  2.55iteration/s, mean_rewards=-207]\u001b[A\n",
            "Training:  77%|███████▋  | 1545/2000 [13:45<03:07,  2.43iteration/s, mean_rewards=-207]\u001b[A\n",
            "Training:  77%|███████▋  | 1545/2000 [13:45<03:07,  2.43iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  77%|███████▋  | 1546/2000 [13:45<03:04,  2.46iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  77%|███████▋  | 1546/2000 [13:45<03:04,  2.46iteration/s, mean_rewards=-35.1]\u001b[A\n",
            "Training:  77%|███████▋  | 1547/2000 [13:45<03:07,  2.42iteration/s, mean_rewards=-35.1]\u001b[A\n",
            "Training:  77%|███████▋  | 1547/2000 [13:46<03:07,  2.42iteration/s, mean_rewards=-132] \u001b[A\n",
            "Training:  77%|███████▋  | 1548/2000 [13:46<03:15,  2.31iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  77%|███████▋  | 1548/2000 [13:46<03:15,  2.31iteration/s, mean_rewards=-162]\u001b[A\n",
            "Training:  77%|███████▋  | 1549/2000 [13:46<03:17,  2.28iteration/s, mean_rewards=-162]\u001b[A\n",
            "Training:  77%|███████▋  | 1549/2000 [13:47<03:17,  2.28iteration/s, mean_rewards=-192]\u001b[A\n",
            "Training:  78%|███████▊  | 1550/2000 [13:47<03:31,  2.13iteration/s, mean_rewards=-192]\u001b[A\n",
            "Training:  78%|███████▊  | 1550/2000 [13:47<03:31,  2.13iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  78%|███████▊  | 1551/2000 [13:47<03:31,  2.12iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  78%|███████▊  | 1551/2000 [13:48<03:31,  2.12iteration/s, mean_rewards=-163]\u001b[A\n",
            "Training:  78%|███████▊  | 1552/2000 [13:48<03:47,  1.97iteration/s, mean_rewards=-163]\u001b[A\n",
            "Training:  78%|███████▊  | 1552/2000 [13:48<03:47,  1.97iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  78%|███████▊  | 1553/2000 [13:48<03:25,  2.18iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  78%|███████▊  | 1553/2000 [13:49<03:25,  2.18iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  78%|███████▊  | 1554/2000 [13:49<03:15,  2.28iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  78%|███████▊  | 1554/2000 [13:49<03:15,  2.28iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  78%|███████▊  | 1555/2000 [13:49<03:06,  2.39iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  78%|███████▊  | 1555/2000 [13:49<03:06,  2.39iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  78%|███████▊  | 1556/2000 [13:49<02:54,  2.54iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  78%|███████▊  | 1556/2000 [13:50<02:54,  2.54iteration/s, mean_rewards=-84.1]\u001b[A\n",
            "Training:  78%|███████▊  | 1557/2000 [13:50<02:48,  2.64iteration/s, mean_rewards=-84.1]\u001b[A\n",
            "Training:  78%|███████▊  | 1557/2000 [13:50<02:48,  2.64iteration/s, mean_rewards=-180] \u001b[A\n",
            "Training:  78%|███████▊  | 1558/2000 [13:50<02:49,  2.60iteration/s, mean_rewards=-180]\u001b[A\n",
            "Training:  78%|███████▊  | 1558/2000 [13:50<02:49,  2.60iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  78%|███████▊  | 1559/2000 [13:51<02:49,  2.60iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  78%|███████▊  | 1559/2000 [13:51<02:49,  2.60iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  78%|███████▊  | 1560/2000 [13:51<02:42,  2.70iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  78%|███████▊  | 1560/2000 [13:51<02:42,  2.70iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  78%|███████▊  | 1561/2000 [13:51<02:43,  2.69iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  78%|███████▊  | 1561/2000 [13:51<02:43,  2.69iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  78%|███████▊  | 1562/2000 [13:52<02:37,  2.77iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  78%|███████▊  | 1562/2000 [13:52<02:37,  2.77iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  78%|███████▊  | 1563/2000 [13:52<02:50,  2.57iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  78%|███████▊  | 1563/2000 [13:52<02:50,  2.57iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  78%|███████▊  | 1564/2000 [13:52<02:46,  2.61iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  78%|███████▊  | 1564/2000 [13:53<02:46,  2.61iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  78%|███████▊  | 1565/2000 [13:53<02:38,  2.75iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  78%|███████▊  | 1565/2000 [13:53<02:38,  2.75iteration/s, mean_rewards=-165]\u001b[A\n",
            "Training:  78%|███████▊  | 1566/2000 [13:53<02:34,  2.81iteration/s, mean_rewards=-165]\u001b[A\n",
            "Training:  78%|███████▊  | 1566/2000 [13:53<02:34,  2.81iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  78%|███████▊  | 1567/2000 [13:53<02:35,  2.78iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  78%|███████▊  | 1567/2000 [13:54<02:35,  2.78iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  78%|███████▊  | 1568/2000 [13:54<02:33,  2.82iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  78%|███████▊  | 1568/2000 [13:54<02:33,  2.82iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  78%|███████▊  | 1569/2000 [13:54<02:28,  2.90iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  78%|███████▊  | 1569/2000 [13:54<02:28,  2.90iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  78%|███████▊  | 1570/2000 [13:54<02:32,  2.82iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  78%|███████▊  | 1570/2000 [13:55<02:32,  2.82iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  79%|███████▊  | 1571/2000 [13:55<02:38,  2.71iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  79%|███████▊  | 1571/2000 [13:55<02:38,  2.71iteration/s, mean_rewards=-189]\u001b[A\n",
            "Training:  79%|███████▊  | 1572/2000 [13:55<02:47,  2.56iteration/s, mean_rewards=-189]\u001b[A\n",
            "Training:  79%|███████▊  | 1572/2000 [13:56<02:47,  2.56iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  79%|███████▊  | 1573/2000 [13:56<02:49,  2.53iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  79%|███████▊  | 1573/2000 [13:56<02:49,  2.53iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  79%|███████▊  | 1574/2000 [13:56<02:47,  2.54iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  79%|███████▊  | 1574/2000 [13:56<02:47,  2.54iteration/s, mean_rewards=-157]\u001b[A\n",
            "Training:  79%|███████▉  | 1575/2000 [13:57<02:46,  2.55iteration/s, mean_rewards=-157]\u001b[A\n",
            "Training:  79%|███████▉  | 1575/2000 [13:57<02:46,  2.55iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:  79%|███████▉  | 1576/2000 [13:57<02:39,  2.65iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:  79%|███████▉  | 1576/2000 [13:57<02:39,  2.65iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  79%|███████▉  | 1577/2000 [13:57<02:38,  2.66iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  79%|███████▉  | 1577/2000 [13:57<02:38,  2.66iteration/s, mean_rewards=-105]\u001b[A\n",
            "Training:  79%|███████▉  | 1578/2000 [13:58<02:38,  2.67iteration/s, mean_rewards=-105]\u001b[A\n",
            "Training:  79%|███████▉  | 1578/2000 [13:58<02:38,  2.67iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  79%|███████▉  | 1579/2000 [13:58<02:39,  2.65iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  79%|███████▉  | 1579/2000 [13:58<02:39,  2.65iteration/s, mean_rewards=-112]\u001b[A\n",
            "Training:  79%|███████▉  | 1580/2000 [13:58<02:43,  2.57iteration/s, mean_rewards=-112]\u001b[A\n",
            "Training:  79%|███████▉  | 1580/2000 [13:59<02:43,  2.57iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:  79%|███████▉  | 1581/2000 [13:59<02:55,  2.38iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:  79%|███████▉  | 1581/2000 [13:59<02:55,  2.38iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  79%|███████▉  | 1582/2000 [13:59<02:51,  2.43iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  79%|███████▉  | 1582/2000 [14:00<02:51,  2.43iteration/s, mean_rewards=-170]\u001b[A\n",
            "Training:  79%|███████▉  | 1583/2000 [14:00<03:06,  2.23iteration/s, mean_rewards=-170]\u001b[A\n",
            "Training:  79%|███████▉  | 1583/2000 [14:00<03:06,  2.23iteration/s, mean_rewards=-78.3]\u001b[A\n",
            "Training:  79%|███████▉  | 1584/2000 [14:00<03:16,  2.12iteration/s, mean_rewards=-78.3]\u001b[A\n",
            "Training:  79%|███████▉  | 1584/2000 [14:01<03:16,  2.12iteration/s, mean_rewards=-127] \u001b[A\n",
            "Training:  79%|███████▉  | 1585/2000 [14:01<03:13,  2.14iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  79%|███████▉  | 1585/2000 [14:01<03:13,  2.14iteration/s, mean_rewards=-100]\u001b[A\n",
            "Training:  79%|███████▉  | 1586/2000 [14:01<03:04,  2.25iteration/s, mean_rewards=-100]\u001b[A\n",
            "Training:  79%|███████▉  | 1586/2000 [14:01<03:04,  2.25iteration/s, mean_rewards=-210]\u001b[A\n",
            "Training:  79%|███████▉  | 1587/2000 [14:02<02:58,  2.32iteration/s, mean_rewards=-210]\u001b[A\n",
            "Training:  79%|███████▉  | 1587/2000 [14:02<02:58,  2.32iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  79%|███████▉  | 1588/2000 [14:02<02:57,  2.32iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  79%|███████▉  | 1588/2000 [14:02<02:57,  2.32iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  79%|███████▉  | 1589/2000 [14:02<02:51,  2.40iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  79%|███████▉  | 1589/2000 [14:03<02:51,  2.40iteration/s, mean_rewards=-171]\u001b[A\n",
            "Training:  80%|███████▉  | 1590/2000 [14:03<02:50,  2.40iteration/s, mean_rewards=-171]\u001b[A\n",
            "Training:  80%|███████▉  | 1590/2000 [14:03<02:50,  2.40iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  80%|███████▉  | 1591/2000 [14:03<02:41,  2.54iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  80%|███████▉  | 1591/2000 [14:03<02:41,  2.54iteration/s, mean_rewards=-157]\u001b[A\n",
            "Training:  80%|███████▉  | 1592/2000 [14:04<02:37,  2.60iteration/s, mean_rewards=-157]\u001b[A\n",
            "Training:  80%|███████▉  | 1592/2000 [14:04<02:37,  2.60iteration/s, mean_rewards=-115]\u001b[A\n",
            "Training:  80%|███████▉  | 1593/2000 [14:04<02:29,  2.72iteration/s, mean_rewards=-115]\u001b[A\n",
            "Training:  80%|███████▉  | 1593/2000 [14:04<02:29,  2.72iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  80%|███████▉  | 1594/2000 [14:04<02:29,  2.72iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  80%|███████▉  | 1594/2000 [14:04<02:29,  2.72iteration/s, mean_rewards=-101]\u001b[A\n",
            "Training:  80%|███████▉  | 1595/2000 [14:05<02:21,  2.85iteration/s, mean_rewards=-101]\u001b[A\n",
            "Training:  80%|███████▉  | 1595/2000 [14:05<02:21,  2.85iteration/s, mean_rewards=-167]\u001b[A\n",
            "Training:  80%|███████▉  | 1596/2000 [14:05<02:25,  2.78iteration/s, mean_rewards=-167]\u001b[A\n",
            "Training:  80%|███████▉  | 1596/2000 [14:05<02:25,  2.78iteration/s, mean_rewards=-167]\u001b[A\n",
            "Training:  80%|███████▉  | 1597/2000 [14:05<02:27,  2.73iteration/s, mean_rewards=-167]\u001b[A\n",
            "Training:  80%|███████▉  | 1597/2000 [14:06<02:27,  2.73iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  80%|███████▉  | 1598/2000 [14:06<02:27,  2.72iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  80%|███████▉  | 1598/2000 [14:06<02:27,  2.72iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  80%|███████▉  | 1599/2000 [14:06<02:30,  2.67iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  80%|███████▉  | 1599/2000 [14:06<02:30,  2.67iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  80%|████████  | 1600/2000 [14:06<02:26,  2.74iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  80%|████████  | 1600/2000 [14:07<02:26,  2.74iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:  80%|████████  | 1601/2000 [14:07<02:20,  2.83iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:  80%|████████  | 1601/2000 [14:07<02:20,  2.83iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  80%|████████  | 1602/2000 [14:07<02:16,  2.92iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  80%|████████  | 1602/2000 [14:07<02:16,  2.92iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  80%|████████  | 1603/2000 [14:07<02:28,  2.68iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  80%|████████  | 1603/2000 [14:08<02:28,  2.68iteration/s, mean_rewards=-119]\u001b[A\n",
            "Training:  80%|████████  | 1604/2000 [14:08<02:26,  2.71iteration/s, mean_rewards=-119]\u001b[A\n",
            "Training:  80%|████████  | 1604/2000 [14:08<02:26,  2.71iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  80%|████████  | 1605/2000 [14:08<02:19,  2.83iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  80%|████████  | 1605/2000 [14:08<02:19,  2.83iteration/s, mean_rewards=-191]\u001b[A\n",
            "Training:  80%|████████  | 1606/2000 [14:09<02:20,  2.81iteration/s, mean_rewards=-191]\u001b[A\n",
            "Training:  80%|████████  | 1606/2000 [14:09<02:20,  2.81iteration/s, mean_rewards=-157]\u001b[A\n",
            "Training:  80%|████████  | 1607/2000 [14:09<02:19,  2.81iteration/s, mean_rewards=-157]\u001b[A\n",
            "Training:  80%|████████  | 1607/2000 [14:09<02:19,  2.81iteration/s, mean_rewards=-181]\u001b[A\n",
            "Training:  80%|████████  | 1608/2000 [14:09<02:23,  2.74iteration/s, mean_rewards=-181]\u001b[A\n",
            "Training:  80%|████████  | 1608/2000 [14:09<02:23,  2.74iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  80%|████████  | 1609/2000 [14:10<02:17,  2.84iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  80%|████████  | 1609/2000 [14:10<02:17,  2.84iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  80%|████████  | 1610/2000 [14:10<02:11,  2.97iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  80%|████████  | 1610/2000 [14:10<02:11,  2.97iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  81%|████████  | 1611/2000 [14:10<02:18,  2.82iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  81%|████████  | 1611/2000 [14:11<02:18,  2.82iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  81%|████████  | 1612/2000 [14:11<02:21,  2.74iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  81%|████████  | 1612/2000 [14:11<02:21,  2.74iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:  81%|████████  | 1613/2000 [14:11<02:35,  2.48iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:  81%|████████  | 1613/2000 [14:12<02:35,  2.48iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  81%|████████  | 1614/2000 [14:12<02:44,  2.34iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  81%|████████  | 1614/2000 [14:12<02:44,  2.34iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  81%|████████  | 1615/2000 [14:12<02:39,  2.41iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  81%|████████  | 1615/2000 [14:12<02:39,  2.41iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  81%|████████  | 1616/2000 [14:12<02:39,  2.41iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  81%|████████  | 1616/2000 [14:13<02:39,  2.41iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  81%|████████  | 1617/2000 [14:13<02:40,  2.39iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  81%|████████  | 1617/2000 [14:13<02:40,  2.39iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  81%|████████  | 1618/2000 [14:13<02:43,  2.33iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  81%|████████  | 1618/2000 [14:14<02:43,  2.33iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  81%|████████  | 1619/2000 [14:14<02:52,  2.20iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  81%|████████  | 1619/2000 [14:14<02:52,  2.20iteration/s, mean_rewards=-93.2]\u001b[A\n",
            "Training:  81%|████████  | 1620/2000 [14:14<02:43,  2.33iteration/s, mean_rewards=-93.2]\u001b[A\n",
            "Training:  81%|████████  | 1620/2000 [14:15<02:43,  2.33iteration/s, mean_rewards=-163] \u001b[A\n",
            "Training:  81%|████████  | 1621/2000 [14:15<02:47,  2.27iteration/s, mean_rewards=-163]\u001b[A\n",
            "Training:  81%|████████  | 1621/2000 [14:15<02:47,  2.27iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  81%|████████  | 1622/2000 [14:15<02:38,  2.39iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  81%|████████  | 1622/2000 [14:15<02:38,  2.39iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  81%|████████  | 1623/2000 [14:15<02:31,  2.49iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  81%|████████  | 1623/2000 [14:16<02:31,  2.49iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  81%|████████  | 1624/2000 [14:16<02:28,  2.53iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  81%|████████  | 1624/2000 [14:16<02:28,  2.53iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  81%|████████▏ | 1625/2000 [14:16<02:26,  2.56iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  81%|████████▏ | 1625/2000 [14:16<02:26,  2.56iteration/s, mean_rewards=-169]\u001b[A\n",
            "Training:  81%|████████▏ | 1626/2000 [14:17<02:24,  2.58iteration/s, mean_rewards=-169]\u001b[A\n",
            "Training:  81%|████████▏ | 1626/2000 [14:17<02:24,  2.58iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  81%|████████▏ | 1627/2000 [14:17<02:14,  2.77iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  81%|████████▏ | 1627/2000 [14:17<02:14,  2.77iteration/s, mean_rewards=-115]\u001b[A\n",
            "Training:  81%|████████▏ | 1628/2000 [14:17<02:10,  2.84iteration/s, mean_rewards=-115]\u001b[A\n",
            "Training:  81%|████████▏ | 1628/2000 [14:17<02:10,  2.84iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  81%|████████▏ | 1629/2000 [14:17<02:04,  2.99iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  81%|████████▏ | 1629/2000 [14:18<02:04,  2.99iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  82%|████████▏ | 1630/2000 [14:18<02:09,  2.86iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  82%|████████▏ | 1630/2000 [14:18<02:09,  2.86iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  82%|████████▏ | 1631/2000 [14:18<02:05,  2.93iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  82%|████████▏ | 1631/2000 [14:18<02:05,  2.93iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  82%|████████▏ | 1632/2000 [14:19<02:10,  2.81iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  82%|████████▏ | 1632/2000 [14:19<02:10,  2.81iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  82%|████████▏ | 1633/2000 [14:19<02:04,  2.94iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  82%|████████▏ | 1633/2000 [14:19<02:04,  2.94iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  82%|████████▏ | 1634/2000 [14:19<02:08,  2.84iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  82%|████████▏ | 1634/2000 [14:20<02:08,  2.84iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  82%|████████▏ | 1635/2000 [14:20<02:15,  2.69iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  82%|████████▏ | 1635/2000 [14:20<02:15,  2.69iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  82%|████████▏ | 1636/2000 [14:20<02:15,  2.69iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  82%|████████▏ | 1636/2000 [14:20<02:15,  2.69iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  82%|████████▏ | 1637/2000 [14:20<02:15,  2.67iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  82%|████████▏ | 1637/2000 [14:21<02:15,  2.67iteration/s, mean_rewards=-172]\u001b[A\n",
            "Training:  82%|████████▏ | 1638/2000 [14:21<02:17,  2.64iteration/s, mean_rewards=-172]\u001b[A\n",
            "Training:  82%|████████▏ | 1638/2000 [14:21<02:17,  2.64iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  82%|████████▏ | 1639/2000 [14:21<02:18,  2.61iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  82%|████████▏ | 1639/2000 [14:21<02:18,  2.61iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  82%|████████▏ | 1640/2000 [14:22<02:17,  2.61iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  82%|████████▏ | 1640/2000 [14:22<02:17,  2.61iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  82%|████████▏ | 1641/2000 [14:22<02:10,  2.75iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  82%|████████▏ | 1641/2000 [14:22<02:10,  2.75iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  82%|████████▏ | 1642/2000 [14:22<02:13,  2.69iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  82%|████████▏ | 1642/2000 [14:23<02:13,  2.69iteration/s, mean_rewards=-187]\u001b[A\n",
            "Training:  82%|████████▏ | 1643/2000 [14:23<02:22,  2.51iteration/s, mean_rewards=-187]\u001b[A\n",
            "Training:  82%|████████▏ | 1643/2000 [14:23<02:22,  2.51iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  82%|████████▏ | 1644/2000 [14:23<02:14,  2.65iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  82%|████████▏ | 1644/2000 [14:23<02:14,  2.65iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  82%|████████▏ | 1645/2000 [14:23<02:12,  2.67iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  82%|████████▏ | 1645/2000 [14:24<02:12,  2.67iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  82%|████████▏ | 1646/2000 [14:24<02:12,  2.68iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  82%|████████▏ | 1646/2000 [14:24<02:12,  2.68iteration/s, mean_rewards=-112]\u001b[A\n",
            "Training:  82%|████████▏ | 1647/2000 [14:24<02:14,  2.62iteration/s, mean_rewards=-112]\u001b[A\n",
            "Training:  82%|████████▏ | 1647/2000 [14:24<02:14,  2.62iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  82%|████████▏ | 1648/2000 [14:25<02:16,  2.59iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  82%|████████▏ | 1648/2000 [14:25<02:16,  2.59iteration/s, mean_rewards=-112]\u001b[A\n",
            "Training:  82%|████████▏ | 1649/2000 [14:25<02:17,  2.56iteration/s, mean_rewards=-112]\u001b[A\n",
            "Training:  82%|████████▏ | 1649/2000 [14:25<02:17,  2.56iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  82%|████████▎ | 1650/2000 [14:25<02:24,  2.42iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  82%|████████▎ | 1650/2000 [14:26<02:24,  2.42iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  83%|████████▎ | 1651/2000 [14:26<02:30,  2.32iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  83%|████████▎ | 1651/2000 [14:26<02:30,  2.32iteration/s, mean_rewards=-170]\u001b[A\n",
            "Training:  83%|████████▎ | 1652/2000 [14:27<02:41,  2.15iteration/s, mean_rewards=-170]\u001b[A\n",
            "Training:  83%|████████▎ | 1652/2000 [14:27<02:41,  2.15iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  83%|████████▎ | 1653/2000 [14:27<02:37,  2.21iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  83%|████████▎ | 1653/2000 [14:27<02:37,  2.21iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  83%|████████▎ | 1654/2000 [14:27<02:24,  2.40iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  83%|████████▎ | 1654/2000 [14:27<02:24,  2.40iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  83%|████████▎ | 1655/2000 [14:28<02:14,  2.56iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  83%|████████▎ | 1655/2000 [14:28<02:14,  2.56iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  83%|████████▎ | 1656/2000 [14:28<02:16,  2.52iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  83%|████████▎ | 1656/2000 [14:28<02:16,  2.52iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  83%|████████▎ | 1657/2000 [14:28<02:06,  2.71iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  83%|████████▎ | 1657/2000 [14:29<02:06,  2.71iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  83%|████████▎ | 1658/2000 [14:29<02:13,  2.57iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  83%|████████▎ | 1658/2000 [14:29<02:13,  2.57iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  83%|████████▎ | 1659/2000 [14:29<02:10,  2.61iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  83%|████████▎ | 1659/2000 [14:29<02:10,  2.61iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  83%|████████▎ | 1660/2000 [14:29<02:07,  2.66iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  83%|████████▎ | 1660/2000 [14:30<02:07,  2.66iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  83%|████████▎ | 1661/2000 [14:30<02:13,  2.54iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  83%|████████▎ | 1661/2000 [14:30<02:13,  2.54iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  83%|████████▎ | 1662/2000 [14:30<02:12,  2.55iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  83%|████████▎ | 1662/2000 [14:31<02:12,  2.55iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  83%|████████▎ | 1663/2000 [14:31<02:12,  2.54iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  83%|████████▎ | 1663/2000 [14:31<02:12,  2.54iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  83%|████████▎ | 1664/2000 [14:31<02:11,  2.56iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  83%|████████▎ | 1664/2000 [14:31<02:11,  2.56iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  83%|████████▎ | 1665/2000 [14:31<02:04,  2.69iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  83%|████████▎ | 1665/2000 [14:32<02:04,  2.69iteration/s, mean_rewards=-152]\u001b[A\n",
            "Training:  83%|████████▎ | 1666/2000 [14:32<02:06,  2.64iteration/s, mean_rewards=-152]\u001b[A\n",
            "Training:  83%|████████▎ | 1666/2000 [14:32<02:06,  2.64iteration/s, mean_rewards=-94.5]\u001b[A\n",
            "Training:  83%|████████▎ | 1667/2000 [14:32<02:12,  2.51iteration/s, mean_rewards=-94.5]\u001b[A\n",
            "Training:  83%|████████▎ | 1667/2000 [14:32<02:12,  2.51iteration/s, mean_rewards=-124] \u001b[A\n",
            "Training:  83%|████████▎ | 1668/2000 [14:33<02:04,  2.67iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  83%|████████▎ | 1668/2000 [14:33<02:04,  2.67iteration/s, mean_rewards=-60.5]\u001b[A\n",
            "Training:  83%|████████▎ | 1669/2000 [14:33<02:05,  2.64iteration/s, mean_rewards=-60.5]\u001b[A\n",
            "Training:  83%|████████▎ | 1669/2000 [14:33<02:05,  2.64iteration/s, mean_rewards=-150] \u001b[A\n",
            "Training:  84%|████████▎ | 1670/2000 [14:33<02:14,  2.45iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  84%|████████▎ | 1670/2000 [14:34<02:14,  2.45iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  84%|████████▎ | 1671/2000 [14:34<02:12,  2.49iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  84%|████████▎ | 1671/2000 [14:34<02:12,  2.49iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  84%|████████▎ | 1672/2000 [14:34<02:16,  2.40iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  84%|████████▎ | 1672/2000 [14:35<02:16,  2.40iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  84%|████████▎ | 1673/2000 [14:35<02:12,  2.47iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  84%|████████▎ | 1673/2000 [14:35<02:12,  2.47iteration/s, mean_rewards=-166]\u001b[A\n",
            "Training:  84%|████████▎ | 1674/2000 [14:35<02:14,  2.42iteration/s, mean_rewards=-166]\u001b[A\n",
            "Training:  84%|████████▎ | 1674/2000 [14:35<02:14,  2.42iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  84%|████████▍ | 1675/2000 [14:35<02:08,  2.54iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  84%|████████▍ | 1675/2000 [14:36<02:08,  2.54iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  84%|████████▍ | 1676/2000 [14:36<02:11,  2.46iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  84%|████████▍ | 1676/2000 [14:36<02:11,  2.46iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  84%|████████▍ | 1677/2000 [14:36<02:12,  2.43iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  84%|████████▍ | 1677/2000 [14:37<02:12,  2.43iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  84%|████████▍ | 1678/2000 [14:37<02:14,  2.39iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  84%|████████▍ | 1678/2000 [14:37<02:14,  2.39iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  84%|████████▍ | 1679/2000 [14:37<02:14,  2.38iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  84%|████████▍ | 1679/2000 [14:38<02:14,  2.38iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  84%|████████▍ | 1680/2000 [14:38<02:25,  2.21iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  84%|████████▍ | 1680/2000 [14:38<02:25,  2.21iteration/s, mean_rewards=-72.5]\u001b[A\n",
            "Training:  84%|████████▍ | 1681/2000 [14:38<02:29,  2.14iteration/s, mean_rewards=-72.5]\u001b[A\n",
            "Training:  84%|████████▍ | 1681/2000 [14:39<02:29,  2.14iteration/s, mean_rewards=-149] \u001b[A\n",
            "Training:  84%|████████▍ | 1682/2000 [14:39<02:28,  2.14iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  84%|████████▍ | 1682/2000 [14:39<02:28,  2.14iteration/s, mean_rewards=-176]\u001b[A\n",
            "Training:  84%|████████▍ | 1683/2000 [14:39<02:35,  2.03iteration/s, mean_rewards=-176]\u001b[A\n",
            "Training:  84%|████████▍ | 1683/2000 [14:39<02:35,  2.03iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  84%|████████▍ | 1684/2000 [14:40<02:26,  2.16iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  84%|████████▍ | 1684/2000 [14:40<02:26,  2.16iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  84%|████████▍ | 1685/2000 [14:40<02:16,  2.30iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  84%|████████▍ | 1685/2000 [14:40<02:16,  2.30iteration/s, mean_rewards=-36.4]\u001b[A\n",
            "Training:  84%|████████▍ | 1686/2000 [14:40<02:04,  2.52iteration/s, mean_rewards=-36.4]\u001b[A\n",
            "Training:  84%|████████▍ | 1686/2000 [14:41<02:04,  2.52iteration/s, mean_rewards=-164] \u001b[A\n",
            "Training:  84%|████████▍ | 1687/2000 [14:41<02:03,  2.53iteration/s, mean_rewards=-164]\u001b[A\n",
            "Training:  84%|████████▍ | 1687/2000 [14:41<02:03,  2.53iteration/s, mean_rewards=-61.6]\u001b[A\n",
            "Training:  84%|████████▍ | 1688/2000 [14:41<02:01,  2.58iteration/s, mean_rewards=-61.6]\u001b[A\n",
            "Training:  84%|████████▍ | 1688/2000 [14:41<02:01,  2.58iteration/s, mean_rewards=-148] \u001b[A\n",
            "Training:  84%|████████▍ | 1689/2000 [14:41<01:58,  2.61iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  84%|████████▍ | 1689/2000 [14:42<01:58,  2.61iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  84%|████████▍ | 1690/2000 [14:42<01:52,  2.75iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  84%|████████▍ | 1690/2000 [14:42<01:52,  2.75iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:  85%|████████▍ | 1691/2000 [14:42<01:55,  2.68iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:  85%|████████▍ | 1691/2000 [14:42<01:55,  2.68iteration/s, mean_rewards=-96] \u001b[A\n",
            "Training:  85%|████████▍ | 1692/2000 [14:43<01:57,  2.61iteration/s, mean_rewards=-96]\u001b[A\n",
            "Training:  85%|████████▍ | 1692/2000 [14:43<01:57,  2.61iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  85%|████████▍ | 1693/2000 [14:43<01:57,  2.62iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  85%|████████▍ | 1693/2000 [14:43<01:57,  2.62iteration/s, mean_rewards=-152]\u001b[A\n",
            "Training:  85%|████████▍ | 1694/2000 [14:43<01:55,  2.65iteration/s, mean_rewards=-152]\u001b[A\n",
            "Training:  85%|████████▍ | 1694/2000 [14:44<01:55,  2.65iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  85%|████████▍ | 1695/2000 [14:44<01:56,  2.62iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  85%|████████▍ | 1695/2000 [14:44<01:56,  2.62iteration/s, mean_rewards=-105]\u001b[A\n",
            "Training:  85%|████████▍ | 1696/2000 [14:44<01:55,  2.63iteration/s, mean_rewards=-105]\u001b[A\n",
            "Training:  85%|████████▍ | 1696/2000 [14:44<01:55,  2.63iteration/s, mean_rewards=-89] \u001b[A\n",
            "Training:  85%|████████▍ | 1697/2000 [14:44<01:56,  2.60iteration/s, mean_rewards=-89]\u001b[A\n",
            "Training:  85%|████████▍ | 1697/2000 [14:45<01:56,  2.60iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  85%|████████▍ | 1698/2000 [14:45<02:00,  2.51iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  85%|████████▍ | 1698/2000 [14:45<02:00,  2.51iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  85%|████████▍ | 1699/2000 [14:45<01:59,  2.52iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  85%|████████▍ | 1699/2000 [14:46<01:59,  2.52iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  85%|████████▌ | 1700/2000 [14:46<02:03,  2.43iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  85%|████████▌ | 1700/2000 [14:46<02:03,  2.43iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  85%|████████▌ | 1701/2000 [14:46<01:58,  2.52iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  85%|████████▌ | 1701/2000 [14:46<01:58,  2.52iteration/s, mean_rewards=-116]\u001b[A\n",
            "Training:  85%|████████▌ | 1702/2000 [14:46<01:54,  2.60iteration/s, mean_rewards=-116]\u001b[A\n",
            "Training:  85%|████████▌ | 1702/2000 [14:47<01:54,  2.60iteration/s, mean_rewards=-51.1]\u001b[A\n",
            "Training:  85%|████████▌ | 1703/2000 [14:47<01:53,  2.61iteration/s, mean_rewards=-51.1]\u001b[A\n",
            "Training:  85%|████████▌ | 1703/2000 [14:47<01:53,  2.61iteration/s, mean_rewards=-163] \u001b[A\n",
            "Training:  85%|████████▌ | 1704/2000 [14:47<01:53,  2.62iteration/s, mean_rewards=-163]\u001b[A\n",
            "Training:  85%|████████▌ | 1704/2000 [14:47<01:53,  2.62iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:  85%|████████▌ | 1705/2000 [14:47<01:47,  2.75iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:  85%|████████▌ | 1705/2000 [14:48<01:47,  2.75iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:  85%|████████▌ | 1706/2000 [14:48<01:48,  2.72iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:  85%|████████▌ | 1706/2000 [14:48<01:48,  2.72iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  85%|████████▌ | 1707/2000 [14:48<01:46,  2.74iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  85%|████████▌ | 1707/2000 [14:48<01:46,  2.74iteration/s, mean_rewards=-105]\u001b[A\n",
            "Training:  85%|████████▌ | 1708/2000 [14:49<01:40,  2.91iteration/s, mean_rewards=-105]\u001b[A\n",
            "Training:  85%|████████▌ | 1708/2000 [14:49<01:40,  2.91iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  85%|████████▌ | 1709/2000 [14:49<01:37,  2.97iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  85%|████████▌ | 1709/2000 [14:49<01:37,  2.97iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  86%|████████▌ | 1710/2000 [14:49<01:36,  3.00iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  86%|████████▌ | 1710/2000 [14:49<01:36,  3.00iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  86%|████████▌ | 1711/2000 [14:50<01:44,  2.77iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  86%|████████▌ | 1711/2000 [14:50<01:44,  2.77iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  86%|████████▌ | 1712/2000 [14:50<01:48,  2.65iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  86%|████████▌ | 1712/2000 [14:50<01:48,  2.65iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  86%|████████▌ | 1713/2000 [14:50<01:52,  2.56iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  86%|████████▌ | 1713/2000 [14:51<01:52,  2.56iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  86%|████████▌ | 1714/2000 [14:51<02:08,  2.22iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  86%|████████▌ | 1714/2000 [14:51<02:08,  2.22iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  86%|████████▌ | 1715/2000 [14:52<02:14,  2.13iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  86%|████████▌ | 1715/2000 [14:52<02:14,  2.13iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  86%|████████▌ | 1716/2000 [14:52<02:18,  2.05iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  86%|████████▌ | 1716/2000 [14:52<02:18,  2.05iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  86%|████████▌ | 1717/2000 [14:53<02:20,  2.01iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  86%|████████▌ | 1717/2000 [14:53<02:20,  2.01iteration/s, mean_rewards=-104]\u001b[A\n",
            "Training:  86%|████████▌ | 1718/2000 [14:53<02:08,  2.19iteration/s, mean_rewards=-104]\u001b[A\n",
            "Training:  86%|████████▌ | 1718/2000 [14:53<02:08,  2.19iteration/s, mean_rewards=-230]\u001b[A\n",
            "Training:  86%|████████▌ | 1719/2000 [14:53<02:03,  2.27iteration/s, mean_rewards=-230]\u001b[A\n",
            "Training:  86%|████████▌ | 1719/2000 [14:54<02:03,  2.27iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  86%|████████▌ | 1720/2000 [14:54<01:59,  2.35iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  86%|████████▌ | 1720/2000 [14:54<01:59,  2.35iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  86%|████████▌ | 1721/2000 [14:54<01:57,  2.37iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  86%|████████▌ | 1721/2000 [14:54<01:57,  2.37iteration/s, mean_rewards=-193]\u001b[A\n",
            "Training:  86%|████████▌ | 1722/2000 [14:55<01:58,  2.35iteration/s, mean_rewards=-193]\u001b[A\n",
            "Training:  86%|████████▌ | 1722/2000 [14:55<01:58,  2.35iteration/s, mean_rewards=-185]\u001b[A\n",
            "Training:  86%|████████▌ | 1723/2000 [14:55<01:58,  2.35iteration/s, mean_rewards=-185]\u001b[A\n",
            "Training:  86%|████████▌ | 1723/2000 [14:55<01:58,  2.35iteration/s, mean_rewards=-171]\u001b[A\n",
            "Training:  86%|████████▌ | 1724/2000 [14:55<01:54,  2.40iteration/s, mean_rewards=-171]\u001b[A\n",
            "Training:  86%|████████▌ | 1724/2000 [14:56<01:54,  2.40iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  86%|████████▋ | 1725/2000 [14:56<01:58,  2.33iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  86%|████████▋ | 1725/2000 [14:56<01:58,  2.33iteration/s, mean_rewards=-106]\u001b[A\n",
            "Training:  86%|████████▋ | 1726/2000 [14:56<01:52,  2.43iteration/s, mean_rewards=-106]\u001b[A\n",
            "Training:  86%|████████▋ | 1726/2000 [14:57<01:52,  2.43iteration/s, mean_rewards=-159]\u001b[A\n",
            "Training:  86%|████████▋ | 1727/2000 [14:57<01:54,  2.39iteration/s, mean_rewards=-159]\u001b[A\n",
            "Training:  86%|████████▋ | 1727/2000 [14:57<01:54,  2.39iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  86%|████████▋ | 1728/2000 [14:57<01:49,  2.47iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  86%|████████▋ | 1728/2000 [14:57<01:49,  2.47iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  86%|████████▋ | 1729/2000 [14:57<01:46,  2.54iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  86%|████████▋ | 1729/2000 [14:58<01:46,  2.54iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  86%|████████▋ | 1730/2000 [14:58<01:48,  2.49iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  86%|████████▋ | 1730/2000 [14:58<01:48,  2.49iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  87%|████████▋ | 1731/2000 [14:58<01:45,  2.54iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  87%|████████▋ | 1731/2000 [14:58<01:45,  2.54iteration/s, mean_rewards=-85.2]\u001b[A\n",
            "Training:  87%|████████▋ | 1732/2000 [14:59<01:45,  2.54iteration/s, mean_rewards=-85.2]\u001b[A\n",
            "Training:  87%|████████▋ | 1732/2000 [14:59<01:45,  2.54iteration/s, mean_rewards=-116] \u001b[A\n",
            "Training:  87%|████████▋ | 1733/2000 [14:59<01:42,  2.59iteration/s, mean_rewards=-116]\u001b[A\n",
            "Training:  87%|████████▋ | 1733/2000 [14:59<01:42,  2.59iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  87%|████████▋ | 1734/2000 [14:59<01:38,  2.70iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  87%|████████▋ | 1734/2000 [15:00<01:38,  2.70iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  87%|████████▋ | 1735/2000 [15:00<01:38,  2.70iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  87%|████████▋ | 1735/2000 [15:00<01:38,  2.70iteration/s, mean_rewards=-92.4]\u001b[A\n",
            "Training:  87%|████████▋ | 1736/2000 [15:00<01:43,  2.56iteration/s, mean_rewards=-92.4]\u001b[A\n",
            "Training:  87%|████████▋ | 1736/2000 [15:00<01:43,  2.56iteration/s, mean_rewards=-125] \u001b[A\n",
            "Training:  87%|████████▋ | 1737/2000 [15:00<01:37,  2.70iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  87%|████████▋ | 1737/2000 [15:01<01:37,  2.70iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  87%|████████▋ | 1738/2000 [15:01<01:39,  2.62iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  87%|████████▋ | 1738/2000 [15:01<01:39,  2.62iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  87%|████████▋ | 1739/2000 [15:01<01:41,  2.58iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  87%|████████▋ | 1739/2000 [15:01<01:41,  2.58iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  87%|████████▋ | 1740/2000 [15:02<01:34,  2.75iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  87%|████████▋ | 1740/2000 [15:02<01:34,  2.75iteration/s, mean_rewards=-79.2]\u001b[A\n",
            "Training:  87%|████████▋ | 1741/2000 [15:02<01:36,  2.68iteration/s, mean_rewards=-79.2]\u001b[A\n",
            "Training:  87%|████████▋ | 1741/2000 [15:02<01:36,  2.68iteration/s, mean_rewards=-139] \u001b[A\n",
            "Training:  87%|████████▋ | 1742/2000 [15:02<01:36,  2.68iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:  87%|████████▋ | 1742/2000 [15:03<01:36,  2.68iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  87%|████████▋ | 1743/2000 [15:03<01:38,  2.62iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  87%|████████▋ | 1743/2000 [15:03<01:38,  2.62iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  87%|████████▋ | 1744/2000 [15:03<01:45,  2.43iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  87%|████████▋ | 1744/2000 [15:04<01:45,  2.43iteration/s, mean_rewards=-159]\u001b[A\n",
            "Training:  87%|████████▋ | 1745/2000 [15:04<01:55,  2.22iteration/s, mean_rewards=-159]\u001b[A\n",
            "Training:  87%|████████▋ | 1745/2000 [15:04<01:55,  2.22iteration/s, mean_rewards=-109]\u001b[A\n",
            "Training:  87%|████████▋ | 1746/2000 [15:04<01:59,  2.13iteration/s, mean_rewards=-109]\u001b[A\n",
            "Training:  87%|████████▋ | 1746/2000 [15:05<01:59,  2.13iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  87%|████████▋ | 1747/2000 [15:05<01:54,  2.22iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  87%|████████▋ | 1747/2000 [15:05<01:54,  2.22iteration/s, mean_rewards=-52.2]\u001b[A\n",
            "Training:  87%|████████▋ | 1748/2000 [15:05<01:52,  2.24iteration/s, mean_rewards=-52.2]\u001b[A\n",
            "Training:  87%|████████▋ | 1748/2000 [15:06<01:52,  2.24iteration/s, mean_rewards=-116] \u001b[A\n",
            "Training:  87%|████████▋ | 1749/2000 [15:06<02:02,  2.05iteration/s, mean_rewards=-116]\u001b[A\n",
            "Training:  87%|████████▋ | 1749/2000 [15:06<02:02,  2.05iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  88%|████████▊ | 1750/2000 [15:06<01:53,  2.20iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  88%|████████▊ | 1750/2000 [15:06<01:53,  2.20iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  88%|████████▊ | 1751/2000 [15:06<01:48,  2.30iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  88%|████████▊ | 1751/2000 [15:07<01:48,  2.30iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  88%|████████▊ | 1752/2000 [15:07<01:39,  2.49iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  88%|████████▊ | 1752/2000 [15:07<01:39,  2.49iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  88%|████████▊ | 1753/2000 [15:07<01:37,  2.52iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  88%|████████▊ | 1753/2000 [15:07<01:37,  2.52iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  88%|████████▊ | 1754/2000 [15:08<01:37,  2.52iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  88%|████████▊ | 1754/2000 [15:08<01:37,  2.52iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  88%|████████▊ | 1755/2000 [15:08<01:30,  2.71iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  88%|████████▊ | 1755/2000 [15:08<01:30,  2.71iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  88%|████████▊ | 1756/2000 [15:08<01:30,  2.68iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  88%|████████▊ | 1756/2000 [15:09<01:30,  2.68iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  88%|████████▊ | 1757/2000 [15:09<01:35,  2.55iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  88%|████████▊ | 1757/2000 [15:09<01:35,  2.55iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  88%|████████▊ | 1758/2000 [15:09<01:33,  2.59iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  88%|████████▊ | 1758/2000 [15:09<01:33,  2.59iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  88%|████████▊ | 1759/2000 [15:09<01:35,  2.51iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  88%|████████▊ | 1759/2000 [15:10<01:35,  2.51iteration/s, mean_rewards=-253]\u001b[A\n",
            "Training:  88%|████████▊ | 1760/2000 [15:10<01:43,  2.32iteration/s, mean_rewards=-253]\u001b[A\n",
            "Training:  88%|████████▊ | 1760/2000 [15:10<01:43,  2.32iteration/s, mean_rewards=-119]\u001b[A\n",
            "Training:  88%|████████▊ | 1761/2000 [15:10<01:45,  2.27iteration/s, mean_rewards=-119]\u001b[A\n",
            "Training:  88%|████████▊ | 1761/2000 [15:11<01:45,  2.27iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  88%|████████▊ | 1762/2000 [15:11<01:36,  2.46iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  88%|████████▊ | 1762/2000 [15:11<01:36,  2.46iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  88%|████████▊ | 1763/2000 [15:11<01:33,  2.55iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  88%|████████▊ | 1763/2000 [15:11<01:33,  2.55iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  88%|████████▊ | 1764/2000 [15:12<01:32,  2.56iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  88%|████████▊ | 1764/2000 [15:12<01:32,  2.56iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  88%|████████▊ | 1765/2000 [15:12<01:27,  2.68iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  88%|████████▊ | 1765/2000 [15:12<01:27,  2.68iteration/s, mean_rewards=-187]\u001b[A\n",
            "Training:  88%|████████▊ | 1766/2000 [15:12<01:34,  2.49iteration/s, mean_rewards=-187]\u001b[A\n",
            "Training:  88%|████████▊ | 1766/2000 [15:13<01:34,  2.49iteration/s, mean_rewards=-36.8]\u001b[A\n",
            "Training:  88%|████████▊ | 1767/2000 [15:13<01:32,  2.51iteration/s, mean_rewards=-36.8]\u001b[A\n",
            "Training:  88%|████████▊ | 1767/2000 [15:13<01:32,  2.51iteration/s, mean_rewards=-112] \u001b[A\n",
            "Training:  88%|████████▊ | 1768/2000 [15:13<01:24,  2.74iteration/s, mean_rewards=-112]\u001b[A\n",
            "Training:  88%|████████▊ | 1768/2000 [15:13<01:24,  2.74iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  88%|████████▊ | 1769/2000 [15:13<01:20,  2.86iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  88%|████████▊ | 1769/2000 [15:14<01:20,  2.86iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  88%|████████▊ | 1770/2000 [15:14<01:26,  2.65iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  88%|████████▊ | 1770/2000 [15:14<01:26,  2.65iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  89%|████████▊ | 1771/2000 [15:14<01:23,  2.75iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  89%|████████▊ | 1771/2000 [15:14<01:23,  2.75iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  89%|████████▊ | 1772/2000 [15:14<01:24,  2.71iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  89%|████████▊ | 1772/2000 [15:15<01:24,  2.71iteration/s, mean_rewards=-187]\u001b[A\n",
            "Training:  89%|████████▊ | 1773/2000 [15:15<01:27,  2.59iteration/s, mean_rewards=-187]\u001b[A\n",
            "Training:  89%|████████▊ | 1773/2000 [15:15<01:27,  2.59iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  89%|████████▊ | 1774/2000 [15:15<01:29,  2.53iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  89%|████████▊ | 1774/2000 [15:16<01:29,  2.53iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  89%|████████▉ | 1775/2000 [15:16<01:27,  2.58iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  89%|████████▉ | 1775/2000 [15:16<01:27,  2.58iteration/s, mean_rewards=-101]\u001b[A\n",
            "Training:  89%|████████▉ | 1776/2000 [15:16<01:27,  2.56iteration/s, mean_rewards=-101]\u001b[A\n",
            "Training:  89%|████████▉ | 1776/2000 [15:16<01:27,  2.56iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  89%|████████▉ | 1777/2000 [15:17<01:34,  2.37iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  89%|████████▉ | 1777/2000 [15:17<01:34,  2.37iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  89%|████████▉ | 1778/2000 [15:17<01:34,  2.34iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  89%|████████▉ | 1778/2000 [15:17<01:34,  2.34iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  89%|████████▉ | 1779/2000 [15:17<01:38,  2.25iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  89%|████████▉ | 1779/2000 [15:18<01:38,  2.25iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  89%|████████▉ | 1780/2000 [15:18<01:34,  2.34iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  89%|████████▉ | 1780/2000 [15:18<01:34,  2.34iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  89%|████████▉ | 1781/2000 [15:18<01:41,  2.15iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  89%|████████▉ | 1781/2000 [15:19<01:41,  2.15iteration/s, mean_rewards=-172]\u001b[A\n",
            "Training:  89%|████████▉ | 1782/2000 [15:19<01:42,  2.13iteration/s, mean_rewards=-172]\u001b[A\n",
            "Training:  89%|████████▉ | 1782/2000 [15:19<01:42,  2.13iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  89%|████████▉ | 1783/2000 [15:19<01:40,  2.15iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  89%|████████▉ | 1783/2000 [15:20<01:40,  2.15iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  89%|████████▉ | 1784/2000 [15:20<01:39,  2.18iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  89%|████████▉ | 1784/2000 [15:20<01:39,  2.18iteration/s, mean_rewards=-203]\u001b[A\n",
            "Training:  89%|████████▉ | 1785/2000 [15:20<01:34,  2.27iteration/s, mean_rewards=-203]\u001b[A\n",
            "Training:  89%|████████▉ | 1785/2000 [15:20<01:34,  2.27iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  89%|████████▉ | 1786/2000 [15:21<01:26,  2.46iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  89%|████████▉ | 1786/2000 [15:21<01:26,  2.46iteration/s, mean_rewards=-40.2]\u001b[A\n",
            "Training:  89%|████████▉ | 1787/2000 [15:21<01:25,  2.49iteration/s, mean_rewards=-40.2]\u001b[A\n",
            "Training:  89%|████████▉ | 1787/2000 [15:21<01:25,  2.49iteration/s, mean_rewards=-123] \u001b[A\n",
            "Training:  89%|████████▉ | 1788/2000 [15:21<01:23,  2.55iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  89%|████████▉ | 1788/2000 [15:22<01:23,  2.55iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  89%|████████▉ | 1789/2000 [15:22<01:20,  2.63iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  89%|████████▉ | 1789/2000 [15:22<01:20,  2.63iteration/s, mean_rewards=-92.1]\u001b[A\n",
            "Training:  90%|████████▉ | 1790/2000 [15:22<01:20,  2.61iteration/s, mean_rewards=-92.1]\u001b[A\n",
            "Training:  90%|████████▉ | 1790/2000 [15:22<01:20,  2.61iteration/s, mean_rewards=-147] \u001b[A\n",
            "Training:  90%|████████▉ | 1791/2000 [15:22<01:15,  2.76iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:  90%|████████▉ | 1791/2000 [15:23<01:15,  2.76iteration/s, mean_rewards=-220]\u001b[A\n",
            "Training:  90%|████████▉ | 1792/2000 [15:23<01:20,  2.57iteration/s, mean_rewards=-220]\u001b[A\n",
            "Training:  90%|████████▉ | 1792/2000 [15:23<01:20,  2.57iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:  90%|████████▉ | 1793/2000 [15:23<01:19,  2.61iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:  90%|████████▉ | 1793/2000 [15:23<01:19,  2.61iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  90%|████████▉ | 1794/2000 [15:24<01:19,  2.59iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  90%|████████▉ | 1794/2000 [15:24<01:19,  2.59iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  90%|████████▉ | 1795/2000 [15:24<01:21,  2.50iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  90%|████████▉ | 1795/2000 [15:24<01:21,  2.50iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  90%|████████▉ | 1796/2000 [15:24<01:20,  2.54iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  90%|████████▉ | 1796/2000 [15:25<01:20,  2.54iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  90%|████████▉ | 1797/2000 [15:25<01:15,  2.68iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  90%|████████▉ | 1797/2000 [15:25<01:15,  2.68iteration/s, mean_rewards=-159]\u001b[A\n",
            "Training:  90%|████████▉ | 1798/2000 [15:25<01:14,  2.71iteration/s, mean_rewards=-159]\u001b[A\n",
            "Training:  90%|████████▉ | 1798/2000 [15:25<01:14,  2.71iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  90%|████████▉ | 1799/2000 [15:26<01:18,  2.55iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  90%|████████▉ | 1799/2000 [15:26<01:18,  2.55iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  90%|█████████ | 1800/2000 [15:26<01:17,  2.60iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  90%|█████████ | 1800/2000 [15:26<01:17,  2.60iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  90%|█████████ | 1801/2000 [15:26<01:16,  2.59iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  90%|█████████ | 1801/2000 [15:26<01:16,  2.59iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  90%|█████████ | 1802/2000 [15:27<01:13,  2.71iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  90%|█████████ | 1802/2000 [15:27<01:13,  2.71iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  90%|█████████ | 1803/2000 [15:27<01:12,  2.70iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  90%|█████████ | 1803/2000 [15:27<01:12,  2.70iteration/s, mean_rewards=-92.6]\u001b[A\n",
            "Training:  90%|█████████ | 1804/2000 [15:27<01:12,  2.69iteration/s, mean_rewards=-92.6]\u001b[A\n",
            "Training:  90%|█████████ | 1804/2000 [15:28<01:12,  2.69iteration/s, mean_rewards=-183] \u001b[A\n",
            "Training:  90%|█████████ | 1805/2000 [15:28<01:12,  2.67iteration/s, mean_rewards=-183]\u001b[A\n",
            "Training:  90%|█████████ | 1805/2000 [15:28<01:12,  2.67iteration/s, mean_rewards=-95.8]\u001b[A\n",
            "Training:  90%|█████████ | 1806/2000 [15:28<01:08,  2.84iteration/s, mean_rewards=-95.8]\u001b[A\n",
            "Training:  90%|█████████ | 1806/2000 [15:28<01:08,  2.84iteration/s, mean_rewards=-69.2]\u001b[A\n",
            "Training:  90%|█████████ | 1807/2000 [15:28<01:06,  2.90iteration/s, mean_rewards=-69.2]\u001b[A\n",
            "Training:  90%|█████████ | 1807/2000 [15:29<01:06,  2.90iteration/s, mean_rewards=-153] \u001b[A\n",
            "Training:  90%|█████████ | 1808/2000 [15:29<01:08,  2.81iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  90%|█████████ | 1808/2000 [15:29<01:08,  2.81iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  90%|█████████ | 1809/2000 [15:29<01:06,  2.85iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  90%|█████████ | 1809/2000 [15:29<01:06,  2.85iteration/s, mean_rewards=-105]\u001b[A\n",
            "Training:  90%|█████████ | 1810/2000 [15:30<01:15,  2.52iteration/s, mean_rewards=-105]\u001b[A\n",
            "Training:  90%|█████████ | 1810/2000 [15:30<01:15,  2.52iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  91%|█████████ | 1811/2000 [15:30<01:19,  2.36iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  91%|█████████ | 1811/2000 [15:30<01:19,  2.36iteration/s, mean_rewards=-178]\u001b[A\n",
            "Training:  91%|█████████ | 1812/2000 [15:31<01:25,  2.20iteration/s, mean_rewards=-178]\u001b[A\n",
            "Training:  91%|█████████ | 1812/2000 [15:31<01:25,  2.20iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  91%|█████████ | 1813/2000 [15:31<01:33,  2.00iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  91%|█████████ | 1813/2000 [15:31<01:33,  2.00iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  91%|█████████ | 1814/2000 [15:32<01:27,  2.13iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  91%|█████████ | 1814/2000 [15:32<01:27,  2.13iteration/s, mean_rewards=-106]\u001b[A\n",
            "Training:  91%|█████████ | 1815/2000 [15:32<01:22,  2.23iteration/s, mean_rewards=-106]\u001b[A\n",
            "Training:  91%|█████████ | 1815/2000 [15:32<01:22,  2.23iteration/s, mean_rewards=-53.1]\u001b[A\n",
            "Training:  91%|█████████ | 1816/2000 [15:32<01:25,  2.14iteration/s, mean_rewards=-53.1]\u001b[A\n",
            "Training:  91%|█████████ | 1816/2000 [15:33<01:25,  2.14iteration/s, mean_rewards=-140] \u001b[A\n",
            "Training:  91%|█████████ | 1817/2000 [15:33<01:21,  2.25iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  91%|█████████ | 1817/2000 [15:33<01:21,  2.25iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  91%|█████████ | 1818/2000 [15:33<01:21,  2.24iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  91%|█████████ | 1818/2000 [15:34<01:21,  2.24iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  91%|█████████ | 1819/2000 [15:34<01:14,  2.42iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  91%|█████████ | 1819/2000 [15:34<01:14,  2.42iteration/s, mean_rewards=-119]\u001b[A\n",
            "Training:  91%|█████████ | 1820/2000 [15:34<01:11,  2.52iteration/s, mean_rewards=-119]\u001b[A\n",
            "Training:  91%|█████████ | 1820/2000 [15:34<01:11,  2.52iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:  91%|█████████ | 1821/2000 [15:34<01:08,  2.63iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:  91%|█████████ | 1821/2000 [15:35<01:08,  2.63iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  91%|█████████ | 1822/2000 [15:35<01:08,  2.62iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  91%|█████████ | 1822/2000 [15:35<01:08,  2.62iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:  91%|█████████ | 1823/2000 [15:35<01:04,  2.73iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:  91%|█████████ | 1823/2000 [15:35<01:04,  2.73iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  91%|█████████ | 1824/2000 [15:36<01:07,  2.62iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  91%|█████████ | 1824/2000 [15:36<01:07,  2.62iteration/s, mean_rewards=-116]\u001b[A\n",
            "Training:  91%|█████████▏| 1825/2000 [15:36<01:06,  2.64iteration/s, mean_rewards=-116]\u001b[A\n",
            "Training:  91%|█████████▏| 1825/2000 [15:36<01:06,  2.64iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  91%|█████████▏| 1826/2000 [15:36<01:07,  2.56iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  91%|█████████▏| 1826/2000 [15:36<01:07,  2.56iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  91%|█████████▏| 1827/2000 [15:37<01:03,  2.73iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  91%|█████████▏| 1827/2000 [15:37<01:03,  2.73iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  91%|█████████▏| 1828/2000 [15:37<01:03,  2.73iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  91%|█████████▏| 1828/2000 [15:37<01:03,  2.73iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  91%|█████████▏| 1829/2000 [15:37<01:01,  2.80iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  91%|█████████▏| 1829/2000 [15:38<01:01,  2.80iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  92%|█████████▏| 1830/2000 [15:38<01:04,  2.62iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  92%|█████████▏| 1830/2000 [15:38<01:04,  2.62iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  92%|█████████▏| 1831/2000 [15:38<01:07,  2.49iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  92%|█████████▏| 1831/2000 [15:38<01:07,  2.49iteration/s, mean_rewards=-89.1]\u001b[A\n",
            "Training:  92%|█████████▏| 1832/2000 [15:39<01:10,  2.38iteration/s, mean_rewards=-89.1]\u001b[A\n",
            "Training:  92%|█████████▏| 1832/2000 [15:39<01:10,  2.38iteration/s, mean_rewards=-110] \u001b[A\n",
            "Training:  92%|█████████▏| 1833/2000 [15:39<01:05,  2.53iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  92%|█████████▏| 1833/2000 [15:39<01:05,  2.53iteration/s, mean_rewards=-198]\u001b[A\n",
            "Training:  92%|█████████▏| 1834/2000 [15:39<01:04,  2.56iteration/s, mean_rewards=-198]\u001b[A\n",
            "Training:  92%|█████████▏| 1834/2000 [15:40<01:04,  2.56iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  92%|█████████▏| 1835/2000 [15:40<01:05,  2.53iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  92%|█████████▏| 1835/2000 [15:40<01:05,  2.53iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  92%|█████████▏| 1836/2000 [15:40<01:00,  2.72iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  92%|█████████▏| 1836/2000 [15:40<01:00,  2.72iteration/s, mean_rewards=-67] \u001b[A\n",
            "Training:  92%|█████████▏| 1837/2000 [15:41<01:05,  2.49iteration/s, mean_rewards=-67]\u001b[A\n",
            "Training:  92%|█████████▏| 1837/2000 [15:41<01:05,  2.49iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  92%|█████████▏| 1838/2000 [15:41<01:00,  2.68iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  92%|█████████▏| 1838/2000 [15:41<01:00,  2.68iteration/s, mean_rewards=-157]\u001b[A\n",
            "Training:  92%|█████████▏| 1839/2000 [15:41<01:01,  2.63iteration/s, mean_rewards=-157]\u001b[A\n",
            "Training:  92%|█████████▏| 1839/2000 [15:42<01:01,  2.63iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  92%|█████████▏| 1840/2000 [15:42<01:01,  2.61iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  92%|█████████▏| 1840/2000 [15:42<01:01,  2.61iteration/s, mean_rewards=-68.4]\u001b[A\n",
            "Training:  92%|█████████▏| 1841/2000 [15:42<01:02,  2.56iteration/s, mean_rewards=-68.4]\u001b[A\n",
            "Training:  92%|█████████▏| 1841/2000 [15:42<01:02,  2.56iteration/s, mean_rewards=-140] \u001b[A\n",
            "Training:  92%|█████████▏| 1842/2000 [15:43<01:04,  2.47iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  92%|█████████▏| 1842/2000 [15:43<01:04,  2.47iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  92%|█████████▏| 1843/2000 [15:43<01:06,  2.37iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  92%|█████████▏| 1843/2000 [15:43<01:06,  2.37iteration/s, mean_rewards=-115]\u001b[A\n",
            "Training:  92%|█████████▏| 1844/2000 [15:43<01:06,  2.33iteration/s, mean_rewards=-115]\u001b[A\n",
            "Training:  92%|█████████▏| 1844/2000 [15:44<01:06,  2.33iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  92%|█████████▏| 1845/2000 [15:44<01:10,  2.20iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  92%|█████████▏| 1845/2000 [15:44<01:10,  2.20iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  92%|█████████▏| 1846/2000 [15:44<01:09,  2.23iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  92%|█████████▏| 1846/2000 [15:45<01:09,  2.23iteration/s, mean_rewards=-75.1]\u001b[A\n",
            "Training:  92%|█████████▏| 1847/2000 [15:45<01:09,  2.20iteration/s, mean_rewards=-75.1]\u001b[A\n",
            "Training:  92%|█████████▏| 1847/2000 [15:45<01:09,  2.20iteration/s, mean_rewards=-107] \u001b[A\n",
            "Training:  92%|█████████▏| 1848/2000 [15:45<01:09,  2.18iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  92%|█████████▏| 1848/2000 [15:46<01:09,  2.18iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  92%|█████████▏| 1849/2000 [15:46<01:08,  2.21iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  92%|█████████▏| 1849/2000 [15:46<01:08,  2.21iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  92%|█████████▎| 1850/2000 [15:46<01:04,  2.33iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  92%|█████████▎| 1850/2000 [15:46<01:04,  2.33iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  93%|█████████▎| 1851/2000 [15:47<01:04,  2.29iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  93%|█████████▎| 1851/2000 [15:47<01:04,  2.29iteration/s, mean_rewards=-72.3]\u001b[A\n",
            "Training:  93%|█████████▎| 1852/2000 [15:47<01:04,  2.28iteration/s, mean_rewards=-72.3]\u001b[A\n",
            "Training:  93%|█████████▎| 1852/2000 [15:47<01:04,  2.28iteration/s, mean_rewards=-96.5]\u001b[A\n",
            "Training:  93%|█████████▎| 1853/2000 [15:47<01:01,  2.37iteration/s, mean_rewards=-96.5]\u001b[A\n",
            "Training:  93%|█████████▎| 1853/2000 [15:48<01:01,  2.37iteration/s, mean_rewards=-84.3]\u001b[A\n",
            "Training:  93%|█████████▎| 1854/2000 [15:48<01:03,  2.30iteration/s, mean_rewards=-84.3]\u001b[A\n",
            "Training:  93%|█████████▎| 1854/2000 [15:48<01:03,  2.30iteration/s, mean_rewards=-115] \u001b[A\n",
            "Training:  93%|█████████▎| 1855/2000 [15:48<00:59,  2.42iteration/s, mean_rewards=-115]\u001b[A\n",
            "Training:  93%|█████████▎| 1855/2000 [15:49<00:59,  2.42iteration/s, mean_rewards=-116]\u001b[A\n",
            "Training:  93%|█████████▎| 1856/2000 [15:49<01:00,  2.36iteration/s, mean_rewards=-116]\u001b[A\n",
            "Training:  93%|█████████▎| 1856/2000 [15:49<01:00,  2.36iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  93%|█████████▎| 1857/2000 [15:49<00:58,  2.44iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  93%|█████████▎| 1857/2000 [15:49<00:58,  2.44iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  93%|█████████▎| 1858/2000 [15:49<00:55,  2.54iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  93%|█████████▎| 1858/2000 [15:50<00:55,  2.54iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  93%|█████████▎| 1859/2000 [15:50<00:52,  2.70iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  93%|█████████▎| 1859/2000 [15:50<00:52,  2.70iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  93%|█████████▎| 1860/2000 [15:50<00:49,  2.81iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  93%|█████████▎| 1860/2000 [15:50<00:49,  2.81iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  93%|█████████▎| 1861/2000 [15:50<00:50,  2.73iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  93%|█████████▎| 1861/2000 [15:51<00:50,  2.73iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  93%|█████████▎| 1862/2000 [15:51<00:54,  2.52iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  93%|█████████▎| 1862/2000 [15:51<00:54,  2.52iteration/s, mean_rewards=-80.8]\u001b[A\n",
            "Training:  93%|█████████▎| 1863/2000 [15:51<00:59,  2.32iteration/s, mean_rewards=-80.8]\u001b[A\n",
            "Training:  93%|█████████▎| 1863/2000 [15:52<00:59,  2.32iteration/s, mean_rewards=-116] \u001b[A\n",
            "Training:  93%|█████████▎| 1864/2000 [15:52<00:52,  2.57iteration/s, mean_rewards=-116]\u001b[A\n",
            "Training:  93%|█████████▎| 1864/2000 [15:52<00:52,  2.57iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  93%|█████████▎| 1865/2000 [15:52<00:50,  2.65iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  93%|█████████▎| 1865/2000 [15:52<00:50,  2.65iteration/s, mean_rewards=-199]\u001b[A\n",
            "Training:  93%|█████████▎| 1866/2000 [15:52<00:52,  2.57iteration/s, mean_rewards=-199]\u001b[A\n",
            "Training:  93%|█████████▎| 1866/2000 [15:53<00:52,  2.57iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  93%|█████████▎| 1867/2000 [15:53<00:48,  2.72iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  93%|█████████▎| 1867/2000 [15:53<00:48,  2.72iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  93%|█████████▎| 1868/2000 [15:53<00:47,  2.78iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  93%|█████████▎| 1868/2000 [15:53<00:47,  2.78iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  93%|█████████▎| 1869/2000 [15:54<00:47,  2.76iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  93%|█████████▎| 1869/2000 [15:54<00:47,  2.76iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  94%|█████████▎| 1870/2000 [15:54<00:47,  2.72iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  94%|█████████▎| 1870/2000 [15:54<00:47,  2.72iteration/s, mean_rewards=-88.6]\u001b[A\n",
            "Training:  94%|█████████▎| 1871/2000 [15:54<00:49,  2.60iteration/s, mean_rewards=-88.6]\u001b[A\n",
            "Training:  94%|█████████▎| 1871/2000 [15:55<00:49,  2.60iteration/s, mean_rewards=-39.1]\u001b[A\n",
            "Training:  94%|█████████▎| 1872/2000 [15:55<00:49,  2.57iteration/s, mean_rewards=-39.1]\u001b[A\n",
            "Training:  94%|█████████▎| 1872/2000 [15:55<00:49,  2.57iteration/s, mean_rewards=-122] \u001b[A\n",
            "Training:  94%|█████████▎| 1873/2000 [15:55<00:48,  2.60iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  94%|█████████▎| 1873/2000 [15:55<00:48,  2.60iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  94%|█████████▎| 1874/2000 [15:56<00:56,  2.24iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  94%|█████████▎| 1874/2000 [15:56<00:56,  2.24iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  94%|█████████▍| 1875/2000 [15:56<00:56,  2.20iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  94%|█████████▍| 1875/2000 [15:56<00:56,  2.20iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  94%|█████████▍| 1876/2000 [15:57<00:55,  2.24iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  94%|█████████▍| 1876/2000 [15:57<00:55,  2.24iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:  94%|█████████▍| 1877/2000 [15:57<00:56,  2.18iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:  94%|█████████▍| 1877/2000 [15:57<00:56,  2.18iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  94%|█████████▍| 1878/2000 [15:58<00:59,  2.05iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  94%|█████████▍| 1878/2000 [15:58<00:59,  2.05iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  94%|█████████▍| 1879/2000 [15:58<00:57,  2.09iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  94%|█████████▍| 1879/2000 [15:58<00:57,  2.09iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  94%|█████████▍| 1880/2000 [15:58<00:52,  2.28iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  94%|█████████▍| 1880/2000 [15:59<00:52,  2.28iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  94%|█████████▍| 1881/2000 [15:59<00:52,  2.28iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  94%|█████████▍| 1881/2000 [15:59<00:52,  2.28iteration/s, mean_rewards=-165]\u001b[A\n",
            "Training:  94%|█████████▍| 1882/2000 [15:59<00:49,  2.37iteration/s, mean_rewards=-165]\u001b[A\n",
            "Training:  94%|█████████▍| 1882/2000 [15:59<00:49,  2.37iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  94%|█████████▍| 1883/2000 [16:00<00:47,  2.47iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  94%|█████████▍| 1883/2000 [16:00<00:47,  2.47iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  94%|█████████▍| 1884/2000 [16:00<00:45,  2.54iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  94%|█████████▍| 1884/2000 [16:00<00:45,  2.54iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  94%|█████████▍| 1885/2000 [16:00<00:45,  2.53iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  94%|█████████▍| 1885/2000 [16:01<00:45,  2.53iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  94%|█████████▍| 1886/2000 [16:01<00:44,  2.59iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  94%|█████████▍| 1886/2000 [16:01<00:44,  2.59iteration/s, mean_rewards=-162]\u001b[A\n",
            "Training:  94%|█████████▍| 1887/2000 [16:01<00:43,  2.58iteration/s, mean_rewards=-162]\u001b[A\n",
            "Training:  94%|█████████▍| 1887/2000 [16:01<00:43,  2.58iteration/s, mean_rewards=-250]\u001b[A\n",
            "Training:  94%|█████████▍| 1888/2000 [16:02<00:45,  2.44iteration/s, mean_rewards=-250]\u001b[A\n",
            "Training:  94%|█████████▍| 1888/2000 [16:02<00:45,  2.44iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:  94%|█████████▍| 1889/2000 [16:02<00:44,  2.48iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:  94%|█████████▍| 1889/2000 [16:02<00:44,  2.48iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  94%|█████████▍| 1890/2000 [16:02<00:44,  2.48iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  94%|█████████▍| 1890/2000 [16:03<00:44,  2.48iteration/s, mean_rewards=-175]\u001b[A\n",
            "Training:  95%|█████████▍| 1891/2000 [16:03<00:45,  2.40iteration/s, mean_rewards=-175]\u001b[A\n",
            "Training:  95%|█████████▍| 1891/2000 [16:03<00:45,  2.40iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:  95%|█████████▍| 1892/2000 [16:03<00:46,  2.34iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:  95%|█████████▍| 1892/2000 [16:04<00:46,  2.34iteration/s, mean_rewards=-80.6]\u001b[A\n",
            "Training:  95%|█████████▍| 1893/2000 [16:04<00:44,  2.41iteration/s, mean_rewards=-80.6]\u001b[A\n",
            "Training:  95%|█████████▍| 1893/2000 [16:04<00:44,  2.41iteration/s, mean_rewards=-108] \u001b[A\n",
            "Training:  95%|█████████▍| 1894/2000 [16:04<00:42,  2.49iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:  95%|█████████▍| 1894/2000 [16:04<00:42,  2.49iteration/s, mean_rewards=-112]\u001b[A\n",
            "Training:  95%|█████████▍| 1895/2000 [16:04<00:43,  2.44iteration/s, mean_rewards=-112]\u001b[A\n",
            "Training:  95%|█████████▍| 1895/2000 [16:05<00:43,  2.44iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  95%|█████████▍| 1896/2000 [16:05<00:41,  2.50iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  95%|█████████▍| 1896/2000 [16:05<00:41,  2.50iteration/s, mean_rewards=-231]\u001b[A\n",
            "Training:  95%|█████████▍| 1897/2000 [16:05<00:40,  2.53iteration/s, mean_rewards=-231]\u001b[A\n",
            "Training:  95%|█████████▍| 1897/2000 [16:05<00:40,  2.53iteration/s, mean_rewards=-179]\u001b[A\n",
            "Training:  95%|█████████▍| 1898/2000 [16:06<00:40,  2.51iteration/s, mean_rewards=-179]\u001b[A\n",
            "Training:  95%|█████████▍| 1898/2000 [16:06<00:40,  2.51iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  95%|█████████▍| 1899/2000 [16:06<00:41,  2.45iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  95%|█████████▍| 1899/2000 [16:06<00:41,  2.45iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  95%|█████████▌| 1900/2000 [16:07<00:42,  2.36iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  95%|█████████▌| 1900/2000 [16:07<00:42,  2.36iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:  95%|█████████▌| 1901/2000 [16:07<00:40,  2.45iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:  95%|█████████▌| 1901/2000 [16:07<00:40,  2.45iteration/s, mean_rewards=-57.5]\u001b[A\n",
            "Training:  95%|█████████▌| 1902/2000 [16:07<00:37,  2.60iteration/s, mean_rewards=-57.5]\u001b[A\n",
            "Training:  95%|█████████▌| 1902/2000 [16:07<00:37,  2.60iteration/s, mean_rewards=-56.1]\u001b[A\n",
            "Training:  95%|█████████▌| 1903/2000 [16:08<00:36,  2.64iteration/s, mean_rewards=-56.1]\u001b[A\n",
            "Training:  95%|█████████▌| 1903/2000 [16:08<00:36,  2.64iteration/s, mean_rewards=-168] \u001b[A\n",
            "Training:  95%|█████████▌| 1904/2000 [16:08<00:37,  2.54iteration/s, mean_rewards=-168]\u001b[A\n",
            "Training:  95%|█████████▌| 1904/2000 [16:08<00:37,  2.54iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  95%|█████████▌| 1905/2000 [16:09<00:40,  2.37iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  95%|█████████▌| 1905/2000 [16:09<00:40,  2.37iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  95%|█████████▌| 1906/2000 [16:09<00:41,  2.27iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  95%|█████████▌| 1906/2000 [16:09<00:41,  2.27iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  95%|█████████▌| 1907/2000 [16:09<00:39,  2.35iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  95%|█████████▌| 1907/2000 [16:10<00:39,  2.35iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  95%|█████████▌| 1908/2000 [16:10<00:38,  2.37iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  95%|█████████▌| 1908/2000 [16:10<00:38,  2.37iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  95%|█████████▌| 1909/2000 [16:10<00:42,  2.12iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  95%|█████████▌| 1909/2000 [16:11<00:42,  2.12iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:  96%|█████████▌| 1910/2000 [16:11<00:46,  1.95iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:  96%|█████████▌| 1910/2000 [16:11<00:46,  1.95iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:  96%|█████████▌| 1911/2000 [16:11<00:43,  2.03iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:  96%|█████████▌| 1911/2000 [16:12<00:43,  2.03iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:  96%|█████████▌| 1912/2000 [16:12<00:41,  2.15iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:  96%|█████████▌| 1912/2000 [16:12<00:41,  2.15iteration/s, mean_rewards=-188]\u001b[A\n",
            "Training:  96%|█████████▌| 1913/2000 [16:12<00:39,  2.19iteration/s, mean_rewards=-188]\u001b[A\n",
            "Training:  96%|█████████▌| 1913/2000 [16:12<00:39,  2.19iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  96%|█████████▌| 1914/2000 [16:13<00:36,  2.38iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  96%|█████████▌| 1914/2000 [16:13<00:36,  2.38iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  96%|█████████▌| 1915/2000 [16:13<00:34,  2.48iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  96%|█████████▌| 1915/2000 [16:13<00:34,  2.48iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  96%|█████████▌| 1916/2000 [16:13<00:33,  2.51iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  96%|█████████▌| 1916/2000 [16:14<00:33,  2.51iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  96%|█████████▌| 1917/2000 [16:14<00:32,  2.57iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  96%|█████████▌| 1917/2000 [16:14<00:32,  2.57iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  96%|█████████▌| 1918/2000 [16:14<00:31,  2.57iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  96%|█████████▌| 1918/2000 [16:14<00:31,  2.57iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:  96%|█████████▌| 1919/2000 [16:15<00:31,  2.57iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:  96%|█████████▌| 1919/2000 [16:15<00:31,  2.57iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  96%|█████████▌| 1920/2000 [16:15<00:31,  2.55iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  96%|█████████▌| 1920/2000 [16:15<00:31,  2.55iteration/s, mean_rewards=-71.5]\u001b[A\n",
            "Training:  96%|█████████▌| 1921/2000 [16:15<00:31,  2.54iteration/s, mean_rewards=-71.5]\u001b[A\n",
            "Training:  96%|█████████▌| 1921/2000 [16:16<00:31,  2.54iteration/s, mean_rewards=-104] \u001b[A\n",
            "Training:  96%|█████████▌| 1922/2000 [16:16<00:28,  2.71iteration/s, mean_rewards=-104]\u001b[A\n",
            "Training:  96%|█████████▌| 1922/2000 [16:16<00:28,  2.71iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  96%|█████████▌| 1923/2000 [16:16<00:29,  2.60iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  96%|█████████▌| 1923/2000 [16:16<00:29,  2.60iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  96%|█████████▌| 1924/2000 [16:16<00:29,  2.59iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  96%|█████████▌| 1924/2000 [16:17<00:29,  2.59iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  96%|█████████▋| 1925/2000 [16:17<00:29,  2.53iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  96%|█████████▋| 1925/2000 [16:17<00:29,  2.53iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  96%|█████████▋| 1926/2000 [16:17<00:28,  2.56iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  96%|█████████▋| 1926/2000 [16:17<00:28,  2.56iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  96%|█████████▋| 1927/2000 [16:18<00:27,  2.62iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  96%|█████████▋| 1927/2000 [16:18<00:27,  2.62iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  96%|█████████▋| 1928/2000 [16:18<00:26,  2.76iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  96%|█████████▋| 1928/2000 [16:18<00:26,  2.76iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  96%|█████████▋| 1929/2000 [16:18<00:26,  2.72iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  96%|█████████▋| 1929/2000 [16:18<00:26,  2.72iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  96%|█████████▋| 1930/2000 [16:19<00:25,  2.80iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  96%|█████████▋| 1930/2000 [16:19<00:25,  2.80iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  97%|█████████▋| 1931/2000 [16:19<00:25,  2.67iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  97%|█████████▋| 1931/2000 [16:19<00:25,  2.67iteration/s, mean_rewards=-90.7]\u001b[A\n",
            "Training:  97%|█████████▋| 1932/2000 [16:19<00:26,  2.61iteration/s, mean_rewards=-90.7]\u001b[A\n",
            "Training:  97%|█████████▋| 1932/2000 [16:20<00:26,  2.61iteration/s, mean_rewards=-133] \u001b[A\n",
            "Training:  97%|█████████▋| 1933/2000 [16:20<00:25,  2.62iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  97%|█████████▋| 1933/2000 [16:20<00:25,  2.62iteration/s, mean_rewards=-179]\u001b[A\n",
            "Training:  97%|█████████▋| 1934/2000 [16:20<00:25,  2.61iteration/s, mean_rewards=-179]\u001b[A\n",
            "Training:  97%|█████████▋| 1934/2000 [16:20<00:25,  2.61iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  97%|█████████▋| 1935/2000 [16:21<00:25,  2.57iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  97%|█████████▋| 1935/2000 [16:21<00:25,  2.57iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  97%|█████████▋| 1936/2000 [16:21<00:24,  2.59iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  97%|█████████▋| 1936/2000 [16:21<00:24,  2.59iteration/s, mean_rewards=-162]\u001b[A\n",
            "Training:  97%|█████████▋| 1937/2000 [16:21<00:24,  2.52iteration/s, mean_rewards=-162]\u001b[A\n",
            "Training:  97%|█████████▋| 1937/2000 [16:22<00:24,  2.52iteration/s, mean_rewards=-165]\u001b[A\n",
            "Training:  97%|█████████▋| 1938/2000 [16:22<00:27,  2.28iteration/s, mean_rewards=-165]\u001b[A\n",
            "Training:  97%|█████████▋| 1938/2000 [16:22<00:27,  2.28iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  97%|█████████▋| 1939/2000 [16:22<00:26,  2.34iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  97%|█████████▋| 1939/2000 [16:23<00:26,  2.34iteration/s, mean_rewards=-93.7]\u001b[A\n",
            "Training:  97%|█████████▋| 1940/2000 [16:23<00:28,  2.10iteration/s, mean_rewards=-93.7]\u001b[A\n",
            "Training:  97%|█████████▋| 1940/2000 [16:23<00:28,  2.10iteration/s, mean_rewards=-126] \u001b[A\n",
            "Training:  97%|█████████▋| 1941/2000 [16:23<00:28,  2.06iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  97%|█████████▋| 1941/2000 [16:24<00:28,  2.06iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  97%|█████████▋| 1942/2000 [16:24<00:27,  2.08iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  97%|█████████▋| 1942/2000 [16:24<00:27,  2.08iteration/s, mean_rewards=-106]\u001b[A\n",
            "Training:  97%|█████████▋| 1943/2000 [16:24<00:26,  2.15iteration/s, mean_rewards=-106]\u001b[A\n",
            "Training:  97%|█████████▋| 1943/2000 [16:25<00:26,  2.15iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  97%|█████████▋| 1944/2000 [16:25<00:26,  2.08iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  97%|█████████▋| 1944/2000 [16:25<00:26,  2.08iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  97%|█████████▋| 1945/2000 [16:25<00:24,  2.21iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  97%|█████████▋| 1945/2000 [16:25<00:24,  2.21iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  97%|█████████▋| 1946/2000 [16:26<00:22,  2.41iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  97%|█████████▋| 1946/2000 [16:26<00:22,  2.41iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:  97%|█████████▋| 1947/2000 [16:26<00:21,  2.52iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:  97%|█████████▋| 1947/2000 [16:26<00:21,  2.52iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  97%|█████████▋| 1948/2000 [16:26<00:19,  2.66iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  97%|█████████▋| 1948/2000 [16:26<00:19,  2.66iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  97%|█████████▋| 1949/2000 [16:27<00:18,  2.77iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  97%|█████████▋| 1949/2000 [16:27<00:18,  2.77iteration/s, mean_rewards=-212]\u001b[A\n",
            "Training:  98%|█████████▊| 1950/2000 [16:27<00:19,  2.62iteration/s, mean_rewards=-212]\u001b[A\n",
            "Training:  98%|█████████▊| 1950/2000 [16:27<00:19,  2.62iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:  98%|█████████▊| 1951/2000 [16:27<00:18,  2.61iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:  98%|█████████▊| 1951/2000 [16:28<00:18,  2.61iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  98%|█████████▊| 1952/2000 [16:28<00:17,  2.71iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  98%|█████████▊| 1952/2000 [16:28<00:17,  2.71iteration/s, mean_rewards=-157]\u001b[A\n",
            "Training:  98%|█████████▊| 1953/2000 [16:28<00:17,  2.69iteration/s, mean_rewards=-157]\u001b[A\n",
            "Training:  98%|█████████▊| 1953/2000 [16:28<00:17,  2.69iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  98%|█████████▊| 1954/2000 [16:28<00:17,  2.65iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  98%|█████████▊| 1954/2000 [16:29<00:17,  2.65iteration/s, mean_rewards=-197]\u001b[A\n",
            "Training:  98%|█████████▊| 1955/2000 [16:29<00:18,  2.49iteration/s, mean_rewards=-197]\u001b[A\n",
            "Training:  98%|█████████▊| 1955/2000 [16:29<00:18,  2.49iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  98%|█████████▊| 1956/2000 [16:29<00:17,  2.47iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  98%|█████████▊| 1956/2000 [16:30<00:17,  2.47iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  98%|█████████▊| 1957/2000 [16:30<00:16,  2.57iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  98%|█████████▊| 1957/2000 [16:30<00:16,  2.57iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  98%|█████████▊| 1958/2000 [16:30<00:16,  2.57iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  98%|█████████▊| 1958/2000 [16:30<00:16,  2.57iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  98%|█████████▊| 1959/2000 [16:30<00:15,  2.70iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  98%|█████████▊| 1959/2000 [16:31<00:15,  2.70iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  98%|█████████▊| 1960/2000 [16:31<00:14,  2.69iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  98%|█████████▊| 1960/2000 [16:31<00:14,  2.69iteration/s, mean_rewards=-109]\u001b[A\n",
            "Training:  98%|█████████▊| 1961/2000 [16:31<00:13,  2.83iteration/s, mean_rewards=-109]\u001b[A\n",
            "Training:  98%|█████████▊| 1961/2000 [16:31<00:13,  2.83iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  98%|█████████▊| 1962/2000 [16:32<00:14,  2.68iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  98%|█████████▊| 1962/2000 [16:32<00:14,  2.68iteration/s, mean_rewards=-81.4]\u001b[A\n",
            "Training:  98%|█████████▊| 1963/2000 [16:32<00:13,  2.70iteration/s, mean_rewards=-81.4]\u001b[A\n",
            "Training:  98%|█████████▊| 1963/2000 [16:32<00:13,  2.70iteration/s, mean_rewards=-114] \u001b[A\n",
            "Training:  98%|█████████▊| 1964/2000 [16:32<00:13,  2.65iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  98%|█████████▊| 1964/2000 [16:33<00:13,  2.65iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  98%|█████████▊| 1965/2000 [16:33<00:13,  2.67iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  98%|█████████▊| 1965/2000 [16:33<00:13,  2.67iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  98%|█████████▊| 1966/2000 [16:33<00:11,  2.84iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  98%|█████████▊| 1966/2000 [16:33<00:11,  2.84iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  98%|█████████▊| 1967/2000 [16:33<00:11,  2.76iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  98%|█████████▊| 1967/2000 [16:34<00:11,  2.76iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  98%|█████████▊| 1968/2000 [16:34<00:11,  2.73iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  98%|█████████▊| 1968/2000 [16:34<00:11,  2.73iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  98%|█████████▊| 1969/2000 [16:34<00:11,  2.72iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  98%|█████████▊| 1969/2000 [16:34<00:11,  2.72iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:  98%|█████████▊| 1970/2000 [16:35<00:11,  2.62iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:  98%|█████████▊| 1970/2000 [16:35<00:11,  2.62iteration/s, mean_rewards=-97.8]\u001b[A\n",
            "Training:  99%|█████████▊| 1971/2000 [16:35<00:10,  2.75iteration/s, mean_rewards=-97.8]\u001b[A\n",
            "Training:  99%|█████████▊| 1971/2000 [16:35<00:10,  2.75iteration/s, mean_rewards=-143] \u001b[A\n",
            "Training:  99%|█████████▊| 1972/2000 [16:35<00:11,  2.51iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  99%|█████████▊| 1972/2000 [16:36<00:11,  2.51iteration/s, mean_rewards=-176]\u001b[A\n",
            "Training:  99%|█████████▊| 1973/2000 [16:36<00:11,  2.37iteration/s, mean_rewards=-176]\u001b[A\n",
            "Training:  99%|█████████▊| 1973/2000 [16:36<00:11,  2.37iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:  99%|█████████▊| 1974/2000 [16:36<00:11,  2.35iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:  99%|█████████▊| 1974/2000 [16:37<00:11,  2.35iteration/s, mean_rewards=-103]\u001b[A\n",
            "Training:  99%|█████████▉| 1975/2000 [16:37<00:11,  2.19iteration/s, mean_rewards=-103]\u001b[A\n",
            "Training:  99%|█████████▉| 1975/2000 [16:37<00:11,  2.19iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  99%|█████████▉| 1976/2000 [16:37<00:11,  2.02iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  99%|█████████▉| 1976/2000 [16:38<00:11,  2.02iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  99%|█████████▉| 1977/2000 [16:38<00:11,  1.96iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  99%|█████████▉| 1977/2000 [16:38<00:11,  1.96iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  99%|█████████▉| 1978/2000 [16:38<00:10,  2.05iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  99%|█████████▉| 1978/2000 [16:39<00:10,  2.05iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  99%|█████████▉| 1979/2000 [16:39<00:09,  2.20iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  99%|█████████▉| 1979/2000 [16:39<00:09,  2.20iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  99%|█████████▉| 1980/2000 [16:39<00:08,  2.34iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  99%|█████████▉| 1980/2000 [16:39<00:08,  2.34iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  99%|█████████▉| 1981/2000 [16:39<00:08,  2.35iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  99%|█████████▉| 1981/2000 [16:40<00:08,  2.35iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  99%|█████████▉| 1982/2000 [16:40<00:07,  2.42iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  99%|█████████▉| 1982/2000 [16:40<00:07,  2.42iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  99%|█████████▉| 1983/2000 [16:40<00:06,  2.58iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  99%|█████████▉| 1983/2000 [16:40<00:06,  2.58iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  99%|█████████▉| 1984/2000 [16:41<00:05,  2.72iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  99%|█████████▉| 1984/2000 [16:41<00:05,  2.72iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  99%|█████████▉| 1985/2000 [16:41<00:05,  2.62iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  99%|█████████▉| 1985/2000 [16:41<00:05,  2.62iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  99%|█████████▉| 1986/2000 [16:41<00:05,  2.68iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  99%|█████████▉| 1986/2000 [16:42<00:05,  2.68iteration/s, mean_rewards=-226]\u001b[A\n",
            "Training:  99%|█████████▉| 1987/2000 [16:42<00:05,  2.53iteration/s, mean_rewards=-226]\u001b[A\n",
            "Training:  99%|█████████▉| 1987/2000 [16:42<00:05,  2.53iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  99%|█████████▉| 1988/2000 [16:42<00:04,  2.69iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  99%|█████████▉| 1988/2000 [16:42<00:04,  2.69iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  99%|█████████▉| 1989/2000 [16:42<00:04,  2.66iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  99%|█████████▉| 1989/2000 [16:43<00:04,  2.66iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training: 100%|█████████▉| 1990/2000 [16:43<00:03,  2.65iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training: 100%|█████████▉| 1990/2000 [16:43<00:03,  2.65iteration/s, mean_rewards=-81.8]\u001b[A\n",
            "Training: 100%|█████████▉| 1991/2000 [16:43<00:03,  2.64iteration/s, mean_rewards=-81.8]\u001b[A\n",
            "Training: 100%|█████████▉| 1991/2000 [16:43<00:03,  2.64iteration/s, mean_rewards=-148] \u001b[A\n",
            "Training: 100%|█████████▉| 1992/2000 [16:44<00:02,  2.76iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training: 100%|█████████▉| 1992/2000 [16:44<00:02,  2.76iteration/s, mean_rewards=-102]\u001b[A\n",
            "Training: 100%|█████████▉| 1993/2000 [16:44<00:02,  2.88iteration/s, mean_rewards=-102]\u001b[A\n",
            "Training: 100%|█████████▉| 1993/2000 [16:44<00:02,  2.88iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training: 100%|█████████▉| 1994/2000 [16:44<00:02,  2.93iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training: 100%|█████████▉| 1994/2000 [16:44<00:02,  2.93iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training: 100%|█████████▉| 1995/2000 [16:44<00:01,  3.00iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training: 100%|█████████▉| 1995/2000 [16:45<00:01,  3.00iteration/s, mean_rewards=-116]\u001b[A\n",
            "Training: 100%|█████████▉| 1996/2000 [16:45<00:01,  3.01iteration/s, mean_rewards=-116]\u001b[A\n",
            "Training: 100%|█████████▉| 1996/2000 [16:45<00:01,  3.01iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training: 100%|█████████▉| 1997/2000 [16:45<00:01,  2.84iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training: 100%|█████████▉| 1997/2000 [16:45<00:01,  2.84iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training: 100%|█████████▉| 1998/2000 [16:46<00:00,  2.94iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training: 100%|█████████▉| 1998/2000 [16:46<00:00,  2.94iteration/s, mean_rewards=-178]\u001b[A\n",
            "Training: 100%|█████████▉| 1999/2000 [16:46<00:00,  2.78iteration/s, mean_rewards=-178]\u001b[A\n",
            "Training: 100%|█████████▉| 1999/2000 [16:46<00:00,  2.78iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training: 100%|██████████| 2000/2000 [16:46<00:00,  1.99iteration/s, mean_rewards=-120]\n"
          ]
        }
      ],
      "source": [
        "env = \"LunarLander-v2\"\n",
        "peturbations = get_peturbations(env, seed)\n",
        "print(\"Online Peturbations are\")\n",
        "print(peturbations)\n",
        "opt = \"base\"\n",
        "train(env, opt, peturbations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mphqlL159LQ3"
      },
      "source": [
        "## Train with TRAC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5nkoWbY83Sx",
        "outputId": "b2c32609-668c-4e3a-b9ed-37ba9d2746d5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:   0%|          | 0/2000 [00:00<?, ?iteration/s]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "USING PACE.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:   0%|          | 0/2000 [00:00<?, ?iteration/s, mean_rewards=-78.6]\u001b[A\n",
            "Training:   0%|          | 1/2000 [00:02<1:10:02,  2.10s/iteration, mean_rewards=-78.6]\u001b[A\n",
            "Training:   0%|          | 1/2000 [00:02<1:10:02,  2.10s/iteration, mean_rewards=-228] \u001b[A\n",
            "Training:   0%|          | 2/2000 [00:03<48:33,  1.46s/iteration, mean_rewards=-228]  \u001b[A\n",
            "Training:   0%|          | 2/2000 [00:03<48:33,  1.46s/iteration, mean_rewards=-278]\u001b[A\n",
            "Training:   0%|          | 3/2000 [00:04<46:20,  1.39s/iteration, mean_rewards=-278]\u001b[A\n",
            "Training:   0%|          | 3/2000 [00:04<46:20,  1.39s/iteration, mean_rewards=-318]\u001b[A\n",
            "Training:   0%|          | 4/2000 [00:05<39:40,  1.19s/iteration, mean_rewards=-318]\u001b[A\n",
            "Training:   0%|          | 4/2000 [00:05<39:40,  1.19s/iteration, mean_rewards=-106]\u001b[A\n",
            "Training:   0%|          | 5/2000 [00:06<34:27,  1.04s/iteration, mean_rewards=-106]\u001b[A\n",
            "Training:   0%|          | 5/2000 [00:06<34:27,  1.04s/iteration, mean_rewards=-177]\u001b[A\n",
            "Training:   0%|          | 6/2000 [00:06<31:56,  1.04iteration/s, mean_rewards=-177]\u001b[A\n",
            "Training:   0%|          | 6/2000 [00:07<31:56,  1.04iteration/s, mean_rewards=-266]\u001b[A\n",
            "Training:   0%|          | 7/2000 [00:07<30:28,  1.09iteration/s, mean_rewards=-266]\u001b[A\n",
            "Training:   0%|          | 7/2000 [00:08<30:28,  1.09iteration/s, mean_rewards=-103]\u001b[A\n",
            "Training:   0%|          | 8/2000 [00:08<29:03,  1.14iteration/s, mean_rewards=-103]\u001b[A\n",
            "Training:   0%|          | 8/2000 [00:08<29:03,  1.14iteration/s, mean_rewards=-177]\u001b[A\n",
            "Training:   0%|          | 9/2000 [00:09<29:07,  1.14iteration/s, mean_rewards=-177]\u001b[A\n",
            "Training:   0%|          | 9/2000 [00:09<29:07,  1.14iteration/s, mean_rewards=-292]\u001b[A\n",
            "Training:   0%|          | 10/2000 [00:10<28:33,  1.16iteration/s, mean_rewards=-292]\u001b[A\n",
            "Training:   0%|          | 10/2000 [00:10<28:33,  1.16iteration/s, mean_rewards=-192]\u001b[A\n",
            "Training:   1%|          | 11/2000 [00:11<31:52,  1.04iteration/s, mean_rewards=-192]\u001b[A\n",
            "Training:   1%|          | 11/2000 [00:11<31:52,  1.04iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:   1%|          | 12/2000 [00:12<31:07,  1.06iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:   1%|          | 12/2000 [00:12<31:07,  1.06iteration/s, mean_rewards=-162]\u001b[A\n",
            "Training:   1%|          | 13/2000 [00:13<29:58,  1.10iteration/s, mean_rewards=-162]\u001b[A\n",
            "Training:   1%|          | 13/2000 [00:13<29:58,  1.10iteration/s, mean_rewards=-191]\u001b[A\n",
            "Training:   1%|          | 14/2000 [00:14<32:53,  1.01iteration/s, mean_rewards=-191]\u001b[A\n",
            "Training:   1%|          | 14/2000 [00:14<32:53,  1.01iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:   1%|          | 15/2000 [00:15<32:48,  1.01iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:   1%|          | 15/2000 [00:15<32:48,  1.01iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:   1%|          | 16/2000 [00:16<36:19,  1.10s/iteration, mean_rewards=-161]\u001b[A\n",
            "Training:   1%|          | 16/2000 [00:17<36:19,  1.10s/iteration, mean_rewards=-312]\u001b[A\n",
            "Training:   1%|          | 17/2000 [00:17<36:29,  1.10s/iteration, mean_rewards=-312]\u001b[A\n",
            "Training:   1%|          | 17/2000 [00:18<36:29,  1.10s/iteration, mean_rewards=-46.3]\u001b[A\n",
            "Training:   1%|          | 18/2000 [00:18<36:28,  1.10s/iteration, mean_rewards=-46.3]\u001b[A\n",
            "Training:   1%|          | 18/2000 [00:19<36:28,  1.10s/iteration, mean_rewards=-51.3]\u001b[A\n",
            "Training:   1%|          | 19/2000 [00:19<33:34,  1.02s/iteration, mean_rewards=-51.3]\u001b[A\n",
            "Training:   1%|          | 19/2000 [00:19<33:34,  1.02s/iteration, mean_rewards=-146] \u001b[A\n",
            "Training:   1%|          | 20/2000 [00:20<31:04,  1.06iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:   1%|          | 20/2000 [00:20<31:04,  1.06iteration/s, mean_rewards=-270]\u001b[A\n",
            "Training:   1%|          | 21/2000 [00:21<32:00,  1.03iteration/s, mean_rewards=-270]\u001b[A\n",
            "Training:   1%|          | 21/2000 [00:21<32:00,  1.03iteration/s, mean_rewards=-231]\u001b[A\n",
            "Training:   1%|          | 22/2000 [00:22<31:29,  1.05iteration/s, mean_rewards=-231]\u001b[A\n",
            "Training:   1%|          | 22/2000 [00:22<31:29,  1.05iteration/s, mean_rewards=-216]\u001b[A\n",
            "Training:   1%|          | 23/2000 [00:23<32:13,  1.02iteration/s, mean_rewards=-216]\u001b[A\n",
            "Training:   1%|          | 23/2000 [00:23<32:13,  1.02iteration/s, mean_rewards=-62.1]\u001b[A\n",
            "Training:   1%|          | 24/2000 [00:24<29:22,  1.12iteration/s, mean_rewards=-62.1]\u001b[A\n",
            "Training:   1%|          | 24/2000 [00:24<29:22,  1.12iteration/s, mean_rewards=-183] \u001b[A\n",
            "Training:   1%|▏         | 25/2000 [00:25<30:54,  1.07iteration/s, mean_rewards=-183]\u001b[A\n",
            "Training:   1%|▏         | 25/2000 [00:25<30:54,  1.07iteration/s, mean_rewards=-70.6]\u001b[A\n",
            "Training:   1%|▏         | 26/2000 [00:26<30:44,  1.07iteration/s, mean_rewards=-70.6]\u001b[A\n",
            "Training:   1%|▏         | 26/2000 [00:26<30:44,  1.07iteration/s, mean_rewards=-176] \u001b[A\n",
            "Training:   1%|▏         | 27/2000 [00:27<31:03,  1.06iteration/s, mean_rewards=-176]\u001b[A\n",
            "Training:   1%|▏         | 27/2000 [00:27<31:03,  1.06iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:   1%|▏         | 28/2000 [00:28<33:39,  1.02s/iteration, mean_rewards=-147]\u001b[A\n",
            "Training:   1%|▏         | 28/2000 [00:28<33:39,  1.02s/iteration, mean_rewards=-150]\u001b[A\n",
            "Training:   1%|▏         | 29/2000 [00:29<37:33,  1.14s/iteration, mean_rewards=-150]\u001b[A\n",
            "Training:   1%|▏         | 29/2000 [00:30<37:33,  1.14s/iteration, mean_rewards=-171]\u001b[A\n",
            "Training:   2%|▏         | 30/2000 [00:30<36:02,  1.10s/iteration, mean_rewards=-171]\u001b[A\n",
            "Training:   2%|▏         | 30/2000 [00:31<36:02,  1.10s/iteration, mean_rewards=-146]\u001b[A\n",
            "Training:   2%|▏         | 31/2000 [00:31<35:46,  1.09s/iteration, mean_rewards=-146]\u001b[A\n",
            "Training:   2%|▏         | 31/2000 [00:32<35:46,  1.09s/iteration, mean_rewards=-109]\u001b[A\n",
            "Training:   2%|▏         | 32/2000 [00:32<34:18,  1.05s/iteration, mean_rewards=-109]\u001b[A\n",
            "Training:   2%|▏         | 32/2000 [00:33<34:18,  1.05s/iteration, mean_rewards=-114]\u001b[A\n",
            "Training:   2%|▏         | 33/2000 [00:34<39:28,  1.20s/iteration, mean_rewards=-114]\u001b[A\n",
            "Training:   2%|▏         | 33/2000 [00:34<39:28,  1.20s/iteration, mean_rewards=-94] \u001b[A\n",
            "Training:   2%|▏         | 34/2000 [00:35<36:19,  1.11s/iteration, mean_rewards=-94]\u001b[A\n",
            "Training:   2%|▏         | 34/2000 [00:35<36:19,  1.11s/iteration, mean_rewards=-132]\u001b[A\n",
            "Training:   2%|▏         | 35/2000 [00:36<35:13,  1.08s/iteration, mean_rewards=-132]\u001b[A\n",
            "Training:   2%|▏         | 35/2000 [00:36<35:13,  1.08s/iteration, mean_rewards=-125]\u001b[A\n",
            "Training:   2%|▏         | 36/2000 [00:37<37:32,  1.15s/iteration, mean_rewards=-125]\u001b[A\n",
            "Training:   2%|▏         | 36/2000 [00:38<37:32,  1.15s/iteration, mean_rewards=-52] \u001b[A\n",
            "Training:   2%|▏         | 37/2000 [00:39<48:09,  1.47s/iteration, mean_rewards=-52]\u001b[A\n",
            "Training:   2%|▏         | 37/2000 [00:40<48:09,  1.47s/iteration, mean_rewards=-68.9]\u001b[A\n",
            "Training:   2%|▏         | 38/2000 [00:41<51:39,  1.58s/iteration, mean_rewards=-68.9]\u001b[A\n",
            "Training:   2%|▏         | 38/2000 [00:42<51:39,  1.58s/iteration, mean_rewards=-32.3]\u001b[A\n",
            "Training:   2%|▏         | 39/2000 [00:43<54:50,  1.68s/iteration, mean_rewards=-32.3]\u001b[A\n",
            "Training:   2%|▏         | 39/2000 [00:44<54:50,  1.68s/iteration, mean_rewards=-15.7]\u001b[A\n",
            "Training:   2%|▏         | 40/2000 [00:46<1:08:35,  2.10s/iteration, mean_rewards=-15.7]\u001b[A\n",
            "Training:   2%|▏         | 40/2000 [00:47<1:08:35,  2.10s/iteration, mean_rewards=-112] \u001b[A\n",
            "Training:   2%|▏         | 41/2000 [00:49<1:16:31,  2.34s/iteration, mean_rewards=-112]\u001b[A\n",
            "Training:   2%|▏         | 41/2000 [00:50<1:16:31,  2.34s/iteration, mean_rewards=-21.1]\u001b[A\n",
            "Training:   2%|▏         | 42/2000 [00:52<1:22:05,  2.52s/iteration, mean_rewards=-21.1]\u001b[A\n",
            "Training:   2%|▏         | 42/2000 [00:54<1:22:05,  2.52s/iteration, mean_rewards=42.3] \u001b[A\n",
            "Training:   2%|▏         | 43/2000 [00:56<1:37:26,  2.99s/iteration, mean_rewards=42.3]\u001b[A\n",
            "Training:   2%|▏         | 43/2000 [00:58<1:37:26,  2.99s/iteration, mean_rewards=56.7]\u001b[A\n",
            "Training:   2%|▏         | 44/2000 [00:59<1:42:42,  3.15s/iteration, mean_rewards=56.7]\u001b[A\n",
            "Training:   2%|▏         | 44/2000 [01:01<1:42:42,  3.15s/iteration, mean_rewards=28.5]\u001b[A\n",
            "Training:   2%|▏         | 45/2000 [01:03<1:46:23,  3.27s/iteration, mean_rewards=28.5]\u001b[A\n",
            "Training:   2%|▏         | 45/2000 [01:05<1:46:23,  3.27s/iteration, mean_rewards=88.3]\u001b[A\n",
            "Training:   2%|▏         | 46/2000 [01:07<1:58:16,  3.63s/iteration, mean_rewards=88.3]\u001b[A\n",
            "Training:   2%|▏         | 46/2000 [01:09<1:58:16,  3.63s/iteration, mean_rewards=-18.1]\u001b[A\n",
            "Training:   2%|▏         | 47/2000 [01:11<1:52:46,  3.46s/iteration, mean_rewards=-18.1]\u001b[A\n",
            "Training:   2%|▏         | 47/2000 [01:12<1:52:46,  3.46s/iteration, mean_rewards=73.3] \u001b[A\n",
            "Training:   2%|▏         | 48/2000 [01:14<1:54:21,  3.51s/iteration, mean_rewards=73.3]\u001b[A\n",
            "Training:   2%|▏         | 48/2000 [01:16<1:54:21,  3.51s/iteration, mean_rewards=65.6]\u001b[A\n",
            "Training:   2%|▏         | 49/2000 [01:18<1:57:48,  3.62s/iteration, mean_rewards=65.6]\u001b[A\n",
            "Training:   2%|▏         | 49/2000 [01:20<1:57:48,  3.62s/iteration, mean_rewards=2.33]\u001b[A\n",
            "Training:   2%|▎         | 50/2000 [01:22<1:56:55,  3.60s/iteration, mean_rewards=2.33]\u001b[A\n",
            "Training:   2%|▎         | 50/2000 [01:23<1:56:55,  3.60s/iteration, mean_rewards=-39] \u001b[A\n",
            "Training:   3%|▎         | 51/2000 [01:25<1:51:25,  3.43s/iteration, mean_rewards=-39]\u001b[A\n",
            "Training:   3%|▎         | 51/2000 [01:26<1:51:25,  3.43s/iteration, mean_rewards=75.2]\u001b[A\n",
            "Training:   3%|▎         | 52/2000 [01:28<1:52:35,  3.47s/iteration, mean_rewards=75.2]\u001b[A\n",
            "Training:   3%|▎         | 52/2000 [01:29<1:52:35,  3.47s/iteration, mean_rewards=-15.8]\u001b[A\n",
            "Training:   3%|▎         | 53/2000 [01:31<1:49:31,  3.38s/iteration, mean_rewards=-15.8]\u001b[A\n",
            "Training:   3%|▎         | 53/2000 [01:33<1:49:31,  3.38s/iteration, mean_rewards=0.515]\u001b[A\n",
            "Training:   3%|▎         | 54/2000 [01:35<1:50:08,  3.40s/iteration, mean_rewards=0.515]\u001b[A\n",
            "Training:   3%|▎         | 54/2000 [01:36<1:50:08,  3.40s/iteration, mean_rewards=-63]  \u001b[A\n",
            "Training:   3%|▎         | 55/2000 [01:38<1:47:11,  3.31s/iteration, mean_rewards=-63]\u001b[A\n",
            "Training:   3%|▎         | 55/2000 [01:39<1:47:11,  3.31s/iteration, mean_rewards=-97.2]\u001b[A\n",
            "Training:   3%|▎         | 56/2000 [01:41<1:45:14,  3.25s/iteration, mean_rewards=-97.2]\u001b[A\n",
            "Training:   3%|▎         | 56/2000 [01:42<1:45:14,  3.25s/iteration, mean_rewards=22.5] \u001b[A\n",
            "Training:   3%|▎         | 57/2000 [01:45<1:49:23,  3.38s/iteration, mean_rewards=22.5]\u001b[A\n",
            "Training:   3%|▎         | 57/2000 [01:47<1:49:23,  3.38s/iteration, mean_rewards=44]  \u001b[A\n",
            "Training:   3%|▎         | 58/2000 [01:49<1:53:37,  3.51s/iteration, mean_rewards=44]\u001b[A\n",
            "Training:   3%|▎         | 58/2000 [01:50<1:53:37,  3.51s/iteration, mean_rewards=0.417]\u001b[A\n",
            "Training:   3%|▎         | 59/2000 [01:52<1:51:22,  3.44s/iteration, mean_rewards=0.417]\u001b[A\n",
            "Training:   3%|▎         | 59/2000 [01:53<1:51:22,  3.44s/iteration, mean_rewards=85.5] \u001b[A\n",
            "Training:   3%|▎         | 60/2000 [01:55<1:51:18,  3.44s/iteration, mean_rewards=85.5]\u001b[A\n",
            "Training:   3%|▎         | 60/2000 [01:57<1:51:18,  3.44s/iteration, mean_rewards=65.2]\u001b[A\n",
            "Training:   3%|▎         | 61/2000 [02:00<2:00:47,  3.74s/iteration, mean_rewards=65.2]\u001b[A\n",
            "Training:   3%|▎         | 61/2000 [02:01<2:00:47,  3.74s/iteration, mean_rewards=56.8]\u001b[A\n",
            "Training:   3%|▎         | 62/2000 [02:03<1:59:28,  3.70s/iteration, mean_rewards=56.8]\u001b[A\n",
            "Training:   3%|▎         | 62/2000 [02:05<1:59:28,  3.70s/iteration, mean_rewards=83.9]\u001b[A\n",
            "Training:   3%|▎         | 63/2000 [02:07<1:58:16,  3.66s/iteration, mean_rewards=83.9]\u001b[A\n",
            "Training:   3%|▎         | 63/2000 [02:09<1:58:16,  3.66s/iteration, mean_rewards=62.5]\u001b[A\n",
            "Training:   3%|▎         | 64/2000 [02:11<2:04:45,  3.87s/iteration, mean_rewards=62.5]\u001b[A\n",
            "Training:   3%|▎         | 64/2000 [02:13<2:04:45,  3.87s/iteration, mean_rewards=57.6]\u001b[A\n",
            "Training:   3%|▎         | 65/2000 [02:15<2:02:33,  3.80s/iteration, mean_rewards=57.6]\u001b[A\n",
            "Training:   3%|▎         | 65/2000 [02:17<2:02:33,  3.80s/iteration, mean_rewards=73.8]\u001b[A\n",
            "Training:   3%|▎         | 66/2000 [02:19<2:01:32,  3.77s/iteration, mean_rewards=73.8]\u001b[A\n",
            "Training:   3%|▎         | 66/2000 [02:20<2:01:32,  3.77s/iteration, mean_rewards=-15.8]\u001b[A\n",
            "Training:   3%|▎         | 67/2000 [02:22<1:56:20,  3.61s/iteration, mean_rewards=-15.8]\u001b[A\n",
            "Training:   3%|▎         | 67/2000 [02:24<1:56:20,  3.61s/iteration, mean_rewards=39.6] \u001b[A\n",
            "Training:   3%|▎         | 68/2000 [02:26<2:01:00,  3.76s/iteration, mean_rewards=39.6]\u001b[A\n",
            "Training:   3%|▎         | 68/2000 [02:28<2:01:00,  3.76s/iteration, mean_rewards=41.5]\u001b[A\n",
            "Training:   3%|▎         | 69/2000 [02:29<1:59:09,  3.70s/iteration, mean_rewards=41.5]\u001b[A\n",
            "Training:   3%|▎         | 69/2000 [02:31<1:59:09,  3.70s/iteration, mean_rewards=58.6]\u001b[A\n",
            "Training:   4%|▎         | 70/2000 [02:33<1:58:04,  3.67s/iteration, mean_rewards=58.6]\u001b[A\n",
            "Training:   4%|▎         | 70/2000 [02:35<1:58:04,  3.67s/iteration, mean_rewards=40.5]\u001b[A\n",
            "Training:   4%|▎         | 71/2000 [02:37<2:03:52,  3.85s/iteration, mean_rewards=40.5]\u001b[A\n",
            "Training:   4%|▎         | 71/2000 [02:39<2:03:52,  3.85s/iteration, mean_rewards=58.2]\u001b[A\n",
            "Training:   4%|▎         | 72/2000 [02:41<2:01:28,  3.78s/iteration, mean_rewards=58.2]\u001b[A\n",
            "Training:   4%|▎         | 72/2000 [02:43<2:01:28,  3.78s/iteration, mean_rewards=59]  \u001b[A\n",
            "Training:   4%|▎         | 73/2000 [02:45<1:59:24,  3.72s/iteration, mean_rewards=59]\u001b[A\n",
            "Training:   4%|▎         | 73/2000 [02:46<1:59:24,  3.72s/iteration, mean_rewards=33]\u001b[A\n",
            "Training:   4%|▎         | 74/2000 [02:49<2:06:26,  3.94s/iteration, mean_rewards=33]\u001b[A\n",
            "Training:   4%|▎         | 74/2000 [02:51<2:06:26,  3.94s/iteration, mean_rewards=58.1]\u001b[A\n",
            "Training:   4%|▍         | 75/2000 [02:53<2:03:53,  3.86s/iteration, mean_rewards=58.1]\u001b[A\n",
            "Training:   4%|▍         | 75/2000 [02:54<2:03:53,  3.86s/iteration, mean_rewards=29.8]\u001b[A\n",
            "Training:   4%|▍         | 76/2000 [02:56<2:01:09,  3.78s/iteration, mean_rewards=29.8]\u001b[A\n",
            "Training:   4%|▍         | 76/2000 [02:58<2:01:09,  3.78s/iteration, mean_rewards=33.3]\u001b[A\n",
            "Training:   4%|▍         | 77/2000 [03:00<2:01:05,  3.78s/iteration, mean_rewards=33.3]\u001b[A\n",
            "Training:   4%|▍         | 77/2000 [03:02<2:01:05,  3.78s/iteration, mean_rewards=-91] \u001b[A\n",
            "Training:   4%|▍         | 78/2000 [03:03<1:53:35,  3.55s/iteration, mean_rewards=-91]\u001b[A\n",
            "Training:   4%|▍         | 78/2000 [03:05<1:53:35,  3.55s/iteration, mean_rewards=-36.2]\u001b[A\n",
            "Training:   4%|▍         | 79/2000 [03:07<1:54:59,  3.59s/iteration, mean_rewards=-36.2]\u001b[A\n",
            "Training:   4%|▍         | 79/2000 [03:08<1:54:59,  3.59s/iteration, mean_rewards=40.3] \u001b[A\n",
            "Training:   4%|▍         | 80/2000 [03:10<1:55:04,  3.60s/iteration, mean_rewards=40.3]\u001b[A\n",
            "Training:   4%|▍         | 80/2000 [03:12<1:55:04,  3.60s/iteration, mean_rewards=32.7]\u001b[A\n",
            "Training:   4%|▍         | 81/2000 [03:15<2:02:39,  3.84s/iteration, mean_rewards=32.7]\u001b[A\n",
            "Training:   4%|▍         | 81/2000 [03:16<2:02:39,  3.84s/iteration, mean_rewards=30.5]\u001b[A\n",
            "Training:   4%|▍         | 82/2000 [03:18<1:59:30,  3.74s/iteration, mean_rewards=30.5]\u001b[A\n",
            "Training:   4%|▍         | 82/2000 [03:20<1:59:30,  3.74s/iteration, mean_rewards=39.8]\u001b[A\n",
            "Training:   4%|▍         | 83/2000 [03:22<1:58:31,  3.71s/iteration, mean_rewards=39.8]\u001b[A\n",
            "Training:   4%|▍         | 83/2000 [03:24<1:58:31,  3.71s/iteration, mean_rewards=36.6]\u001b[A\n",
            "Training:   4%|▍         | 84/2000 [03:26<2:00:16,  3.77s/iteration, mean_rewards=36.6]\u001b[A\n",
            "Training:   4%|▍         | 84/2000 [03:28<2:00:16,  3.77s/iteration, mean_rewards=8.89]\u001b[A\n",
            "Training:   4%|▍         | 85/2000 [03:30<2:04:12,  3.89s/iteration, mean_rewards=8.89]\u001b[A\n",
            "Training:   4%|▍         | 85/2000 [03:31<2:04:12,  3.89s/iteration, mean_rewards=-26.7]\u001b[A\n",
            "Training:   4%|▍         | 86/2000 [03:33<1:57:38,  3.69s/iteration, mean_rewards=-26.7]\u001b[A\n",
            "Training:   4%|▍         | 86/2000 [03:34<1:57:38,  3.69s/iteration, mean_rewards=-8.06]\u001b[A\n",
            "Training:   4%|▍         | 87/2000 [03:36<1:48:31,  3.40s/iteration, mean_rewards=-8.06]\u001b[A\n",
            "Training:   4%|▍         | 87/2000 [03:38<1:48:31,  3.40s/iteration, mean_rewards=13.4] \u001b[A\n",
            "Training:   4%|▍         | 88/2000 [03:40<1:56:25,  3.65s/iteration, mean_rewards=13.4]\u001b[A\n",
            "Training:   4%|▍         | 88/2000 [03:42<1:56:25,  3.65s/iteration, mean_rewards=-44.2]\u001b[A\n",
            "Training:   4%|▍         | 89/2000 [03:44<1:54:30,  3.60s/iteration, mean_rewards=-44.2]\u001b[A\n",
            "Training:   4%|▍         | 89/2000 [03:45<1:54:30,  3.60s/iteration, mean_rewards=30.8] \u001b[A\n",
            "Training:   4%|▍         | 90/2000 [03:47<1:55:31,  3.63s/iteration, mean_rewards=30.8]\u001b[A\n",
            "Training:   4%|▍         | 90/2000 [03:49<1:55:31,  3.63s/iteration, mean_rewards=13.6]\u001b[A\n",
            "Training:   5%|▍         | 91/2000 [03:51<1:58:41,  3.73s/iteration, mean_rewards=13.6]\u001b[A\n",
            "Training:   5%|▍         | 91/2000 [03:53<1:58:41,  3.73s/iteration, mean_rewards=26.4]\u001b[A\n",
            "Training:   5%|▍         | 92/2000 [03:55<2:01:37,  3.82s/iteration, mean_rewards=26.4]\u001b[A\n",
            "Training:   5%|▍         | 92/2000 [03:56<2:01:37,  3.82s/iteration, mean_rewards=-104]\u001b[A\n",
            "Training:   5%|▍         | 93/2000 [03:57<1:39:19,  3.13s/iteration, mean_rewards=-104]\u001b[A\n",
            "Training:   5%|▍         | 93/2000 [03:58<1:39:19,  3.13s/iteration, mean_rewards=-103]\u001b[A\n",
            "Training:   5%|▍         | 94/2000 [03:59<1:29:54,  2.83s/iteration, mean_rewards=-103]\u001b[A\n",
            "Training:   5%|▍         | 94/2000 [04:01<1:29:54,  2.83s/iteration, mean_rewards=-41.4]\u001b[A\n",
            "Training:   5%|▍         | 95/2000 [04:02<1:35:43,  3.01s/iteration, mean_rewards=-41.4]\u001b[A\n",
            "Training:   5%|▍         | 95/2000 [04:04<1:35:43,  3.01s/iteration, mean_rewards=-64.8]\u001b[A\n",
            "Training:   5%|▍         | 96/2000 [04:06<1:43:13,  3.25s/iteration, mean_rewards=-64.8]\u001b[A\n",
            "Training:   5%|▍         | 96/2000 [04:07<1:43:13,  3.25s/iteration, mean_rewards=-30.6]\u001b[A\n",
            "Training:   5%|▍         | 97/2000 [04:09<1:38:40,  3.11s/iteration, mean_rewards=-30.6]\u001b[A\n",
            "Training:   5%|▍         | 97/2000 [04:11<1:38:40,  3.11s/iteration, mean_rewards=36.6] \u001b[A\n",
            "Training:   5%|▍         | 98/2000 [04:13<1:42:57,  3.25s/iteration, mean_rewards=36.6]\u001b[A\n",
            "Training:   5%|▍         | 98/2000 [04:14<1:42:57,  3.25s/iteration, mean_rewards=34.7]\u001b[A\n",
            "Training:   5%|▍         | 99/2000 [04:16<1:47:09,  3.38s/iteration, mean_rewards=34.7]\u001b[A\n",
            "Training:   5%|▍         | 99/2000 [04:18<1:47:09,  3.38s/iteration, mean_rewards=-12.7]\u001b[A\n",
            "Training:   5%|▌         | 100/2000 [04:20<1:47:58,  3.41s/iteration, mean_rewards=-12.7]\u001b[A\n",
            "Training:   5%|▌         | 100/2000 [04:21<1:47:58,  3.41s/iteration, mean_rewards=16.4] \u001b[A\n",
            "Training:   5%|▌         | 101/2000 [04:23<1:50:08,  3.48s/iteration, mean_rewards=16.4]\u001b[A\n",
            "Training:   5%|▌         | 101/2000 [04:25<1:50:08,  3.48s/iteration, mean_rewards=-31.2]\u001b[A\n",
            "Training:   5%|▌         | 102/2000 [04:27<1:50:31,  3.49s/iteration, mean_rewards=-31.2]\u001b[A\n",
            "Training:   5%|▌         | 102/2000 [04:29<1:50:31,  3.49s/iteration, mean_rewards=-24.2]\u001b[A\n",
            "Training:   5%|▌         | 103/2000 [04:31<1:59:55,  3.79s/iteration, mean_rewards=-24.2]\u001b[A\n",
            "Training:   5%|▌         | 103/2000 [04:32<1:59:55,  3.79s/iteration, mean_rewards=-103] \u001b[A\n",
            "Training:   5%|▌         | 104/2000 [04:34<1:46:28,  3.37s/iteration, mean_rewards=-103]\u001b[A\n",
            "Training:   5%|▌         | 104/2000 [04:35<1:46:28,  3.37s/iteration, mean_rewards=1.99]\u001b[A\n",
            "Training:   5%|▌         | 105/2000 [04:37<1:47:54,  3.42s/iteration, mean_rewards=1.99]\u001b[A\n",
            "Training:   5%|▌         | 105/2000 [04:38<1:47:54,  3.42s/iteration, mean_rewards=-36.8]\u001b[A\n",
            "Training:   5%|▌         | 106/2000 [04:40<1:39:01,  3.14s/iteration, mean_rewards=-36.8]\u001b[A\n",
            "Training:   5%|▌         | 106/2000 [04:41<1:39:01,  3.14s/iteration, mean_rewards=-104] \u001b[A\n",
            "Training:   5%|▌         | 107/2000 [04:42<1:31:35,  2.90s/iteration, mean_rewards=-104]\u001b[A\n",
            "Training:   5%|▌         | 107/2000 [04:44<1:31:35,  2.90s/iteration, mean_rewards=-78] \u001b[A\n",
            "Training:   5%|▌         | 108/2000 [04:46<1:38:06,  3.11s/iteration, mean_rewards=-78]\u001b[A\n",
            "Training:   5%|▌         | 108/2000 [04:47<1:38:06,  3.11s/iteration, mean_rewards=-95.3]\u001b[A\n",
            "Training:   5%|▌         | 109/2000 [04:48<1:31:44,  2.91s/iteration, mean_rewards=-95.3]\u001b[A\n",
            "Training:   5%|▌         | 109/2000 [04:50<1:31:44,  2.91s/iteration, mean_rewards=-52.7]\u001b[A\n",
            "Training:   6%|▌         | 110/2000 [04:52<1:36:17,  3.06s/iteration, mean_rewards=-52.7]\u001b[A\n",
            "Training:   6%|▌         | 110/2000 [04:53<1:36:17,  3.06s/iteration, mean_rewards=-33.8]\u001b[A\n",
            "Training:   6%|▌         | 111/2000 [04:54<1:31:35,  2.91s/iteration, mean_rewards=-33.8]\u001b[A\n",
            "Training:   6%|▌         | 111/2000 [04:55<1:31:35,  2.91s/iteration, mean_rewards=-91.4]\u001b[A\n",
            "Training:   6%|▌         | 112/2000 [04:57<1:28:35,  2.82s/iteration, mean_rewards=-91.4]\u001b[A\n",
            "Training:   6%|▌         | 112/2000 [04:58<1:28:35,  2.82s/iteration, mean_rewards=-55.2]\u001b[A\n",
            "Training:   6%|▌         | 113/2000 [05:00<1:28:44,  2.82s/iteration, mean_rewards=-55.2]\u001b[A\n",
            "Training:   6%|▌         | 113/2000 [05:01<1:28:44,  2.82s/iteration, mean_rewards=6.31] \u001b[A\n",
            "Training:   6%|▌         | 114/2000 [05:03<1:36:04,  3.06s/iteration, mean_rewards=6.31]\u001b[A\n",
            "Training:   6%|▌         | 114/2000 [05:04<1:36:04,  3.06s/iteration, mean_rewards=-106]\u001b[A\n",
            "Training:   6%|▌         | 115/2000 [05:05<1:27:41,  2.79s/iteration, mean_rewards=-106]\u001b[A\n",
            "Training:   6%|▌         | 115/2000 [05:07<1:27:41,  2.79s/iteration, mean_rewards=-35.7]\u001b[A\n",
            "Training:   6%|▌         | 116/2000 [05:09<1:32:25,  2.94s/iteration, mean_rewards=-35.7]\u001b[A\n",
            "Training:   6%|▌         | 116/2000 [05:10<1:32:25,  2.94s/iteration, mean_rewards=-49.5]\u001b[A\n",
            "Training:   6%|▌         | 117/2000 [05:12<1:31:38,  2.92s/iteration, mean_rewards=-49.5]\u001b[A\n",
            "Training:   6%|▌         | 117/2000 [05:13<1:31:38,  2.92s/iteration, mean_rewards=14.7] \u001b[A\n",
            "Training:   6%|▌         | 118/2000 [05:15<1:37:26,  3.11s/iteration, mean_rewards=14.7]\u001b[A\n",
            "Training:   6%|▌         | 118/2000 [05:17<1:37:26,  3.11s/iteration, mean_rewards=-29.9]\u001b[A\n",
            "Training:   6%|▌         | 119/2000 [05:18<1:39:32,  3.18s/iteration, mean_rewards=-29.9]\u001b[A\n",
            "Training:   6%|▌         | 119/2000 [05:20<1:39:32,  3.18s/iteration, mean_rewards=-33.7]\u001b[A\n",
            "Training:   6%|▌         | 120/2000 [05:22<1:42:06,  3.26s/iteration, mean_rewards=-33.7]\u001b[A\n",
            "Training:   6%|▌         | 120/2000 [05:23<1:42:06,  3.26s/iteration, mean_rewards=-104] \u001b[A\n",
            "Training:   6%|▌         | 121/2000 [05:24<1:35:50,  3.06s/iteration, mean_rewards=-104]\u001b[A\n",
            "Training:   6%|▌         | 121/2000 [05:26<1:35:50,  3.06s/iteration, mean_rewards=-48.1]\u001b[A\n",
            "Training:   6%|▌         | 122/2000 [05:27<1:30:36,  2.89s/iteration, mean_rewards=-48.1]\u001b[A\n",
            "Training:   6%|▌         | 122/2000 [05:28<1:30:36,  2.89s/iteration, mean_rewards=-73.8]\u001b[A\n",
            "Training:   6%|▌         | 123/2000 [05:28<1:17:35,  2.48s/iteration, mean_rewards=-73.8]\u001b[A\n",
            "Training:   6%|▌         | 123/2000 [05:30<1:17:35,  2.48s/iteration, mean_rewards=7.62] \u001b[A\n",
            "Training:   6%|▌         | 124/2000 [05:32<1:26:54,  2.78s/iteration, mean_rewards=7.62]\u001b[A\n",
            "Training:   6%|▌         | 124/2000 [05:33<1:26:54,  2.78s/iteration, mean_rewards=-20] \u001b[A\n",
            "Training:   6%|▋         | 125/2000 [05:35<1:33:52,  3.00s/iteration, mean_rewards=-20]\u001b[A\n",
            "Training:   6%|▋         | 125/2000 [05:37<1:33:52,  3.00s/iteration, mean_rewards=22.1]\u001b[A\n",
            "Training:   6%|▋         | 126/2000 [05:39<1:39:34,  3.19s/iteration, mean_rewards=22.1]\u001b[A\n",
            "Training:   6%|▋         | 126/2000 [05:41<1:39:34,  3.19s/iteration, mean_rewards=23.2]\u001b[A\n",
            "Training:   6%|▋         | 127/2000 [05:43<1:43:06,  3.30s/iteration, mean_rewards=23.2]\u001b[A\n",
            "Training:   6%|▋         | 127/2000 [05:44<1:43:06,  3.30s/iteration, mean_rewards=14.9]\u001b[A\n",
            "Training:   6%|▋         | 128/2000 [05:47<1:48:16,  3.47s/iteration, mean_rewards=14.9]\u001b[A\n",
            "Training:   6%|▋         | 128/2000 [05:49<1:48:16,  3.47s/iteration, mean_rewards=30.2]\u001b[A\n",
            "Training:   6%|▋         | 129/2000 [05:51<1:55:20,  3.70s/iteration, mean_rewards=30.2]\u001b[A\n",
            "Training:   6%|▋         | 129/2000 [05:53<1:55:20,  3.70s/iteration, mean_rewards=22.8]\u001b[A\n",
            "Training:   6%|▋         | 130/2000 [05:54<1:55:20,  3.70s/iteration, mean_rewards=22.8]\u001b[A\n",
            "Training:   6%|▋         | 130/2000 [05:56<1:55:20,  3.70s/iteration, mean_rewards=37.8]\u001b[A\n",
            "Training:   7%|▋         | 131/2000 [05:58<1:54:10,  3.67s/iteration, mean_rewards=37.8]\u001b[A\n",
            "Training:   7%|▋         | 131/2000 [06:00<1:54:10,  3.67s/iteration, mean_rewards=-4.28]\u001b[A\n",
            "Training:   7%|▋         | 132/2000 [06:02<1:59:52,  3.85s/iteration, mean_rewards=-4.28]\u001b[A\n",
            "Training:   7%|▋         | 132/2000 [06:04<1:59:52,  3.85s/iteration, mean_rewards=-21]  \u001b[A\n",
            "Training:   7%|▋         | 133/2000 [06:05<1:51:53,  3.60s/iteration, mean_rewards=-21]\u001b[A\n",
            "Training:   7%|▋         | 133/2000 [06:07<1:51:53,  3.60s/iteration, mean_rewards=36.3]\u001b[A\n",
            "Training:   7%|▋         | 134/2000 [06:09<1:51:57,  3.60s/iteration, mean_rewards=36.3]\u001b[A\n",
            "Training:   7%|▋         | 134/2000 [06:11<1:51:57,  3.60s/iteration, mean_rewards=16.5]\u001b[A\n",
            "Training:   7%|▋         | 135/2000 [06:13<1:57:26,  3.78s/iteration, mean_rewards=16.5]\u001b[A\n",
            "Training:   7%|▋         | 135/2000 [06:15<1:57:26,  3.78s/iteration, mean_rewards=26.2]\u001b[A\n",
            "Training:   7%|▋         | 136/2000 [06:17<1:58:43,  3.82s/iteration, mean_rewards=26.2]\u001b[A\n",
            "Training:   7%|▋         | 136/2000 [06:19<1:58:43,  3.82s/iteration, mean_rewards=4.58]\u001b[A\n",
            "Training:   7%|▋         | 137/2000 [06:21<1:55:34,  3.72s/iteration, mean_rewards=4.58]\u001b[A\n",
            "Training:   7%|▋         | 137/2000 [06:22<1:55:34,  3.72s/iteration, mean_rewards=7.43]\u001b[A\n",
            "Training:   7%|▋         | 138/2000 [06:24<1:56:06,  3.74s/iteration, mean_rewards=7.43]\u001b[A\n",
            "Training:   7%|▋         | 138/2000 [06:26<1:56:06,  3.74s/iteration, mean_rewards=-28.2]\u001b[A\n",
            "Training:   7%|▋         | 139/2000 [06:28<1:53:56,  3.67s/iteration, mean_rewards=-28.2]\u001b[A\n",
            "Training:   7%|▋         | 139/2000 [06:29<1:53:56,  3.67s/iteration, mean_rewards=-52.9]\u001b[A\n",
            "Training:   7%|▋         | 140/2000 [06:31<1:48:19,  3.49s/iteration, mean_rewards=-52.9]\u001b[A\n",
            "Training:   7%|▋         | 140/2000 [06:33<1:48:19,  3.49s/iteration, mean_rewards=3.67] \u001b[A\n",
            "Training:   7%|▋         | 141/2000 [06:35<1:49:39,  3.54s/iteration, mean_rewards=3.67]\u001b[A\n",
            "Training:   7%|▋         | 141/2000 [06:36<1:49:39,  3.54s/iteration, mean_rewards=16.8]\u001b[A\n",
            "Training:   7%|▋         | 142/2000 [06:39<1:54:13,  3.69s/iteration, mean_rewards=16.8]\u001b[A\n",
            "Training:   7%|▋         | 142/2000 [06:40<1:54:13,  3.69s/iteration, mean_rewards=-2.09]\u001b[A\n",
            "Training:   7%|▋         | 143/2000 [06:42<1:54:47,  3.71s/iteration, mean_rewards=-2.09]\u001b[A\n",
            "Training:   7%|▋         | 143/2000 [06:44<1:54:47,  3.71s/iteration, mean_rewards=3.3]  \u001b[A\n",
            "Training:   7%|▋         | 144/2000 [06:46<1:52:34,  3.64s/iteration, mean_rewards=3.3]\u001b[A\n",
            "Training:   7%|▋         | 144/2000 [06:48<1:52:34,  3.64s/iteration, mean_rewards=-6.01]\u001b[A\n",
            "Training:   7%|▋         | 145/2000 [06:50<1:54:40,  3.71s/iteration, mean_rewards=-6.01]\u001b[A\n",
            "Training:   7%|▋         | 145/2000 [06:52<1:54:40,  3.71s/iteration, mean_rewards=-15.5]\u001b[A\n",
            "Training:   7%|▋         | 146/2000 [06:54<1:57:11,  3.79s/iteration, mean_rewards=-15.5]\u001b[A\n",
            "Training:   7%|▋         | 146/2000 [06:55<1:57:11,  3.79s/iteration, mean_rewards=16.5] \u001b[A\n",
            "Training:   7%|▋         | 147/2000 [06:57<1:55:28,  3.74s/iteration, mean_rewards=16.5]\u001b[A\n",
            "Training:   7%|▋         | 147/2000 [06:59<1:55:28,  3.74s/iteration, mean_rewards=18.9]\u001b[A\n",
            "Training:   7%|▋         | 148/2000 [07:01<1:54:05,  3.70s/iteration, mean_rewards=18.9]\u001b[A\n",
            "Training:   7%|▋         | 148/2000 [07:02<1:54:05,  3.70s/iteration, mean_rewards=-61.9]\u001b[A\n",
            "Training:   7%|▋         | 149/2000 [07:04<1:45:44,  3.43s/iteration, mean_rewards=-61.9]\u001b[A\n",
            "Training:   7%|▋         | 149/2000 [07:06<1:45:44,  3.43s/iteration, mean_rewards=23.2] \u001b[A\n",
            "Training:   8%|▊         | 150/2000 [07:08<1:50:53,  3.60s/iteration, mean_rewards=23.2]\u001b[A\n",
            "Training:   8%|▊         | 150/2000 [07:09<1:50:53,  3.60s/iteration, mean_rewards=32.2]\u001b[A\n",
            "Training:   8%|▊         | 151/2000 [07:11<1:51:53,  3.63s/iteration, mean_rewards=32.2]\u001b[A\n",
            "Training:   8%|▊         | 151/2000 [07:13<1:51:53,  3.63s/iteration, mean_rewards=19.7]\u001b[A\n",
            "Training:   8%|▊         | 152/2000 [07:15<1:51:56,  3.63s/iteration, mean_rewards=19.7]\u001b[A\n",
            "Training:   8%|▊         | 152/2000 [07:17<1:51:56,  3.63s/iteration, mean_rewards=31.8]\u001b[A\n",
            "Training:   8%|▊         | 153/2000 [07:19<1:57:49,  3.83s/iteration, mean_rewards=31.8]\u001b[A\n",
            "Training:   8%|▊         | 153/2000 [07:21<1:57:49,  3.83s/iteration, mean_rewards=37.4]\u001b[A\n",
            "Training:   8%|▊         | 154/2000 [07:23<1:55:51,  3.77s/iteration, mean_rewards=37.4]\u001b[A\n",
            "Training:   8%|▊         | 154/2000 [07:25<1:55:51,  3.77s/iteration, mean_rewards=15.7]\u001b[A\n",
            "Training:   8%|▊         | 155/2000 [07:27<1:54:00,  3.71s/iteration, mean_rewards=15.7]\u001b[A\n",
            "Training:   8%|▊         | 155/2000 [07:28<1:54:00,  3.71s/iteration, mean_rewards=13.2]\u001b[A\n",
            "Training:   8%|▊         | 156/2000 [07:31<1:59:38,  3.89s/iteration, mean_rewards=13.2]\u001b[A\n",
            "Training:   8%|▊         | 156/2000 [07:32<1:59:38,  3.89s/iteration, mean_rewards=36.1]\u001b[A\n",
            "Training:   8%|▊         | 157/2000 [07:34<1:56:26,  3.79s/iteration, mean_rewards=36.1]\u001b[A\n",
            "Training:   8%|▊         | 157/2000 [07:36<1:56:26,  3.79s/iteration, mean_rewards=12.9]\u001b[A\n",
            "Training:   8%|▊         | 158/2000 [07:38<1:55:33,  3.76s/iteration, mean_rewards=12.9]\u001b[A\n",
            "Training:   8%|▊         | 158/2000 [07:40<1:55:33,  3.76s/iteration, mean_rewards=19.3]\u001b[A\n",
            "Training:   8%|▊         | 159/2000 [07:42<1:56:50,  3.81s/iteration, mean_rewards=19.3]\u001b[A\n",
            "Training:   8%|▊         | 159/2000 [07:44<1:56:50,  3.81s/iteration, mean_rewards=-3.63]\u001b[A\n",
            "Training:   8%|▊         | 160/2000 [07:46<1:59:30,  3.90s/iteration, mean_rewards=-3.63]\u001b[A\n",
            "Training:   8%|▊         | 160/2000 [07:48<1:59:30,  3.90s/iteration, mean_rewards=25]   \u001b[A\n",
            "Training:   8%|▊         | 161/2000 [07:50<1:57:17,  3.83s/iteration, mean_rewards=25]\u001b[A\n",
            "Training:   8%|▊         | 161/2000 [07:51<1:57:17,  3.83s/iteration, mean_rewards=31.9]\u001b[A\n",
            "Training:   8%|▊         | 162/2000 [07:53<1:55:23,  3.77s/iteration, mean_rewards=31.9]\u001b[A\n",
            "Training:   8%|▊         | 162/2000 [07:56<1:55:23,  3.77s/iteration, mean_rewards=23.3]\u001b[A\n",
            "Training:   8%|▊         | 163/2000 [07:58<2:00:17,  3.93s/iteration, mean_rewards=23.3]\u001b[A\n",
            "Training:   8%|▊         | 163/2000 [07:59<2:00:17,  3.93s/iteration, mean_rewards=1.67]\u001b[A\n",
            "Training:   8%|▊         | 164/2000 [08:01<1:58:11,  3.86s/iteration, mean_rewards=1.67]\u001b[A\n",
            "Training:   8%|▊         | 164/2000 [08:03<1:58:11,  3.86s/iteration, mean_rewards=22.3]\u001b[A\n",
            "Training:   8%|▊         | 165/2000 [08:05<1:55:35,  3.78s/iteration, mean_rewards=22.3]\u001b[A\n",
            "Training:   8%|▊         | 165/2000 [08:07<1:55:35,  3.78s/iteration, mean_rewards=4.99]\u001b[A\n",
            "Training:   8%|▊         | 166/2000 [08:10<2:03:28,  4.04s/iteration, mean_rewards=4.99]\u001b[A\n",
            "Training:   8%|▊         | 166/2000 [08:11<2:03:28,  4.04s/iteration, mean_rewards=9.99]\u001b[A\n",
            "Training:   8%|▊         | 167/2000 [08:13<2:00:24,  3.94s/iteration, mean_rewards=9.99]\u001b[A\n",
            "Training:   8%|▊         | 167/2000 [08:15<2:00:24,  3.94s/iteration, mean_rewards=21.2]\u001b[A\n",
            "Training:   8%|▊         | 168/2000 [08:17<1:58:00,  3.86s/iteration, mean_rewards=21.2]\u001b[A\n",
            "Training:   8%|▊         | 168/2000 [08:19<1:58:00,  3.86s/iteration, mean_rewards=37.6]\u001b[A\n",
            "Training:   8%|▊         | 169/2000 [08:21<2:00:27,  3.95s/iteration, mean_rewards=37.6]\u001b[A\n",
            "Training:   8%|▊         | 169/2000 [08:23<2:00:27,  3.95s/iteration, mean_rewards=-48.2]\u001b[A\n",
            "Training:   8%|▊         | 170/2000 [08:24<1:53:26,  3.72s/iteration, mean_rewards=-48.2]\u001b[A\n",
            "Training:   8%|▊         | 170/2000 [08:26<1:53:26,  3.72s/iteration, mean_rewards=23.4] \u001b[A\n",
            "Training:   9%|▊         | 171/2000 [08:28<1:51:36,  3.66s/iteration, mean_rewards=23.4]\u001b[A\n",
            "Training:   9%|▊         | 171/2000 [08:30<1:51:36,  3.66s/iteration, mean_rewards=40.7]\u001b[A\n",
            "Training:   9%|▊         | 172/2000 [08:31<1:50:20,  3.62s/iteration, mean_rewards=40.7]\u001b[A\n",
            "Training:   9%|▊         | 172/2000 [08:34<1:50:20,  3.62s/iteration, mean_rewards=22.1]\u001b[A\n",
            "Training:   9%|▊         | 173/2000 [08:36<1:57:19,  3.85s/iteration, mean_rewards=22.1]\u001b[A\n",
            "Training:   9%|▊         | 173/2000 [08:38<1:57:19,  3.85s/iteration, mean_rewards=33.5]\u001b[A\n",
            "Training:   9%|▊         | 174/2000 [08:39<1:55:28,  3.79s/iteration, mean_rewards=33.5]\u001b[A\n",
            "Training:   9%|▊         | 174/2000 [08:41<1:55:28,  3.79s/iteration, mean_rewards=18.8]\u001b[A\n",
            "Training:   9%|▉         | 175/2000 [08:43<1:53:05,  3.72s/iteration, mean_rewards=18.8]\u001b[A\n",
            "Training:   9%|▉         | 175/2000 [08:45<1:53:05,  3.72s/iteration, mean_rewards=31.8]\u001b[A\n",
            "Training:   9%|▉         | 176/2000 [08:48<1:59:54,  3.94s/iteration, mean_rewards=31.8]\u001b[A\n",
            "Training:   9%|▉         | 176/2000 [08:49<1:59:54,  3.94s/iteration, mean_rewards=16.1]\u001b[A\n",
            "Training:   9%|▉         | 177/2000 [08:51<1:56:45,  3.84s/iteration, mean_rewards=16.1]\u001b[A\n",
            "Training:   9%|▉         | 177/2000 [08:53<1:56:45,  3.84s/iteration, mean_rewards=55]  \u001b[A\n",
            "Training:   9%|▉         | 178/2000 [08:55<1:54:29,  3.77s/iteration, mean_rewards=55]\u001b[A\n",
            "Training:   9%|▉         | 178/2000 [08:56<1:54:29,  3.77s/iteration, mean_rewards=20.7]\u001b[A\n",
            "Training:   9%|▉         | 179/2000 [08:59<1:57:01,  3.86s/iteration, mean_rewards=20.7]\u001b[A\n",
            "Training:   9%|▉         | 179/2000 [09:01<1:57:01,  3.86s/iteration, mean_rewards=33.8]\u001b[A\n",
            "Training:   9%|▉         | 180/2000 [09:03<1:59:01,  3.92s/iteration, mean_rewards=33.8]\u001b[A\n",
            "Training:   9%|▉         | 180/2000 [09:05<1:59:01,  3.92s/iteration, mean_rewards=17.4]\u001b[A\n",
            "Training:   9%|▉         | 181/2000 [09:06<1:56:25,  3.84s/iteration, mean_rewards=17.4]\u001b[A\n",
            "Training:   9%|▉         | 181/2000 [09:08<1:56:25,  3.84s/iteration, mean_rewards=16.9]\u001b[A\n",
            "Training:   9%|▉         | 182/2000 [09:10<1:55:32,  3.81s/iteration, mean_rewards=16.9]\u001b[A\n",
            "Training:   9%|▉         | 182/2000 [09:13<1:55:32,  3.81s/iteration, mean_rewards=44.8]\u001b[A\n",
            "Training:   9%|▉         | 183/2000 [09:15<2:00:37,  3.98s/iteration, mean_rewards=44.8]\u001b[A\n",
            "Training:   9%|▉         | 183/2000 [09:16<2:00:37,  3.98s/iteration, mean_rewards=18.9]\u001b[A\n",
            "Training:   9%|▉         | 184/2000 [09:18<1:57:53,  3.89s/iteration, mean_rewards=18.9]\u001b[A\n",
            "Training:   9%|▉         | 184/2000 [09:20<1:57:53,  3.89s/iteration, mean_rewards=16.4]\u001b[A\n",
            "Training:   9%|▉         | 185/2000 [09:22<1:54:49,  3.80s/iteration, mean_rewards=16.4]\u001b[A\n",
            "Training:   9%|▉         | 185/2000 [09:24<1:54:49,  3.80s/iteration, mean_rewards=26.2]\u001b[A\n",
            "Training:   9%|▉         | 186/2000 [09:27<2:02:19,  4.05s/iteration, mean_rewards=26.2]\u001b[A\n",
            "Training:   9%|▉         | 186/2000 [09:28<2:02:19,  4.05s/iteration, mean_rewards=8.61]\u001b[A\n",
            "Training:   9%|▉         | 187/2000 [09:30<1:58:26,  3.92s/iteration, mean_rewards=8.61]\u001b[A\n",
            "Training:   9%|▉         | 187/2000 [09:32<1:58:26,  3.92s/iteration, mean_rewards=19.6]\u001b[A\n",
            "Training:   9%|▉         | 188/2000 [09:34<1:55:23,  3.82s/iteration, mean_rewards=19.6]\u001b[A\n",
            "Training:   9%|▉         | 188/2000 [09:35<1:55:23,  3.82s/iteration, mean_rewards=44.5]\u001b[A\n",
            "Training:   9%|▉         | 189/2000 [09:38<1:57:07,  3.88s/iteration, mean_rewards=44.5]\u001b[A\n",
            "Training:   9%|▉         | 189/2000 [09:40<1:57:07,  3.88s/iteration, mean_rewards=37.4]\u001b[A\n",
            "Training:  10%|▉         | 190/2000 [09:42<1:59:56,  3.98s/iteration, mean_rewards=37.4]\u001b[A\n",
            "Training:  10%|▉         | 190/2000 [09:44<1:59:56,  3.98s/iteration, mean_rewards=39.1]\u001b[A\n",
            "Training:  10%|▉         | 191/2000 [09:46<1:57:04,  3.88s/iteration, mean_rewards=39.1]\u001b[A\n",
            "Training:  10%|▉         | 191/2000 [09:47<1:57:04,  3.88s/iteration, mean_rewards=30.6]\u001b[A\n",
            "Training:  10%|▉         | 192/2000 [09:49<1:55:24,  3.83s/iteration, mean_rewards=30.6]\u001b[A\n",
            "Training:  10%|▉         | 192/2000 [09:52<1:55:24,  3.83s/iteration, mean_rewards=30.2]\u001b[A\n",
            "Training:  10%|▉         | 193/2000 [09:54<2:01:18,  4.03s/iteration, mean_rewards=30.2]\u001b[A\n",
            "Training:  10%|▉         | 193/2000 [09:55<2:01:18,  4.03s/iteration, mean_rewards=30.5]\u001b[A\n",
            "Training:  10%|▉         | 194/2000 [09:57<1:57:04,  3.89s/iteration, mean_rewards=30.5]\u001b[A\n",
            "Training:  10%|▉         | 194/2000 [09:59<1:57:04,  3.89s/iteration, mean_rewards=1.83]\u001b[A\n",
            "Training:  10%|▉         | 195/2000 [10:01<1:55:16,  3.83s/iteration, mean_rewards=1.83]\u001b[A\n",
            "Training:  10%|▉         | 195/2000 [10:03<1:55:16,  3.83s/iteration, mean_rewards=22.1]\u001b[A\n",
            "Training:  10%|▉         | 196/2000 [10:06<2:02:53,  4.09s/iteration, mean_rewards=22.1]\u001b[A\n",
            "Training:  10%|▉         | 196/2000 [10:07<2:02:53,  4.09s/iteration, mean_rewards=27.2]\u001b[A\n",
            "Training:  10%|▉         | 197/2000 [10:09<1:58:48,  3.95s/iteration, mean_rewards=27.2]\u001b[A\n",
            "Training:  10%|▉         | 197/2000 [10:11<1:58:48,  3.95s/iteration, mean_rewards=54.7]\u001b[A\n",
            "Training:  10%|▉         | 198/2000 [10:13<1:56:02,  3.86s/iteration, mean_rewards=54.7]\u001b[A\n",
            "Training:  10%|▉         | 198/2000 [10:15<1:56:02,  3.86s/iteration, mean_rewards=59.9]\u001b[A\n",
            "Training:  10%|▉         | 199/2000 [10:17<1:58:06,  3.94s/iteration, mean_rewards=59.9]\u001b[A\n",
            "Training:  10%|▉         | 199/2000 [10:19<1:58:06,  3.94s/iteration, mean_rewards=41.1]\u001b[A\n",
            "Training:  10%|█         | 200/2000 [10:21<1:57:48,  3.93s/iteration, mean_rewards=41.1]\u001b[A\n",
            "Training:  10%|█         | 200/2000 [10:21<1:57:48,  3.93s/iteration, mean_rewards=-409]\u001b[A\n",
            "Training:  10%|█         | 201/2000 [10:22<1:28:14,  2.94s/iteration, mean_rewards=-409]\u001b[A\n",
            "Training:  10%|█         | 201/2000 [10:22<1:28:14,  2.94s/iteration, mean_rewards=-114]\u001b[A\n",
            "Training:  10%|█         | 202/2000 [10:23<1:09:06,  2.31s/iteration, mean_rewards=-114]\u001b[A\n",
            "Training:  10%|█         | 202/2000 [10:23<1:09:06,  2.31s/iteration, mean_rewards=-232]\u001b[A\n",
            "Training:  10%|█         | 203/2000 [10:23<55:22,  1.85s/iteration, mean_rewards=-232]  \u001b[A\n",
            "Training:  10%|█         | 203/2000 [10:24<55:22,  1.85s/iteration, mean_rewards=-134]\u001b[A\n",
            "Training:  10%|█         | 204/2000 [10:24<48:38,  1.63s/iteration, mean_rewards=-134]\u001b[A\n",
            "Training:  10%|█         | 204/2000 [10:25<48:38,  1.63s/iteration, mean_rewards=-101]\u001b[A\n",
            "Training:  10%|█         | 205/2000 [10:26<43:54,  1.47s/iteration, mean_rewards=-101]\u001b[A\n",
            "Training:  10%|█         | 205/2000 [10:26<43:54,  1.47s/iteration, mean_rewards=-113]\u001b[A\n",
            "Training:  10%|█         | 206/2000 [10:26<36:49,  1.23s/iteration, mean_rewards=-113]\u001b[A\n",
            "Training:  10%|█         | 206/2000 [10:27<36:49,  1.23s/iteration, mean_rewards=-102]\u001b[A\n",
            "Training:  10%|█         | 207/2000 [10:27<34:13,  1.15s/iteration, mean_rewards=-102]\u001b[A\n",
            "Training:  10%|█         | 207/2000 [10:28<34:13,  1.15s/iteration, mean_rewards=-152]\u001b[A\n",
            "Training:  10%|█         | 208/2000 [10:28<35:11,  1.18s/iteration, mean_rewards=-152]\u001b[A\n",
            "Training:  10%|█         | 208/2000 [10:29<35:11,  1.18s/iteration, mean_rewards=-154]\u001b[A\n",
            "Training:  10%|█         | 209/2000 [10:30<37:29,  1.26s/iteration, mean_rewards=-154]\u001b[A\n",
            "Training:  10%|█         | 209/2000 [10:30<37:29,  1.26s/iteration, mean_rewards=-267]\u001b[A\n",
            "Training:  10%|█         | 210/2000 [10:31<38:45,  1.30s/iteration, mean_rewards=-267]\u001b[A\n",
            "Training:  10%|█         | 210/2000 [10:32<38:45,  1.30s/iteration, mean_rewards=-231]\u001b[A\n",
            "Training:  11%|█         | 211/2000 [10:32<35:03,  1.18s/iteration, mean_rewards=-231]\u001b[A\n",
            "Training:  11%|█         | 211/2000 [10:33<35:03,  1.18s/iteration, mean_rewards=-272]\u001b[A\n",
            "Training:  11%|█         | 212/2000 [10:33<34:04,  1.14s/iteration, mean_rewards=-272]\u001b[A\n",
            "Training:  11%|█         | 212/2000 [10:34<34:04,  1.14s/iteration, mean_rewards=-362]\u001b[A\n",
            "Training:  11%|█         | 213/2000 [10:34<32:04,  1.08s/iteration, mean_rewards=-362]\u001b[A\n",
            "Training:  11%|█         | 213/2000 [10:34<32:04,  1.08s/iteration, mean_rewards=-194]\u001b[A\n",
            "Training:  11%|█         | 214/2000 [10:35<29:29,  1.01iteration/s, mean_rewards=-194]\u001b[A\n",
            "Training:  11%|█         | 214/2000 [10:35<29:29,  1.01iteration/s, mean_rewards=-401]\u001b[A\n",
            "Training:  11%|█         | 215/2000 [10:36<27:39,  1.08iteration/s, mean_rewards=-401]\u001b[A\n",
            "Training:  11%|█         | 215/2000 [10:36<27:39,  1.08iteration/s, mean_rewards=-214]\u001b[A\n",
            "Training:  11%|█         | 216/2000 [10:36<26:08,  1.14iteration/s, mean_rewards=-214]\u001b[A\n",
            "Training:  11%|█         | 216/2000 [10:37<26:08,  1.14iteration/s, mean_rewards=-90.4]\u001b[A\n",
            "Training:  11%|█         | 217/2000 [10:38<27:47,  1.07iteration/s, mean_rewards=-90.4]\u001b[A\n",
            "Training:  11%|█         | 217/2000 [10:38<27:47,  1.07iteration/s, mean_rewards=-154] \u001b[A\n",
            "Training:  11%|█         | 218/2000 [10:38<27:54,  1.06iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  11%|█         | 218/2000 [10:39<27:54,  1.06iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  11%|█         | 219/2000 [10:39<26:44,  1.11iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  11%|█         | 219/2000 [10:40<26:44,  1.11iteration/s, mean_rewards=-371]\u001b[A\n",
            "Training:  11%|█         | 220/2000 [10:40<27:55,  1.06iteration/s, mean_rewards=-371]\u001b[A\n",
            "Training:  11%|█         | 220/2000 [10:41<27:55,  1.06iteration/s, mean_rewards=-306]\u001b[A\n",
            "Training:  11%|█         | 221/2000 [10:41<29:24,  1.01iteration/s, mean_rewards=-306]\u001b[A\n",
            "Training:  11%|█         | 221/2000 [10:42<29:24,  1.01iteration/s, mean_rewards=-202]\u001b[A\n",
            "Training:  11%|█         | 222/2000 [10:42<30:09,  1.02s/iteration, mean_rewards=-202]\u001b[A\n",
            "Training:  11%|█         | 222/2000 [10:43<30:09,  1.02s/iteration, mean_rewards=-247]\u001b[A\n",
            "Training:  11%|█         | 223/2000 [10:44<33:01,  1.12s/iteration, mean_rewards=-247]\u001b[A\n",
            "Training:  11%|█         | 223/2000 [10:44<33:01,  1.12s/iteration, mean_rewards=-152]\u001b[A\n",
            "Training:  11%|█         | 224/2000 [10:45<32:36,  1.10s/iteration, mean_rewards=-152]\u001b[A\n",
            "Training:  11%|█         | 224/2000 [10:45<32:36,  1.10s/iteration, mean_rewards=-151]\u001b[A\n",
            "Training:  11%|█▏        | 225/2000 [10:46<30:14,  1.02s/iteration, mean_rewards=-151]\u001b[A\n",
            "Training:  11%|█▏        | 225/2000 [10:46<30:14,  1.02s/iteration, mean_rewards=-110]\u001b[A\n",
            "Training:  11%|█▏        | 226/2000 [10:47<29:18,  1.01iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  11%|█▏        | 226/2000 [10:47<29:18,  1.01iteration/s, mean_rewards=-335]\u001b[A\n",
            "Training:  11%|█▏        | 227/2000 [10:48<29:49,  1.01s/iteration, mean_rewards=-335]\u001b[A\n",
            "Training:  11%|█▏        | 227/2000 [10:48<29:49,  1.01s/iteration, mean_rewards=-122]\u001b[A\n",
            "Training:  11%|█▏        | 228/2000 [10:48<27:37,  1.07iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  11%|█▏        | 228/2000 [10:49<27:37,  1.07iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:  11%|█▏        | 229/2000 [10:49<26:18,  1.12iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:  11%|█▏        | 229/2000 [10:50<26:18,  1.12iteration/s, mean_rewards=-81.4]\u001b[A\n",
            "Training:  12%|█▏        | 230/2000 [10:50<25:25,  1.16iteration/s, mean_rewards=-81.4]\u001b[A\n",
            "Training:  12%|█▏        | 230/2000 [10:50<25:25,  1.16iteration/s, mean_rewards=-332] \u001b[A\n",
            "Training:  12%|█▏        | 231/2000 [10:51<26:08,  1.13iteration/s, mean_rewards=-332]\u001b[A\n",
            "Training:  12%|█▏        | 231/2000 [10:51<26:08,  1.13iteration/s, mean_rewards=-305]\u001b[A\n",
            "Training:  12%|█▏        | 232/2000 [10:52<28:11,  1.05iteration/s, mean_rewards=-305]\u001b[A\n",
            "Training:  12%|█▏        | 232/2000 [10:53<28:11,  1.05iteration/s, mean_rewards=-88.5]\u001b[A\n",
            "Training:  12%|█▏        | 233/2000 [10:53<28:01,  1.05iteration/s, mean_rewards=-88.5]\u001b[A\n",
            "Training:  12%|█▏        | 233/2000 [10:53<28:01,  1.05iteration/s, mean_rewards=-131] \u001b[A\n",
            "Training:  12%|█▏        | 234/2000 [10:54<28:11,  1.04iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  12%|█▏        | 234/2000 [10:54<28:11,  1.04iteration/s, mean_rewards=-266]\u001b[A\n",
            "Training:  12%|█▏        | 235/2000 [10:55<29:09,  1.01iteration/s, mean_rewards=-266]\u001b[A\n",
            "Training:  12%|█▏        | 235/2000 [10:56<29:09,  1.01iteration/s, mean_rewards=-345]\u001b[A\n",
            "Training:  12%|█▏        | 236/2000 [10:56<32:29,  1.10s/iteration, mean_rewards=-345]\u001b[A\n",
            "Training:  12%|█▏        | 236/2000 [10:57<32:29,  1.10s/iteration, mean_rewards=-216]\u001b[A\n",
            "Training:  12%|█▏        | 237/2000 [10:57<30:54,  1.05s/iteration, mean_rewards=-216]\u001b[A\n",
            "Training:  12%|█▏        | 237/2000 [10:58<30:54,  1.05s/iteration, mean_rewards=-225]\u001b[A\n",
            "Training:  12%|█▏        | 238/2000 [10:58<28:27,  1.03iteration/s, mean_rewards=-225]\u001b[A\n",
            "Training:  12%|█▏        | 238/2000 [10:58<28:27,  1.03iteration/s, mean_rewards=-96] \u001b[A\n",
            "Training:  12%|█▏        | 239/2000 [10:59<26:32,  1.11iteration/s, mean_rewards=-96]\u001b[A\n",
            "Training:  12%|█▏        | 239/2000 [10:59<26:32,  1.11iteration/s, mean_rewards=-90.6]\u001b[A\n",
            "Training:  12%|█▏        | 240/2000 [11:00<26:36,  1.10iteration/s, mean_rewards=-90.6]\u001b[A\n",
            "Training:  12%|█▏        | 240/2000 [11:00<26:36,  1.10iteration/s, mean_rewards=-228] \u001b[A\n",
            "Training:  12%|█▏        | 241/2000 [11:01<25:43,  1.14iteration/s, mean_rewards=-228]\u001b[A\n",
            "Training:  12%|█▏        | 241/2000 [11:01<25:43,  1.14iteration/s, mean_rewards=-160]\u001b[A\n",
            "Training:  12%|█▏        | 242/2000 [11:01<25:11,  1.16iteration/s, mean_rewards=-160]\u001b[A\n",
            "Training:  12%|█▏        | 242/2000 [11:02<25:11,  1.16iteration/s, mean_rewards=-109]\u001b[A\n",
            "Training:  12%|█▏        | 243/2000 [11:02<24:40,  1.19iteration/s, mean_rewards=-109]\u001b[A\n",
            "Training:  12%|█▏        | 243/2000 [11:03<24:40,  1.19iteration/s, mean_rewards=-152]\u001b[A\n",
            "Training:  12%|█▏        | 244/2000 [11:03<26:47,  1.09iteration/s, mean_rewards=-152]\u001b[A\n",
            "Training:  12%|█▏        | 244/2000 [11:04<26:47,  1.09iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  12%|█▏        | 245/2000 [11:04<25:59,  1.13iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  12%|█▏        | 245/2000 [11:05<25:59,  1.13iteration/s, mean_rewards=-385]\u001b[A\n",
            "Training:  12%|█▏        | 246/2000 [11:05<28:30,  1.03iteration/s, mean_rewards=-385]\u001b[A\n",
            "Training:  12%|█▏        | 246/2000 [11:06<28:30,  1.03iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  12%|█▏        | 247/2000 [11:06<28:17,  1.03iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  12%|█▏        | 247/2000 [11:07<28:17,  1.03iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  12%|█▏        | 248/2000 [11:08<30:57,  1.06s/iteration, mean_rewards=-131]\u001b[A\n",
            "Training:  12%|█▏        | 248/2000 [11:08<30:57,  1.06s/iteration, mean_rewards=-205]\u001b[A\n",
            "Training:  12%|█▏        | 249/2000 [11:09<31:23,  1.08s/iteration, mean_rewards=-205]\u001b[A\n",
            "Training:  12%|█▏        | 249/2000 [11:09<31:23,  1.08s/iteration, mean_rewards=-271]\u001b[A\n",
            "Training:  12%|█▎        | 250/2000 [11:10<30:19,  1.04s/iteration, mean_rewards=-271]\u001b[A\n",
            "Training:  12%|█▎        | 250/2000 [11:10<30:19,  1.04s/iteration, mean_rewards=-208]\u001b[A\n",
            "Training:  13%|█▎        | 251/2000 [11:10<28:28,  1.02iteration/s, mean_rewards=-208]\u001b[A\n",
            "Training:  13%|█▎        | 251/2000 [11:11<28:28,  1.02iteration/s, mean_rewards=-230]\u001b[A\n",
            "Training:  13%|█▎        | 252/2000 [11:12<29:22,  1.01s/iteration, mean_rewards=-230]\u001b[A\n",
            "Training:  13%|█▎        | 252/2000 [11:12<29:22,  1.01s/iteration, mean_rewards=-256]\u001b[A\n",
            "Training:  13%|█▎        | 253/2000 [11:12<28:39,  1.02iteration/s, mean_rewards=-256]\u001b[A\n",
            "Training:  13%|█▎        | 253/2000 [11:13<28:39,  1.02iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  13%|█▎        | 254/2000 [11:13<25:57,  1.12iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  13%|█▎        | 254/2000 [11:14<25:57,  1.12iteration/s, mean_rewards=-88.3]\u001b[A\n",
            "Training:  13%|█▎        | 255/2000 [11:14<25:09,  1.16iteration/s, mean_rewards=-88.3]\u001b[A\n",
            "Training:  13%|█▎        | 255/2000 [11:14<25:09,  1.16iteration/s, mean_rewards=-366] \u001b[A\n",
            "Training:  13%|█▎        | 256/2000 [11:15<25:44,  1.13iteration/s, mean_rewards=-366]\u001b[A\n",
            "Training:  13%|█▎        | 256/2000 [11:15<25:44,  1.13iteration/s, mean_rewards=-209]\u001b[A\n",
            "Training:  13%|█▎        | 257/2000 [11:16<25:04,  1.16iteration/s, mean_rewards=-209]\u001b[A\n",
            "Training:  13%|█▎        | 257/2000 [11:16<25:04,  1.16iteration/s, mean_rewards=-203]\u001b[A\n",
            "Training:  13%|█▎        | 258/2000 [11:16<23:43,  1.22iteration/s, mean_rewards=-203]\u001b[A\n",
            "Training:  13%|█▎        | 258/2000 [11:17<23:43,  1.22iteration/s, mean_rewards=-309]\u001b[A\n",
            "Training:  13%|█▎        | 259/2000 [11:17<24:34,  1.18iteration/s, mean_rewards=-309]\u001b[A\n",
            "Training:  13%|█▎        | 259/2000 [11:18<24:34,  1.18iteration/s, mean_rewards=-243]\u001b[A\n",
            "Training:  13%|█▎        | 260/2000 [11:18<24:32,  1.18iteration/s, mean_rewards=-243]\u001b[A\n",
            "Training:  13%|█▎        | 260/2000 [11:19<24:32,  1.18iteration/s, mean_rewards=-237]\u001b[A\n",
            "Training:  13%|█▎        | 261/2000 [11:19<25:02,  1.16iteration/s, mean_rewards=-237]\u001b[A\n",
            "Training:  13%|█▎        | 261/2000 [11:19<25:02,  1.16iteration/s, mean_rewards=-212]\u001b[A\n",
            "Training:  13%|█▎        | 262/2000 [11:20<26:25,  1.10iteration/s, mean_rewards=-212]\u001b[A\n",
            "Training:  13%|█▎        | 262/2000 [11:21<26:25,  1.10iteration/s, mean_rewards=-256]\u001b[A\n",
            "Training:  13%|█▎        | 263/2000 [11:21<28:05,  1.03iteration/s, mean_rewards=-256]\u001b[A\n",
            "Training:  13%|█▎        | 263/2000 [11:22<28:05,  1.03iteration/s, mean_rewards=-258]\u001b[A\n",
            "Training:  13%|█▎        | 264/2000 [11:23<31:06,  1.08s/iteration, mean_rewards=-258]\u001b[A\n",
            "Training:  13%|█▎        | 264/2000 [11:23<31:06,  1.08s/iteration, mean_rewards=-215]\u001b[A\n",
            "Training:  13%|█▎        | 265/2000 [11:24<32:06,  1.11s/iteration, mean_rewards=-215]\u001b[A\n",
            "Training:  13%|█▎        | 265/2000 [11:24<32:06,  1.11s/iteration, mean_rewards=-181]\u001b[A\n",
            "Training:  13%|█▎        | 266/2000 [11:25<29:25,  1.02s/iteration, mean_rewards=-181]\u001b[A\n",
            "Training:  13%|█▎        | 266/2000 [11:25<29:25,  1.02s/iteration, mean_rewards=-97.8]\u001b[A\n",
            "Training:  13%|█▎        | 267/2000 [11:25<27:25,  1.05iteration/s, mean_rewards=-97.8]\u001b[A\n",
            "Training:  13%|█▎        | 267/2000 [11:26<27:25,  1.05iteration/s, mean_rewards=-107] \u001b[A\n",
            "Training:  13%|█▎        | 268/2000 [11:26<25:09,  1.15iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  13%|█▎        | 268/2000 [11:26<25:09,  1.15iteration/s, mean_rewards=-204]\u001b[A\n",
            "Training:  13%|█▎        | 269/2000 [11:27<23:39,  1.22iteration/s, mean_rewards=-204]\u001b[A\n",
            "Training:  13%|█▎        | 269/2000 [11:27<23:39,  1.22iteration/s, mean_rewards=-293]\u001b[A\n",
            "Training:  14%|█▎        | 270/2000 [11:28<23:30,  1.23iteration/s, mean_rewards=-293]\u001b[A\n",
            "Training:  14%|█▎        | 270/2000 [11:28<23:30,  1.23iteration/s, mean_rewards=-271]\u001b[A\n",
            "Training:  14%|█▎        | 271/2000 [11:28<23:27,  1.23iteration/s, mean_rewards=-271]\u001b[A\n",
            "Training:  14%|█▎        | 271/2000 [11:29<23:27,  1.23iteration/s, mean_rewards=-163]\u001b[A\n",
            "Training:  14%|█▎        | 272/2000 [11:29<22:25,  1.28iteration/s, mean_rewards=-163]\u001b[A\n",
            "Training:  14%|█▎        | 272/2000 [11:29<22:25,  1.28iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  14%|█▎        | 273/2000 [11:30<23:46,  1.21iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  14%|█▎        | 273/2000 [11:30<23:46,  1.21iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  14%|█▎        | 274/2000 [11:31<23:26,  1.23iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  14%|█▎        | 274/2000 [11:31<23:26,  1.23iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  14%|█▍        | 275/2000 [11:32<23:15,  1.24iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  14%|█▍        | 275/2000 [11:32<23:15,  1.24iteration/s, mean_rewards=-103]\u001b[A\n",
            "Training:  14%|█▍        | 276/2000 [11:32<22:37,  1.27iteration/s, mean_rewards=-103]\u001b[A\n",
            "Training:  14%|█▍        | 276/2000 [11:33<22:37,  1.27iteration/s, mean_rewards=-254]\u001b[A\n",
            "Training:  14%|█▍        | 277/2000 [11:33<25:08,  1.14iteration/s, mean_rewards=-254]\u001b[A\n",
            "Training:  14%|█▍        | 277/2000 [11:34<25:08,  1.14iteration/s, mean_rewards=-242]\u001b[A\n",
            "Training:  14%|█▍        | 278/2000 [11:35<27:21,  1.05iteration/s, mean_rewards=-242]\u001b[A\n",
            "Training:  14%|█▍        | 278/2000 [11:35<27:21,  1.05iteration/s, mean_rewards=-422]\u001b[A\n",
            "Training:  14%|█▍        | 279/2000 [11:36<27:57,  1.03iteration/s, mean_rewards=-422]\u001b[A\n",
            "Training:  14%|█▍        | 279/2000 [11:36<27:57,  1.03iteration/s, mean_rewards=-220]\u001b[A\n",
            "Training:  14%|█▍        | 280/2000 [11:36<27:21,  1.05iteration/s, mean_rewards=-220]\u001b[A\n",
            "Training:  14%|█▍        | 280/2000 [11:37<27:21,  1.05iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  14%|█▍        | 281/2000 [11:37<27:17,  1.05iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  14%|█▍        | 281/2000 [11:38<27:17,  1.05iteration/s, mean_rewards=-212]\u001b[A\n",
            "Training:  14%|█▍        | 282/2000 [11:38<24:54,  1.15iteration/s, mean_rewards=-212]\u001b[A\n",
            "Training:  14%|█▍        | 282/2000 [11:38<24:54,  1.15iteration/s, mean_rewards=-199]\u001b[A\n",
            "Training:  14%|█▍        | 283/2000 [11:39<25:12,  1.13iteration/s, mean_rewards=-199]\u001b[A\n",
            "Training:  14%|█▍        | 283/2000 [11:39<25:12,  1.13iteration/s, mean_rewards=-266]\u001b[A\n",
            "Training:  14%|█▍        | 284/2000 [11:40<26:01,  1.10iteration/s, mean_rewards=-266]\u001b[A\n",
            "Training:  14%|█▍        | 284/2000 [11:40<26:01,  1.10iteration/s, mean_rewards=-254]\u001b[A\n",
            "Training:  14%|█▍        | 285/2000 [11:41<25:10,  1.14iteration/s, mean_rewards=-254]\u001b[A\n",
            "Training:  14%|█▍        | 285/2000 [11:41<25:10,  1.14iteration/s, mean_rewards=-219]\u001b[A\n",
            "Training:  14%|█▍        | 286/2000 [11:42<24:50,  1.15iteration/s, mean_rewards=-219]\u001b[A\n",
            "Training:  14%|█▍        | 286/2000 [11:42<24:50,  1.15iteration/s, mean_rewards=-105]\u001b[A\n",
            "Training:  14%|█▍        | 287/2000 [11:42<23:32,  1.21iteration/s, mean_rewards=-105]\u001b[A\n",
            "Training:  14%|█▍        | 287/2000 [11:43<23:32,  1.21iteration/s, mean_rewards=-213]\u001b[A\n",
            "Training:  14%|█▍        | 288/2000 [11:43<23:14,  1.23iteration/s, mean_rewards=-213]\u001b[A\n",
            "Training:  14%|█▍        | 288/2000 [11:44<23:14,  1.23iteration/s, mean_rewards=-384]\u001b[A\n",
            "Training:  14%|█▍        | 289/2000 [11:44<26:12,  1.09iteration/s, mean_rewards=-384]\u001b[A\n",
            "Training:  14%|█▍        | 289/2000 [11:45<26:12,  1.09iteration/s, mean_rewards=-159]\u001b[A\n",
            "Training:  14%|█▍        | 290/2000 [11:46<30:14,  1.06s/iteration, mean_rewards=-159]\u001b[A\n",
            "Training:  14%|█▍        | 290/2000 [11:46<30:14,  1.06s/iteration, mean_rewards=-110]\u001b[A\n",
            "Training:  15%|█▍        | 291/2000 [11:47<31:07,  1.09s/iteration, mean_rewards=-110]\u001b[A\n",
            "Training:  15%|█▍        | 291/2000 [11:47<31:07,  1.09s/iteration, mean_rewards=-134]\u001b[A\n",
            "Training:  15%|█▍        | 292/2000 [11:48<32:06,  1.13s/iteration, mean_rewards=-134]\u001b[A\n",
            "Training:  15%|█▍        | 292/2000 [11:49<32:06,  1.13s/iteration, mean_rewards=-413]\u001b[A\n",
            "Training:  15%|█▍        | 293/2000 [11:49<32:29,  1.14s/iteration, mean_rewards=-413]\u001b[A\n",
            "Training:  15%|█▍        | 293/2000 [11:50<32:29,  1.14s/iteration, mean_rewards=-160]\u001b[A\n",
            "Training:  15%|█▍        | 294/2000 [11:50<30:44,  1.08s/iteration, mean_rewards=-160]\u001b[A\n",
            "Training:  15%|█▍        | 294/2000 [11:50<30:44,  1.08s/iteration, mean_rewards=-186]\u001b[A\n",
            "Training:  15%|█▍        | 295/2000 [11:51<28:15,  1.01iteration/s, mean_rewards=-186]\u001b[A\n",
            "Training:  15%|█▍        | 295/2000 [11:51<28:15,  1.01iteration/s, mean_rewards=-74.5]\u001b[A\n",
            "Training:  15%|█▍        | 296/2000 [11:52<29:10,  1.03s/iteration, mean_rewards=-74.5]\u001b[A\n",
            "Training:  15%|█▍        | 296/2000 [11:52<29:10,  1.03s/iteration, mean_rewards=-109] \u001b[A\n",
            "Training:  15%|█▍        | 297/2000 [11:53<28:50,  1.02s/iteration, mean_rewards=-109]\u001b[A\n",
            "Training:  15%|█▍        | 297/2000 [11:53<28:50,  1.02s/iteration, mean_rewards=-276]\u001b[A\n",
            "Training:  15%|█▍        | 298/2000 [11:54<28:59,  1.02s/iteration, mean_rewards=-276]\u001b[A\n",
            "Training:  15%|█▍        | 298/2000 [11:54<28:59,  1.02s/iteration, mean_rewards=-336]\u001b[A\n",
            "Training:  15%|█▍        | 299/2000 [11:55<27:16,  1.04iteration/s, mean_rewards=-336]\u001b[A\n",
            "Training:  15%|█▍        | 299/2000 [11:55<27:16,  1.04iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:  15%|█▌        | 300/2000 [11:56<28:22,  1.00s/iteration, mean_rewards=-161]\u001b[A\n",
            "Training:  15%|█▌        | 300/2000 [11:56<28:22,  1.00s/iteration, mean_rewards=-357]\u001b[A\n",
            "Training:  15%|█▌        | 301/2000 [11:57<30:55,  1.09s/iteration, mean_rewards=-357]\u001b[A\n",
            "Training:  15%|█▌        | 301/2000 [11:58<30:55,  1.09s/iteration, mean_rewards=-145]\u001b[A\n",
            "Training:  15%|█▌        | 302/2000 [11:59<33:27,  1.18s/iteration, mean_rewards=-145]\u001b[A\n",
            "Training:  15%|█▌        | 302/2000 [11:59<33:27,  1.18s/iteration, mean_rewards=-76.7]\u001b[A\n",
            "Training:  15%|█▌        | 303/2000 [12:00<31:33,  1.12s/iteration, mean_rewards=-76.7]\u001b[A\n",
            "Training:  15%|█▌        | 303/2000 [12:00<31:33,  1.12s/iteration, mean_rewards=-192] \u001b[A\n",
            "Training:  15%|█▌        | 304/2000 [12:00<27:45,  1.02iteration/s, mean_rewards=-192]\u001b[A\n",
            "Training:  15%|█▌        | 304/2000 [12:01<27:45,  1.02iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  15%|█▌        | 305/2000 [12:01<25:21,  1.11iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  15%|█▌        | 305/2000 [12:01<25:21,  1.11iteration/s, mean_rewards=-373]\u001b[A\n",
            "Training:  15%|█▌        | 306/2000 [12:02<26:51,  1.05iteration/s, mean_rewards=-373]\u001b[A\n",
            "Training:  15%|█▌        | 306/2000 [12:02<26:51,  1.05iteration/s, mean_rewards=-79.9]\u001b[A\n",
            "Training:  15%|█▌        | 307/2000 [12:03<25:43,  1.10iteration/s, mean_rewards=-79.9]\u001b[A\n",
            "Training:  15%|█▌        | 307/2000 [12:03<25:43,  1.10iteration/s, mean_rewards=-259] \u001b[A\n",
            "Training:  15%|█▌        | 308/2000 [12:04<25:07,  1.12iteration/s, mean_rewards=-259]\u001b[A\n",
            "Training:  15%|█▌        | 308/2000 [12:04<25:07,  1.12iteration/s, mean_rewards=-222]\u001b[A\n",
            "Training:  15%|█▌        | 309/2000 [12:05<25:38,  1.10iteration/s, mean_rewards=-222]\u001b[A\n",
            "Training:  15%|█▌        | 309/2000 [12:05<25:38,  1.10iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  16%|█▌        | 310/2000 [12:05<24:31,  1.15iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  16%|█▌        | 310/2000 [12:06<24:31,  1.15iteration/s, mean_rewards=-170]\u001b[A\n",
            "Training:  16%|█▌        | 311/2000 [12:06<23:45,  1.18iteration/s, mean_rewards=-170]\u001b[A\n",
            "Training:  16%|█▌        | 311/2000 [12:07<23:45,  1.18iteration/s, mean_rewards=-92.6]\u001b[A\n",
            "Training:  16%|█▌        | 312/2000 [12:07<26:23,  1.07iteration/s, mean_rewards=-92.6]\u001b[A\n",
            "Training:  16%|█▌        | 312/2000 [12:08<26:23,  1.07iteration/s, mean_rewards=-335] \u001b[A\n",
            "Training:  16%|█▌        | 313/2000 [12:08<26:35,  1.06iteration/s, mean_rewards=-335]\u001b[A\n",
            "Training:  16%|█▌        | 313/2000 [12:09<26:35,  1.06iteration/s, mean_rewards=-201]\u001b[A\n",
            "Training:  16%|█▌        | 314/2000 [12:09<26:15,  1.07iteration/s, mean_rewards=-201]\u001b[A\n",
            "Training:  16%|█▌        | 314/2000 [12:10<26:15,  1.07iteration/s, mean_rewards=-79.9]\u001b[A\n",
            "Training:  16%|█▌        | 315/2000 [12:10<26:36,  1.06iteration/s, mean_rewards=-79.9]\u001b[A\n",
            "Training:  16%|█▌        | 315/2000 [12:11<26:36,  1.06iteration/s, mean_rewards=-115] \u001b[A\n",
            "Training:  16%|█▌        | 316/2000 [12:11<27:36,  1.02iteration/s, mean_rewards=-115]\u001b[A\n",
            "Training:  16%|█▌        | 316/2000 [12:12<27:36,  1.02iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  16%|█▌        | 317/2000 [12:12<27:19,  1.03iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  16%|█▌        | 317/2000 [12:13<27:19,  1.03iteration/s, mean_rewards=-170]\u001b[A\n",
            "Training:  16%|█▌        | 318/2000 [12:13<25:47,  1.09iteration/s, mean_rewards=-170]\u001b[A\n",
            "Training:  16%|█▌        | 318/2000 [12:13<25:47,  1.09iteration/s, mean_rewards=28.1]\u001b[A\n",
            "Training:  16%|█▌        | 319/2000 [12:14<24:33,  1.14iteration/s, mean_rewards=28.1]\u001b[A\n",
            "Training:  16%|█▌        | 319/2000 [12:14<24:33,  1.14iteration/s, mean_rewards=-152]\u001b[A\n",
            "Training:  16%|█▌        | 320/2000 [12:15<24:54,  1.12iteration/s, mean_rewards=-152]\u001b[A\n",
            "Training:  16%|█▌        | 320/2000 [12:15<24:54,  1.12iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:  16%|█▌        | 321/2000 [12:16<25:32,  1.10iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:  16%|█▌        | 321/2000 [12:16<25:32,  1.10iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  16%|█▌        | 322/2000 [12:17<25:58,  1.08iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  16%|█▌        | 322/2000 [12:17<25:58,  1.08iteration/s, mean_rewards=-164]\u001b[A\n",
            "Training:  16%|█▌        | 323/2000 [12:17<24:01,  1.16iteration/s, mean_rewards=-164]\u001b[A\n",
            "Training:  16%|█▌        | 323/2000 [12:18<24:01,  1.16iteration/s, mean_rewards=-255]\u001b[A\n",
            "Training:  16%|█▌        | 324/2000 [12:18<24:52,  1.12iteration/s, mean_rewards=-255]\u001b[A\n",
            "Training:  16%|█▌        | 324/2000 [12:19<24:52,  1.12iteration/s, mean_rewards=-251]\u001b[A\n",
            "Training:  16%|█▋        | 325/2000 [12:19<24:20,  1.15iteration/s, mean_rewards=-251]\u001b[A\n",
            "Training:  16%|█▋        | 325/2000 [12:20<24:20,  1.15iteration/s, mean_rewards=-103]\u001b[A\n",
            "Training:  16%|█▋        | 326/2000 [12:20<24:51,  1.12iteration/s, mean_rewards=-103]\u001b[A\n",
            "Training:  16%|█▋        | 326/2000 [12:21<24:51,  1.12iteration/s, mean_rewards=-345]\u001b[A\n",
            "Training:  16%|█▋        | 327/2000 [12:21<25:59,  1.07iteration/s, mean_rewards=-345]\u001b[A\n",
            "Training:  16%|█▋        | 327/2000 [12:22<25:59,  1.07iteration/s, mean_rewards=-32] \u001b[A\n",
            "Training:  16%|█▋        | 328/2000 [12:22<27:26,  1.02iteration/s, mean_rewards=-32]\u001b[A\n",
            "Training:  16%|█▋        | 328/2000 [12:23<27:26,  1.02iteration/s, mean_rewards=-214]\u001b[A\n",
            "Training:  16%|█▋        | 329/2000 [12:23<27:44,  1.00iteration/s, mean_rewards=-214]\u001b[A\n",
            "Training:  16%|█▋        | 329/2000 [12:24<27:44,  1.00iteration/s, mean_rewards=-238]\u001b[A\n",
            "Training:  16%|█▋        | 330/2000 [12:25<29:32,  1.06s/iteration, mean_rewards=-238]\u001b[A\n",
            "Training:  16%|█▋        | 330/2000 [12:25<29:32,  1.06s/iteration, mean_rewards=-122]\u001b[A\n",
            "Training:  17%|█▋        | 331/2000 [12:26<30:01,  1.08s/iteration, mean_rewards=-122]\u001b[A\n",
            "Training:  17%|█▋        | 331/2000 [12:26<30:01,  1.08s/iteration, mean_rewards=-264]\u001b[A\n",
            "Training:  17%|█▋        | 332/2000 [12:27<29:46,  1.07s/iteration, mean_rewards=-264]\u001b[A\n",
            "Training:  17%|█▋        | 332/2000 [12:27<29:46,  1.07s/iteration, mean_rewards=-93.8]\u001b[A\n",
            "Training:  17%|█▋        | 333/2000 [12:28<28:49,  1.04s/iteration, mean_rewards=-93.8]\u001b[A\n",
            "Training:  17%|█▋        | 333/2000 [12:28<28:49,  1.04s/iteration, mean_rewards=-233] \u001b[A\n",
            "Training:  17%|█▋        | 334/2000 [12:28<26:41,  1.04iteration/s, mean_rewards=-233]\u001b[A\n",
            "Training:  17%|█▋        | 334/2000 [12:29<26:41,  1.04iteration/s, mean_rewards=-220]\u001b[A\n",
            "Training:  17%|█▋        | 335/2000 [12:29<25:12,  1.10iteration/s, mean_rewards=-220]\u001b[A\n",
            "Training:  17%|█▋        | 335/2000 [12:30<25:12,  1.10iteration/s, mean_rewards=-449]\u001b[A\n",
            "Training:  17%|█▋        | 336/2000 [12:30<26:26,  1.05iteration/s, mean_rewards=-449]\u001b[A\n",
            "Training:  17%|█▋        | 336/2000 [12:31<26:26,  1.05iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  17%|█▋        | 337/2000 [12:31<26:14,  1.06iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  17%|█▋        | 337/2000 [12:31<26:14,  1.06iteration/s, mean_rewards=-207]\u001b[A\n",
            "Training:  17%|█▋        | 338/2000 [12:32<23:48,  1.16iteration/s, mean_rewards=-207]\u001b[A\n",
            "Training:  17%|█▋        | 338/2000 [12:32<23:48,  1.16iteration/s, mean_rewards=-201]\u001b[A\n",
            "Training:  17%|█▋        | 339/2000 [12:33<23:27,  1.18iteration/s, mean_rewards=-201]\u001b[A\n",
            "Training:  17%|█▋        | 339/2000 [12:33<23:27,  1.18iteration/s, mean_rewards=0.705]\u001b[A\n",
            "Training:  17%|█▋        | 340/2000 [12:34<23:58,  1.15iteration/s, mean_rewards=0.705]\u001b[A\n",
            "Training:  17%|█▋        | 340/2000 [12:34<23:58,  1.15iteration/s, mean_rewards=-257] \u001b[A\n",
            "Training:  17%|█▋        | 341/2000 [12:35<24:45,  1.12iteration/s, mean_rewards=-257]\u001b[A\n",
            "Training:  17%|█▋        | 341/2000 [12:35<24:45,  1.12iteration/s, mean_rewards=-284]\u001b[A\n",
            "Training:  17%|█▋        | 342/2000 [12:36<25:10,  1.10iteration/s, mean_rewards=-284]\u001b[A\n",
            "Training:  17%|█▋        | 342/2000 [12:37<25:10,  1.10iteration/s, mean_rewards=-54.9]\u001b[A\n",
            "Training:  17%|█▋        | 343/2000 [12:38<38:57,  1.41s/iteration, mean_rewards=-54.9]\u001b[A\n",
            "Training:  17%|█▋        | 343/2000 [12:38<38:57,  1.41s/iteration, mean_rewards=-86.1]\u001b[A\n",
            "Training:  17%|█▋        | 344/2000 [12:39<34:52,  1.26s/iteration, mean_rewards=-86.1]\u001b[A\n",
            "Training:  17%|█▋        | 344/2000 [12:39<34:52,  1.26s/iteration, mean_rewards=-392] \u001b[A\n",
            "Training:  17%|█▋        | 345/2000 [12:40<31:55,  1.16s/iteration, mean_rewards=-392]\u001b[A\n",
            "Training:  17%|█▋        | 345/2000 [12:40<31:55,  1.16s/iteration, mean_rewards=-151]\u001b[A\n",
            "Training:  17%|█▋        | 346/2000 [12:41<29:00,  1.05s/iteration, mean_rewards=-151]\u001b[A\n",
            "Training:  17%|█▋        | 346/2000 [12:41<29:00,  1.05s/iteration, mean_rewards=-32] \u001b[A\n",
            "Training:  17%|█▋        | 347/2000 [12:42<26:56,  1.02iteration/s, mean_rewards=-32]\u001b[A\n",
            "Training:  17%|█▋        | 347/2000 [12:42<26:56,  1.02iteration/s, mean_rewards=-254]\u001b[A\n",
            "Training:  17%|█▋        | 348/2000 [12:43<27:23,  1.01iteration/s, mean_rewards=-254]\u001b[A\n",
            "Training:  17%|█▋        | 348/2000 [12:43<27:23,  1.01iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  17%|█▋        | 349/2000 [12:43<26:47,  1.03iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  17%|█▋        | 349/2000 [12:44<26:47,  1.03iteration/s, mean_rewards=-168]\u001b[A\n",
            "Training:  18%|█▊        | 350/2000 [12:44<25:14,  1.09iteration/s, mean_rewards=-168]\u001b[A\n",
            "Training:  18%|█▊        | 350/2000 [12:45<25:14,  1.09iteration/s, mean_rewards=-96.4]\u001b[A\n",
            "Training:  18%|█▊        | 351/2000 [12:45<24:01,  1.14iteration/s, mean_rewards=-96.4]\u001b[A\n",
            "Training:  18%|█▊        | 351/2000 [12:45<24:01,  1.14iteration/s, mean_rewards=-141] \u001b[A\n",
            "Training:  18%|█▊        | 352/2000 [12:46<23:22,  1.18iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  18%|█▊        | 352/2000 [12:46<23:22,  1.18iteration/s, mean_rewards=-106]\u001b[A\n",
            "Training:  18%|█▊        | 353/2000 [12:47<21:52,  1.26iteration/s, mean_rewards=-106]\u001b[A\n",
            "Training:  18%|█▊        | 353/2000 [12:47<21:52,  1.26iteration/s, mean_rewards=-318]\u001b[A\n",
            "Training:  18%|█▊        | 354/2000 [12:47<22:14,  1.23iteration/s, mean_rewards=-318]\u001b[A\n",
            "Training:  18%|█▊        | 354/2000 [12:48<22:14,  1.23iteration/s, mean_rewards=-214]\u001b[A\n",
            "Training:  18%|█▊        | 355/2000 [12:48<24:18,  1.13iteration/s, mean_rewards=-214]\u001b[A\n",
            "Training:  18%|█▊        | 355/2000 [12:49<24:18,  1.13iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:  18%|█▊        | 356/2000 [12:50<28:11,  1.03s/iteration, mean_rewards=-138]\u001b[A\n",
            "Training:  18%|█▊        | 356/2000 [12:50<28:11,  1.03s/iteration, mean_rewards=-337]\u001b[A\n",
            "Training:  18%|█▊        | 357/2000 [12:51<27:27,  1.00s/iteration, mean_rewards=-337]\u001b[A\n",
            "Training:  18%|█▊        | 357/2000 [12:51<27:27,  1.00s/iteration, mean_rewards=-335]\u001b[A\n",
            "Training:  18%|█▊        | 358/2000 [12:52<26:42,  1.02iteration/s, mean_rewards=-335]\u001b[A\n",
            "Training:  18%|█▊        | 358/2000 [12:52<26:42,  1.02iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  18%|█▊        | 359/2000 [12:53<27:22,  1.00s/iteration, mean_rewards=-144]\u001b[A\n",
            "Training:  18%|█▊        | 359/2000 [12:53<27:22,  1.00s/iteration, mean_rewards=-120]\u001b[A\n",
            "Training:  18%|█▊        | 360/2000 [12:54<26:13,  1.04iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  18%|█▊        | 360/2000 [12:54<26:13,  1.04iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  18%|█▊        | 361/2000 [12:54<25:10,  1.09iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  18%|█▊        | 361/2000 [12:55<25:10,  1.09iteration/s, mean_rewards=-165]\u001b[A\n",
            "Training:  18%|█▊        | 362/2000 [12:55<24:25,  1.12iteration/s, mean_rewards=-165]\u001b[A\n",
            "Training:  18%|█▊        | 362/2000 [12:56<24:25,  1.12iteration/s, mean_rewards=-165]\u001b[A\n",
            "Training:  18%|█▊        | 363/2000 [12:56<24:55,  1.09iteration/s, mean_rewards=-165]\u001b[A\n",
            "Training:  18%|█▊        | 363/2000 [12:56<24:55,  1.09iteration/s, mean_rewards=-257]\u001b[A\n",
            "Training:  18%|█▊        | 364/2000 [12:57<23:23,  1.17iteration/s, mean_rewards=-257]\u001b[A\n",
            "Training:  18%|█▊        | 364/2000 [12:57<23:23,  1.17iteration/s, mean_rewards=-76.3]\u001b[A\n",
            "Training:  18%|█▊        | 365/2000 [12:58<24:06,  1.13iteration/s, mean_rewards=-76.3]\u001b[A\n",
            "Training:  18%|█▊        | 365/2000 [12:58<24:06,  1.13iteration/s, mean_rewards=-106] \u001b[A\n",
            "Training:  18%|█▊        | 366/2000 [12:59<23:33,  1.16iteration/s, mean_rewards=-106]\u001b[A\n",
            "Training:  18%|█▊        | 366/2000 [12:59<23:33,  1.16iteration/s, mean_rewards=-261]\u001b[A\n",
            "Training:  18%|█▊        | 367/2000 [13:00<24:20,  1.12iteration/s, mean_rewards=-261]\u001b[A\n",
            "Training:  18%|█▊        | 367/2000 [13:00<24:20,  1.12iteration/s, mean_rewards=-255]\u001b[A\n",
            "Training:  18%|█▊        | 368/2000 [13:01<24:07,  1.13iteration/s, mean_rewards=-255]\u001b[A\n",
            "Training:  18%|█▊        | 368/2000 [13:01<24:07,  1.13iteration/s, mean_rewards=-216]\u001b[A\n",
            "Training:  18%|█▊        | 369/2000 [13:02<28:34,  1.05s/iteration, mean_rewards=-216]\u001b[A\n",
            "Training:  18%|█▊        | 369/2000 [13:02<28:34,  1.05s/iteration, mean_rewards=-273]\u001b[A\n",
            "Training:  18%|█▊        | 370/2000 [13:03<27:51,  1.03s/iteration, mean_rewards=-273]\u001b[A\n",
            "Training:  18%|█▊        | 370/2000 [13:03<27:51,  1.03s/iteration, mean_rewards=-239]\u001b[A\n",
            "Training:  19%|█▊        | 371/2000 [13:04<26:35,  1.02iteration/s, mean_rewards=-239]\u001b[A\n",
            "Training:  19%|█▊        | 371/2000 [13:04<26:35,  1.02iteration/s, mean_rewards=-43] \u001b[A\n",
            "Training:  19%|█▊        | 372/2000 [13:04<24:06,  1.13iteration/s, mean_rewards=-43]\u001b[A\n",
            "Training:  19%|█▊        | 372/2000 [13:05<24:06,  1.13iteration/s, mean_rewards=-329]\u001b[A\n",
            "Training:  19%|█▊        | 373/2000 [13:05<24:36,  1.10iteration/s, mean_rewards=-329]\u001b[A\n",
            "Training:  19%|█▊        | 373/2000 [13:06<24:36,  1.10iteration/s, mean_rewards=-337]\u001b[A\n",
            "Training:  19%|█▊        | 374/2000 [13:06<24:50,  1.09iteration/s, mean_rewards=-337]\u001b[A\n",
            "Training:  19%|█▊        | 374/2000 [13:07<24:50,  1.09iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  19%|█▉        | 375/2000 [13:07<23:03,  1.17iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  19%|█▉        | 375/2000 [13:07<23:03,  1.17iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  19%|█▉        | 376/2000 [13:08<22:54,  1.18iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  19%|█▉        | 376/2000 [13:08<22:54,  1.18iteration/s, mean_rewards=-391]\u001b[A\n",
            "Training:  19%|█▉        | 377/2000 [13:09<25:04,  1.08iteration/s, mean_rewards=-391]\u001b[A\n",
            "Training:  19%|█▉        | 377/2000 [13:09<25:04,  1.08iteration/s, mean_rewards=-265]\u001b[A\n",
            "Training:  19%|█▉        | 378/2000 [13:10<26:13,  1.03iteration/s, mean_rewards=-265]\u001b[A\n",
            "Training:  19%|█▉        | 378/2000 [13:10<26:13,  1.03iteration/s, mean_rewards=-306]\u001b[A\n",
            "Training:  19%|█▉        | 379/2000 [13:11<24:58,  1.08iteration/s, mean_rewards=-306]\u001b[A\n",
            "Training:  19%|█▉        | 379/2000 [13:11<24:58,  1.08iteration/s, mean_rewards=-215]\u001b[A\n",
            "Training:  19%|█▉        | 380/2000 [13:12<25:12,  1.07iteration/s, mean_rewards=-215]\u001b[A\n",
            "Training:  19%|█▉        | 380/2000 [13:12<25:12,  1.07iteration/s, mean_rewards=-226]\u001b[A\n",
            "Training:  19%|█▉        | 381/2000 [13:13<24:07,  1.12iteration/s, mean_rewards=-226]\u001b[A\n",
            "Training:  19%|█▉        | 381/2000 [13:13<24:07,  1.12iteration/s, mean_rewards=-160]\u001b[A\n",
            "Training:  19%|█▉        | 382/2000 [13:14<24:55,  1.08iteration/s, mean_rewards=-160]\u001b[A\n",
            "Training:  19%|█▉        | 382/2000 [13:14<24:55,  1.08iteration/s, mean_rewards=-373]\u001b[A\n",
            "Training:  19%|█▉        | 383/2000 [13:15<27:55,  1.04s/iteration, mean_rewards=-373]\u001b[A\n",
            "Training:  19%|█▉        | 383/2000 [13:15<27:55,  1.04s/iteration, mean_rewards=-182]\u001b[A\n",
            "Training:  19%|█▉        | 384/2000 [13:16<28:39,  1.06s/iteration, mean_rewards=-182]\u001b[A\n",
            "Training:  19%|█▉        | 384/2000 [13:16<28:39,  1.06s/iteration, mean_rewards=-347]\u001b[A\n",
            "Training:  19%|█▉        | 385/2000 [13:17<26:35,  1.01iteration/s, mean_rewards=-347]\u001b[A\n",
            "Training:  19%|█▉        | 385/2000 [13:17<26:35,  1.01iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  19%|█▉        | 386/2000 [13:18<26:13,  1.03iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  19%|█▉        | 386/2000 [13:18<26:13,  1.03iteration/s, mean_rewards=-244]\u001b[A\n",
            "Training:  19%|█▉        | 387/2000 [13:19<25:02,  1.07iteration/s, mean_rewards=-244]\u001b[A\n",
            "Training:  19%|█▉        | 387/2000 [13:19<25:02,  1.07iteration/s, mean_rewards=-304]\u001b[A\n",
            "Training:  19%|█▉        | 388/2000 [13:20<25:23,  1.06iteration/s, mean_rewards=-304]\u001b[A\n",
            "Training:  19%|█▉        | 388/2000 [13:20<25:23,  1.06iteration/s, mean_rewards=-104]\u001b[A\n",
            "Training:  19%|█▉        | 389/2000 [13:20<23:21,  1.15iteration/s, mean_rewards=-104]\u001b[A\n",
            "Training:  19%|█▉        | 389/2000 [13:21<23:21,  1.15iteration/s, mean_rewards=-193]\u001b[A\n",
            "Training:  20%|█▉        | 390/2000 [13:22<26:54,  1.00s/iteration, mean_rewards=-193]\u001b[A\n",
            "Training:  20%|█▉        | 390/2000 [13:22<26:54,  1.00s/iteration, mean_rewards=-83.4]\u001b[A\n",
            "Training:  20%|█▉        | 391/2000 [13:23<26:28,  1.01iteration/s, mean_rewards=-83.4]\u001b[A\n",
            "Training:  20%|█▉        | 391/2000 [13:23<26:28,  1.01iteration/s, mean_rewards=-224] \u001b[A\n",
            "Training:  20%|█▉        | 392/2000 [13:23<25:52,  1.04iteration/s, mean_rewards=-224]\u001b[A\n",
            "Training:  20%|█▉        | 392/2000 [13:24<25:52,  1.04iteration/s, mean_rewards=-196]\u001b[A\n",
            "Training:  20%|█▉        | 393/2000 [13:24<24:16,  1.10iteration/s, mean_rewards=-196]\u001b[A\n",
            "Training:  20%|█▉        | 393/2000 [13:25<24:16,  1.10iteration/s, mean_rewards=-210]\u001b[A\n",
            "Training:  20%|█▉        | 394/2000 [13:25<23:25,  1.14iteration/s, mean_rewards=-210]\u001b[A\n",
            "Training:  20%|█▉        | 394/2000 [13:25<23:25,  1.14iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:  20%|█▉        | 395/2000 [13:26<22:47,  1.17iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:  20%|█▉        | 395/2000 [13:26<22:47,  1.17iteration/s, mean_rewards=-203]\u001b[A\n",
            "Training:  20%|█▉        | 396/2000 [13:27<24:06,  1.11iteration/s, mean_rewards=-203]\u001b[A\n",
            "Training:  20%|█▉        | 396/2000 [13:27<24:06,  1.11iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  20%|█▉        | 397/2000 [13:28<28:04,  1.05s/iteration, mean_rewards=-135]\u001b[A\n",
            "Training:  20%|█▉        | 397/2000 [13:29<28:04,  1.05s/iteration, mean_rewards=-182]\u001b[A\n",
            "Training:  20%|█▉        | 398/2000 [13:29<27:07,  1.02s/iteration, mean_rewards=-182]\u001b[A\n",
            "Training:  20%|█▉        | 398/2000 [13:30<27:07,  1.02s/iteration, mean_rewards=-328]\u001b[A\n",
            "Training:  20%|█▉        | 399/2000 [13:30<27:35,  1.03s/iteration, mean_rewards=-328]\u001b[A\n",
            "Training:  20%|█▉        | 399/2000 [13:31<27:35,  1.03s/iteration, mean_rewards=-288]\u001b[A\n",
            "Training:  20%|██        | 400/2000 [13:31<25:49,  1.03iteration/s, mean_rewards=-288]\u001b[A\n",
            "Training:  20%|██        | 400/2000 [13:32<25:49,  1.03iteration/s, mean_rewards=-239]\u001b[A\n",
            "Training:  20%|██        | 401/2000 [13:32<26:37,  1.00iteration/s, mean_rewards=-239]\u001b[A\n",
            "Training:  20%|██        | 401/2000 [13:32<26:37,  1.00iteration/s, mean_rewards=-79.3]\u001b[A\n",
            "Training:  20%|██        | 402/2000 [13:33<23:58,  1.11iteration/s, mean_rewards=-79.3]\u001b[A\n",
            "Training:  20%|██        | 402/2000 [13:33<23:58,  1.11iteration/s, mean_rewards=-233] \u001b[A\n",
            "Training:  20%|██        | 403/2000 [13:34<23:17,  1.14iteration/s, mean_rewards=-233]\u001b[A\n",
            "Training:  20%|██        | 403/2000 [13:34<23:17,  1.14iteration/s, mean_rewards=-346]\u001b[A\n",
            "Training:  20%|██        | 404/2000 [13:35<23:02,  1.15iteration/s, mean_rewards=-346]\u001b[A\n",
            "Training:  20%|██        | 404/2000 [13:35<23:02,  1.15iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  20%|██        | 405/2000 [13:35<23:26,  1.13iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  20%|██        | 405/2000 [13:36<23:26,  1.13iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  20%|██        | 406/2000 [13:36<22:58,  1.16iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  20%|██        | 406/2000 [13:37<22:58,  1.16iteration/s, mean_rewards=-115]\u001b[A\n",
            "Training:  20%|██        | 407/2000 [13:37<23:11,  1.15iteration/s, mean_rewards=-115]\u001b[A\n",
            "Training:  20%|██        | 407/2000 [13:38<23:11,  1.15iteration/s, mean_rewards=-194]\u001b[A\n",
            "Training:  20%|██        | 408/2000 [13:38<23:24,  1.13iteration/s, mean_rewards=-194]\u001b[A\n",
            "Training:  20%|██        | 408/2000 [13:39<23:24,  1.13iteration/s, mean_rewards=-163]\u001b[A\n",
            "Training:  20%|██        | 409/2000 [13:39<27:45,  1.05s/iteration, mean_rewards=-163]\u001b[A\n",
            "Training:  20%|██        | 409/2000 [13:40<27:45,  1.05s/iteration, mean_rewards=-108]\u001b[A\n",
            "Training:  20%|██        | 410/2000 [13:41<28:29,  1.08s/iteration, mean_rewards=-108]\u001b[A\n",
            "Training:  20%|██        | 410/2000 [13:41<28:29,  1.08s/iteration, mean_rewards=-117]\u001b[A\n",
            "Training:  21%|██        | 411/2000 [13:42<27:46,  1.05s/iteration, mean_rewards=-117]\u001b[A\n",
            "Training:  21%|██        | 411/2000 [13:42<27:46,  1.05s/iteration, mean_rewards=-307]\u001b[A\n",
            "Training:  21%|██        | 412/2000 [13:43<28:13,  1.07s/iteration, mean_rewards=-307]\u001b[A\n",
            "Training:  21%|██        | 412/2000 [13:43<28:13,  1.07s/iteration, mean_rewards=-154]\u001b[A\n",
            "Training:  21%|██        | 413/2000 [13:43<25:19,  1.04iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  21%|██        | 413/2000 [13:44<25:19,  1.04iteration/s, mean_rewards=-249]\u001b[A\n",
            "Training:  21%|██        | 414/2000 [13:44<23:51,  1.11iteration/s, mean_rewards=-249]\u001b[A\n",
            "Training:  21%|██        | 414/2000 [13:44<23:51,  1.11iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  21%|██        | 415/2000 [13:45<23:03,  1.15iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  21%|██        | 415/2000 [13:45<23:03,  1.15iteration/s, mean_rewards=-191]\u001b[A\n",
            "Training:  21%|██        | 416/2000 [13:46<23:29,  1.12iteration/s, mean_rewards=-191]\u001b[A\n",
            "Training:  21%|██        | 416/2000 [13:46<23:29,  1.12iteration/s, mean_rewards=-195]\u001b[A\n",
            "Training:  21%|██        | 417/2000 [13:47<23:58,  1.10iteration/s, mean_rewards=-195]\u001b[A\n",
            "Training:  21%|██        | 417/2000 [13:47<23:58,  1.10iteration/s, mean_rewards=-313]\u001b[A\n",
            "Training:  21%|██        | 418/2000 [13:48<24:11,  1.09iteration/s, mean_rewards=-313]\u001b[A\n",
            "Training:  21%|██        | 418/2000 [13:48<24:11,  1.09iteration/s, mean_rewards=-164]\u001b[A\n",
            "Training:  21%|██        | 419/2000 [13:49<23:28,  1.12iteration/s, mean_rewards=-164]\u001b[A\n",
            "Training:  21%|██        | 419/2000 [13:49<23:28,  1.12iteration/s, mean_rewards=-106]\u001b[A\n",
            "Training:  21%|██        | 420/2000 [13:50<23:50,  1.10iteration/s, mean_rewards=-106]\u001b[A\n",
            "Training:  21%|██        | 420/2000 [13:50<23:50,  1.10iteration/s, mean_rewards=-313]\u001b[A\n",
            "Training:  21%|██        | 421/2000 [13:50<23:08,  1.14iteration/s, mean_rewards=-313]\u001b[A\n",
            "Training:  21%|██        | 421/2000 [13:51<23:08,  1.14iteration/s, mean_rewards=-166]\u001b[A\n",
            "Training:  21%|██        | 422/2000 [13:51<22:10,  1.19iteration/s, mean_rewards=-166]\u001b[A\n",
            "Training:  21%|██        | 422/2000 [13:51<22:10,  1.19iteration/s, mean_rewards=-159]\u001b[A\n",
            "Training:  21%|██        | 423/2000 [13:52<21:00,  1.25iteration/s, mean_rewards=-159]\u001b[A\n",
            "Training:  21%|██        | 423/2000 [13:52<21:00,  1.25iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  21%|██        | 424/2000 [13:53<23:17,  1.13iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  21%|██        | 424/2000 [13:54<23:17,  1.13iteration/s, mean_rewards=-185]\u001b[A\n",
            "Training:  21%|██▏       | 425/2000 [13:55<28:41,  1.09s/iteration, mean_rewards=-185]\u001b[A\n",
            "Training:  21%|██▏       | 425/2000 [13:55<28:41,  1.09s/iteration, mean_rewards=-236]\u001b[A\n",
            "Training:  21%|██▏       | 426/2000 [13:56<27:47,  1.06s/iteration, mean_rewards=-236]\u001b[A\n",
            "Training:  21%|██▏       | 426/2000 [13:56<27:47,  1.06s/iteration, mean_rewards=-283]\u001b[A\n",
            "Training:  21%|██▏       | 427/2000 [13:56<25:45,  1.02iteration/s, mean_rewards=-283]\u001b[A\n",
            "Training:  21%|██▏       | 427/2000 [13:57<25:45,  1.02iteration/s, mean_rewards=-274]\u001b[A\n",
            "Training:  21%|██▏       | 428/2000 [13:57<23:18,  1.12iteration/s, mean_rewards=-274]\u001b[A\n",
            "Training:  21%|██▏       | 428/2000 [13:57<23:18,  1.12iteration/s, mean_rewards=-238]\u001b[A\n",
            "Training:  21%|██▏       | 429/2000 [13:58<22:44,  1.15iteration/s, mean_rewards=-238]\u001b[A\n",
            "Training:  21%|██▏       | 429/2000 [13:58<22:44,  1.15iteration/s, mean_rewards=-208]\u001b[A\n",
            "Training:  22%|██▏       | 430/2000 [13:59<25:04,  1.04iteration/s, mean_rewards=-208]\u001b[A\n",
            "Training:  22%|██▏       | 430/2000 [13:59<25:04,  1.04iteration/s, mean_rewards=-63.6]\u001b[A\n",
            "Training:  22%|██▏       | 431/2000 [14:00<23:55,  1.09iteration/s, mean_rewards=-63.6]\u001b[A\n",
            "Training:  22%|██▏       | 431/2000 [14:00<23:55,  1.09iteration/s, mean_rewards=-448] \u001b[A\n",
            "Training:  22%|██▏       | 432/2000 [14:01<25:06,  1.04iteration/s, mean_rewards=-448]\u001b[A\n",
            "Training:  22%|██▏       | 432/2000 [14:01<25:06,  1.04iteration/s, mean_rewards=-174]\u001b[A\n",
            "Training:  22%|██▏       | 433/2000 [14:02<25:03,  1.04iteration/s, mean_rewards=-174]\u001b[A\n",
            "Training:  22%|██▏       | 433/2000 [14:02<25:03,  1.04iteration/s, mean_rewards=-15.2]\u001b[A\n",
            "Training:  22%|██▏       | 434/2000 [14:03<23:32,  1.11iteration/s, mean_rewards=-15.2]\u001b[A\n",
            "Training:  22%|██▏       | 434/2000 [14:03<23:32,  1.11iteration/s, mean_rewards=-171] \u001b[A\n",
            "Training:  22%|██▏       | 435/2000 [14:03<21:33,  1.21iteration/s, mean_rewards=-171]\u001b[A\n",
            "Training:  22%|██▏       | 435/2000 [14:04<21:33,  1.21iteration/s, mean_rewards=-193]\u001b[A\n",
            "Training:  22%|██▏       | 436/2000 [14:04<21:09,  1.23iteration/s, mean_rewards=-193]\u001b[A\n",
            "Training:  22%|██▏       | 436/2000 [14:04<21:09,  1.23iteration/s, mean_rewards=-89.7]\u001b[A\n",
            "Training:  22%|██▏       | 437/2000 [14:05<21:02,  1.24iteration/s, mean_rewards=-89.7]\u001b[A\n",
            "Training:  22%|██▏       | 437/2000 [14:05<21:02,  1.24iteration/s, mean_rewards=-292] \u001b[A\n",
            "Training:  22%|██▏       | 438/2000 [14:06<25:12,  1.03iteration/s, mean_rewards=-292]\u001b[A\n",
            "Training:  22%|██▏       | 438/2000 [14:07<25:12,  1.03iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  22%|██▏       | 439/2000 [14:08<31:12,  1.20s/iteration, mean_rewards=-146]\u001b[A\n",
            "Training:  22%|██▏       | 439/2000 [14:08<31:12,  1.20s/iteration, mean_rewards=-230]\u001b[A\n",
            "Training:  22%|██▏       | 440/2000 [14:09<29:24,  1.13s/iteration, mean_rewards=-230]\u001b[A\n",
            "Training:  22%|██▏       | 440/2000 [14:09<29:24,  1.13s/iteration, mean_rewards=-232]\u001b[A\n",
            "Training:  22%|██▏       | 441/2000 [14:10<28:03,  1.08s/iteration, mean_rewards=-232]\u001b[A\n",
            "Training:  22%|██▏       | 441/2000 [14:10<28:03,  1.08s/iteration, mean_rewards=-68.6]\u001b[A\n",
            "Training:  22%|██▏       | 442/2000 [14:11<25:38,  1.01iteration/s, mean_rewards=-68.6]\u001b[A\n",
            "Training:  22%|██▏       | 442/2000 [14:11<25:38,  1.01iteration/s, mean_rewards=-269] \u001b[A\n",
            "Training:  22%|██▏       | 443/2000 [14:11<24:19,  1.07iteration/s, mean_rewards=-269]\u001b[A\n",
            "Training:  22%|██▏       | 443/2000 [14:12<24:19,  1.07iteration/s, mean_rewards=-190]\u001b[A\n",
            "Training:  22%|██▏       | 444/2000 [14:12<24:10,  1.07iteration/s, mean_rewards=-190]\u001b[A\n",
            "Training:  22%|██▏       | 444/2000 [14:13<24:10,  1.07iteration/s, mean_rewards=-182]\u001b[A\n",
            "Training:  22%|██▏       | 445/2000 [14:13<23:17,  1.11iteration/s, mean_rewards=-182]\u001b[A\n",
            "Training:  22%|██▏       | 445/2000 [14:13<23:17,  1.11iteration/s, mean_rewards=-180]\u001b[A\n",
            "Training:  22%|██▏       | 446/2000 [14:14<21:37,  1.20iteration/s, mean_rewards=-180]\u001b[A\n",
            "Training:  22%|██▏       | 446/2000 [14:14<21:37,  1.20iteration/s, mean_rewards=-219]\u001b[A\n",
            "Training:  22%|██▏       | 447/2000 [14:15<23:28,  1.10iteration/s, mean_rewards=-219]\u001b[A\n",
            "Training:  22%|██▏       | 447/2000 [14:15<23:28,  1.10iteration/s, mean_rewards=-371]\u001b[A\n",
            "Training:  22%|██▏       | 448/2000 [14:16<23:54,  1.08iteration/s, mean_rewards=-371]\u001b[A\n",
            "Training:  22%|██▏       | 448/2000 [14:16<23:54,  1.08iteration/s, mean_rewards=-152]\u001b[A\n",
            "Training:  22%|██▏       | 449/2000 [14:17<21:55,  1.18iteration/s, mean_rewards=-152]\u001b[A\n",
            "Training:  22%|██▏       | 449/2000 [14:17<21:55,  1.18iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  22%|██▎       | 450/2000 [14:18<23:44,  1.09iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  22%|██▎       | 450/2000 [14:18<23:44,  1.09iteration/s, mean_rewards=-268]\u001b[A\n",
            "Training:  23%|██▎       | 451/2000 [14:18<22:42,  1.14iteration/s, mean_rewards=-268]\u001b[A\n",
            "Training:  23%|██▎       | 451/2000 [14:19<22:42,  1.14iteration/s, mean_rewards=-112]\u001b[A\n",
            "Training:  23%|██▎       | 452/2000 [14:20<25:40,  1.01iteration/s, mean_rewards=-112]\u001b[A\n",
            "Training:  23%|██▎       | 452/2000 [14:20<25:40,  1.01iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  23%|██▎       | 453/2000 [14:21<26:36,  1.03s/iteration, mean_rewards=-125]\u001b[A\n",
            "Training:  23%|██▎       | 453/2000 [14:21<26:36,  1.03s/iteration, mean_rewards=-152]\u001b[A\n",
            "Training:  23%|██▎       | 454/2000 [14:22<25:48,  1.00s/iteration, mean_rewards=-152]\u001b[A\n",
            "Training:  23%|██▎       | 454/2000 [14:22<25:48,  1.00s/iteration, mean_rewards=-365]\u001b[A\n",
            "Training:  23%|██▎       | 455/2000 [14:23<24:09,  1.07iteration/s, mean_rewards=-365]\u001b[A\n",
            "Training:  23%|██▎       | 455/2000 [14:23<24:09,  1.07iteration/s, mean_rewards=-101]\u001b[A\n",
            "Training:  23%|██▎       | 456/2000 [14:23<24:23,  1.06iteration/s, mean_rewards=-101]\u001b[A\n",
            "Training:  23%|██▎       | 456/2000 [14:24<24:23,  1.06iteration/s, mean_rewards=-364]\u001b[A\n",
            "Training:  23%|██▎       | 457/2000 [14:24<24:13,  1.06iteration/s, mean_rewards=-364]\u001b[A\n",
            "Training:  23%|██▎       | 457/2000 [14:25<24:13,  1.06iteration/s, mean_rewards=-200]\u001b[A\n",
            "Training:  23%|██▎       | 458/2000 [14:25<22:52,  1.12iteration/s, mean_rewards=-200]\u001b[A\n",
            "Training:  23%|██▎       | 458/2000 [14:26<22:52,  1.12iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  23%|██▎       | 459/2000 [14:26<23:16,  1.10iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  23%|██▎       | 459/2000 [14:26<23:16,  1.10iteration/s, mean_rewards=-222]\u001b[A\n",
            "Training:  23%|██▎       | 460/2000 [14:27<22:25,  1.14iteration/s, mean_rewards=-222]\u001b[A\n",
            "Training:  23%|██▎       | 460/2000 [14:27<22:25,  1.14iteration/s, mean_rewards=-284]\u001b[A\n",
            "Training:  23%|██▎       | 461/2000 [14:28<23:06,  1.11iteration/s, mean_rewards=-284]\u001b[A\n",
            "Training:  23%|██▎       | 461/2000 [14:28<23:06,  1.11iteration/s, mean_rewards=-193]\u001b[A\n",
            "Training:  23%|██▎       | 462/2000 [14:29<23:09,  1.11iteration/s, mean_rewards=-193]\u001b[A\n",
            "Training:  23%|██▎       | 462/2000 [14:29<23:09,  1.11iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  23%|██▎       | 463/2000 [14:29<21:10,  1.21iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  23%|██▎       | 463/2000 [14:30<21:10,  1.21iteration/s, mean_rewards=-235]\u001b[A\n",
            "Training:  23%|██▎       | 464/2000 [14:30<22:03,  1.16iteration/s, mean_rewards=-235]\u001b[A\n",
            "Training:  23%|██▎       | 464/2000 [14:31<22:03,  1.16iteration/s, mean_rewards=-91.8]\u001b[A\n",
            "Training:  23%|██▎       | 465/2000 [14:32<24:37,  1.04iteration/s, mean_rewards=-91.8]\u001b[A\n",
            "Training:  23%|██▎       | 465/2000 [14:32<24:37,  1.04iteration/s, mean_rewards=-96.5]\u001b[A\n",
            "Training:  23%|██▎       | 466/2000 [14:33<26:57,  1.05s/iteration, mean_rewards=-96.5]\u001b[A\n",
            "Training:  23%|██▎       | 466/2000 [14:33<26:57,  1.05s/iteration, mean_rewards=-176] \u001b[A\n",
            "Training:  23%|██▎       | 467/2000 [14:34<26:33,  1.04s/iteration, mean_rewards=-176]\u001b[A\n",
            "Training:  23%|██▎       | 467/2000 [14:34<26:33,  1.04s/iteration, mean_rewards=-187]\u001b[A\n",
            "Training:  23%|██▎       | 468/2000 [14:35<25:37,  1.00s/iteration, mean_rewards=-187]\u001b[A\n",
            "Training:  23%|██▎       | 468/2000 [14:35<25:37,  1.00s/iteration, mean_rewards=-138]\u001b[A\n",
            "Training:  23%|██▎       | 469/2000 [14:36<25:00,  1.02iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:  23%|██▎       | 469/2000 [14:36<25:00,  1.02iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  24%|██▎       | 470/2000 [14:37<24:25,  1.04iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  24%|██▎       | 470/2000 [14:37<24:25,  1.04iteration/s, mean_rewards=-288]\u001b[A\n",
            "Training:  24%|██▎       | 471/2000 [14:38<24:02,  1.06iteration/s, mean_rewards=-288]\u001b[A\n",
            "Training:  24%|██▎       | 471/2000 [14:38<24:02,  1.06iteration/s, mean_rewards=-178]\u001b[A\n",
            "Training:  24%|██▎       | 472/2000 [14:38<21:48,  1.17iteration/s, mean_rewards=-178]\u001b[A\n",
            "Training:  24%|██▎       | 472/2000 [14:38<21:48,  1.17iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  24%|██▎       | 473/2000 [14:39<20:19,  1.25iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  24%|██▎       | 473/2000 [14:39<20:19,  1.25iteration/s, mean_rewards=-237]\u001b[A\n",
            "Training:  24%|██▎       | 474/2000 [14:40<20:15,  1.26iteration/s, mean_rewards=-237]\u001b[A\n",
            "Training:  24%|██▎       | 474/2000 [14:40<20:15,  1.26iteration/s, mean_rewards=-233]\u001b[A\n",
            "Training:  24%|██▍       | 475/2000 [14:40<20:19,  1.25iteration/s, mean_rewards=-233]\u001b[A\n",
            "Training:  24%|██▍       | 475/2000 [14:41<20:19,  1.25iteration/s, mean_rewards=-164]\u001b[A\n",
            "Training:  24%|██▍       | 476/2000 [14:41<19:03,  1.33iteration/s, mean_rewards=-164]\u001b[A\n",
            "Training:  24%|██▍       | 476/2000 [14:41<19:03,  1.33iteration/s, mean_rewards=-85.8]\u001b[A\n",
            "Training:  24%|██▍       | 477/2000 [14:42<20:06,  1.26iteration/s, mean_rewards=-85.8]\u001b[A\n",
            "Training:  24%|██▍       | 477/2000 [14:42<20:06,  1.26iteration/s, mean_rewards=-292] \u001b[A\n",
            "Training:  24%|██▍       | 478/2000 [14:43<21:15,  1.19iteration/s, mean_rewards=-292]\u001b[A\n",
            "Training:  24%|██▍       | 478/2000 [14:43<21:15,  1.19iteration/s, mean_rewards=-289]\u001b[A\n",
            "Training:  24%|██▍       | 479/2000 [14:44<21:46,  1.16iteration/s, mean_rewards=-289]\u001b[A\n",
            "Training:  24%|██▍       | 479/2000 [14:44<21:46,  1.16iteration/s, mean_rewards=-167]\u001b[A\n",
            "Training:  24%|██▍       | 480/2000 [14:45<24:23,  1.04iteration/s, mean_rewards=-167]\u001b[A\n",
            "Training:  24%|██▍       | 480/2000 [14:45<24:23,  1.04iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:  24%|██▍       | 481/2000 [14:46<26:07,  1.03s/iteration, mean_rewards=-145]\u001b[A\n",
            "Training:  24%|██▍       | 481/2000 [14:47<26:07,  1.03s/iteration, mean_rewards=-152]\u001b[A\n",
            "Training:  24%|██▍       | 482/2000 [14:47<25:37,  1.01s/iteration, mean_rewards=-152]\u001b[A\n",
            "Training:  24%|██▍       | 482/2000 [14:48<25:37,  1.01s/iteration, mean_rewards=-127]\u001b[A\n",
            "Training:  24%|██▍       | 483/2000 [14:48<24:07,  1.05iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  24%|██▍       | 483/2000 [14:48<24:07,  1.05iteration/s, mean_rewards=-160]\u001b[A\n",
            "Training:  24%|██▍       | 484/2000 [14:49<22:40,  1.11iteration/s, mean_rewards=-160]\u001b[A\n",
            "Training:  24%|██▍       | 484/2000 [14:49<22:40,  1.11iteration/s, mean_rewards=-194]\u001b[A\n",
            "Training:  24%|██▍       | 485/2000 [14:50<23:37,  1.07iteration/s, mean_rewards=-194]\u001b[A\n",
            "Training:  24%|██▍       | 485/2000 [14:50<23:37,  1.07iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  24%|██▍       | 486/2000 [14:50<21:28,  1.17iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  24%|██▍       | 486/2000 [14:51<21:28,  1.17iteration/s, mean_rewards=-229]\u001b[A\n",
            "Training:  24%|██▍       | 487/2000 [14:52<23:12,  1.09iteration/s, mean_rewards=-229]\u001b[A\n",
            "Training:  24%|██▍       | 487/2000 [14:52<23:12,  1.09iteration/s, mean_rewards=-209]\u001b[A\n",
            "Training:  24%|██▍       | 488/2000 [14:52<22:10,  1.14iteration/s, mean_rewards=-209]\u001b[A\n",
            "Training:  24%|██▍       | 488/2000 [14:53<22:10,  1.14iteration/s, mean_rewards=-206]\u001b[A\n",
            "Training:  24%|██▍       | 489/2000 [14:53<22:27,  1.12iteration/s, mean_rewards=-206]\u001b[A\n",
            "Training:  24%|██▍       | 489/2000 [14:54<22:27,  1.12iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  24%|██▍       | 490/2000 [14:54<21:45,  1.16iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  24%|██▍       | 490/2000 [14:54<21:45,  1.16iteration/s, mean_rewards=-311]\u001b[A\n",
            "Training:  25%|██▍       | 491/2000 [14:55<21:23,  1.18iteration/s, mean_rewards=-311]\u001b[A\n",
            "Training:  25%|██▍       | 491/2000 [14:55<21:23,  1.18iteration/s, mean_rewards=-97.5]\u001b[A\n",
            "Training:  25%|██▍       | 492/2000 [14:56<20:15,  1.24iteration/s, mean_rewards=-97.5]\u001b[A\n",
            "Training:  25%|██▍       | 492/2000 [14:56<20:15,  1.24iteration/s, mean_rewards=-265] \u001b[A\n",
            "Training:  25%|██▍       | 493/2000 [14:56<20:14,  1.24iteration/s, mean_rewards=-265]\u001b[A\n",
            "Training:  25%|██▍       | 493/2000 [14:57<20:14,  1.24iteration/s, mean_rewards=-209]\u001b[A\n",
            "Training:  25%|██▍       | 494/2000 [14:57<22:36,  1.11iteration/s, mean_rewards=-209]\u001b[A\n",
            "Training:  25%|██▍       | 494/2000 [14:58<22:36,  1.11iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  25%|██▍       | 495/2000 [14:59<25:00,  1.00iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  25%|██▍       | 495/2000 [14:59<25:00,  1.00iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:  25%|██▍       | 496/2000 [15:00<24:52,  1.01iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:  25%|██▍       | 496/2000 [15:00<24:52,  1.01iteration/s, mean_rewards=-170]\u001b[A\n",
            "Training:  25%|██▍       | 497/2000 [15:01<24:35,  1.02iteration/s, mean_rewards=-170]\u001b[A\n",
            "Training:  25%|██▍       | 497/2000 [15:01<24:35,  1.02iteration/s, mean_rewards=-95.1]\u001b[A\n",
            "Training:  25%|██▍       | 498/2000 [15:01<21:55,  1.14iteration/s, mean_rewards=-95.1]\u001b[A\n",
            "Training:  25%|██▍       | 498/2000 [15:02<21:55,  1.14iteration/s, mean_rewards=-285] \u001b[A\n",
            "Training:  25%|██▍       | 499/2000 [15:02<22:18,  1.12iteration/s, mean_rewards=-285]\u001b[A\n",
            "Training:  25%|██▍       | 499/2000 [15:03<22:18,  1.12iteration/s, mean_rewards=-297]\u001b[A\n",
            "Training:  25%|██▌       | 500/2000 [15:03<23:16,  1.07iteration/s, mean_rewards=-297]\u001b[A\n",
            "Training:  25%|██▌       | 500/2000 [15:04<23:16,  1.07iteration/s, mean_rewards=-171]\u001b[A\n",
            "Training:  25%|██▌       | 501/2000 [15:04<23:14,  1.08iteration/s, mean_rewards=-171]\u001b[A\n",
            "Training:  25%|██▌       | 501/2000 [15:04<23:14,  1.08iteration/s, mean_rewards=-100]\u001b[A\n",
            "Training:  25%|██▌       | 502/2000 [15:05<22:02,  1.13iteration/s, mean_rewards=-100]\u001b[A\n",
            "Training:  25%|██▌       | 502/2000 [15:05<22:02,  1.13iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  25%|██▌       | 503/2000 [15:06<23:25,  1.06iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  25%|██▌       | 503/2000 [15:06<23:25,  1.06iteration/s, mean_rewards=-244]\u001b[A\n",
            "Training:  25%|██▌       | 504/2000 [15:07<23:13,  1.07iteration/s, mean_rewards=-244]\u001b[A\n",
            "Training:  25%|██▌       | 504/2000 [15:07<23:13,  1.07iteration/s, mean_rewards=-189]\u001b[A\n",
            "Training:  25%|██▌       | 505/2000 [15:08<23:17,  1.07iteration/s, mean_rewards=-189]\u001b[A\n",
            "Training:  25%|██▌       | 505/2000 [15:08<23:17,  1.07iteration/s, mean_rewards=-198]\u001b[A\n",
            "Training:  25%|██▌       | 506/2000 [15:09<22:05,  1.13iteration/s, mean_rewards=-198]\u001b[A\n",
            "Training:  25%|██▌       | 506/2000 [15:09<22:05,  1.13iteration/s, mean_rewards=-294]\u001b[A\n",
            "Training:  25%|██▌       | 507/2000 [15:10<24:21,  1.02iteration/s, mean_rewards=-294]\u001b[A\n",
            "Training:  25%|██▌       | 507/2000 [15:10<24:21,  1.02iteration/s, mean_rewards=-191]\u001b[A\n",
            "Training:  25%|██▌       | 508/2000 [15:11<26:09,  1.05s/iteration, mean_rewards=-191]\u001b[A\n",
            "Training:  25%|██▌       | 508/2000 [15:11<26:09,  1.05s/iteration, mean_rewards=-167]\u001b[A\n",
            "Training:  25%|██▌       | 509/2000 [15:12<26:28,  1.07s/iteration, mean_rewards=-167]\u001b[A\n",
            "Training:  25%|██▌       | 509/2000 [15:13<26:28,  1.07s/iteration, mean_rewards=-126]\u001b[A\n",
            "Training:  26%|██▌       | 510/2000 [15:13<26:07,  1.05s/iteration, mean_rewards=-126]\u001b[A\n",
            "Training:  26%|██▌       | 510/2000 [15:13<26:07,  1.05s/iteration, mean_rewards=-87.4]\u001b[A\n",
            "Training:  26%|██▌       | 511/2000 [15:14<24:01,  1.03iteration/s, mean_rewards=-87.4]\u001b[A\n",
            "Training:  26%|██▌       | 511/2000 [15:14<24:01,  1.03iteration/s, mean_rewards=-141] \u001b[A\n",
            "Training:  26%|██▌       | 512/2000 [15:15<22:27,  1.10iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  26%|██▌       | 512/2000 [15:15<22:27,  1.10iteration/s, mean_rewards=-356]\u001b[A\n",
            "Training:  26%|██▌       | 513/2000 [15:16<24:01,  1.03iteration/s, mean_rewards=-356]\u001b[A\n",
            "Training:  26%|██▌       | 513/2000 [15:16<24:01,  1.03iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  26%|██▌       | 514/2000 [15:17<23:46,  1.04iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  26%|██▌       | 514/2000 [15:17<23:46,  1.04iteration/s, mean_rewards=-252]\u001b[A\n",
            "Training:  26%|██▌       | 515/2000 [15:18<25:29,  1.03s/iteration, mean_rewards=-252]\u001b[A\n",
            "Training:  26%|██▌       | 515/2000 [15:18<25:29,  1.03s/iteration, mean_rewards=-161]\u001b[A\n",
            "Training:  26%|██▌       | 516/2000 [15:19<23:45,  1.04iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:  26%|██▌       | 516/2000 [15:19<23:45,  1.04iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  26%|██▌       | 517/2000 [15:20<22:42,  1.09iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  26%|██▌       | 517/2000 [15:20<22:42,  1.09iteration/s, mean_rewards=-160]\u001b[A\n",
            "Training:  26%|██▌       | 518/2000 [15:20<22:50,  1.08iteration/s, mean_rewards=-160]\u001b[A\n",
            "Training:  26%|██▌       | 518/2000 [15:21<22:50,  1.08iteration/s, mean_rewards=-224]\u001b[A\n",
            "Training:  26%|██▌       | 519/2000 [15:21<21:56,  1.12iteration/s, mean_rewards=-224]\u001b[A\n",
            "Training:  26%|██▌       | 519/2000 [15:22<21:56,  1.12iteration/s, mean_rewards=-181]\u001b[A\n",
            "Training:  26%|██▌       | 520/2000 [15:22<21:58,  1.12iteration/s, mean_rewards=-181]\u001b[A\n",
            "Training:  26%|██▌       | 520/2000 [15:23<21:58,  1.12iteration/s, mean_rewards=-64.1]\u001b[A\n",
            "Training:  26%|██▌       | 521/2000 [15:23<23:51,  1.03iteration/s, mean_rewards=-64.1]\u001b[A\n",
            "Training:  26%|██▌       | 521/2000 [15:24<23:51,  1.03iteration/s, mean_rewards=-192] \u001b[A\n",
            "Training:  26%|██▌       | 522/2000 [15:24<24:57,  1.01s/iteration, mean_rewards=-192]\u001b[A\n",
            "Training:  26%|██▌       | 522/2000 [15:25<24:57,  1.01s/iteration, mean_rewards=-166]\u001b[A\n",
            "Training:  26%|██▌       | 523/2000 [15:26<26:56,  1.09s/iteration, mean_rewards=-166]\u001b[A\n",
            "Training:  26%|██▌       | 523/2000 [15:26<26:56,  1.09s/iteration, mean_rewards=-37.1]\u001b[A\n",
            "Training:  26%|██▌       | 524/2000 [15:26<23:39,  1.04iteration/s, mean_rewards=-37.1]\u001b[A\n",
            "Training:  26%|██▌       | 524/2000 [15:27<23:39,  1.04iteration/s, mean_rewards=-152] \u001b[A\n",
            "Training:  26%|██▋       | 525/2000 [15:27<24:31,  1.00iteration/s, mean_rewards=-152]\u001b[A\n",
            "Training:  26%|██▋       | 525/2000 [15:28<24:31,  1.00iteration/s, mean_rewards=-263]\u001b[A\n",
            "Training:  26%|██▋       | 526/2000 [15:28<22:13,  1.11iteration/s, mean_rewards=-263]\u001b[A\n",
            "Training:  26%|██▋       | 526/2000 [15:29<22:13,  1.11iteration/s, mean_rewards=-236]\u001b[A\n",
            "Training:  26%|██▋       | 527/2000 [15:29<21:47,  1.13iteration/s, mean_rewards=-236]\u001b[A\n",
            "Training:  26%|██▋       | 527/2000 [15:29<21:47,  1.13iteration/s, mean_rewards=-192]\u001b[A\n",
            "Training:  26%|██▋       | 528/2000 [15:30<22:13,  1.10iteration/s, mean_rewards=-192]\u001b[A\n",
            "Training:  26%|██▋       | 528/2000 [15:30<22:13,  1.10iteration/s, mean_rewards=-421]\u001b[A\n",
            "Training:  26%|██▋       | 529/2000 [15:31<23:26,  1.05iteration/s, mean_rewards=-421]\u001b[A\n",
            "Training:  26%|██▋       | 529/2000 [15:31<23:26,  1.05iteration/s, mean_rewards=-233]\u001b[A\n",
            "Training:  26%|██▋       | 530/2000 [15:32<22:10,  1.10iteration/s, mean_rewards=-233]\u001b[A\n",
            "Training:  26%|██▋       | 530/2000 [15:32<22:10,  1.10iteration/s, mean_rewards=-322]\u001b[A\n",
            "Training:  27%|██▋       | 531/2000 [15:33<23:17,  1.05iteration/s, mean_rewards=-322]\u001b[A\n",
            "Training:  27%|██▋       | 531/2000 [15:33<23:17,  1.05iteration/s, mean_rewards=-176]\u001b[A\n",
            "Training:  27%|██▋       | 532/2000 [15:34<21:08,  1.16iteration/s, mean_rewards=-176]\u001b[A\n",
            "Training:  27%|██▋       | 532/2000 [15:34<21:08,  1.16iteration/s, mean_rewards=-208]\u001b[A\n",
            "Training:  27%|██▋       | 533/2000 [15:35<22:29,  1.09iteration/s, mean_rewards=-208]\u001b[A\n",
            "Training:  27%|██▋       | 533/2000 [15:35<22:29,  1.09iteration/s, mean_rewards=-202]\u001b[A\n",
            "Training:  27%|██▋       | 534/2000 [15:36<23:35,  1.04iteration/s, mean_rewards=-202]\u001b[A\n",
            "Training:  27%|██▋       | 534/2000 [15:36<23:35,  1.04iteration/s, mean_rewards=-276]\u001b[A\n",
            "Training:  27%|██▋       | 535/2000 [15:37<24:05,  1.01iteration/s, mean_rewards=-276]\u001b[A\n",
            "Training:  27%|██▋       | 535/2000 [15:37<24:05,  1.01iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  27%|██▋       | 536/2000 [15:38<26:40,  1.09s/iteration, mean_rewards=-124]\u001b[A\n",
            "Training:  27%|██▋       | 536/2000 [15:38<26:40,  1.09s/iteration, mean_rewards=-131]\u001b[A\n",
            "Training:  27%|██▋       | 537/2000 [15:39<24:37,  1.01s/iteration, mean_rewards=-131]\u001b[A\n",
            "Training:  27%|██▋       | 537/2000 [15:39<24:37,  1.01s/iteration, mean_rewards=-211]\u001b[A\n",
            "Training:  27%|██▋       | 538/2000 [15:40<21:58,  1.11iteration/s, mean_rewards=-211]\u001b[A\n",
            "Training:  27%|██▋       | 538/2000 [15:40<21:58,  1.11iteration/s, mean_rewards=-240]\u001b[A\n",
            "Training:  27%|██▋       | 539/2000 [15:40<21:13,  1.15iteration/s, mean_rewards=-240]\u001b[A\n",
            "Training:  27%|██▋       | 539/2000 [15:41<21:13,  1.15iteration/s, mean_rewards=-266]\u001b[A\n",
            "Training:  27%|██▋       | 540/2000 [15:41<21:43,  1.12iteration/s, mean_rewards=-266]\u001b[A\n",
            "Training:  27%|██▋       | 540/2000 [15:42<21:43,  1.12iteration/s, mean_rewards=-165]\u001b[A\n",
            "Training:  27%|██▋       | 541/2000 [15:42<20:54,  1.16iteration/s, mean_rewards=-165]\u001b[A\n",
            "Training:  27%|██▋       | 541/2000 [15:42<20:54,  1.16iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:  27%|██▋       | 542/2000 [15:43<21:21,  1.14iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:  27%|██▋       | 542/2000 [15:43<21:21,  1.14iteration/s, mean_rewards=-305]\u001b[A\n",
            "Training:  27%|██▋       | 543/2000 [15:44<21:10,  1.15iteration/s, mean_rewards=-305]\u001b[A\n",
            "Training:  27%|██▋       | 543/2000 [15:44<21:10,  1.15iteration/s, mean_rewards=-271]\u001b[A\n",
            "Training:  27%|██▋       | 544/2000 [15:45<21:55,  1.11iteration/s, mean_rewards=-271]\u001b[A\n",
            "Training:  27%|██▋       | 544/2000 [15:45<21:55,  1.11iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  27%|██▋       | 545/2000 [15:45<20:20,  1.19iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  27%|██▋       | 545/2000 [15:46<20:20,  1.19iteration/s, mean_rewards=-214]\u001b[A\n",
            "Training:  27%|██▋       | 546/2000 [15:47<21:56,  1.10iteration/s, mean_rewards=-214]\u001b[A\n",
            "Training:  27%|██▋       | 546/2000 [15:47<21:56,  1.10iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  27%|██▋       | 547/2000 [15:47<21:07,  1.15iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  27%|██▋       | 547/2000 [15:48<21:07,  1.15iteration/s, mean_rewards=-293]\u001b[A\n",
            "Training:  27%|██▋       | 548/2000 [15:48<20:33,  1.18iteration/s, mean_rewards=-293]\u001b[A\n",
            "Training:  27%|██▋       | 548/2000 [15:49<20:33,  1.18iteration/s, mean_rewards=-175]\u001b[A\n",
            "Training:  27%|██▋       | 549/2000 [15:49<23:18,  1.04iteration/s, mean_rewards=-175]\u001b[A\n",
            "Training:  27%|██▋       | 549/2000 [15:50<23:18,  1.04iteration/s, mean_rewards=-239]\u001b[A\n",
            "Training:  28%|██▊       | 550/2000 [15:50<24:27,  1.01s/iteration, mean_rewards=-239]\u001b[A\n",
            "Training:  28%|██▊       | 550/2000 [15:51<24:27,  1.01s/iteration, mean_rewards=-263]\u001b[A\n",
            "Training:  28%|██▊       | 551/2000 [15:52<25:00,  1.04s/iteration, mean_rewards=-263]\u001b[A\n",
            "Training:  28%|██▊       | 551/2000 [15:52<25:00,  1.04s/iteration, mean_rewards=-246]\u001b[A\n",
            "Training:  28%|██▊       | 552/2000 [15:53<24:32,  1.02s/iteration, mean_rewards=-246]\u001b[A\n",
            "Training:  28%|██▊       | 552/2000 [15:53<24:32,  1.02s/iteration, mean_rewards=-295]\u001b[A\n",
            "Training:  28%|██▊       | 553/2000 [15:54<25:12,  1.05s/iteration, mean_rewards=-295]\u001b[A\n",
            "Training:  28%|██▊       | 553/2000 [15:54<25:12,  1.05s/iteration, mean_rewards=-261]\u001b[A\n",
            "Training:  28%|██▊       | 554/2000 [15:55<23:47,  1.01iteration/s, mean_rewards=-261]\u001b[A\n",
            "Training:  28%|██▊       | 554/2000 [15:55<23:47,  1.01iteration/s, mean_rewards=-242]\u001b[A\n",
            "Training:  28%|██▊       | 555/2000 [15:55<22:38,  1.06iteration/s, mean_rewards=-242]\u001b[A\n",
            "Training:  28%|██▊       | 555/2000 [15:56<22:38,  1.06iteration/s, mean_rewards=-208]\u001b[A\n",
            "Training:  28%|██▊       | 556/2000 [15:56<21:36,  1.11iteration/s, mean_rewards=-208]\u001b[A\n",
            "Training:  28%|██▊       | 556/2000 [15:56<21:36,  1.11iteration/s, mean_rewards=-213]\u001b[A\n",
            "Training:  28%|██▊       | 557/2000 [15:57<20:52,  1.15iteration/s, mean_rewards=-213]\u001b[A\n",
            "Training:  28%|██▊       | 557/2000 [15:57<20:52,  1.15iteration/s, mean_rewards=-187]\u001b[A\n",
            "Training:  28%|██▊       | 558/2000 [15:58<21:29,  1.12iteration/s, mean_rewards=-187]\u001b[A\n",
            "Training:  28%|██▊       | 558/2000 [15:58<21:29,  1.12iteration/s, mean_rewards=-398]\u001b[A\n",
            "Training:  28%|██▊       | 559/2000 [15:59<22:38,  1.06iteration/s, mean_rewards=-398]\u001b[A\n",
            "Training:  28%|██▊       | 559/2000 [15:59<22:38,  1.06iteration/s, mean_rewards=-47.7]\u001b[A\n",
            "Training:  28%|██▊       | 560/2000 [16:00<22:38,  1.06iteration/s, mean_rewards=-47.7]\u001b[A\n",
            "Training:  28%|██▊       | 560/2000 [16:00<22:38,  1.06iteration/s, mean_rewards=-244] \u001b[A\n",
            "Training:  28%|██▊       | 561/2000 [16:01<21:32,  1.11iteration/s, mean_rewards=-244]\u001b[A\n",
            "Training:  28%|██▊       | 561/2000 [16:01<21:32,  1.11iteration/s, mean_rewards=-67] \u001b[A\n",
            "Training:  28%|██▊       | 562/2000 [16:01<19:43,  1.22iteration/s, mean_rewards=-67]\u001b[A\n",
            "Training:  28%|██▊       | 562/2000 [16:02<19:43,  1.22iteration/s, mean_rewards=-260]\u001b[A\n",
            "Training:  28%|██▊       | 563/2000 [16:03<22:09,  1.08iteration/s, mean_rewards=-260]\u001b[A\n",
            "Training:  28%|██▊       | 563/2000 [16:03<22:09,  1.08iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:  28%|██▊       | 564/2000 [16:04<23:19,  1.03iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:  28%|██▊       | 564/2000 [16:04<23:19,  1.03iteration/s, mean_rewards=-374]\u001b[A\n",
            "Training:  28%|██▊       | 565/2000 [16:05<26:31,  1.11s/iteration, mean_rewards=-374]\u001b[A\n",
            "Training:  28%|██▊       | 565/2000 [16:05<26:31,  1.11s/iteration, mean_rewards=-254]\u001b[A\n",
            "Training:  28%|██▊       | 566/2000 [16:06<25:18,  1.06s/iteration, mean_rewards=-254]\u001b[A\n",
            "Training:  28%|██▊       | 566/2000 [16:06<25:18,  1.06s/iteration, mean_rewards=-209]\u001b[A\n",
            "Training:  28%|██▊       | 567/2000 [16:07<24:09,  1.01s/iteration, mean_rewards=-209]\u001b[A\n",
            "Training:  28%|██▊       | 567/2000 [16:07<24:09,  1.01s/iteration, mean_rewards=-234]\u001b[A\n",
            "Training:  28%|██▊       | 568/2000 [16:08<22:37,  1.05iteration/s, mean_rewards=-234]\u001b[A\n",
            "Training:  28%|██▊       | 568/2000 [16:08<22:37,  1.05iteration/s, mean_rewards=-245]\u001b[A\n",
            "Training:  28%|██▊       | 569/2000 [16:08<21:45,  1.10iteration/s, mean_rewards=-245]\u001b[A\n",
            "Training:  28%|██▊       | 569/2000 [16:09<21:45,  1.10iteration/s, mean_rewards=-28] \u001b[A\n",
            "Training:  28%|██▊       | 570/2000 [16:09<20:02,  1.19iteration/s, mean_rewards=-28]\u001b[A\n",
            "Training:  28%|██▊       | 570/2000 [16:09<20:02,  1.19iteration/s, mean_rewards=-282]\u001b[A\n",
            "Training:  29%|██▊       | 571/2000 [16:10<19:44,  1.21iteration/s, mean_rewards=-282]\u001b[A\n",
            "Training:  29%|██▊       | 571/2000 [16:10<19:44,  1.21iteration/s, mean_rewards=-219]\u001b[A\n",
            "Training:  29%|██▊       | 572/2000 [16:11<18:47,  1.27iteration/s, mean_rewards=-219]\u001b[A\n",
            "Training:  29%|██▊       | 572/2000 [16:11<18:47,  1.27iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:  29%|██▊       | 573/2000 [16:11<18:54,  1.26iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:  29%|██▊       | 573/2000 [16:12<18:54,  1.26iteration/s, mean_rewards=-170]\u001b[A\n",
            "Training:  29%|██▊       | 574/2000 [16:13<21:06,  1.13iteration/s, mean_rewards=-170]\u001b[A\n",
            "Training:  29%|██▊       | 574/2000 [16:13<21:06,  1.13iteration/s, mean_rewards=-212]\u001b[A\n",
            "Training:  29%|██▉       | 575/2000 [16:13<20:32,  1.16iteration/s, mean_rewards=-212]\u001b[A\n",
            "Training:  29%|██▉       | 575/2000 [16:14<20:32,  1.16iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  29%|██▉       | 576/2000 [16:15<22:27,  1.06iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  29%|██▉       | 576/2000 [16:15<22:27,  1.06iteration/s, mean_rewards=-271]\u001b[A\n",
            "Training:  29%|██▉       | 577/2000 [16:16<25:45,  1.09s/iteration, mean_rewards=-271]\u001b[A\n",
            "Training:  29%|██▉       | 577/2000 [16:16<25:45,  1.09s/iteration, mean_rewards=-172]\u001b[A\n",
            "Training:  29%|██▉       | 578/2000 [16:17<26:39,  1.12s/iteration, mean_rewards=-172]\u001b[A\n",
            "Training:  29%|██▉       | 578/2000 [16:17<26:39,  1.12s/iteration, mean_rewards=-133]\u001b[A\n",
            "Training:  29%|██▉       | 579/2000 [16:18<24:39,  1.04s/iteration, mean_rewards=-133]\u001b[A\n",
            "Training:  29%|██▉       | 579/2000 [16:18<24:39,  1.04s/iteration, mean_rewards=-220]\u001b[A\n",
            "Training:  29%|██▉       | 580/2000 [16:19<22:48,  1.04iteration/s, mean_rewards=-220]\u001b[A\n",
            "Training:  29%|██▉       | 580/2000 [16:19<22:48,  1.04iteration/s, mean_rewards=-222]\u001b[A\n",
            "Training:  29%|██▉       | 581/2000 [16:20<21:37,  1.09iteration/s, mean_rewards=-222]\u001b[A\n",
            "Training:  29%|██▉       | 581/2000 [16:20<21:37,  1.09iteration/s, mean_rewards=-225]\u001b[A\n",
            "Training:  29%|██▉       | 582/2000 [16:21<22:57,  1.03iteration/s, mean_rewards=-225]\u001b[A\n",
            "Training:  29%|██▉       | 582/2000 [16:21<22:57,  1.03iteration/s, mean_rewards=-278]\u001b[A\n",
            "Training:  29%|██▉       | 583/2000 [16:22<22:39,  1.04iteration/s, mean_rewards=-278]\u001b[A\n",
            "Training:  29%|██▉       | 583/2000 [16:22<22:39,  1.04iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  29%|██▉       | 584/2000 [16:22<21:28,  1.10iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  29%|██▉       | 584/2000 [16:23<21:28,  1.10iteration/s, mean_rewards=-287]\u001b[A\n",
            "Training:  29%|██▉       | 585/2000 [16:23<21:26,  1.10iteration/s, mean_rewards=-287]\u001b[A\n",
            "Training:  29%|██▉       | 585/2000 [16:24<21:26,  1.10iteration/s, mean_rewards=-294]\u001b[A\n",
            "Training:  29%|██▉       | 586/2000 [16:24<21:33,  1.09iteration/s, mean_rewards=-294]\u001b[A\n",
            "Training:  29%|██▉       | 586/2000 [16:25<21:33,  1.09iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:  29%|██▉       | 587/2000 [16:25<23:15,  1.01iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:  29%|██▉       | 587/2000 [16:26<23:15,  1.01iteration/s, mean_rewards=-164]\u001b[A\n",
            "Training:  29%|██▉       | 588/2000 [16:26<23:31,  1.00iteration/s, mean_rewards=-164]\u001b[A\n",
            "Training:  29%|██▉       | 588/2000 [16:27<23:31,  1.00iteration/s, mean_rewards=-195]\u001b[A\n",
            "Training:  29%|██▉       | 589/2000 [16:27<22:27,  1.05iteration/s, mean_rewards=-195]\u001b[A\n",
            "Training:  29%|██▉       | 589/2000 [16:28<22:27,  1.05iteration/s, mean_rewards=-289]\u001b[A\n",
            "Training:  30%|██▉       | 590/2000 [16:29<24:29,  1.04s/iteration, mean_rewards=-289]\u001b[A\n",
            "Training:  30%|██▉       | 590/2000 [16:29<24:29,  1.04s/iteration, mean_rewards=-236]\u001b[A\n",
            "Training:  30%|██▉       | 591/2000 [16:30<28:20,  1.21s/iteration, mean_rewards=-236]\u001b[A\n",
            "Training:  30%|██▉       | 591/2000 [16:30<28:20,  1.21s/iteration, mean_rewards=-110]\u001b[A\n",
            "Training:  30%|██▉       | 592/2000 [16:31<25:46,  1.10s/iteration, mean_rewards=-110]\u001b[A\n",
            "Training:  30%|██▉       | 592/2000 [16:31<25:46,  1.10s/iteration, mean_rewards=-75] \u001b[A\n",
            "Training:  30%|██▉       | 593/2000 [16:32<23:46,  1.01s/iteration, mean_rewards=-75]\u001b[A\n",
            "Training:  30%|██▉       | 593/2000 [16:32<23:46,  1.01s/iteration, mean_rewards=-198]\u001b[A\n",
            "Training:  30%|██▉       | 594/2000 [16:33<23:27,  1.00s/iteration, mean_rewards=-198]\u001b[A\n",
            "Training:  30%|██▉       | 594/2000 [16:33<23:27,  1.00s/iteration, mean_rewards=-179]\u001b[A\n",
            "Training:  30%|██▉       | 595/2000 [16:34<23:15,  1.01iteration/s, mean_rewards=-179]\u001b[A\n",
            "Training:  30%|██▉       | 595/2000 [16:34<23:15,  1.01iteration/s, mean_rewards=-95.3]\u001b[A\n",
            "Training:  30%|██▉       | 596/2000 [16:34<21:10,  1.10iteration/s, mean_rewards=-95.3]\u001b[A\n",
            "Training:  30%|██▉       | 596/2000 [16:35<21:10,  1.10iteration/s, mean_rewards=-199] \u001b[A\n",
            "Training:  30%|██▉       | 597/2000 [16:35<21:38,  1.08iteration/s, mean_rewards=-199]\u001b[A\n",
            "Training:  30%|██▉       | 597/2000 [16:36<21:38,  1.08iteration/s, mean_rewards=-231]\u001b[A\n",
            "Training:  30%|██▉       | 598/2000 [16:36<21:39,  1.08iteration/s, mean_rewards=-231]\u001b[A\n",
            "Training:  30%|██▉       | 598/2000 [16:37<21:39,  1.08iteration/s, mean_rewards=-223]\u001b[A\n",
            "Training:  30%|██▉       | 599/2000 [16:37<21:14,  1.10iteration/s, mean_rewards=-223]\u001b[A\n",
            "Training:  30%|██▉       | 599/2000 [16:37<21:14,  1.10iteration/s, mean_rewards=-84.3]\u001b[A\n",
            "Training:  30%|███       | 600/2000 [16:38<19:32,  1.19iteration/s, mean_rewards=-84.3]\u001b[A\n",
            "Training:  30%|███       | 600/2000 [16:38<19:32,  1.19iteration/s, mean_rewards=-90.6]\u001b[A\n",
            "Training:  30%|███       | 601/2000 [16:39<18:29,  1.26iteration/s, mean_rewards=-90.6]\u001b[A\n",
            "Training:  30%|███       | 601/2000 [16:39<18:29,  1.26iteration/s, mean_rewards=-299] \u001b[A\n",
            "Training:  30%|███       | 602/2000 [16:39<18:28,  1.26iteration/s, mean_rewards=-299]\u001b[A\n",
            "Training:  30%|███       | 602/2000 [16:40<18:28,  1.26iteration/s, mean_rewards=-349]\u001b[A\n",
            "Training:  30%|███       | 603/2000 [16:40<19:16,  1.21iteration/s, mean_rewards=-349]\u001b[A\n",
            "Training:  30%|███       | 603/2000 [16:41<19:16,  1.21iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  30%|███       | 604/2000 [16:42<24:29,  1.05s/iteration, mean_rewards=-151]\u001b[A\n",
            "Training:  30%|███       | 604/2000 [16:42<24:29,  1.05s/iteration, mean_rewards=-392]\u001b[A\n",
            "Training:  30%|███       | 605/2000 [16:43<24:57,  1.07s/iteration, mean_rewards=-392]\u001b[A\n",
            "Training:  30%|███       | 605/2000 [16:43<24:57,  1.07s/iteration, mean_rewards=-185]\u001b[A\n",
            "Training:  30%|███       | 606/2000 [16:44<23:02,  1.01iteration/s, mean_rewards=-185]\u001b[A\n",
            "Training:  30%|███       | 606/2000 [16:44<23:02,  1.01iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  30%|███       | 607/2000 [16:45<22:38,  1.03iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  30%|███       | 607/2000 [16:45<22:38,  1.03iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  30%|███       | 608/2000 [16:45<21:19,  1.09iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  30%|███       | 608/2000 [16:46<21:19,  1.09iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  30%|███       | 609/2000 [16:47<22:20,  1.04iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  30%|███       | 609/2000 [16:47<22:20,  1.04iteration/s, mean_rewards=-104]\u001b[A\n",
            "Training:  30%|███       | 610/2000 [16:47<20:13,  1.15iteration/s, mean_rewards=-104]\u001b[A\n",
            "Training:  30%|███       | 610/2000 [16:48<20:13,  1.15iteration/s, mean_rewards=-459]\u001b[A\n",
            "Training:  31%|███       | 611/2000 [16:48<20:48,  1.11iteration/s, mean_rewards=-459]\u001b[A\n",
            "Training:  31%|███       | 611/2000 [16:49<20:48,  1.11iteration/s, mean_rewards=-165]\u001b[A\n",
            "Training:  31%|███       | 612/2000 [16:49<20:56,  1.10iteration/s, mean_rewards=-165]\u001b[A\n",
            "Training:  31%|███       | 612/2000 [16:49<20:56,  1.10iteration/s, mean_rewards=-64.2]\u001b[A\n",
            "Training:  31%|███       | 613/2000 [16:50<19:05,  1.21iteration/s, mean_rewards=-64.2]\u001b[A\n",
            "Training:  31%|███       | 613/2000 [16:50<19:05,  1.21iteration/s, mean_rewards=-185] \u001b[A\n",
            "Training:  31%|███       | 614/2000 [16:50<18:02,  1.28iteration/s, mean_rewards=-185]\u001b[A\n",
            "Training:  31%|███       | 614/2000 [16:51<18:02,  1.28iteration/s, mean_rewards=-266]\u001b[A\n",
            "Training:  31%|███       | 615/2000 [16:51<18:07,  1.27iteration/s, mean_rewards=-266]\u001b[A\n",
            "Training:  31%|███       | 615/2000 [16:51<18:07,  1.27iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  31%|███       | 616/2000 [16:52<17:20,  1.33iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  31%|███       | 616/2000 [16:52<17:20,  1.33iteration/s, mean_rewards=-84.9]\u001b[A\n",
            "Training:  31%|███       | 617/2000 [16:53<16:35,  1.39iteration/s, mean_rewards=-84.9]\u001b[A\n",
            "Training:  31%|███       | 617/2000 [16:53<16:35,  1.39iteration/s, mean_rewards=-245] \u001b[A\n",
            "Training:  31%|███       | 618/2000 [16:54<19:17,  1.19iteration/s, mean_rewards=-245]\u001b[A\n",
            "Training:  31%|███       | 618/2000 [16:54<19:17,  1.19iteration/s, mean_rewards=-171]\u001b[A\n",
            "Training:  31%|███       | 619/2000 [16:55<19:43,  1.17iteration/s, mean_rewards=-171]\u001b[A\n",
            "Training:  31%|███       | 619/2000 [16:55<19:43,  1.17iteration/s, mean_rewards=-246]\u001b[A\n",
            "Training:  31%|███       | 620/2000 [16:56<21:34,  1.07iteration/s, mean_rewards=-246]\u001b[A\n",
            "Training:  31%|███       | 620/2000 [16:56<21:34,  1.07iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  31%|███       | 621/2000 [16:56<20:44,  1.11iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  31%|███       | 621/2000 [16:57<20:44,  1.11iteration/s, mean_rewards=-195]\u001b[A\n",
            "Training:  31%|███       | 622/2000 [16:57<20:20,  1.13iteration/s, mean_rewards=-195]\u001b[A\n",
            "Training:  31%|███       | 622/2000 [16:58<20:20,  1.13iteration/s, mean_rewards=-240]\u001b[A\n",
            "Training:  31%|███       | 623/2000 [16:58<20:02,  1.15iteration/s, mean_rewards=-240]\u001b[A\n",
            "Training:  31%|███       | 623/2000 [16:58<20:02,  1.15iteration/s, mean_rewards=-234]\u001b[A\n",
            "Training:  31%|███       | 624/2000 [16:59<19:28,  1.18iteration/s, mean_rewards=-234]\u001b[A\n",
            "Training:  31%|███       | 624/2000 [16:59<19:28,  1.18iteration/s, mean_rewards=-163]\u001b[A\n",
            "Training:  31%|███▏      | 625/2000 [17:00<20:13,  1.13iteration/s, mean_rewards=-163]\u001b[A\n",
            "Training:  31%|███▏      | 625/2000 [17:00<20:13,  1.13iteration/s, mean_rewards=-218]\u001b[A\n",
            "Training:  31%|███▏      | 626/2000 [17:01<20:29,  1.12iteration/s, mean_rewards=-218]\u001b[A\n",
            "Training:  31%|███▏      | 626/2000 [17:01<20:29,  1.12iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  31%|███▏      | 627/2000 [17:02<19:03,  1.20iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  31%|███▏      | 627/2000 [17:02<19:03,  1.20iteration/s, mean_rewards=-264]\u001b[A\n",
            "Training:  31%|███▏      | 628/2000 [17:02<18:45,  1.22iteration/s, mean_rewards=-264]\u001b[A\n",
            "Training:  31%|███▏      | 628/2000 [17:03<18:45,  1.22iteration/s, mean_rewards=-163]\u001b[A\n",
            "Training:  31%|███▏      | 629/2000 [17:03<18:28,  1.24iteration/s, mean_rewards=-163]\u001b[A\n",
            "Training:  31%|███▏      | 629/2000 [17:03<18:28,  1.24iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  32%|███▏      | 630/2000 [17:04<18:09,  1.26iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  32%|███▏      | 630/2000 [17:04<18:09,  1.26iteration/s, mean_rewards=-319]\u001b[A\n",
            "Training:  32%|███▏      | 631/2000 [17:05<17:19,  1.32iteration/s, mean_rewards=-319]\u001b[A\n",
            "Training:  32%|███▏      | 631/2000 [17:05<17:19,  1.32iteration/s, mean_rewards=-197]\u001b[A\n",
            "Training:  32%|███▏      | 632/2000 [17:05<18:20,  1.24iteration/s, mean_rewards=-197]\u001b[A\n",
            "Training:  32%|███▏      | 632/2000 [17:06<18:20,  1.24iteration/s, mean_rewards=-103]\u001b[A\n",
            "Training:  32%|███▏      | 633/2000 [17:07<21:07,  1.08iteration/s, mean_rewards=-103]\u001b[A\n",
            "Training:  32%|███▏      | 633/2000 [17:07<21:07,  1.08iteration/s, mean_rewards=-247]\u001b[A\n",
            "Training:  32%|███▏      | 634/2000 [17:08<24:32,  1.08s/iteration, mean_rewards=-247]\u001b[A\n",
            "Training:  32%|███▏      | 634/2000 [17:08<24:32,  1.08s/iteration, mean_rewards=-197]\u001b[A\n",
            "Training:  32%|███▏      | 635/2000 [17:09<22:30,  1.01iteration/s, mean_rewards=-197]\u001b[A\n",
            "Training:  32%|███▏      | 635/2000 [17:09<22:30,  1.01iteration/s, mean_rewards=-213]\u001b[A\n",
            "Training:  32%|███▏      | 636/2000 [17:10<21:50,  1.04iteration/s, mean_rewards=-213]\u001b[A\n",
            "Training:  32%|███▏      | 636/2000 [17:10<21:50,  1.04iteration/s, mean_rewards=-326]\u001b[A\n",
            "Training:  32%|███▏      | 637/2000 [17:11<21:46,  1.04iteration/s, mean_rewards=-326]\u001b[A\n",
            "Training:  32%|███▏      | 637/2000 [17:11<21:46,  1.04iteration/s, mean_rewards=-116]\u001b[A\n",
            "Training:  32%|███▏      | 638/2000 [17:12<21:24,  1.06iteration/s, mean_rewards=-116]\u001b[A\n",
            "Training:  32%|███▏      | 638/2000 [17:12<21:24,  1.06iteration/s, mean_rewards=-183]\u001b[A\n",
            "Training:  32%|███▏      | 639/2000 [17:12<20:21,  1.11iteration/s, mean_rewards=-183]\u001b[A\n",
            "Training:  32%|███▏      | 639/2000 [17:13<20:21,  1.11iteration/s, mean_rewards=-212]\u001b[A\n",
            "Training:  32%|███▏      | 640/2000 [17:14<21:37,  1.05iteration/s, mean_rewards=-212]\u001b[A\n",
            "Training:  32%|███▏      | 640/2000 [17:14<21:37,  1.05iteration/s, mean_rewards=-207]\u001b[A\n",
            "Training:  32%|███▏      | 641/2000 [17:14<19:48,  1.14iteration/s, mean_rewards=-207]\u001b[A\n",
            "Training:  32%|███▏      | 641/2000 [17:15<19:48,  1.14iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  32%|███▏      | 642/2000 [17:15<20:06,  1.13iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  32%|███▏      | 642/2000 [17:16<20:06,  1.13iteration/s, mean_rewards=-186]\u001b[A\n",
            "Training:  32%|███▏      | 643/2000 [17:16<21:24,  1.06iteration/s, mean_rewards=-186]\u001b[A\n",
            "Training:  32%|███▏      | 643/2000 [17:17<21:24,  1.06iteration/s, mean_rewards=-193]\u001b[A\n",
            "Training:  32%|███▏      | 644/2000 [17:17<22:15,  1.02iteration/s, mean_rewards=-193]\u001b[A\n",
            "Training:  32%|███▏      | 644/2000 [17:18<22:15,  1.02iteration/s, mean_rewards=-289]\u001b[A\n",
            "Training:  32%|███▏      | 645/2000 [17:18<22:01,  1.03iteration/s, mean_rewards=-289]\u001b[A\n",
            "Training:  32%|███▏      | 645/2000 [17:19<22:01,  1.03iteration/s, mean_rewards=-302]\u001b[A\n",
            "Training:  32%|███▏      | 646/2000 [17:20<24:36,  1.09s/iteration, mean_rewards=-302]\u001b[A\n",
            "Training:  32%|███▏      | 646/2000 [17:20<24:36,  1.09s/iteration, mean_rewards=-256]\u001b[A\n",
            "Training:  32%|███▏      | 647/2000 [17:21<25:00,  1.11s/iteration, mean_rewards=-256]\u001b[A\n",
            "Training:  32%|███▏      | 647/2000 [17:21<25:00,  1.11s/iteration, mean_rewards=-325]\u001b[A\n",
            "Training:  32%|███▏      | 648/2000 [17:22<25:04,  1.11s/iteration, mean_rewards=-325]\u001b[A\n",
            "Training:  32%|███▏      | 648/2000 [17:22<25:04,  1.11s/iteration, mean_rewards=-151]\u001b[A\n",
            "Training:  32%|███▏      | 649/2000 [17:23<23:55,  1.06s/iteration, mean_rewards=-151]\u001b[A\n",
            "Training:  32%|███▏      | 649/2000 [17:23<23:55,  1.06s/iteration, mean_rewards=-146]\u001b[A\n",
            "Training:  32%|███▎      | 650/2000 [17:24<22:54,  1.02s/iteration, mean_rewards=-146]\u001b[A\n",
            "Training:  32%|███▎      | 650/2000 [17:24<22:54,  1.02s/iteration, mean_rewards=-175]\u001b[A\n",
            "Training:  33%|███▎      | 651/2000 [17:25<21:20,  1.05iteration/s, mean_rewards=-175]\u001b[A\n",
            "Training:  33%|███▎      | 651/2000 [17:25<21:20,  1.05iteration/s, mean_rewards=-221]\u001b[A\n",
            "Training:  33%|███▎      | 652/2000 [17:26<22:08,  1.01iteration/s, mean_rewards=-221]\u001b[A\n",
            "Training:  33%|███▎      | 652/2000 [17:26<22:08,  1.01iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  33%|███▎      | 653/2000 [17:26<20:54,  1.07iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  33%|███▎      | 653/2000 [17:27<20:54,  1.07iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  33%|███▎      | 654/2000 [17:27<19:56,  1.13iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  33%|███▎      | 654/2000 [17:28<19:56,  1.13iteration/s, mean_rewards=-244]\u001b[A\n",
            "Training:  33%|███▎      | 655/2000 [17:28<20:19,  1.10iteration/s, mean_rewards=-244]\u001b[A\n",
            "Training:  33%|███▎      | 655/2000 [17:28<20:19,  1.10iteration/s, mean_rewards=-256]\u001b[A\n",
            "Training:  33%|███▎      | 656/2000 [17:29<19:34,  1.14iteration/s, mean_rewards=-256]\u001b[A\n",
            "Training:  33%|███▎      | 656/2000 [17:29<19:34,  1.14iteration/s, mean_rewards=-91.8]\u001b[A\n",
            "Training:  33%|███▎      | 657/2000 [17:30<18:58,  1.18iteration/s, mean_rewards=-91.8]\u001b[A\n",
            "Training:  33%|███▎      | 657/2000 [17:30<18:58,  1.18iteration/s, mean_rewards=-104] \u001b[A\n",
            "Training:  33%|███▎      | 658/2000 [17:31<19:38,  1.14iteration/s, mean_rewards=-104]\u001b[A\n",
            "Training:  33%|███▎      | 658/2000 [17:31<19:38,  1.14iteration/s, mean_rewards=-85.7]\u001b[A\n",
            "Training:  33%|███▎      | 659/2000 [17:31<19:00,  1.18iteration/s, mean_rewards=-85.7]\u001b[A\n",
            "Training:  33%|███▎      | 659/2000 [17:32<19:00,  1.18iteration/s, mean_rewards=-150] \u001b[A\n",
            "Training:  33%|███▎      | 660/2000 [17:32<18:28,  1.21iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  33%|███▎      | 660/2000 [17:33<18:28,  1.21iteration/s, mean_rewards=-220]\u001b[A\n",
            "Training:  33%|███▎      | 661/2000 [17:33<20:17,  1.10iteration/s, mean_rewards=-220]\u001b[A\n",
            "Training:  33%|███▎      | 661/2000 [17:34<20:17,  1.10iteration/s, mean_rewards=-202]\u001b[A\n",
            "Training:  33%|███▎      | 662/2000 [17:34<21:03,  1.06iteration/s, mean_rewards=-202]\u001b[A\n",
            "Training:  33%|███▎      | 662/2000 [17:35<21:03,  1.06iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  33%|███▎      | 663/2000 [17:35<20:46,  1.07iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  33%|███▎      | 663/2000 [17:36<20:46,  1.07iteration/s, mean_rewards=-226]\u001b[A\n",
            "Training:  33%|███▎      | 664/2000 [17:36<20:26,  1.09iteration/s, mean_rewards=-226]\u001b[A\n",
            "Training:  33%|███▎      | 664/2000 [17:36<20:26,  1.09iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  33%|███▎      | 665/2000 [17:37<18:30,  1.20iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  33%|███▎      | 665/2000 [17:37<18:30,  1.20iteration/s, mean_rewards=-165]\u001b[A\n",
            "Training:  33%|███▎      | 666/2000 [17:38<20:05,  1.11iteration/s, mean_rewards=-165]\u001b[A\n",
            "Training:  33%|███▎      | 666/2000 [17:38<20:05,  1.11iteration/s, mean_rewards=-91.3]\u001b[A\n",
            "Training:  33%|███▎      | 667/2000 [17:39<19:19,  1.15iteration/s, mean_rewards=-91.3]\u001b[A\n",
            "Training:  33%|███▎      | 667/2000 [17:39<19:19,  1.15iteration/s, mean_rewards=-110] \u001b[A\n",
            "Training:  33%|███▎      | 668/2000 [17:39<18:37,  1.19iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  33%|███▎      | 668/2000 [17:40<18:37,  1.19iteration/s, mean_rewards=-262]\u001b[A\n",
            "Training:  33%|███▎      | 669/2000 [17:40<19:03,  1.16iteration/s, mean_rewards=-262]\u001b[A\n",
            "Training:  33%|███▎      | 669/2000 [17:41<19:03,  1.16iteration/s, mean_rewards=-233]\u001b[A\n",
            "Training:  34%|███▎      | 670/2000 [17:41<19:48,  1.12iteration/s, mean_rewards=-233]\u001b[A\n",
            "Training:  34%|███▎      | 670/2000 [17:42<19:48,  1.12iteration/s, mean_rewards=-272]\u001b[A\n",
            "Training:  34%|███▎      | 671/2000 [17:42<20:05,  1.10iteration/s, mean_rewards=-272]\u001b[A\n",
            "Training:  34%|███▎      | 671/2000 [17:43<20:05,  1.10iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  34%|███▎      | 672/2000 [17:43<19:09,  1.16iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  34%|███▎      | 672/2000 [17:43<19:09,  1.16iteration/s, mean_rewards=-109]\u001b[A\n",
            "Training:  34%|███▎      | 673/2000 [17:44<17:36,  1.26iteration/s, mean_rewards=-109]\u001b[A\n",
            "Training:  34%|███▎      | 673/2000 [17:44<17:36,  1.26iteration/s, mean_rewards=-179]\u001b[A\n",
            "Training:  34%|███▎      | 674/2000 [17:45<19:17,  1.15iteration/s, mean_rewards=-179]\u001b[A\n",
            "Training:  34%|███▎      | 674/2000 [17:45<19:17,  1.15iteration/s, mean_rewards=-229]\u001b[A\n",
            "Training:  34%|███▍      | 675/2000 [17:46<20:51,  1.06iteration/s, mean_rewards=-229]\u001b[A\n",
            "Training:  34%|███▍      | 675/2000 [17:46<20:51,  1.06iteration/s, mean_rewards=-267]\u001b[A\n",
            "Training:  34%|███▍      | 676/2000 [17:47<22:35,  1.02s/iteration, mean_rewards=-267]\u001b[A\n",
            "Training:  34%|███▍      | 676/2000 [17:47<22:35,  1.02s/iteration, mean_rewards=-266]\u001b[A\n",
            "Training:  34%|███▍      | 677/2000 [17:48<20:57,  1.05iteration/s, mean_rewards=-266]\u001b[A\n",
            "Training:  34%|███▍      | 677/2000 [17:48<20:57,  1.05iteration/s, mean_rewards=-269]\u001b[A\n",
            "Training:  34%|███▍      | 678/2000 [17:49<22:03,  1.00s/iteration, mean_rewards=-269]\u001b[A\n",
            "Training:  34%|███▍      | 678/2000 [17:49<22:03,  1.00s/iteration, mean_rewards=-112]\u001b[A\n",
            "Training:  34%|███▍      | 679/2000 [17:50<22:22,  1.02s/iteration, mean_rewards=-112]\u001b[A\n",
            "Training:  34%|███▍      | 679/2000 [17:50<22:22,  1.02s/iteration, mean_rewards=-75.9]\u001b[A\n",
            "Training:  34%|███▍      | 680/2000 [17:51<23:23,  1.06s/iteration, mean_rewards=-75.9]\u001b[A\n",
            "Training:  34%|███▍      | 680/2000 [17:51<23:23,  1.06s/iteration, mean_rewards=-118] \u001b[A\n",
            "Training:  34%|███▍      | 681/2000 [17:52<21:40,  1.01iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  34%|███▍      | 681/2000 [17:52<21:40,  1.01iteration/s, mean_rewards=-299]\u001b[A\n",
            "Training:  34%|███▍      | 682/2000 [17:53<21:26,  1.02iteration/s, mean_rewards=-299]\u001b[A\n",
            "Training:  34%|███▍      | 682/2000 [17:53<21:26,  1.02iteration/s, mean_rewards=-335]\u001b[A\n",
            "Training:  34%|███▍      | 683/2000 [17:54<21:07,  1.04iteration/s, mean_rewards=-335]\u001b[A\n",
            "Training:  34%|███▍      | 683/2000 [17:54<21:07,  1.04iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  34%|███▍      | 684/2000 [17:55<20:57,  1.05iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  34%|███▍      | 684/2000 [17:55<20:57,  1.05iteration/s, mean_rewards=-376]\u001b[A\n",
            "Training:  34%|███▍      | 685/2000 [17:56<19:53,  1.10iteration/s, mean_rewards=-376]\u001b[A\n",
            "Training:  34%|███▍      | 685/2000 [17:56<19:53,  1.10iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  34%|███▍      | 686/2000 [17:56<18:16,  1.20iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  34%|███▍      | 686/2000 [17:57<18:16,  1.20iteration/s, mean_rewards=-224]\u001b[A\n",
            "Training:  34%|███▍      | 687/2000 [17:57<17:52,  1.22iteration/s, mean_rewards=-224]\u001b[A\n",
            "Training:  34%|███▍      | 687/2000 [17:57<17:52,  1.22iteration/s, mean_rewards=-112]\u001b[A\n",
            "Training:  34%|███▍      | 688/2000 [17:58<19:44,  1.11iteration/s, mean_rewards=-112]\u001b[A\n",
            "Training:  34%|███▍      | 688/2000 [17:58<19:44,  1.11iteration/s, mean_rewards=-206]\u001b[A\n",
            "Training:  34%|███▍      | 689/2000 [17:59<21:20,  1.02iteration/s, mean_rewards=-206]\u001b[A\n",
            "Training:  34%|███▍      | 689/2000 [18:00<21:20,  1.02iteration/s, mean_rewards=-193]\u001b[A\n",
            "Training:  34%|███▍      | 690/2000 [18:00<22:13,  1.02s/iteration, mean_rewards=-193]\u001b[A\n",
            "Training:  34%|███▍      | 690/2000 [18:01<22:13,  1.02s/iteration, mean_rewards=-219]\u001b[A\n",
            "Training:  35%|███▍      | 691/2000 [18:01<21:36,  1.01iteration/s, mean_rewards=-219]\u001b[A\n",
            "Training:  35%|███▍      | 691/2000 [18:02<21:36,  1.01iteration/s, mean_rewards=-276]\u001b[A\n",
            "Training:  35%|███▍      | 692/2000 [18:02<20:41,  1.05iteration/s, mean_rewards=-276]\u001b[A\n",
            "Training:  35%|███▍      | 692/2000 [18:02<20:41,  1.05iteration/s, mean_rewards=-89.7]\u001b[A\n",
            "Training:  35%|███▍      | 693/2000 [18:03<18:55,  1.15iteration/s, mean_rewards=-89.7]\u001b[A\n",
            "Training:  35%|███▍      | 693/2000 [18:03<18:55,  1.15iteration/s, mean_rewards=-106] \u001b[A\n",
            "Training:  35%|███▍      | 694/2000 [18:04<18:31,  1.18iteration/s, mean_rewards=-106]\u001b[A\n",
            "Training:  35%|███▍      | 694/2000 [18:04<18:31,  1.18iteration/s, mean_rewards=-232]\u001b[A\n",
            "Training:  35%|███▍      | 695/2000 [18:05<20:04,  1.08iteration/s, mean_rewards=-232]\u001b[A\n",
            "Training:  35%|███▍      | 695/2000 [18:05<20:04,  1.08iteration/s, mean_rewards=-104]\u001b[A\n",
            "Training:  35%|███▍      | 696/2000 [18:05<18:18,  1.19iteration/s, mean_rewards=-104]\u001b[A\n",
            "Training:  35%|███▍      | 696/2000 [18:06<18:18,  1.19iteration/s, mean_rewards=-223]\u001b[A\n",
            "Training:  35%|███▍      | 697/2000 [18:06<19:29,  1.11iteration/s, mean_rewards=-223]\u001b[A\n",
            "Training:  35%|███▍      | 697/2000 [18:07<19:29,  1.11iteration/s, mean_rewards=-208]\u001b[A\n",
            "Training:  35%|███▍      | 698/2000 [18:07<18:50,  1.15iteration/s, mean_rewards=-208]\u001b[A\n",
            "Training:  35%|███▍      | 698/2000 [18:08<18:50,  1.15iteration/s, mean_rewards=-249]\u001b[A\n",
            "Training:  35%|███▍      | 699/2000 [18:08<19:08,  1.13iteration/s, mean_rewards=-249]\u001b[A\n",
            "Training:  35%|███▍      | 699/2000 [18:08<19:08,  1.13iteration/s, mean_rewards=-290]\u001b[A\n",
            "Training:  35%|███▌      | 700/2000 [18:09<18:37,  1.16iteration/s, mean_rewards=-290]\u001b[A\n",
            "Training:  35%|███▌      | 700/2000 [18:09<18:37,  1.16iteration/s, mean_rewards=-70.6]\u001b[A\n",
            "Training:  35%|███▌      | 701/2000 [18:10<17:33,  1.23iteration/s, mean_rewards=-70.6]\u001b[A\n",
            "Training:  35%|███▌      | 701/2000 [18:10<17:33,  1.23iteration/s, mean_rewards=13.9] \u001b[A\n",
            "Training:  35%|███▌      | 702/2000 [18:11<21:31,  1.01iteration/s, mean_rewards=13.9]\u001b[A\n",
            "Training:  35%|███▌      | 702/2000 [18:11<21:31,  1.01iteration/s, mean_rewards=-200]\u001b[A\n",
            "Training:  35%|███▌      | 703/2000 [18:12<21:04,  1.03iteration/s, mean_rewards=-200]\u001b[A\n",
            "Training:  35%|███▌      | 703/2000 [18:12<21:04,  1.03iteration/s, mean_rewards=-185]\u001b[A\n",
            "Training:  35%|███▌      | 704/2000 [18:13<21:30,  1.00iteration/s, mean_rewards=-185]\u001b[A\n",
            "Training:  35%|███▌      | 704/2000 [18:13<21:30,  1.00iteration/s, mean_rewards=-210]\u001b[A\n",
            "Training:  35%|███▌      | 705/2000 [18:14<20:14,  1.07iteration/s, mean_rewards=-210]\u001b[A\n",
            "Training:  35%|███▌      | 705/2000 [18:14<20:14,  1.07iteration/s, mean_rewards=-41.5]\u001b[A\n",
            "Training:  35%|███▌      | 706/2000 [18:15<19:21,  1.11iteration/s, mean_rewards=-41.5]\u001b[A\n",
            "Training:  35%|███▌      | 706/2000 [18:15<19:21,  1.11iteration/s, mean_rewards=-167] \u001b[A\n",
            "Training:  35%|███▌      | 707/2000 [18:15<18:40,  1.15iteration/s, mean_rewards=-167]\u001b[A\n",
            "Training:  35%|███▌      | 707/2000 [18:16<18:40,  1.15iteration/s, mean_rewards=-212]\u001b[A\n",
            "Training:  35%|███▌      | 708/2000 [18:18<28:32,  1.33s/iteration, mean_rewards=-212]\u001b[A\n",
            "Training:  35%|███▌      | 708/2000 [18:18<28:32,  1.33s/iteration, mean_rewards=-97.8]\u001b[A\n",
            "Training:  35%|███▌      | 709/2000 [18:19<26:06,  1.21s/iteration, mean_rewards=-97.8]\u001b[A\n",
            "Training:  35%|███▌      | 709/2000 [18:19<26:06,  1.21s/iteration, mean_rewards=-108] \u001b[A\n",
            "Training:  36%|███▌      | 710/2000 [18:20<23:41,  1.10s/iteration, mean_rewards=-108]\u001b[A\n",
            "Training:  36%|███▌      | 710/2000 [18:20<23:41,  1.10s/iteration, mean_rewards=-118]\u001b[A\n",
            "Training:  36%|███▌      | 711/2000 [18:21<22:39,  1.05s/iteration, mean_rewards=-118]\u001b[A\n",
            "Training:  36%|███▌      | 711/2000 [18:21<22:39,  1.05s/iteration, mean_rewards=-271]\u001b[A\n",
            "Training:  36%|███▌      | 712/2000 [18:21<20:54,  1.03iteration/s, mean_rewards=-271]\u001b[A\n",
            "Training:  36%|███▌      | 712/2000 [18:22<20:54,  1.03iteration/s, mean_rewards=-325]\u001b[A\n",
            "Training:  36%|███▌      | 713/2000 [18:22<19:26,  1.10iteration/s, mean_rewards=-325]\u001b[A\n",
            "Training:  36%|███▌      | 713/2000 [18:22<19:26,  1.10iteration/s, mean_rewards=-417]\u001b[A\n",
            "Training:  36%|███▌      | 714/2000 [18:23<19:19,  1.11iteration/s, mean_rewards=-417]\u001b[A\n",
            "Training:  36%|███▌      | 714/2000 [18:23<19:19,  1.11iteration/s, mean_rewards=-218]\u001b[A\n",
            "Training:  36%|███▌      | 715/2000 [18:24<20:16,  1.06iteration/s, mean_rewards=-218]\u001b[A\n",
            "Training:  36%|███▌      | 715/2000 [18:24<20:16,  1.06iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  36%|███▌      | 716/2000 [18:25<20:18,  1.05iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  36%|███▌      | 716/2000 [18:25<20:18,  1.05iteration/s, mean_rewards=-85.7]\u001b[A\n",
            "Training:  36%|███▌      | 717/2000 [18:26<21:31,  1.01s/iteration, mean_rewards=-85.7]\u001b[A\n",
            "Training:  36%|███▌      | 717/2000 [18:26<21:31,  1.01s/iteration, mean_rewards=-123] \u001b[A\n",
            "Training:  36%|███▌      | 718/2000 [18:27<19:22,  1.10iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  36%|███▌      | 718/2000 [18:27<19:22,  1.10iteration/s, mean_rewards=-104]\u001b[A\n",
            "Training:  36%|███▌      | 719/2000 [18:27<17:45,  1.20iteration/s, mean_rewards=-104]\u001b[A\n",
            "Training:  36%|███▌      | 719/2000 [18:28<17:45,  1.20iteration/s, mean_rewards=-367]\u001b[A\n",
            "Training:  36%|███▌      | 720/2000 [18:28<18:17,  1.17iteration/s, mean_rewards=-367]\u001b[A\n",
            "Training:  36%|███▌      | 720/2000 [18:29<18:17,  1.17iteration/s, mean_rewards=-227]\u001b[A\n",
            "Training:  36%|███▌      | 721/2000 [18:29<18:35,  1.15iteration/s, mean_rewards=-227]\u001b[A\n",
            "Training:  36%|███▌      | 721/2000 [18:30<18:35,  1.15iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  36%|███▌      | 722/2000 [18:30<17:46,  1.20iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  36%|███▌      | 722/2000 [18:30<17:46,  1.20iteration/s, mean_rewards=-301]\u001b[A\n",
            "Training:  36%|███▌      | 723/2000 [18:31<19:07,  1.11iteration/s, mean_rewards=-301]\u001b[A\n",
            "Training:  36%|███▌      | 723/2000 [18:31<19:07,  1.11iteration/s, mean_rewards=-341]\u001b[A\n",
            "Training:  36%|███▌      | 724/2000 [18:32<19:11,  1.11iteration/s, mean_rewards=-341]\u001b[A\n",
            "Training:  36%|███▌      | 724/2000 [18:32<19:11,  1.11iteration/s, mean_rewards=-268]\u001b[A\n",
            "Training:  36%|███▋      | 725/2000 [18:33<19:57,  1.06iteration/s, mean_rewards=-268]\u001b[A\n",
            "Training:  36%|███▋      | 725/2000 [18:33<19:57,  1.06iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  36%|███▋      | 726/2000 [18:34<19:44,  1.08iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  36%|███▋      | 726/2000 [18:34<19:44,  1.08iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  36%|███▋      | 727/2000 [18:35<19:52,  1.07iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  36%|███▋      | 727/2000 [18:35<19:52,  1.07iteration/s, mean_rewards=-208]\u001b[A\n",
            "Training:  36%|███▋      | 728/2000 [18:36<19:59,  1.06iteration/s, mean_rewards=-208]\u001b[A\n",
            "Training:  36%|███▋      | 728/2000 [18:36<19:59,  1.06iteration/s, mean_rewards=-289]\u001b[A\n",
            "Training:  36%|███▋      | 729/2000 [18:37<20:30,  1.03iteration/s, mean_rewards=-289]\u001b[A\n",
            "Training:  36%|███▋      | 729/2000 [18:37<20:30,  1.03iteration/s, mean_rewards=-106]\u001b[A\n",
            "Training:  36%|███▋      | 730/2000 [18:38<19:59,  1.06iteration/s, mean_rewards=-106]\u001b[A\n",
            "Training:  36%|███▋      | 730/2000 [18:38<19:59,  1.06iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:  37%|███▋      | 731/2000 [18:39<21:47,  1.03s/iteration, mean_rewards=-147]\u001b[A\n",
            "Training:  37%|███▋      | 731/2000 [18:39<21:47,  1.03s/iteration, mean_rewards=-103]\u001b[A\n",
            "Training:  37%|███▋      | 732/2000 [18:40<20:57,  1.01iteration/s, mean_rewards=-103]\u001b[A\n",
            "Training:  37%|███▋      | 732/2000 [18:40<20:57,  1.01iteration/s, mean_rewards=-172]\u001b[A\n",
            "Training:  37%|███▋      | 733/2000 [18:41<19:48,  1.07iteration/s, mean_rewards=-172]\u001b[A\n",
            "Training:  37%|███▋      | 733/2000 [18:41<19:48,  1.07iteration/s, mean_rewards=-241]\u001b[A\n",
            "Training:  37%|███▋      | 734/2000 [18:42<20:37,  1.02iteration/s, mean_rewards=-241]\u001b[A\n",
            "Training:  37%|███▋      | 734/2000 [18:42<20:37,  1.02iteration/s, mean_rewards=-173]\u001b[A\n",
            "Training:  37%|███▋      | 735/2000 [18:43<20:11,  1.04iteration/s, mean_rewards=-173]\u001b[A\n",
            "Training:  37%|███▋      | 735/2000 [18:43<20:11,  1.04iteration/s, mean_rewards=-194]\u001b[A\n",
            "Training:  37%|███▋      | 736/2000 [18:43<18:27,  1.14iteration/s, mean_rewards=-194]\u001b[A\n",
            "Training:  37%|███▋      | 736/2000 [18:44<18:27,  1.14iteration/s, mean_rewards=-319]\u001b[A\n",
            "Training:  37%|███▋      | 737/2000 [18:44<19:36,  1.07iteration/s, mean_rewards=-319]\u001b[A\n",
            "Training:  37%|███▋      | 737/2000 [18:45<19:36,  1.07iteration/s, mean_rewards=-58.4]\u001b[A\n",
            "Training:  37%|███▋      | 738/2000 [18:45<18:30,  1.14iteration/s, mean_rewards=-58.4]\u001b[A\n",
            "Training:  37%|███▋      | 738/2000 [18:46<18:30,  1.14iteration/s, mean_rewards=-192] \u001b[A\n",
            "Training:  37%|███▋      | 739/2000 [18:46<17:59,  1.17iteration/s, mean_rewards=-192]\u001b[A\n",
            "Training:  37%|███▋      | 739/2000 [18:46<17:59,  1.17iteration/s, mean_rewards=-80.1]\u001b[A\n",
            "Training:  37%|███▋      | 740/2000 [18:47<16:57,  1.24iteration/s, mean_rewards=-80.1]\u001b[A\n",
            "Training:  37%|███▋      | 740/2000 [18:47<16:57,  1.24iteration/s, mean_rewards=-274] \u001b[A\n",
            "Training:  37%|███▋      | 741/2000 [18:47<16:49,  1.25iteration/s, mean_rewards=-274]\u001b[A\n",
            "Training:  37%|███▋      | 741/2000 [18:48<16:49,  1.25iteration/s, mean_rewards=-252]\u001b[A\n",
            "Training:  37%|███▋      | 742/2000 [18:48<17:33,  1.19iteration/s, mean_rewards=-252]\u001b[A\n",
            "Training:  37%|███▋      | 742/2000 [18:49<17:33,  1.19iteration/s, mean_rewards=-194]\u001b[A\n",
            "Training:  37%|███▋      | 743/2000 [18:49<18:19,  1.14iteration/s, mean_rewards=-194]\u001b[A\n",
            "Training:  37%|███▋      | 743/2000 [18:50<18:19,  1.14iteration/s, mean_rewards=-83.6]\u001b[A\n",
            "Training:  37%|███▋      | 744/2000 [18:50<17:04,  1.23iteration/s, mean_rewards=-83.6]\u001b[A\n",
            "Training:  37%|███▋      | 744/2000 [18:50<17:04,  1.23iteration/s, mean_rewards=-244] \u001b[A\n",
            "Training:  37%|███▋      | 745/2000 [18:51<19:36,  1.07iteration/s, mean_rewards=-244]\u001b[A\n",
            "Training:  37%|███▋      | 745/2000 [18:52<19:36,  1.07iteration/s, mean_rewards=-76.8]\u001b[A\n",
            "Training:  37%|███▋      | 746/2000 [18:52<20:16,  1.03iteration/s, mean_rewards=-76.8]\u001b[A\n",
            "Training:  37%|███▋      | 746/2000 [18:53<20:16,  1.03iteration/s, mean_rewards=-111] \u001b[A\n",
            "Training:  37%|███▋      | 747/2000 [18:53<19:03,  1.10iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  37%|███▋      | 747/2000 [18:53<19:03,  1.10iteration/s, mean_rewards=-75.9]\u001b[A\n",
            "Training:  37%|███▋      | 748/2000 [18:54<16:51,  1.24iteration/s, mean_rewards=-75.9]\u001b[A\n",
            "Training:  37%|███▋      | 748/2000 [18:54<16:51,  1.24iteration/s, mean_rewards=-225] \u001b[A\n",
            "Training:  37%|███▋      | 749/2000 [18:54<16:41,  1.25iteration/s, mean_rewards=-225]\u001b[A\n",
            "Training:  37%|███▋      | 749/2000 [18:55<16:41,  1.25iteration/s, mean_rewards=-214]\u001b[A\n",
            "Training:  38%|███▊      | 750/2000 [18:55<17:25,  1.20iteration/s, mean_rewards=-214]\u001b[A\n",
            "Training:  38%|███▊      | 750/2000 [18:56<17:25,  1.20iteration/s, mean_rewards=-219]\u001b[A\n",
            "Training:  38%|███▊      | 751/2000 [18:56<16:46,  1.24iteration/s, mean_rewards=-219]\u001b[A\n",
            "Training:  38%|███▊      | 751/2000 [18:56<16:46,  1.24iteration/s, mean_rewards=-203]\u001b[A\n",
            "Training:  38%|███▊      | 752/2000 [18:57<16:36,  1.25iteration/s, mean_rewards=-203]\u001b[A\n",
            "Training:  38%|███▊      | 752/2000 [18:57<16:36,  1.25iteration/s, mean_rewards=-193]\u001b[A\n",
            "Training:  38%|███▊      | 753/2000 [18:58<17:10,  1.21iteration/s, mean_rewards=-193]\u001b[A\n",
            "Training:  38%|███▊      | 753/2000 [18:58<17:10,  1.21iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  38%|███▊      | 754/2000 [18:59<16:52,  1.23iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  38%|███▊      | 754/2000 [18:59<16:52,  1.23iteration/s, mean_rewards=-232]\u001b[A\n",
            "Training:  38%|███▊      | 755/2000 [18:59<17:38,  1.18iteration/s, mean_rewards=-232]\u001b[A\n",
            "Training:  38%|███▊      | 755/2000 [19:00<17:38,  1.18iteration/s, mean_rewards=-95.1]\u001b[A\n",
            "Training:  38%|███▊      | 756/2000 [19:00<18:08,  1.14iteration/s, mean_rewards=-95.1]\u001b[A\n",
            "Training:  38%|███▊      | 756/2000 [19:01<18:08,  1.14iteration/s, mean_rewards=-127] \u001b[A\n",
            "Training:  38%|███▊      | 757/2000 [19:01<17:09,  1.21iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  38%|███▊      | 757/2000 [19:01<17:09,  1.21iteration/s, mean_rewards=-112]\u001b[A\n",
            "Training:  38%|███▊      | 758/2000 [19:02<17:52,  1.16iteration/s, mean_rewards=-112]\u001b[A\n",
            "Training:  38%|███▊      | 758/2000 [19:03<17:52,  1.16iteration/s, mean_rewards=-383]\u001b[A\n",
            "Training:  38%|███▊      | 759/2000 [19:03<20:57,  1.01s/iteration, mean_rewards=-383]\u001b[A\n",
            "Training:  38%|███▊      | 759/2000 [19:04<20:57,  1.01s/iteration, mean_rewards=-108]\u001b[A\n",
            "Training:  38%|███▊      | 760/2000 [19:04<20:37,  1.00iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:  38%|███▊      | 760/2000 [19:05<20:37,  1.00iteration/s, mean_rewards=-202]\u001b[A\n",
            "Training:  38%|███▊      | 761/2000 [19:05<19:23,  1.06iteration/s, mean_rewards=-202]\u001b[A\n",
            "Training:  38%|███▊      | 761/2000 [19:06<19:23,  1.06iteration/s, mean_rewards=-88.9]\u001b[A\n",
            "Training:  38%|███▊      | 762/2000 [19:06<18:39,  1.11iteration/s, mean_rewards=-88.9]\u001b[A\n",
            "Training:  38%|███▊      | 762/2000 [19:06<18:39,  1.11iteration/s, mean_rewards=-195] \u001b[A\n",
            "Training:  38%|███▊      | 763/2000 [19:07<18:53,  1.09iteration/s, mean_rewards=-195]\u001b[A\n",
            "Training:  38%|███▊      | 763/2000 [19:07<18:53,  1.09iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  38%|███▊      | 764/2000 [19:08<17:22,  1.19iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  38%|███▊      | 764/2000 [19:08<17:22,  1.19iteration/s, mean_rewards=-239]\u001b[A\n",
            "Training:  38%|███▊      | 765/2000 [19:08<17:10,  1.20iteration/s, mean_rewards=-239]\u001b[A\n",
            "Training:  38%|███▊      | 765/2000 [19:09<17:10,  1.20iteration/s, mean_rewards=-73.6]\u001b[A\n",
            "Training:  38%|███▊      | 766/2000 [19:09<16:09,  1.27iteration/s, mean_rewards=-73.6]\u001b[A\n",
            "Training:  38%|███▊      | 766/2000 [19:09<16:09,  1.27iteration/s, mean_rewards=-75.5]\u001b[A\n",
            "Training:  38%|███▊      | 767/2000 [19:10<15:32,  1.32iteration/s, mean_rewards=-75.5]\u001b[A\n",
            "Training:  38%|███▊      | 767/2000 [19:10<15:32,  1.32iteration/s, mean_rewards=-97.4]\u001b[A\n",
            "Training:  38%|███▊      | 768/2000 [19:11<17:36,  1.17iteration/s, mean_rewards=-97.4]\u001b[A\n",
            "Training:  38%|███▊      | 768/2000 [19:11<17:36,  1.17iteration/s, mean_rewards=-134] \u001b[A\n",
            "Training:  38%|███▊      | 769/2000 [19:12<16:41,  1.23iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  38%|███▊      | 769/2000 [19:12<16:41,  1.23iteration/s, mean_rewards=-184]\u001b[A\n",
            "Training:  38%|███▊      | 770/2000 [19:13<17:31,  1.17iteration/s, mean_rewards=-184]\u001b[A\n",
            "Training:  38%|███▊      | 770/2000 [19:13<17:31,  1.17iteration/s, mean_rewards=-270]\u001b[A\n",
            "Training:  39%|███▊      | 771/2000 [19:13<17:52,  1.15iteration/s, mean_rewards=-270]\u001b[A\n",
            "Training:  39%|███▊      | 771/2000 [19:14<17:52,  1.15iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  39%|███▊      | 772/2000 [19:14<18:52,  1.08iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  39%|███▊      | 772/2000 [19:15<18:52,  1.08iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  39%|███▊      | 773/2000 [19:15<18:38,  1.10iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  39%|███▊      | 773/2000 [19:16<18:38,  1.10iteration/s, mean_rewards=-303]\u001b[A\n",
            "Training:  39%|███▊      | 774/2000 [19:17<21:13,  1.04s/iteration, mean_rewards=-303]\u001b[A\n",
            "Training:  39%|███▊      | 774/2000 [19:17<21:13,  1.04s/iteration, mean_rewards=-81.1]\u001b[A\n",
            "Training:  39%|███▉      | 775/2000 [19:18<19:48,  1.03iteration/s, mean_rewards=-81.1]\u001b[A\n",
            "Training:  39%|███▉      | 775/2000 [19:18<19:48,  1.03iteration/s, mean_rewards=-123] \u001b[A\n",
            "Training:  39%|███▉      | 776/2000 [19:18<18:05,  1.13iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  39%|███▉      | 776/2000 [19:19<18:05,  1.13iteration/s, mean_rewards=-167]\u001b[A\n",
            "Training:  39%|███▉      | 777/2000 [19:19<17:33,  1.16iteration/s, mean_rewards=-167]\u001b[A\n",
            "Training:  39%|███▉      | 777/2000 [19:19<17:33,  1.16iteration/s, mean_rewards=-274]\u001b[A\n",
            "Training:  39%|███▉      | 778/2000 [19:20<18:10,  1.12iteration/s, mean_rewards=-274]\u001b[A\n",
            "Training:  39%|███▉      | 778/2000 [19:20<18:10,  1.12iteration/s, mean_rewards=-97] \u001b[A\n",
            "Training:  39%|███▉      | 779/2000 [19:21<17:29,  1.16iteration/s, mean_rewards=-97]\u001b[A\n",
            "Training:  39%|███▉      | 779/2000 [19:21<17:29,  1.16iteration/s, mean_rewards=-89.4]\u001b[A\n",
            "Training:  39%|███▉      | 780/2000 [19:21<16:23,  1.24iteration/s, mean_rewards=-89.4]\u001b[A\n",
            "Training:  39%|███▉      | 780/2000 [19:22<16:23,  1.24iteration/s, mean_rewards=-240] \u001b[A\n",
            "Training:  39%|███▉      | 781/2000 [19:22<17:12,  1.18iteration/s, mean_rewards=-240]\u001b[A\n",
            "Training:  39%|███▉      | 781/2000 [19:23<17:12,  1.18iteration/s, mean_rewards=-260]\u001b[A\n",
            "Training:  39%|███▉      | 782/2000 [19:23<17:59,  1.13iteration/s, mean_rewards=-260]\u001b[A\n",
            "Training:  39%|███▉      | 782/2000 [19:24<17:59,  1.13iteration/s, mean_rewards=-105]\u001b[A\n",
            "Training:  39%|███▉      | 783/2000 [19:24<17:41,  1.15iteration/s, mean_rewards=-105]\u001b[A\n",
            "Training:  39%|███▉      | 783/2000 [19:25<17:41,  1.15iteration/s, mean_rewards=-267]\u001b[A\n",
            "Training:  39%|███▉      | 784/2000 [19:25<17:47,  1.14iteration/s, mean_rewards=-267]\u001b[A\n",
            "Training:  39%|███▉      | 784/2000 [19:25<17:47,  1.14iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  39%|███▉      | 785/2000 [19:26<16:37,  1.22iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  39%|███▉      | 785/2000 [19:26<16:37,  1.22iteration/s, mean_rewards=-291]\u001b[A\n",
            "Training:  39%|███▉      | 786/2000 [19:27<16:25,  1.23iteration/s, mean_rewards=-291]\u001b[A\n",
            "Training:  39%|███▉      | 786/2000 [19:27<16:25,  1.23iteration/s, mean_rewards=-296]\u001b[A\n",
            "Training:  39%|███▉      | 787/2000 [19:28<18:00,  1.12iteration/s, mean_rewards=-296]\u001b[A\n",
            "Training:  39%|███▉      | 787/2000 [19:28<18:00,  1.12iteration/s, mean_rewards=-193]\u001b[A\n",
            "Training:  39%|███▉      | 788/2000 [19:29<21:11,  1.05s/iteration, mean_rewards=-193]\u001b[A\n",
            "Training:  39%|███▉      | 788/2000 [19:29<21:11,  1.05s/iteration, mean_rewards=-321]\u001b[A\n",
            "Training:  39%|███▉      | 789/2000 [19:30<19:36,  1.03iteration/s, mean_rewards=-321]\u001b[A\n",
            "Training:  39%|███▉      | 789/2000 [19:30<19:36,  1.03iteration/s, mean_rewards=-90.6]\u001b[A\n",
            "Training:  40%|███▉      | 790/2000 [19:31<20:06,  1.00iteration/s, mean_rewards=-90.6]\u001b[A\n",
            "Training:  40%|███▉      | 790/2000 [19:31<20:06,  1.00iteration/s, mean_rewards=-217] \u001b[A\n",
            "Training:  40%|███▉      | 791/2000 [19:32<19:05,  1.06iteration/s, mean_rewards=-217]\u001b[A\n",
            "Training:  40%|███▉      | 791/2000 [19:32<19:05,  1.06iteration/s, mean_rewards=-253]\u001b[A\n",
            "Training:  40%|███▉      | 792/2000 [19:33<17:54,  1.12iteration/s, mean_rewards=-253]\u001b[A\n",
            "Training:  40%|███▉      | 792/2000 [19:33<17:54,  1.12iteration/s, mean_rewards=-182]\u001b[A\n",
            "Training:  40%|███▉      | 793/2000 [19:33<17:53,  1.12iteration/s, mean_rewards=-182]\u001b[A\n",
            "Training:  40%|███▉      | 793/2000 [19:34<17:53,  1.12iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  40%|███▉      | 794/2000 [19:34<18:06,  1.11iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  40%|███▉      | 794/2000 [19:35<18:06,  1.11iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  40%|███▉      | 795/2000 [19:35<18:27,  1.09iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  40%|███▉      | 795/2000 [19:36<18:27,  1.09iteration/s, mean_rewards=-406]\u001b[A\n",
            "Training:  40%|███▉      | 796/2000 [19:36<17:55,  1.12iteration/s, mean_rewards=-406]\u001b[A\n",
            "Training:  40%|███▉      | 796/2000 [19:36<17:55,  1.12iteration/s, mean_rewards=-88.2]\u001b[A\n",
            "Training:  40%|███▉      | 797/2000 [19:37<17:18,  1.16iteration/s, mean_rewards=-88.2]\u001b[A\n",
            "Training:  40%|███▉      | 797/2000 [19:37<17:18,  1.16iteration/s, mean_rewards=-151] \u001b[A\n",
            "Training:  40%|███▉      | 798/2000 [19:38<16:16,  1.23iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  40%|███▉      | 798/2000 [19:38<16:16,  1.23iteration/s, mean_rewards=-220]\u001b[A\n",
            "Training:  40%|███▉      | 799/2000 [19:38<15:15,  1.31iteration/s, mean_rewards=-220]\u001b[A\n",
            "Training:  40%|███▉      | 799/2000 [19:39<15:15,  1.31iteration/s, mean_rewards=-198]\u001b[A\n",
            "Training:  40%|████      | 800/2000 [19:39<14:36,  1.37iteration/s, mean_rewards=-198]\u001b[A\n",
            "Training:  40%|████      | 800/2000 [19:39<14:36,  1.37iteration/s, mean_rewards=-195]\u001b[A\n",
            "Training:  40%|████      | 801/2000 [19:40<15:15,  1.31iteration/s, mean_rewards=-195]\u001b[A\n",
            "Training:  40%|████      | 801/2000 [19:40<15:15,  1.31iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  40%|████      | 802/2000 [19:41<18:01,  1.11iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  40%|████      | 802/2000 [19:41<18:01,  1.11iteration/s, mean_rewards=-233]\u001b[A\n",
            "Training:  40%|████      | 803/2000 [19:42<19:16,  1.04iteration/s, mean_rewards=-233]\u001b[A\n",
            "Training:  40%|████      | 803/2000 [19:42<19:16,  1.04iteration/s, mean_rewards=-338]\u001b[A\n",
            "Training:  40%|████      | 804/2000 [19:43<18:22,  1.08iteration/s, mean_rewards=-338]\u001b[A\n",
            "Training:  40%|████      | 804/2000 [19:43<18:22,  1.08iteration/s, mean_rewards=-105]\u001b[A\n",
            "Training:  40%|████      | 805/2000 [19:44<18:29,  1.08iteration/s, mean_rewards=-105]\u001b[A\n",
            "Training:  40%|████      | 805/2000 [19:44<18:29,  1.08iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  40%|████      | 806/2000 [19:45<17:42,  1.12iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  40%|████      | 806/2000 [19:45<17:42,  1.12iteration/s, mean_rewards=-188]\u001b[A\n",
            "Training:  40%|████      | 807/2000 [19:46<18:34,  1.07iteration/s, mean_rewards=-188]\u001b[A\n",
            "Training:  40%|████      | 807/2000 [19:46<18:34,  1.07iteration/s, mean_rewards=-264]\u001b[A\n",
            "Training:  40%|████      | 808/2000 [19:46<17:10,  1.16iteration/s, mean_rewards=-264]\u001b[A\n",
            "Training:  40%|████      | 808/2000 [19:47<17:10,  1.16iteration/s, mean_rewards=-231]\u001b[A\n",
            "Training:  40%|████      | 809/2000 [19:47<16:16,  1.22iteration/s, mean_rewards=-231]\u001b[A\n",
            "Training:  40%|████      | 809/2000 [19:47<16:16,  1.22iteration/s, mean_rewards=-101]\u001b[A\n",
            "Training:  40%|████      | 810/2000 [19:48<15:37,  1.27iteration/s, mean_rewards=-101]\u001b[A\n",
            "Training:  40%|████      | 810/2000 [19:48<15:37,  1.27iteration/s, mean_rewards=-167]\u001b[A\n",
            "Training:  41%|████      | 811/2000 [19:49<15:48,  1.25iteration/s, mean_rewards=-167]\u001b[A\n",
            "Training:  41%|████      | 811/2000 [19:49<15:48,  1.25iteration/s, mean_rewards=-152]\u001b[A\n",
            "Training:  41%|████      | 812/2000 [19:49<15:52,  1.25iteration/s, mean_rewards=-152]\u001b[A\n",
            "Training:  41%|████      | 812/2000 [19:50<15:52,  1.25iteration/s, mean_rewards=-334]\u001b[A\n",
            "Training:  41%|████      | 813/2000 [19:50<16:06,  1.23iteration/s, mean_rewards=-334]\u001b[A\n",
            "Training:  41%|████      | 813/2000 [19:51<16:06,  1.23iteration/s, mean_rewards=-402]\u001b[A\n",
            "Training:  41%|████      | 814/2000 [19:51<16:56,  1.17iteration/s, mean_rewards=-402]\u001b[A\n",
            "Training:  41%|████      | 814/2000 [19:52<16:56,  1.17iteration/s, mean_rewards=-216]\u001b[A\n",
            "Training:  41%|████      | 815/2000 [19:52<17:57,  1.10iteration/s, mean_rewards=-216]\u001b[A\n",
            "Training:  41%|████      | 815/2000 [19:53<17:57,  1.10iteration/s, mean_rewards=-168]\u001b[A\n",
            "Training:  41%|████      | 816/2000 [19:53<18:38,  1.06iteration/s, mean_rewards=-168]\u001b[A\n",
            "Training:  41%|████      | 816/2000 [19:54<18:38,  1.06iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  41%|████      | 817/2000 [19:54<19:54,  1.01s/iteration, mean_rewards=-123]\u001b[A\n",
            "Training:  41%|████      | 817/2000 [19:55<19:54,  1.01s/iteration, mean_rewards=-174]\u001b[A\n",
            "Training:  41%|████      | 818/2000 [19:56<20:09,  1.02s/iteration, mean_rewards=-174]\u001b[A\n",
            "Training:  41%|████      | 818/2000 [19:56<20:09,  1.02s/iteration, mean_rewards=-82.7]\u001b[A\n",
            "Training:  41%|████      | 819/2000 [19:56<19:30,  1.01iteration/s, mean_rewards=-82.7]\u001b[A\n",
            "Training:  41%|████      | 819/2000 [19:57<19:30,  1.01iteration/s, mean_rewards=-318] \u001b[A\n",
            "Training:  41%|████      | 820/2000 [19:57<19:11,  1.02iteration/s, mean_rewards=-318]\u001b[A\n",
            "Training:  41%|████      | 820/2000 [19:58<19:11,  1.02iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  41%|████      | 821/2000 [19:58<17:14,  1.14iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  41%|████      | 821/2000 [19:58<17:14,  1.14iteration/s, mean_rewards=-337]\u001b[A\n",
            "Training:  41%|████      | 822/2000 [19:59<18:14,  1.08iteration/s, mean_rewards=-337]\u001b[A\n",
            "Training:  41%|████      | 822/2000 [19:59<18:14,  1.08iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  41%|████      | 823/2000 [20:00<18:26,  1.06iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  41%|████      | 823/2000 [20:00<18:26,  1.06iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  41%|████      | 824/2000 [20:01<19:09,  1.02iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  41%|████      | 824/2000 [20:01<19:09,  1.02iteration/s, mean_rewards=-80.8]\u001b[A\n",
            "Training:  41%|████▏     | 825/2000 [20:02<18:49,  1.04iteration/s, mean_rewards=-80.8]\u001b[A\n",
            "Training:  41%|████▏     | 825/2000 [20:02<18:49,  1.04iteration/s, mean_rewards=-196] \u001b[A\n",
            "Training:  41%|████▏     | 826/2000 [20:03<17:12,  1.14iteration/s, mean_rewards=-196]\u001b[A\n",
            "Training:  41%|████▏     | 826/2000 [20:03<17:12,  1.14iteration/s, mean_rewards=-169]\u001b[A\n",
            "Training:  41%|████▏     | 827/2000 [20:04<18:21,  1.06iteration/s, mean_rewards=-169]\u001b[A\n",
            "Training:  41%|████▏     | 827/2000 [20:04<18:21,  1.06iteration/s, mean_rewards=-182]\u001b[A\n",
            "Training:  41%|████▏     | 828/2000 [20:05<18:43,  1.04iteration/s, mean_rewards=-182]\u001b[A\n",
            "Training:  41%|████▏     | 828/2000 [20:05<18:43,  1.04iteration/s, mean_rewards=-341]\u001b[A\n",
            "Training:  41%|████▏     | 829/2000 [20:06<19:49,  1.02s/iteration, mean_rewards=-341]\u001b[A\n",
            "Training:  41%|████▏     | 829/2000 [20:06<19:49,  1.02s/iteration, mean_rewards=-185]\u001b[A\n",
            "Training:  42%|████▏     | 830/2000 [20:07<19:33,  1.00s/iteration, mean_rewards=-185]\u001b[A\n",
            "Training:  42%|████▏     | 830/2000 [20:07<19:33,  1.00s/iteration, mean_rewards=-107]\u001b[A\n",
            "Training:  42%|████▏     | 831/2000 [20:08<20:08,  1.03s/iteration, mean_rewards=-107]\u001b[A\n",
            "Training:  42%|████▏     | 831/2000 [20:08<20:08,  1.03s/iteration, mean_rewards=-258]\u001b[A\n",
            "Training:  42%|████▏     | 832/2000 [20:09<20:08,  1.03s/iteration, mean_rewards=-258]\u001b[A\n",
            "Training:  42%|████▏     | 832/2000 [20:09<20:08,  1.03s/iteration, mean_rewards=-227]\u001b[A\n",
            "Training:  42%|████▏     | 833/2000 [20:10<19:10,  1.01iteration/s, mean_rewards=-227]\u001b[A\n",
            "Training:  42%|████▏     | 833/2000 [20:10<19:10,  1.01iteration/s, mean_rewards=-101]\u001b[A\n",
            "Training:  42%|████▏     | 834/2000 [20:11<18:22,  1.06iteration/s, mean_rewards=-101]\u001b[A\n",
            "Training:  42%|████▏     | 834/2000 [20:11<18:22,  1.06iteration/s, mean_rewards=-179]\u001b[A\n",
            "Training:  42%|████▏     | 835/2000 [20:12<17:46,  1.09iteration/s, mean_rewards=-179]\u001b[A\n",
            "Training:  42%|████▏     | 835/2000 [20:12<17:46,  1.09iteration/s, mean_rewards=-244]\u001b[A\n",
            "Training:  42%|████▏     | 836/2000 [20:13<17:50,  1.09iteration/s, mean_rewards=-244]\u001b[A\n",
            "Training:  42%|████▏     | 836/2000 [20:13<17:50,  1.09iteration/s, mean_rewards=-223]\u001b[A\n",
            "Training:  42%|████▏     | 837/2000 [20:14<18:04,  1.07iteration/s, mean_rewards=-223]\u001b[A\n",
            "Training:  42%|████▏     | 837/2000 [20:14<18:04,  1.07iteration/s, mean_rewards=-159]\u001b[A\n",
            "Training:  42%|████▏     | 838/2000 [20:14<17:15,  1.12iteration/s, mean_rewards=-159]\u001b[A\n",
            "Training:  42%|████▏     | 838/2000 [20:15<17:15,  1.12iteration/s, mean_rewards=-252]\u001b[A\n",
            "Training:  42%|████▏     | 839/2000 [20:15<18:05,  1.07iteration/s, mean_rewards=-252]\u001b[A\n",
            "Training:  42%|████▏     | 839/2000 [20:16<18:05,  1.07iteration/s, mean_rewards=-237]\u001b[A\n",
            "Training:  42%|████▏     | 840/2000 [20:16<17:22,  1.11iteration/s, mean_rewards=-237]\u001b[A\n",
            "Training:  42%|████▏     | 840/2000 [20:17<17:22,  1.11iteration/s, mean_rewards=-264]\u001b[A\n",
            "Training:  42%|████▏     | 841/2000 [20:17<16:51,  1.15iteration/s, mean_rewards=-264]\u001b[A\n",
            "Training:  42%|████▏     | 841/2000 [20:17<16:51,  1.15iteration/s, mean_rewards=-236]\u001b[A\n",
            "Training:  42%|████▏     | 842/2000 [20:18<17:07,  1.13iteration/s, mean_rewards=-236]\u001b[A\n",
            "Training:  42%|████▏     | 842/2000 [20:18<17:07,  1.13iteration/s, mean_rewards=-262]\u001b[A\n",
            "Training:  42%|████▏     | 843/2000 [20:19<18:51,  1.02iteration/s, mean_rewards=-262]\u001b[A\n",
            "Training:  42%|████▏     | 843/2000 [20:20<18:51,  1.02iteration/s, mean_rewards=-68.4]\u001b[A\n",
            "Training:  42%|████▏     | 844/2000 [20:21<21:25,  1.11s/iteration, mean_rewards=-68.4]\u001b[A\n",
            "Training:  42%|████▏     | 844/2000 [20:21<21:25,  1.11s/iteration, mean_rewards=-141] \u001b[A\n",
            "Training:  42%|████▏     | 845/2000 [20:22<21:00,  1.09s/iteration, mean_rewards=-141]\u001b[A\n",
            "Training:  42%|████▏     | 845/2000 [20:22<21:00,  1.09s/iteration, mean_rewards=-358]\u001b[A\n",
            "Training:  42%|████▏     | 846/2000 [20:22<19:32,  1.02s/iteration, mean_rewards=-358]\u001b[A\n",
            "Training:  42%|████▏     | 846/2000 [20:23<19:32,  1.02s/iteration, mean_rewards=-210]\u001b[A\n",
            "Training:  42%|████▏     | 847/2000 [20:23<18:34,  1.03iteration/s, mean_rewards=-210]\u001b[A\n",
            "Training:  42%|████▏     | 847/2000 [20:24<18:34,  1.03iteration/s, mean_rewards=-325]\u001b[A\n",
            "Training:  42%|████▏     | 848/2000 [20:24<17:41,  1.09iteration/s, mean_rewards=-325]\u001b[A\n",
            "Training:  42%|████▏     | 848/2000 [20:24<17:41,  1.09iteration/s, mean_rewards=-233]\u001b[A\n",
            "Training:  42%|████▏     | 849/2000 [20:25<17:27,  1.10iteration/s, mean_rewards=-233]\u001b[A\n",
            "Training:  42%|████▏     | 849/2000 [20:25<17:27,  1.10iteration/s, mean_rewards=-337]\u001b[A\n",
            "Training:  42%|████▎     | 850/2000 [20:26<17:00,  1.13iteration/s, mean_rewards=-337]\u001b[A\n",
            "Training:  42%|████▎     | 850/2000 [20:26<17:00,  1.13iteration/s, mean_rewards=-257]\u001b[A\n",
            "Training:  43%|████▎     | 851/2000 [20:26<15:53,  1.21iteration/s, mean_rewards=-257]\u001b[A\n",
            "Training:  43%|████▎     | 851/2000 [20:27<15:53,  1.21iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  43%|████▎     | 852/2000 [20:27<16:08,  1.18iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  43%|████▎     | 852/2000 [20:28<16:08,  1.18iteration/s, mean_rewards=-201]\u001b[A\n",
            "Training:  43%|████▎     | 853/2000 [20:28<16:56,  1.13iteration/s, mean_rewards=-201]\u001b[A\n",
            "Training:  43%|████▎     | 853/2000 [20:29<16:56,  1.13iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  43%|████▎     | 854/2000 [20:29<16:13,  1.18iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  43%|████▎     | 854/2000 [20:29<16:13,  1.18iteration/s, mean_rewards=-295]\u001b[A\n",
            "Training:  43%|████▎     | 855/2000 [20:30<16:22,  1.17iteration/s, mean_rewards=-295]\u001b[A\n",
            "Training:  43%|████▎     | 855/2000 [20:30<16:22,  1.17iteration/s, mean_rewards=-298]\u001b[A\n",
            "Training:  43%|████▎     | 856/2000 [20:31<18:29,  1.03iteration/s, mean_rewards=-298]\u001b[A\n",
            "Training:  43%|████▎     | 856/2000 [20:32<18:29,  1.03iteration/s, mean_rewards=-226]\u001b[A\n",
            "Training:  43%|████▎     | 857/2000 [20:32<18:45,  1.02iteration/s, mean_rewards=-226]\u001b[A\n",
            "Training:  43%|████▎     | 857/2000 [20:33<18:45,  1.02iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  43%|████▎     | 858/2000 [20:33<19:10,  1.01s/iteration, mean_rewards=-131]\u001b[A\n",
            "Training:  43%|████▎     | 858/2000 [20:34<19:10,  1.01s/iteration, mean_rewards=-282]\u001b[A\n",
            "Training:  43%|████▎     | 859/2000 [20:34<18:35,  1.02iteration/s, mean_rewards=-282]\u001b[A\n",
            "Training:  43%|████▎     | 859/2000 [20:35<18:35,  1.02iteration/s, mean_rewards=-239]\u001b[A\n",
            "Training:  43%|████▎     | 860/2000 [20:35<18:21,  1.03iteration/s, mean_rewards=-239]\u001b[A\n",
            "Training:  43%|████▎     | 860/2000 [20:35<18:21,  1.03iteration/s, mean_rewards=-163]\u001b[A\n",
            "Training:  43%|████▎     | 861/2000 [20:36<17:29,  1.08iteration/s, mean_rewards=-163]\u001b[A\n",
            "Training:  43%|████▎     | 861/2000 [20:36<17:29,  1.08iteration/s, mean_rewards=-186]\u001b[A\n",
            "Training:  43%|████▎     | 862/2000 [20:37<16:42,  1.13iteration/s, mean_rewards=-186]\u001b[A\n",
            "Training:  43%|████▎     | 862/2000 [20:37<16:42,  1.13iteration/s, mean_rewards=-89.7]\u001b[A\n",
            "Training:  43%|████▎     | 863/2000 [20:37<15:24,  1.23iteration/s, mean_rewards=-89.7]\u001b[A\n",
            "Training:  43%|████▎     | 863/2000 [20:38<15:24,  1.23iteration/s, mean_rewards=-171] \u001b[A\n",
            "Training:  43%|████▎     | 864/2000 [20:38<14:34,  1.30iteration/s, mean_rewards=-171]\u001b[A\n",
            "Training:  43%|████▎     | 864/2000 [20:38<14:34,  1.30iteration/s, mean_rewards=-64.9]\u001b[A\n",
            "Training:  43%|████▎     | 865/2000 [20:39<14:46,  1.28iteration/s, mean_rewards=-64.9]\u001b[A\n",
            "Training:  43%|████▎     | 865/2000 [20:39<14:46,  1.28iteration/s, mean_rewards=-197] \u001b[A\n",
            "Training:  43%|████▎     | 866/2000 [20:40<15:52,  1.19iteration/s, mean_rewards=-197]\u001b[A\n",
            "Training:  43%|████▎     | 866/2000 [20:40<15:52,  1.19iteration/s, mean_rewards=-119]\u001b[A\n",
            "Training:  43%|████▎     | 867/2000 [20:41<15:04,  1.25iteration/s, mean_rewards=-119]\u001b[A\n",
            "Training:  43%|████▎     | 867/2000 [20:41<15:04,  1.25iteration/s, mean_rewards=-207]\u001b[A\n",
            "Training:  43%|████▎     | 868/2000 [20:41<15:39,  1.20iteration/s, mean_rewards=-207]\u001b[A\n",
            "Training:  43%|████▎     | 868/2000 [20:42<15:39,  1.20iteration/s, mean_rewards=-289]\u001b[A\n",
            "Training:  43%|████▎     | 869/2000 [20:43<16:59,  1.11iteration/s, mean_rewards=-289]\u001b[A\n",
            "Training:  43%|████▎     | 869/2000 [20:43<16:59,  1.11iteration/s, mean_rewards=-252]\u001b[A\n",
            "Training:  44%|████▎     | 870/2000 [20:43<17:06,  1.10iteration/s, mean_rewards=-252]\u001b[A\n",
            "Training:  44%|████▎     | 870/2000 [20:44<17:06,  1.10iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:  44%|████▎     | 871/2000 [20:44<16:57,  1.11iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:  44%|████▎     | 871/2000 [20:45<16:57,  1.11iteration/s, mean_rewards=-285]\u001b[A\n",
            "Training:  44%|████▎     | 872/2000 [20:45<17:20,  1.08iteration/s, mean_rewards=-285]\u001b[A\n",
            "Training:  44%|████▎     | 872/2000 [20:46<17:20,  1.08iteration/s, mean_rewards=-164]\u001b[A\n",
            "Training:  44%|████▎     | 873/2000 [20:46<18:22,  1.02iteration/s, mean_rewards=-164]\u001b[A\n",
            "Training:  44%|████▎     | 873/2000 [20:47<18:22,  1.02iteration/s, mean_rewards=-109]\u001b[A\n",
            "Training:  44%|████▎     | 874/2000 [20:47<18:10,  1.03iteration/s, mean_rewards=-109]\u001b[A\n",
            "Training:  44%|████▎     | 874/2000 [20:48<18:10,  1.03iteration/s, mean_rewards=-320]\u001b[A\n",
            "Training:  44%|████▍     | 875/2000 [20:49<19:25,  1.04s/iteration, mean_rewards=-320]\u001b[A\n",
            "Training:  44%|████▍     | 875/2000 [20:49<19:25,  1.04s/iteration, mean_rewards=-187]\u001b[A\n",
            "Training:  44%|████▍     | 876/2000 [20:50<18:53,  1.01s/iteration, mean_rewards=-187]\u001b[A\n",
            "Training:  44%|████▍     | 876/2000 [20:50<18:53,  1.01s/iteration, mean_rewards=-192]\u001b[A\n",
            "Training:  44%|████▍     | 877/2000 [20:51<19:27,  1.04s/iteration, mean_rewards=-192]\u001b[A\n",
            "Training:  44%|████▍     | 877/2000 [20:51<19:27,  1.04s/iteration, mean_rewards=-241]\u001b[A\n",
            "Training:  44%|████▍     | 878/2000 [20:51<18:16,  1.02iteration/s, mean_rewards=-241]\u001b[A\n",
            "Training:  44%|████▍     | 878/2000 [20:52<18:16,  1.02iteration/s, mean_rewards=-231]\u001b[A\n",
            "Training:  44%|████▍     | 879/2000 [20:53<18:52,  1.01s/iteration, mean_rewards=-231]\u001b[A\n",
            "Training:  44%|████▍     | 879/2000 [20:53<18:52,  1.01s/iteration, mean_rewards=-178]\u001b[A\n",
            "Training:  44%|████▍     | 880/2000 [20:53<17:44,  1.05iteration/s, mean_rewards=-178]\u001b[A\n",
            "Training:  44%|████▍     | 880/2000 [20:54<17:44,  1.05iteration/s, mean_rewards=-322]\u001b[A\n",
            "Training:  44%|████▍     | 881/2000 [20:54<16:49,  1.11iteration/s, mean_rewards=-322]\u001b[A\n",
            "Training:  44%|████▍     | 881/2000 [20:54<16:49,  1.11iteration/s, mean_rewards=-232]\u001b[A\n",
            "Training:  44%|████▍     | 882/2000 [20:55<15:41,  1.19iteration/s, mean_rewards=-232]\u001b[A\n",
            "Training:  44%|████▍     | 882/2000 [20:55<15:41,  1.19iteration/s, mean_rewards=-172]\u001b[A\n",
            "Training:  44%|████▍     | 883/2000 [20:56<15:23,  1.21iteration/s, mean_rewards=-172]\u001b[A\n",
            "Training:  44%|████▍     | 883/2000 [20:56<15:23,  1.21iteration/s, mean_rewards=-189]\u001b[A\n",
            "Training:  44%|████▍     | 884/2000 [20:57<16:17,  1.14iteration/s, mean_rewards=-189]\u001b[A\n",
            "Training:  44%|████▍     | 884/2000 [20:57<16:17,  1.14iteration/s, mean_rewards=-221]\u001b[A\n",
            "Training:  44%|████▍     | 885/2000 [20:58<16:47,  1.11iteration/s, mean_rewards=-221]\u001b[A\n",
            "Training:  44%|████▍     | 885/2000 [20:58<16:47,  1.11iteration/s, mean_rewards=-258]\u001b[A\n",
            "Training:  44%|████▍     | 886/2000 [20:59<20:23,  1.10s/iteration, mean_rewards=-258]\u001b[A\n",
            "Training:  44%|████▍     | 886/2000 [21:00<20:23,  1.10s/iteration, mean_rewards=-254]\u001b[A\n",
            "Training:  44%|████▍     | 887/2000 [21:00<20:27,  1.10s/iteration, mean_rewards=-254]\u001b[A\n",
            "Training:  44%|████▍     | 887/2000 [21:01<20:27,  1.10s/iteration, mean_rewards=-119]\u001b[A\n",
            "Training:  44%|████▍     | 888/2000 [21:01<19:30,  1.05s/iteration, mean_rewards=-119]\u001b[A\n",
            "Training:  44%|████▍     | 888/2000 [21:02<19:30,  1.05s/iteration, mean_rewards=-39.7]\u001b[A\n",
            "Training:  44%|████▍     | 889/2000 [21:02<18:03,  1.02iteration/s, mean_rewards=-39.7]\u001b[A\n",
            "Training:  44%|████▍     | 889/2000 [21:02<18:03,  1.02iteration/s, mean_rewards=-227] \u001b[A\n",
            "Training:  44%|████▍     | 890/2000 [21:03<17:13,  1.07iteration/s, mean_rewards=-227]\u001b[A\n",
            "Training:  44%|████▍     | 890/2000 [21:03<17:13,  1.07iteration/s, mean_rewards=-353]\u001b[A\n",
            "Training:  45%|████▍     | 891/2000 [21:04<16:36,  1.11iteration/s, mean_rewards=-353]\u001b[A\n",
            "Training:  45%|████▍     | 891/2000 [21:04<16:36,  1.11iteration/s, mean_rewards=-212]\u001b[A\n",
            "Training:  45%|████▍     | 892/2000 [21:05<17:47,  1.04iteration/s, mean_rewards=-212]\u001b[A\n",
            "Training:  45%|████▍     | 892/2000 [21:05<17:47,  1.04iteration/s, mean_rewards=-87] \u001b[A\n",
            "Training:  45%|████▍     | 893/2000 [21:06<17:31,  1.05iteration/s, mean_rewards=-87]\u001b[A\n",
            "Training:  45%|████▍     | 893/2000 [21:06<17:31,  1.05iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  45%|████▍     | 894/2000 [21:07<16:50,  1.09iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  45%|████▍     | 894/2000 [21:07<16:50,  1.09iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  45%|████▍     | 895/2000 [21:07<16:45,  1.10iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  45%|████▍     | 895/2000 [21:08<16:45,  1.10iteration/s, mean_rewards=-157]\u001b[A\n",
            "Training:  45%|████▍     | 896/2000 [21:08<15:30,  1.19iteration/s, mean_rewards=-157]\u001b[A\n",
            "Training:  45%|████▍     | 896/2000 [21:08<15:30,  1.19iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  45%|████▍     | 897/2000 [21:09<17:10,  1.07iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  45%|████▍     | 897/2000 [21:10<17:10,  1.07iteration/s, mean_rewards=-81.2]\u001b[A\n",
            "Training:  45%|████▍     | 898/2000 [21:10<16:43,  1.10iteration/s, mean_rewards=-81.2]\u001b[A\n",
            "Training:  45%|████▍     | 898/2000 [21:11<16:43,  1.10iteration/s, mean_rewards=-296] \u001b[A\n",
            "Training:  45%|████▍     | 899/2000 [21:11<18:43,  1.02s/iteration, mean_rewards=-296]\u001b[A\n",
            "Training:  45%|████▍     | 899/2000 [21:12<18:43,  1.02s/iteration, mean_rewards=-203]\u001b[A\n",
            "Training:  45%|████▌     | 900/2000 [21:12<17:59,  1.02iteration/s, mean_rewards=-203]\u001b[A\n",
            "Training:  45%|████▌     | 900/2000 [21:13<17:59,  1.02iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:  45%|████▌     | 901/2000 [21:13<17:31,  1.04iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:  45%|████▌     | 901/2000 [21:13<17:31,  1.04iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  45%|████▌     | 902/2000 [21:14<16:06,  1.14iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  45%|████▌     | 902/2000 [21:14<16:06,  1.14iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  45%|████▌     | 903/2000 [21:15<16:28,  1.11iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  45%|████▌     | 903/2000 [21:15<16:28,  1.11iteration/s, mean_rewards=-289]\u001b[A\n",
            "Training:  45%|████▌     | 904/2000 [21:15<15:03,  1.21iteration/s, mean_rewards=-289]\u001b[A\n",
            "Training:  45%|████▌     | 904/2000 [21:16<15:03,  1.21iteration/s, mean_rewards=-258]\u001b[A\n",
            "Training:  45%|████▌     | 905/2000 [21:16<14:54,  1.22iteration/s, mean_rewards=-258]\u001b[A\n",
            "Training:  45%|████▌     | 905/2000 [21:17<14:54,  1.22iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  45%|████▌     | 906/2000 [21:17<13:56,  1.31iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  45%|████▌     | 906/2000 [21:17<13:56,  1.31iteration/s, mean_rewards=-239]\u001b[A\n",
            "Training:  45%|████▌     | 907/2000 [21:18<14:00,  1.30iteration/s, mean_rewards=-239]\u001b[A\n",
            "Training:  45%|████▌     | 907/2000 [21:18<14:00,  1.30iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  45%|████▌     | 908/2000 [21:19<14:47,  1.23iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  45%|████▌     | 908/2000 [21:19<14:47,  1.23iteration/s, mean_rewards=-174]\u001b[A\n",
            "Training:  45%|████▌     | 909/2000 [21:19<14:54,  1.22iteration/s, mean_rewards=-174]\u001b[A\n",
            "Training:  45%|████▌     | 909/2000 [21:20<14:54,  1.22iteration/s, mean_rewards=-254]\u001b[A\n",
            "Training:  46%|████▌     | 910/2000 [21:21<16:48,  1.08iteration/s, mean_rewards=-254]\u001b[A\n",
            "Training:  46%|████▌     | 910/2000 [21:21<16:48,  1.08iteration/s, mean_rewards=-209]\u001b[A\n",
            "Training:  46%|████▌     | 911/2000 [21:22<16:44,  1.08iteration/s, mean_rewards=-209]\u001b[A\n",
            "Training:  46%|████▌     | 911/2000 [21:22<16:44,  1.08iteration/s, mean_rewards=-282]\u001b[A\n",
            "Training:  46%|████▌     | 912/2000 [21:23<17:33,  1.03iteration/s, mean_rewards=-282]\u001b[A\n",
            "Training:  46%|████▌     | 912/2000 [21:23<17:33,  1.03iteration/s, mean_rewards=-191]\u001b[A\n",
            "Training:  46%|████▌     | 913/2000 [21:24<18:31,  1.02s/iteration, mean_rewards=-191]\u001b[A\n",
            "Training:  46%|████▌     | 913/2000 [21:24<18:31,  1.02s/iteration, mean_rewards=-238]\u001b[A\n",
            "Training:  46%|████▌     | 914/2000 [21:25<19:08,  1.06s/iteration, mean_rewards=-238]\u001b[A\n",
            "Training:  46%|████▌     | 914/2000 [21:25<19:08,  1.06s/iteration, mean_rewards=-47.5]\u001b[A\n",
            "Training:  46%|████▌     | 915/2000 [21:26<18:33,  1.03s/iteration, mean_rewards=-47.5]\u001b[A\n",
            "Training:  46%|████▌     | 915/2000 [21:26<18:33,  1.03s/iteration, mean_rewards=-166] \u001b[A\n",
            "Training:  46%|████▌     | 916/2000 [21:27<19:08,  1.06s/iteration, mean_rewards=-166]\u001b[A\n",
            "Training:  46%|████▌     | 916/2000 [21:27<19:08,  1.06s/iteration, mean_rewards=-40] \u001b[A\n",
            "Training:  46%|████▌     | 917/2000 [21:28<18:25,  1.02s/iteration, mean_rewards=-40]\u001b[A\n",
            "Training:  46%|████▌     | 917/2000 [21:28<18:25,  1.02s/iteration, mean_rewards=-209]\u001b[A\n",
            "Training:  46%|████▌     | 918/2000 [21:29<18:43,  1.04s/iteration, mean_rewards=-209]\u001b[A\n",
            "Training:  46%|████▌     | 918/2000 [21:29<18:43,  1.04s/iteration, mean_rewards=-158]\u001b[A\n",
            "Training:  46%|████▌     | 919/2000 [21:30<17:23,  1.04iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  46%|████▌     | 919/2000 [21:30<17:23,  1.04iteration/s, mean_rewards=-522]\u001b[A\n",
            "Training:  46%|████▌     | 920/2000 [21:31<17:09,  1.05iteration/s, mean_rewards=-522]\u001b[A\n",
            "Training:  46%|████▌     | 920/2000 [21:31<17:09,  1.05iteration/s, mean_rewards=-163]\u001b[A\n",
            "Training:  46%|████▌     | 921/2000 [21:32<17:45,  1.01iteration/s, mean_rewards=-163]\u001b[A\n",
            "Training:  46%|████▌     | 921/2000 [21:32<17:45,  1.01iteration/s, mean_rewards=-230]\u001b[A\n",
            "Training:  46%|████▌     | 922/2000 [21:33<16:51,  1.07iteration/s, mean_rewards=-230]\u001b[A\n",
            "Training:  46%|████▌     | 922/2000 [21:33<16:51,  1.07iteration/s, mean_rewards=-249]\u001b[A\n",
            "Training:  46%|████▌     | 923/2000 [21:34<16:56,  1.06iteration/s, mean_rewards=-249]\u001b[A\n",
            "Training:  46%|████▌     | 923/2000 [21:34<16:56,  1.06iteration/s, mean_rewards=-208]\u001b[A\n",
            "Training:  46%|████▌     | 924/2000 [21:35<17:58,  1.00s/iteration, mean_rewards=-208]\u001b[A\n",
            "Training:  46%|████▌     | 924/2000 [21:35<17:58,  1.00s/iteration, mean_rewards=-115]\u001b[A\n",
            "Training:  46%|████▋     | 925/2000 [21:36<17:38,  1.02iteration/s, mean_rewards=-115]\u001b[A\n",
            "Training:  46%|████▋     | 925/2000 [21:36<17:38,  1.02iteration/s, mean_rewards=-168]\u001b[A\n",
            "Training:  46%|████▋     | 926/2000 [21:37<18:22,  1.03s/iteration, mean_rewards=-168]\u001b[A\n",
            "Training:  46%|████▋     | 926/2000 [21:38<18:22,  1.03s/iteration, mean_rewards=-39.5]\u001b[A\n",
            "Training:  46%|████▋     | 927/2000 [21:39<26:06,  1.46s/iteration, mean_rewards=-39.5]\u001b[A\n",
            "Training:  46%|████▋     | 927/2000 [21:40<26:06,  1.46s/iteration, mean_rewards=-165] \u001b[A\n",
            "Training:  46%|████▋     | 928/2000 [21:40<22:24,  1.25s/iteration, mean_rewards=-165]\u001b[A\n",
            "Training:  46%|████▋     | 928/2000 [21:40<22:24,  1.25s/iteration, mean_rewards=-276]\u001b[A\n",
            "Training:  46%|████▋     | 929/2000 [21:41<21:20,  1.20s/iteration, mean_rewards=-276]\u001b[A\n",
            "Training:  46%|████▋     | 929/2000 [21:41<21:20,  1.20s/iteration, mean_rewards=-236]\u001b[A\n",
            "Training:  46%|████▋     | 930/2000 [21:42<19:46,  1.11s/iteration, mean_rewards=-236]\u001b[A\n",
            "Training:  46%|████▋     | 930/2000 [21:42<19:46,  1.11s/iteration, mean_rewards=-186]\u001b[A\n",
            "Training:  47%|████▋     | 931/2000 [21:43<18:16,  1.03s/iteration, mean_rewards=-186]\u001b[A\n",
            "Training:  47%|████▋     | 931/2000 [21:43<18:16,  1.03s/iteration, mean_rewards=-170]\u001b[A\n",
            "Training:  47%|████▋     | 932/2000 [21:44<17:06,  1.04iteration/s, mean_rewards=-170]\u001b[A\n",
            "Training:  47%|████▋     | 932/2000 [21:44<17:06,  1.04iteration/s, mean_rewards=-246]\u001b[A\n",
            "Training:  47%|████▋     | 933/2000 [21:44<16:06,  1.10iteration/s, mean_rewards=-246]\u001b[A\n",
            "Training:  47%|████▋     | 933/2000 [21:45<16:06,  1.10iteration/s, mean_rewards=-238]\u001b[A\n",
            "Training:  47%|████▋     | 934/2000 [21:45<15:31,  1.14iteration/s, mean_rewards=-238]\u001b[A\n",
            "Training:  47%|████▋     | 934/2000 [21:46<15:31,  1.14iteration/s, mean_rewards=-359]\u001b[A\n",
            "Training:  47%|████▋     | 935/2000 [21:46<16:39,  1.07iteration/s, mean_rewards=-359]\u001b[A\n",
            "Training:  47%|████▋     | 935/2000 [21:47<16:39,  1.07iteration/s, mean_rewards=-92.4]\u001b[A\n",
            "Training:  47%|████▋     | 936/2000 [21:47<17:27,  1.02iteration/s, mean_rewards=-92.4]\u001b[A\n",
            "Training:  47%|████▋     | 936/2000 [21:48<17:27,  1.02iteration/s, mean_rewards=-75.9]\u001b[A\n",
            "Training:  47%|████▋     | 937/2000 [21:49<20:12,  1.14s/iteration, mean_rewards=-75.9]\u001b[A\n",
            "Training:  47%|████▋     | 937/2000 [21:50<20:12,  1.14s/iteration, mean_rewards=-253] \u001b[A\n",
            "Training:  47%|████▋     | 938/2000 [21:50<21:09,  1.20s/iteration, mean_rewards=-253]\u001b[A\n",
            "Training:  47%|████▋     | 938/2000 [21:51<21:09,  1.20s/iteration, mean_rewards=-96.5]\u001b[A\n",
            "Training:  47%|████▋     | 939/2000 [21:51<20:35,  1.16s/iteration, mean_rewards=-96.5]\u001b[A\n",
            "Training:  47%|████▋     | 939/2000 [21:52<20:35,  1.16s/iteration, mean_rewards=-213] \u001b[A\n",
            "Training:  47%|████▋     | 940/2000 [21:52<19:24,  1.10s/iteration, mean_rewards=-213]\u001b[A\n",
            "Training:  47%|████▋     | 940/2000 [21:53<19:24,  1.10s/iteration, mean_rewards=-96.2]\u001b[A\n",
            "Training:  47%|████▋     | 941/2000 [21:53<17:18,  1.02iteration/s, mean_rewards=-96.2]\u001b[A\n",
            "Training:  47%|████▋     | 941/2000 [21:53<17:18,  1.02iteration/s, mean_rewards=-223] \u001b[A\n",
            "Training:  47%|████▋     | 942/2000 [21:54<16:19,  1.08iteration/s, mean_rewards=-223]\u001b[A\n",
            "Training:  47%|████▋     | 942/2000 [21:54<16:19,  1.08iteration/s, mean_rewards=-212]\u001b[A\n",
            "Training:  47%|████▋     | 943/2000 [21:55<15:37,  1.13iteration/s, mean_rewards=-212]\u001b[A\n",
            "Training:  47%|████▋     | 943/2000 [21:55<15:37,  1.13iteration/s, mean_rewards=-230]\u001b[A\n",
            "Training:  47%|████▋     | 944/2000 [21:55<15:13,  1.16iteration/s, mean_rewards=-230]\u001b[A\n",
            "Training:  47%|████▋     | 944/2000 [21:56<15:13,  1.16iteration/s, mean_rewards=-167]\u001b[A\n",
            "Training:  47%|████▋     | 945/2000 [21:56<16:18,  1.08iteration/s, mean_rewards=-167]\u001b[A\n",
            "Training:  47%|████▋     | 945/2000 [21:57<16:18,  1.08iteration/s, mean_rewards=-91.4]\u001b[A\n",
            "Training:  47%|████▋     | 946/2000 [21:57<15:07,  1.16iteration/s, mean_rewards=-91.4]\u001b[A\n",
            "Training:  47%|████▋     | 946/2000 [21:57<15:07,  1.16iteration/s, mean_rewards=-87.7]\u001b[A\n",
            "Training:  47%|████▋     | 947/2000 [21:58<14:52,  1.18iteration/s, mean_rewards=-87.7]\u001b[A\n",
            "Training:  47%|████▋     | 947/2000 [21:58<14:52,  1.18iteration/s, mean_rewards=-222] \u001b[A\n",
            "Training:  47%|████▋     | 948/2000 [21:59<14:35,  1.20iteration/s, mean_rewards=-222]\u001b[A\n",
            "Training:  47%|████▋     | 948/2000 [21:59<14:35,  1.20iteration/s, mean_rewards=-157]\u001b[A\n",
            "Training:  47%|████▋     | 949/2000 [21:59<13:49,  1.27iteration/s, mean_rewards=-157]\u001b[A\n",
            "Training:  47%|████▋     | 949/2000 [22:00<13:49,  1.27iteration/s, mean_rewards=-232]\u001b[A\n",
            "Training:  48%|████▊     | 950/2000 [22:01<16:11,  1.08iteration/s, mean_rewards=-232]\u001b[A\n",
            "Training:  48%|████▊     | 950/2000 [22:01<16:11,  1.08iteration/s, mean_rewards=-280]\u001b[A\n",
            "Training:  48%|████▊     | 951/2000 [22:02<18:36,  1.06s/iteration, mean_rewards=-280]\u001b[A\n",
            "Training:  48%|████▊     | 951/2000 [22:02<18:36,  1.06s/iteration, mean_rewards=-57.9]\u001b[A\n",
            "Training:  48%|████▊     | 952/2000 [22:03<17:34,  1.01s/iteration, mean_rewards=-57.9]\u001b[A\n",
            "Training:  48%|████▊     | 952/2000 [22:03<17:34,  1.01s/iteration, mean_rewards=-125] \u001b[A\n",
            "Training:  48%|████▊     | 953/2000 [22:04<17:17,  1.01iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  48%|████▊     | 953/2000 [22:04<17:17,  1.01iteration/s, mean_rewards=-77.3]\u001b[A\n",
            "Training:  48%|████▊     | 954/2000 [22:05<15:40,  1.11iteration/s, mean_rewards=-77.3]\u001b[A\n",
            "Training:  48%|████▊     | 954/2000 [22:05<15:40,  1.11iteration/s, mean_rewards=-43.5]\u001b[A\n",
            "Training:  48%|████▊     | 955/2000 [22:05<15:09,  1.15iteration/s, mean_rewards=-43.5]\u001b[A\n",
            "Training:  48%|████▊     | 955/2000 [22:06<15:09,  1.15iteration/s, mean_rewards=-52]  \u001b[A\n",
            "Training:  48%|████▊     | 956/2000 [22:06<15:30,  1.12iteration/s, mean_rewards=-52]\u001b[A\n",
            "Training:  48%|████▊     | 956/2000 [22:07<15:30,  1.12iteration/s, mean_rewards=-115]\u001b[A\n",
            "Training:  48%|████▊     | 957/2000 [22:07<15:08,  1.15iteration/s, mean_rewards=-115]\u001b[A\n",
            "Training:  48%|████▊     | 957/2000 [22:08<15:08,  1.15iteration/s, mean_rewards=-287]\u001b[A\n",
            "Training:  48%|████▊     | 958/2000 [22:08<16:29,  1.05iteration/s, mean_rewards=-287]\u001b[A\n",
            "Training:  48%|████▊     | 958/2000 [22:09<16:29,  1.05iteration/s, mean_rewards=-279]\u001b[A\n",
            "Training:  48%|████▊     | 959/2000 [22:09<16:14,  1.07iteration/s, mean_rewards=-279]\u001b[A\n",
            "Training:  48%|████▊     | 959/2000 [22:10<16:14,  1.07iteration/s, mean_rewards=-247]\u001b[A\n",
            "Training:  48%|████▊     | 960/2000 [22:10<16:47,  1.03iteration/s, mean_rewards=-247]\u001b[A\n",
            "Training:  48%|████▊     | 960/2000 [22:11<16:47,  1.03iteration/s, mean_rewards=-211]\u001b[A\n",
            "Training:  48%|████▊     | 961/2000 [22:11<16:27,  1.05iteration/s, mean_rewards=-211]\u001b[A\n",
            "Training:  48%|████▊     | 961/2000 [22:12<16:27,  1.05iteration/s, mean_rewards=-179]\u001b[A\n",
            "Training:  48%|████▊     | 962/2000 [22:12<16:26,  1.05iteration/s, mean_rewards=-179]\u001b[A\n",
            "Training:  48%|████▊     | 962/2000 [22:12<16:26,  1.05iteration/s, mean_rewards=-104]\u001b[A\n",
            "Training:  48%|████▊     | 963/2000 [22:13<17:05,  1.01iteration/s, mean_rewards=-104]\u001b[A\n",
            "Training:  48%|████▊     | 963/2000 [22:14<17:05,  1.01iteration/s, mean_rewards=-233]\u001b[A\n",
            "Training:  48%|████▊     | 964/2000 [22:15<19:27,  1.13s/iteration, mean_rewards=-233]\u001b[A\n",
            "Training:  48%|████▊     | 964/2000 [22:15<19:27,  1.13s/iteration, mean_rewards=-219]\u001b[A\n",
            "Training:  48%|████▊     | 965/2000 [22:16<20:07,  1.17s/iteration, mean_rewards=-219]\u001b[A\n",
            "Training:  48%|████▊     | 965/2000 [22:16<20:07,  1.17s/iteration, mean_rewards=-146]\u001b[A\n",
            "Training:  48%|████▊     | 966/2000 [22:17<18:08,  1.05s/iteration, mean_rewards=-146]\u001b[A\n",
            "Training:  48%|████▊     | 966/2000 [22:17<18:08,  1.05s/iteration, mean_rewards=-144]\u001b[A\n",
            "Training:  48%|████▊     | 967/2000 [22:18<17:32,  1.02s/iteration, mean_rewards=-144]\u001b[A\n",
            "Training:  48%|████▊     | 967/2000 [22:18<17:32,  1.02s/iteration, mean_rewards=-372]\u001b[A\n",
            "Training:  48%|████▊     | 968/2000 [22:18<16:10,  1.06iteration/s, mean_rewards=-372]\u001b[A\n",
            "Training:  48%|████▊     | 968/2000 [22:19<16:10,  1.06iteration/s, mean_rewards=-225]\u001b[A\n",
            "Training:  48%|████▊     | 969/2000 [22:19<15:27,  1.11iteration/s, mean_rewards=-225]\u001b[A\n",
            "Training:  48%|████▊     | 969/2000 [22:20<15:27,  1.11iteration/s, mean_rewards=-215]\u001b[A\n",
            "Training:  48%|████▊     | 970/2000 [22:20<16:18,  1.05iteration/s, mean_rewards=-215]\u001b[A\n",
            "Training:  48%|████▊     | 970/2000 [22:21<16:18,  1.05iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  49%|████▊     | 971/2000 [22:21<15:25,  1.11iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  49%|████▊     | 971/2000 [22:21<15:25,  1.11iteration/s, mean_rewards=-190]\u001b[A\n",
            "Training:  49%|████▊     | 972/2000 [22:22<14:52,  1.15iteration/s, mean_rewards=-190]\u001b[A\n",
            "Training:  49%|████▊     | 972/2000 [22:22<14:52,  1.15iteration/s, mean_rewards=-179]\u001b[A\n",
            "Training:  49%|████▊     | 973/2000 [22:23<15:07,  1.13iteration/s, mean_rewards=-179]\u001b[A\n",
            "Training:  49%|████▊     | 973/2000 [22:23<15:07,  1.13iteration/s, mean_rewards=-119]\u001b[A\n",
            "Training:  49%|████▊     | 974/2000 [22:23<13:59,  1.22iteration/s, mean_rewards=-119]\u001b[A\n",
            "Training:  49%|████▊     | 974/2000 [22:24<13:59,  1.22iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  49%|████▉     | 975/2000 [22:24<13:22,  1.28iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  49%|████▉     | 975/2000 [22:24<13:22,  1.28iteration/s, mean_rewards=-213]\u001b[A\n",
            "Training:  49%|████▉     | 976/2000 [22:25<14:03,  1.21iteration/s, mean_rewards=-213]\u001b[A\n",
            "Training:  49%|████▉     | 976/2000 [22:25<14:03,  1.21iteration/s, mean_rewards=-300]\u001b[A\n",
            "Training:  49%|████▉     | 977/2000 [22:26<14:51,  1.15iteration/s, mean_rewards=-300]\u001b[A\n",
            "Training:  49%|████▉     | 977/2000 [22:26<14:51,  1.15iteration/s, mean_rewards=-198]\u001b[A\n",
            "Training:  49%|████▉     | 978/2000 [22:27<18:00,  1.06s/iteration, mean_rewards=-198]\u001b[A\n",
            "Training:  49%|████▉     | 978/2000 [22:28<18:00,  1.06s/iteration, mean_rewards=-108]\u001b[A\n",
            "Training:  49%|████▉     | 979/2000 [22:29<17:53,  1.05s/iteration, mean_rewards=-108]\u001b[A\n",
            "Training:  49%|████▉     | 979/2000 [22:29<17:53,  1.05s/iteration, mean_rewards=-289]\u001b[A\n",
            "Training:  49%|████▉     | 980/2000 [22:29<16:46,  1.01iteration/s, mean_rewards=-289]\u001b[A\n",
            "Training:  49%|████▉     | 980/2000 [22:30<16:46,  1.01iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  49%|████▉     | 981/2000 [22:30<15:12,  1.12iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  49%|████▉     | 981/2000 [22:30<15:12,  1.12iteration/s, mean_rewards=-320]\u001b[A\n",
            "Training:  49%|████▉     | 982/2000 [22:31<15:33,  1.09iteration/s, mean_rewards=-320]\u001b[A\n",
            "Training:  49%|████▉     | 982/2000 [22:31<15:33,  1.09iteration/s, mean_rewards=-262]\u001b[A\n",
            "Training:  49%|████▉     | 983/2000 [22:32<14:51,  1.14iteration/s, mean_rewards=-262]\u001b[A\n",
            "Training:  49%|████▉     | 983/2000 [22:32<14:51,  1.14iteration/s, mean_rewards=-92] \u001b[A\n",
            "Training:  49%|████▉     | 984/2000 [22:33<15:03,  1.12iteration/s, mean_rewards=-92]\u001b[A\n",
            "Training:  49%|████▉     | 984/2000 [22:33<15:03,  1.12iteration/s, mean_rewards=-217]\u001b[A\n",
            "Training:  49%|████▉     | 985/2000 [22:33<14:09,  1.19iteration/s, mean_rewards=-217]\u001b[A\n",
            "Training:  49%|████▉     | 985/2000 [22:34<14:09,  1.19iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:  49%|████▉     | 986/2000 [22:35<15:31,  1.09iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:  49%|████▉     | 986/2000 [22:35<15:31,  1.09iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  49%|████▉     | 987/2000 [22:35<14:18,  1.18iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  49%|████▉     | 987/2000 [22:36<14:18,  1.18iteration/s, mean_rewards=-109]\u001b[A\n",
            "Training:  49%|████▉     | 988/2000 [22:36<14:44,  1.14iteration/s, mean_rewards=-109]\u001b[A\n",
            "Training:  49%|████▉     | 988/2000 [22:36<14:44,  1.14iteration/s, mean_rewards=-234]\u001b[A\n",
            "Training:  49%|████▉     | 989/2000 [22:37<13:49,  1.22iteration/s, mean_rewards=-234]\u001b[A\n",
            "Training:  49%|████▉     | 989/2000 [22:37<13:49,  1.22iteration/s, mean_rewards=-285]\u001b[A\n",
            "Training:  50%|████▉     | 990/2000 [22:38<14:19,  1.18iteration/s, mean_rewards=-285]\u001b[A\n",
            "Training:  50%|████▉     | 990/2000 [22:38<14:19,  1.18iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:  50%|████▉     | 991/2000 [22:39<14:50,  1.13iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:  50%|████▉     | 991/2000 [22:39<14:50,  1.13iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:  50%|████▉     | 992/2000 [22:40<14:57,  1.12iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:  50%|████▉     | 992/2000 [22:40<14:57,  1.12iteration/s, mean_rewards=-163]\u001b[A\n",
            "Training:  50%|████▉     | 993/2000 [22:41<17:23,  1.04s/iteration, mean_rewards=-163]\u001b[A\n",
            "Training:  50%|████▉     | 993/2000 [22:41<17:23,  1.04s/iteration, mean_rewards=-94.6]\u001b[A\n",
            "Training:  50%|████▉     | 994/2000 [22:42<15:49,  1.06iteration/s, mean_rewards=-94.6]\u001b[A\n",
            "Training:  50%|████▉     | 994/2000 [22:42<15:49,  1.06iteration/s, mean_rewards=-66.1]\u001b[A\n",
            "Training:  50%|████▉     | 995/2000 [22:42<14:42,  1.14iteration/s, mean_rewards=-66.1]\u001b[A\n",
            "Training:  50%|████▉     | 995/2000 [22:43<14:42,  1.14iteration/s, mean_rewards=-417] \u001b[A\n",
            "Training:  50%|████▉     | 996/2000 [22:43<15:32,  1.08iteration/s, mean_rewards=-417]\u001b[A\n",
            "Training:  50%|████▉     | 996/2000 [22:44<15:32,  1.08iteration/s, mean_rewards=-115]\u001b[A\n",
            "Training:  50%|████▉     | 997/2000 [22:44<14:05,  1.19iteration/s, mean_rewards=-115]\u001b[A\n",
            "Training:  50%|████▉     | 997/2000 [22:44<14:05,  1.19iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  50%|████▉     | 998/2000 [22:45<13:09,  1.27iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  50%|████▉     | 998/2000 [22:45<13:09,  1.27iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  50%|████▉     | 999/2000 [22:46<13:15,  1.26iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  50%|████▉     | 999/2000 [22:46<13:15,  1.26iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  50%|█████     | 1000/2000 [22:47<13:51,  1.20iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  50%|█████     | 1000/2000 [22:47<13:51,  1.20iteration/s, mean_rewards=-234]\u001b[A\n",
            "Training:  50%|█████     | 1001/2000 [22:47<13:47,  1.21iteration/s, mean_rewards=-234]\u001b[A\n",
            "Training:  50%|█████     | 1001/2000 [22:48<13:47,  1.21iteration/s, mean_rewards=-77.6]\u001b[A\n",
            "Training:  50%|█████     | 1002/2000 [22:48<13:28,  1.23iteration/s, mean_rewards=-77.6]\u001b[A\n",
            "Training:  50%|█████     | 1002/2000 [22:49<13:28,  1.23iteration/s, mean_rewards=-120] \u001b[A\n",
            "Training:  50%|█████     | 1003/2000 [22:49<14:28,  1.15iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  50%|█████     | 1003/2000 [22:49<14:28,  1.15iteration/s, mean_rewards=-382]\u001b[A\n",
            "Training:  50%|█████     | 1004/2000 [22:50<14:37,  1.13iteration/s, mean_rewards=-382]\u001b[A\n",
            "Training:  50%|█████     | 1004/2000 [22:50<14:37,  1.13iteration/s, mean_rewards=-206]\u001b[A\n",
            "Training:  50%|█████     | 1005/2000 [22:51<14:49,  1.12iteration/s, mean_rewards=-206]\u001b[A\n",
            "Training:  50%|█████     | 1005/2000 [22:51<14:49,  1.12iteration/s, mean_rewards=-197]\u001b[A\n",
            "Training:  50%|█████     | 1006/2000 [22:52<16:23,  1.01iteration/s, mean_rewards=-197]\u001b[A\n",
            "Training:  50%|█████     | 1006/2000 [22:53<16:23,  1.01iteration/s, mean_rewards=-264]\u001b[A\n",
            "Training:  50%|█████     | 1007/2000 [22:54<18:09,  1.10s/iteration, mean_rewards=-264]\u001b[A\n",
            "Training:  50%|█████     | 1007/2000 [22:54<18:09,  1.10s/iteration, mean_rewards=-314]\u001b[A\n",
            "Training:  50%|█████     | 1008/2000 [22:55<18:18,  1.11s/iteration, mean_rewards=-314]\u001b[A\n",
            "Training:  50%|█████     | 1008/2000 [22:55<18:18,  1.11s/iteration, mean_rewards=-279]\u001b[A\n",
            "Training:  50%|█████     | 1009/2000 [22:55<16:54,  1.02s/iteration, mean_rewards=-279]\u001b[A\n",
            "Training:  50%|█████     | 1009/2000 [22:56<16:54,  1.02s/iteration, mean_rewards=-362]\u001b[A\n",
            "Training:  50%|█████     | 1010/2000 [22:56<15:39,  1.05iteration/s, mean_rewards=-362]\u001b[A\n",
            "Training:  50%|█████     | 1010/2000 [22:57<15:39,  1.05iteration/s, mean_rewards=-93.3]\u001b[A\n",
            "Training:  51%|█████     | 1011/2000 [22:57<14:13,  1.16iteration/s, mean_rewards=-93.3]\u001b[A\n",
            "Training:  51%|█████     | 1011/2000 [22:57<14:13,  1.16iteration/s, mean_rewards=-215] \u001b[A\n",
            "Training:  51%|█████     | 1012/2000 [22:58<13:52,  1.19iteration/s, mean_rewards=-215]\u001b[A\n",
            "Training:  51%|█████     | 1012/2000 [22:58<13:52,  1.19iteration/s, mean_rewards=-195]\u001b[A\n",
            "Training:  51%|█████     | 1013/2000 [22:58<13:02,  1.26iteration/s, mean_rewards=-195]\u001b[A\n",
            "Training:  51%|█████     | 1013/2000 [22:59<13:02,  1.26iteration/s, mean_rewards=-63.5]\u001b[A\n",
            "Training:  51%|█████     | 1014/2000 [22:59<12:58,  1.27iteration/s, mean_rewards=-63.5]\u001b[A\n",
            "Training:  51%|█████     | 1014/2000 [22:59<12:58,  1.27iteration/s, mean_rewards=-47.8]\u001b[A\n",
            "Training:  51%|█████     | 1015/2000 [23:00<12:33,  1.31iteration/s, mean_rewards=-47.8]\u001b[A\n",
            "Training:  51%|█████     | 1015/2000 [23:00<12:33,  1.31iteration/s, mean_rewards=-245] \u001b[A\n",
            "Training:  51%|█████     | 1016/2000 [23:01<13:20,  1.23iteration/s, mean_rewards=-245]\u001b[A\n",
            "Training:  51%|█████     | 1016/2000 [23:01<13:20,  1.23iteration/s, mean_rewards=-383]\u001b[A\n",
            "Training:  51%|█████     | 1017/2000 [23:02<13:52,  1.18iteration/s, mean_rewards=-383]\u001b[A\n",
            "Training:  51%|█████     | 1017/2000 [23:02<13:52,  1.18iteration/s, mean_rewards=-321]\u001b[A\n",
            "Training:  51%|█████     | 1018/2000 [23:03<15:31,  1.05iteration/s, mean_rewards=-321]\u001b[A\n",
            "Training:  51%|█████     | 1018/2000 [23:03<15:31,  1.05iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:  51%|█████     | 1019/2000 [23:04<14:14,  1.15iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:  51%|█████     | 1019/2000 [23:04<14:14,  1.15iteration/s, mean_rewards=-251]\u001b[A\n",
            "Training:  51%|█████     | 1020/2000 [23:05<15:26,  1.06iteration/s, mean_rewards=-251]\u001b[A\n",
            "Training:  51%|█████     | 1020/2000 [23:05<15:26,  1.06iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  51%|█████     | 1021/2000 [23:06<16:08,  1.01iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  51%|█████     | 1021/2000 [23:06<16:08,  1.01iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  51%|█████     | 1022/2000 [23:07<16:13,  1.00iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  51%|█████     | 1022/2000 [23:07<16:13,  1.00iteration/s, mean_rewards=-58.7]\u001b[A\n",
            "Training:  51%|█████     | 1023/2000 [23:08<15:15,  1.07iteration/s, mean_rewards=-58.7]\u001b[A\n",
            "Training:  51%|█████     | 1023/2000 [23:08<15:15,  1.07iteration/s, mean_rewards=-174] \u001b[A\n",
            "Training:  51%|█████     | 1024/2000 [23:08<14:23,  1.13iteration/s, mean_rewards=-174]\u001b[A\n",
            "Training:  51%|█████     | 1024/2000 [23:09<14:23,  1.13iteration/s, mean_rewards=-175]\u001b[A\n",
            "Training:  51%|█████▏    | 1025/2000 [23:09<13:21,  1.22iteration/s, mean_rewards=-175]\u001b[A\n",
            "Training:  51%|█████▏    | 1025/2000 [23:09<13:21,  1.22iteration/s, mean_rewards=-256]\u001b[A\n",
            "Training:  51%|█████▏    | 1026/2000 [23:10<14:23,  1.13iteration/s, mean_rewards=-256]\u001b[A\n",
            "Training:  51%|█████▏    | 1026/2000 [23:11<14:23,  1.13iteration/s, mean_rewards=-315]\u001b[A\n",
            "Training:  51%|█████▏    | 1027/2000 [23:11<15:19,  1.06iteration/s, mean_rewards=-315]\u001b[A\n",
            "Training:  51%|█████▏    | 1027/2000 [23:12<15:19,  1.06iteration/s, mean_rewards=-232]\u001b[A\n",
            "Training:  51%|█████▏    | 1028/2000 [23:12<15:44,  1.03iteration/s, mean_rewards=-232]\u001b[A\n",
            "Training:  51%|█████▏    | 1028/2000 [23:13<15:44,  1.03iteration/s, mean_rewards=-227]\u001b[A\n",
            "Training:  51%|█████▏    | 1029/2000 [23:13<16:01,  1.01iteration/s, mean_rewards=-227]\u001b[A\n",
            "Training:  51%|█████▏    | 1029/2000 [23:14<16:01,  1.01iteration/s, mean_rewards=-42.3]\u001b[A\n",
            "Training:  52%|█████▏    | 1030/2000 [23:14<15:44,  1.03iteration/s, mean_rewards=-42.3]\u001b[A\n",
            "Training:  52%|█████▏    | 1030/2000 [23:15<15:44,  1.03iteration/s, mean_rewards=-159] \u001b[A\n",
            "Training:  52%|█████▏    | 1031/2000 [23:15<15:39,  1.03iteration/s, mean_rewards=-159]\u001b[A\n",
            "Training:  52%|█████▏    | 1031/2000 [23:16<15:39,  1.03iteration/s, mean_rewards=-277]\u001b[A\n",
            "Training:  52%|█████▏    | 1032/2000 [23:16<16:26,  1.02s/iteration, mean_rewards=-277]\u001b[A\n",
            "Training:  52%|█████▏    | 1032/2000 [23:17<16:26,  1.02s/iteration, mean_rewards=-211]\u001b[A\n",
            "Training:  52%|█████▏    | 1033/2000 [23:18<17:44,  1.10s/iteration, mean_rewards=-211]\u001b[A\n",
            "Training:  52%|█████▏    | 1033/2000 [23:18<17:44,  1.10s/iteration, mean_rewards=-101]\u001b[A\n",
            "Training:  52%|█████▏    | 1034/2000 [23:19<18:56,  1.18s/iteration, mean_rewards=-101]\u001b[A\n",
            "Training:  52%|█████▏    | 1034/2000 [23:19<18:56,  1.18s/iteration, mean_rewards=-100]\u001b[A\n",
            "Training:  52%|█████▏    | 1035/2000 [23:20<17:01,  1.06s/iteration, mean_rewards=-100]\u001b[A\n",
            "Training:  52%|█████▏    | 1035/2000 [23:20<17:01,  1.06s/iteration, mean_rewards=-334]\u001b[A\n",
            "Training:  52%|█████▏    | 1036/2000 [23:21<15:58,  1.01iteration/s, mean_rewards=-334]\u001b[A\n",
            "Training:  52%|█████▏    | 1036/2000 [23:21<15:58,  1.01iteration/s, mean_rewards=-103]\u001b[A\n",
            "Training:  52%|█████▏    | 1037/2000 [23:22<15:47,  1.02iteration/s, mean_rewards=-103]\u001b[A\n",
            "Training:  52%|█████▏    | 1037/2000 [23:22<15:47,  1.02iteration/s, mean_rewards=-89.9]\u001b[A\n",
            "Training:  52%|█████▏    | 1038/2000 [23:22<14:18,  1.12iteration/s, mean_rewards=-89.9]\u001b[A\n",
            "Training:  52%|█████▏    | 1038/2000 [23:23<14:18,  1.12iteration/s, mean_rewards=-207] \u001b[A\n",
            "Training:  52%|█████▏    | 1039/2000 [23:23<13:52,  1.15iteration/s, mean_rewards=-207]\u001b[A\n",
            "Training:  52%|█████▏    | 1039/2000 [23:23<13:52,  1.15iteration/s, mean_rewards=-187]\u001b[A\n",
            "Training:  52%|█████▏    | 1040/2000 [23:24<15:22,  1.04iteration/s, mean_rewards=-187]\u001b[A\n",
            "Training:  52%|█████▏    | 1040/2000 [23:24<15:22,  1.04iteration/s, mean_rewards=-189]\u001b[A\n",
            "Training:  52%|█████▏    | 1041/2000 [23:25<14:29,  1.10iteration/s, mean_rewards=-189]\u001b[A\n",
            "Training:  52%|█████▏    | 1041/2000 [23:25<14:29,  1.10iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  52%|█████▏    | 1042/2000 [23:26<13:40,  1.17iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  52%|█████▏    | 1042/2000 [23:26<13:40,  1.17iteration/s, mean_rewards=-210]\u001b[A\n",
            "Training:  52%|█████▏    | 1043/2000 [23:27<14:02,  1.14iteration/s, mean_rewards=-210]\u001b[A\n",
            "Training:  52%|█████▏    | 1043/2000 [23:27<14:02,  1.14iteration/s, mean_rewards=-201]\u001b[A\n",
            "Training:  52%|█████▏    | 1044/2000 [23:28<14:46,  1.08iteration/s, mean_rewards=-201]\u001b[A\n",
            "Training:  52%|█████▏    | 1044/2000 [23:28<14:46,  1.08iteration/s, mean_rewards=-266]\u001b[A\n",
            "Training:  52%|█████▏    | 1045/2000 [23:29<15:27,  1.03iteration/s, mean_rewards=-266]\u001b[A\n",
            "Training:  52%|█████▏    | 1045/2000 [23:29<15:27,  1.03iteration/s, mean_rewards=-186]\u001b[A\n",
            "Training:  52%|█████▏    | 1046/2000 [23:30<16:07,  1.01s/iteration, mean_rewards=-186]\u001b[A\n",
            "Training:  52%|█████▏    | 1046/2000 [23:30<16:07,  1.01s/iteration, mean_rewards=-108]\u001b[A\n",
            "Training:  52%|█████▏    | 1047/2000 [23:31<15:26,  1.03iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:  52%|█████▏    | 1047/2000 [23:31<15:26,  1.03iteration/s, mean_rewards=-244]\u001b[A\n",
            "Training:  52%|█████▏    | 1048/2000 [23:32<16:10,  1.02s/iteration, mean_rewards=-244]\u001b[A\n",
            "Training:  52%|█████▏    | 1048/2000 [23:32<16:10,  1.02s/iteration, mean_rewards=-130]\u001b[A\n",
            "Training:  52%|█████▏    | 1049/2000 [23:33<16:41,  1.05s/iteration, mean_rewards=-130]\u001b[A\n",
            "Training:  52%|█████▏    | 1049/2000 [23:33<16:41,  1.05s/iteration, mean_rewards=-342]\u001b[A\n",
            "Training:  52%|█████▎    | 1050/2000 [23:34<15:23,  1.03iteration/s, mean_rewards=-342]\u001b[A\n",
            "Training:  52%|█████▎    | 1050/2000 [23:34<15:23,  1.03iteration/s, mean_rewards=-152]\u001b[A\n",
            "Training:  53%|█████▎    | 1051/2000 [23:35<15:33,  1.02iteration/s, mean_rewards=-152]\u001b[A\n",
            "Training:  53%|█████▎    | 1051/2000 [23:35<15:33,  1.02iteration/s, mean_rewards=-271]\u001b[A\n",
            "Training:  53%|█████▎    | 1052/2000 [23:36<14:39,  1.08iteration/s, mean_rewards=-271]\u001b[A\n",
            "Training:  53%|█████▎    | 1052/2000 [23:36<14:39,  1.08iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  53%|█████▎    | 1053/2000 [23:36<14:28,  1.09iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  53%|█████▎    | 1053/2000 [23:37<14:28,  1.09iteration/s, mean_rewards=-152]\u001b[A\n",
            "Training:  53%|█████▎    | 1054/2000 [23:37<13:55,  1.13iteration/s, mean_rewards=-152]\u001b[A\n",
            "Training:  53%|█████▎    | 1054/2000 [23:38<13:55,  1.13iteration/s, mean_rewards=-221]\u001b[A\n",
            "Training:  53%|█████▎    | 1055/2000 [23:38<13:28,  1.17iteration/s, mean_rewards=-221]\u001b[A\n",
            "Training:  53%|█████▎    | 1055/2000 [23:38<13:28,  1.17iteration/s, mean_rewards=-115]\u001b[A\n",
            "Training:  53%|█████▎    | 1056/2000 [23:39<13:13,  1.19iteration/s, mean_rewards=-115]\u001b[A\n",
            "Training:  53%|█████▎    | 1056/2000 [23:39<13:13,  1.19iteration/s, mean_rewards=-82.6]\u001b[A\n",
            "Training:  53%|█████▎    | 1057/2000 [23:40<14:17,  1.10iteration/s, mean_rewards=-82.6]\u001b[A\n",
            "Training:  53%|█████▎    | 1057/2000 [23:40<14:17,  1.10iteration/s, mean_rewards=-202] \u001b[A\n",
            "Training:  53%|█████▎    | 1058/2000 [23:41<14:59,  1.05iteration/s, mean_rewards=-202]\u001b[A\n",
            "Training:  53%|█████▎    | 1058/2000 [23:41<14:59,  1.05iteration/s, mean_rewards=-242]\u001b[A\n",
            "Training:  53%|█████▎    | 1059/2000 [23:42<14:17,  1.10iteration/s, mean_rewards=-242]\u001b[A\n",
            "Training:  53%|█████▎    | 1059/2000 [23:42<14:17,  1.10iteration/s, mean_rewards=-313]\u001b[A\n",
            "Training:  53%|█████▎    | 1060/2000 [23:43<15:49,  1.01s/iteration, mean_rewards=-313]\u001b[A\n",
            "Training:  53%|█████▎    | 1060/2000 [23:44<15:49,  1.01s/iteration, mean_rewards=-199]\u001b[A\n",
            "Training:  53%|█████▎    | 1061/2000 [23:44<16:57,  1.08s/iteration, mean_rewards=-199]\u001b[A\n",
            "Training:  53%|█████▎    | 1061/2000 [23:45<16:57,  1.08s/iteration, mean_rewards=-385]\u001b[A\n",
            "Training:  53%|█████▎    | 1062/2000 [23:45<17:03,  1.09s/iteration, mean_rewards=-385]\u001b[A\n",
            "Training:  53%|█████▎    | 1062/2000 [23:46<17:03,  1.09s/iteration, mean_rewards=-196]\u001b[A\n",
            "Training:  53%|█████▎    | 1063/2000 [23:46<15:42,  1.01s/iteration, mean_rewards=-196]\u001b[A\n",
            "Training:  53%|█████▎    | 1063/2000 [23:47<15:42,  1.01s/iteration, mean_rewards=-293]\u001b[A\n",
            "Training:  53%|█████▎    | 1064/2000 [23:47<14:29,  1.08iteration/s, mean_rewards=-293]\u001b[A\n",
            "Training:  53%|█████▎    | 1064/2000 [23:47<14:29,  1.08iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  53%|█████▎    | 1065/2000 [23:48<14:27,  1.08iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  53%|█████▎    | 1065/2000 [23:48<14:27,  1.08iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  53%|█████▎    | 1066/2000 [23:49<15:03,  1.03iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  53%|█████▎    | 1066/2000 [23:49<15:03,  1.03iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  53%|█████▎    | 1067/2000 [23:50<14:25,  1.08iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  53%|█████▎    | 1067/2000 [23:50<14:25,  1.08iteration/s, mean_rewards=-301]\u001b[A\n",
            "Training:  53%|█████▎    | 1068/2000 [23:51<15:05,  1.03iteration/s, mean_rewards=-301]\u001b[A\n",
            "Training:  53%|█████▎    | 1068/2000 [23:51<15:05,  1.03iteration/s, mean_rewards=-219]\u001b[A\n",
            "Training:  53%|█████▎    | 1069/2000 [23:52<16:12,  1.04s/iteration, mean_rewards=-219]\u001b[A\n",
            "Training:  53%|█████▎    | 1069/2000 [23:52<16:12,  1.04s/iteration, mean_rewards=-235]\u001b[A\n",
            "Training:  54%|█████▎    | 1070/2000 [23:53<15:41,  1.01s/iteration, mean_rewards=-235]\u001b[A\n",
            "Training:  54%|█████▎    | 1070/2000 [23:53<15:41,  1.01s/iteration, mean_rewards=-122]\u001b[A\n",
            "Training:  54%|█████▎    | 1071/2000 [23:54<14:48,  1.05iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  54%|█████▎    | 1071/2000 [23:54<14:48,  1.05iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  54%|█████▎    | 1072/2000 [23:55<14:04,  1.10iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  54%|█████▎    | 1072/2000 [23:55<14:04,  1.10iteration/s, mean_rewards=-209]\u001b[A\n",
            "Training:  54%|█████▎    | 1073/2000 [23:56<14:36,  1.06iteration/s, mean_rewards=-209]\u001b[A\n",
            "Training:  54%|█████▎    | 1073/2000 [23:56<14:36,  1.06iteration/s, mean_rewards=-209]\u001b[A\n",
            "Training:  54%|█████▎    | 1074/2000 [23:57<16:58,  1.10s/iteration, mean_rewards=-209]\u001b[A\n",
            "Training:  54%|█████▎    | 1074/2000 [23:58<16:58,  1.10s/iteration, mean_rewards=-219]\u001b[A\n",
            "Training:  54%|█████▍    | 1075/2000 [23:58<17:27,  1.13s/iteration, mean_rewards=-219]\u001b[A\n",
            "Training:  54%|█████▍    | 1075/2000 [23:59<17:27,  1.13s/iteration, mean_rewards=-276]\u001b[A\n",
            "Training:  54%|█████▍    | 1076/2000 [23:59<15:27,  1.00s/iteration, mean_rewards=-276]\u001b[A\n",
            "Training:  54%|█████▍    | 1076/2000 [23:59<15:27,  1.00s/iteration, mean_rewards=-310]\u001b[A\n",
            "Training:  54%|█████▍    | 1077/2000 [24:00<15:16,  1.01iteration/s, mean_rewards=-310]\u001b[A\n",
            "Training:  54%|█████▍    | 1077/2000 [24:00<15:16,  1.01iteration/s, mean_rewards=-170]\u001b[A\n",
            "Training:  54%|█████▍    | 1078/2000 [24:01<14:50,  1.04iteration/s, mean_rewards=-170]\u001b[A\n",
            "Training:  54%|█████▍    | 1078/2000 [24:01<14:50,  1.04iteration/s, mean_rewards=-159]\u001b[A\n",
            "Training:  54%|█████▍    | 1079/2000 [24:02<14:41,  1.05iteration/s, mean_rewards=-159]\u001b[A\n",
            "Training:  54%|█████▍    | 1079/2000 [24:02<14:41,  1.05iteration/s, mean_rewards=-217]\u001b[A\n",
            "Training:  54%|█████▍    | 1080/2000 [24:03<15:17,  1.00iteration/s, mean_rewards=-217]\u001b[A\n",
            "Training:  54%|█████▍    | 1080/2000 [24:03<15:17,  1.00iteration/s, mean_rewards=-212]\u001b[A\n",
            "Training:  54%|█████▍    | 1081/2000 [24:04<15:01,  1.02iteration/s, mean_rewards=-212]\u001b[A\n",
            "Training:  54%|█████▍    | 1081/2000 [24:04<15:01,  1.02iteration/s, mean_rewards=-238]\u001b[A\n",
            "Training:  54%|█████▍    | 1082/2000 [24:05<14:26,  1.06iteration/s, mean_rewards=-238]\u001b[A\n",
            "Training:  54%|█████▍    | 1082/2000 [24:05<14:26,  1.06iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  54%|█████▍    | 1083/2000 [24:06<13:42,  1.11iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  54%|█████▍    | 1083/2000 [24:06<13:42,  1.11iteration/s, mean_rewards=-172]\u001b[A\n",
            "Training:  54%|█████▍    | 1084/2000 [24:06<13:18,  1.15iteration/s, mean_rewards=-172]\u001b[A\n",
            "Training:  54%|█████▍    | 1084/2000 [24:07<13:18,  1.15iteration/s, mean_rewards=-469]\u001b[A\n",
            "Training:  54%|█████▍    | 1085/2000 [24:07<14:05,  1.08iteration/s, mean_rewards=-469]\u001b[A\n",
            "Training:  54%|█████▍    | 1085/2000 [24:08<14:05,  1.08iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  54%|█████▍    | 1086/2000 [24:08<13:49,  1.10iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  54%|█████▍    | 1086/2000 [24:09<13:49,  1.10iteration/s, mean_rewards=-112]\u001b[A\n",
            "Training:  54%|█████▍    | 1087/2000 [24:09<13:45,  1.11iteration/s, mean_rewards=-112]\u001b[A\n",
            "Training:  54%|█████▍    | 1087/2000 [24:10<13:45,  1.11iteration/s, mean_rewards=-303]\u001b[A\n",
            "Training:  54%|█████▍    | 1088/2000 [24:11<16:18,  1.07s/iteration, mean_rewards=-303]\u001b[A\n",
            "Training:  54%|█████▍    | 1088/2000 [24:11<16:18,  1.07s/iteration, mean_rewards=-64] \u001b[A\n",
            "Training:  54%|█████▍    | 1089/2000 [24:12<15:49,  1.04s/iteration, mean_rewards=-64]\u001b[A\n",
            "Training:  54%|█████▍    | 1089/2000 [24:12<15:49,  1.04s/iteration, mean_rewards=-224]\u001b[A\n",
            "Training:  55%|█████▍    | 1090/2000 [24:13<15:57,  1.05s/iteration, mean_rewards=-224]\u001b[A\n",
            "Training:  55%|█████▍    | 1090/2000 [24:13<15:57,  1.05s/iteration, mean_rewards=-342]\u001b[A\n",
            "Training:  55%|█████▍    | 1091/2000 [24:13<14:50,  1.02iteration/s, mean_rewards=-342]\u001b[A\n",
            "Training:  55%|█████▍    | 1091/2000 [24:14<14:50,  1.02iteration/s, mean_rewards=-49] \u001b[A\n",
            "Training:  55%|█████▍    | 1092/2000 [24:14<14:38,  1.03iteration/s, mean_rewards=-49]\u001b[A\n",
            "Training:  55%|█████▍    | 1092/2000 [24:15<14:38,  1.03iteration/s, mean_rewards=-231]\u001b[A\n",
            "Training:  55%|█████▍    | 1093/2000 [24:15<15:05,  1.00iteration/s, mean_rewards=-231]\u001b[A\n",
            "Training:  55%|█████▍    | 1093/2000 [24:16<15:05,  1.00iteration/s, mean_rewards=-159]\u001b[A\n",
            "Training:  55%|█████▍    | 1094/2000 [24:16<14:15,  1.06iteration/s, mean_rewards=-159]\u001b[A\n",
            "Training:  55%|█████▍    | 1094/2000 [24:17<14:15,  1.06iteration/s, mean_rewards=-234]\u001b[A\n",
            "Training:  55%|█████▍    | 1095/2000 [24:17<13:44,  1.10iteration/s, mean_rewards=-234]\u001b[A\n",
            "Training:  55%|█████▍    | 1095/2000 [24:18<13:44,  1.10iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  55%|█████▍    | 1096/2000 [24:18<13:44,  1.10iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  55%|█████▍    | 1096/2000 [24:18<13:44,  1.10iteration/s, mean_rewards=-340]\u001b[A\n",
            "Training:  55%|█████▍    | 1097/2000 [24:19<13:19,  1.13iteration/s, mean_rewards=-340]\u001b[A\n",
            "Training:  55%|█████▍    | 1097/2000 [24:19<13:19,  1.13iteration/s, mean_rewards=-239]\u001b[A\n",
            "Training:  55%|█████▍    | 1098/2000 [24:20<12:26,  1.21iteration/s, mean_rewards=-239]\u001b[A\n",
            "Training:  55%|█████▍    | 1098/2000 [24:20<12:26,  1.21iteration/s, mean_rewards=-171]\u001b[A\n",
            "Training:  55%|█████▍    | 1099/2000 [24:20<11:13,  1.34iteration/s, mean_rewards=-171]\u001b[A\n",
            "Training:  55%|█████▍    | 1099/2000 [24:20<11:13,  1.34iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  55%|█████▌    | 1100/2000 [24:21<12:27,  1.20iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  55%|█████▌    | 1100/2000 [24:22<12:27,  1.20iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  55%|█████▌    | 1101/2000 [24:23<15:13,  1.02s/iteration, mean_rewards=-151]\u001b[A\n",
            "Training:  55%|█████▌    | 1101/2000 [24:23<15:13,  1.02s/iteration, mean_rewards=-77.3]\u001b[A\n",
            "Training:  55%|█████▌    | 1102/2000 [24:24<14:45,  1.01iteration/s, mean_rewards=-77.3]\u001b[A\n",
            "Training:  55%|█████▌    | 1102/2000 [24:24<14:45,  1.01iteration/s, mean_rewards=-188] \u001b[A\n",
            "Training:  55%|█████▌    | 1103/2000 [24:24<13:57,  1.07iteration/s, mean_rewards=-188]\u001b[A\n",
            "Training:  55%|█████▌    | 1103/2000 [24:25<13:57,  1.07iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:  55%|█████▌    | 1104/2000 [24:25<13:21,  1.12iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:  55%|█████▌    | 1104/2000 [24:26<13:21,  1.12iteration/s, mean_rewards=-354]\u001b[A\n",
            "Training:  55%|█████▌    | 1105/2000 [24:26<13:45,  1.08iteration/s, mean_rewards=-354]\u001b[A\n",
            "Training:  55%|█████▌    | 1105/2000 [24:27<13:45,  1.08iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  55%|█████▌    | 1106/2000 [24:27<13:52,  1.07iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  55%|█████▌    | 1106/2000 [24:27<13:52,  1.07iteration/s, mean_rewards=-157]\u001b[A\n",
            "Training:  55%|█████▌    | 1107/2000 [24:28<13:15,  1.12iteration/s, mean_rewards=-157]\u001b[A\n",
            "Training:  55%|█████▌    | 1107/2000 [24:28<13:15,  1.12iteration/s, mean_rewards=-226]\u001b[A\n",
            "Training:  55%|█████▌    | 1108/2000 [24:29<14:41,  1.01iteration/s, mean_rewards=-226]\u001b[A\n",
            "Training:  55%|█████▌    | 1108/2000 [24:29<14:41,  1.01iteration/s, mean_rewards=-220]\u001b[A\n",
            "Training:  55%|█████▌    | 1109/2000 [24:30<13:53,  1.07iteration/s, mean_rewards=-220]\u001b[A\n",
            "Training:  55%|█████▌    | 1109/2000 [24:30<13:53,  1.07iteration/s, mean_rewards=-447]\u001b[A\n",
            "Training:  56%|█████▌    | 1110/2000 [24:31<14:23,  1.03iteration/s, mean_rewards=-447]\u001b[A\n",
            "Training:  56%|█████▌    | 1110/2000 [24:31<14:23,  1.03iteration/s, mean_rewards=-317]\u001b[A\n",
            "Training:  56%|█████▌    | 1111/2000 [24:32<14:04,  1.05iteration/s, mean_rewards=-317]\u001b[A\n",
            "Training:  56%|█████▌    | 1111/2000 [24:32<14:04,  1.05iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  56%|█████▌    | 1112/2000 [24:33<13:27,  1.10iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  56%|█████▌    | 1112/2000 [24:33<13:27,  1.10iteration/s, mean_rewards=-249]\u001b[A\n",
            "Training:  56%|█████▌    | 1113/2000 [24:34<14:39,  1.01iteration/s, mean_rewards=-249]\u001b[A\n",
            "Training:  56%|█████▌    | 1113/2000 [24:34<14:39,  1.01iteration/s, mean_rewards=-299]\u001b[A\n",
            "Training:  56%|█████▌    | 1114/2000 [24:35<16:17,  1.10s/iteration, mean_rewards=-299]\u001b[A\n",
            "Training:  56%|█████▌    | 1114/2000 [24:36<16:17,  1.10s/iteration, mean_rewards=-292]\u001b[A\n",
            "Training:  56%|█████▌    | 1115/2000 [24:37<18:21,  1.24s/iteration, mean_rewards=-292]\u001b[A\n",
            "Training:  56%|█████▌    | 1115/2000 [24:37<18:21,  1.24s/iteration, mean_rewards=-115]\u001b[A\n",
            "Training:  56%|█████▌    | 1116/2000 [24:38<16:33,  1.12s/iteration, mean_rewards=-115]\u001b[A\n",
            "Training:  56%|█████▌    | 1116/2000 [24:38<16:33,  1.12s/iteration, mean_rewards=-70.9]\u001b[A\n",
            "Training:  56%|█████▌    | 1117/2000 [24:38<14:37,  1.01iteration/s, mean_rewards=-70.9]\u001b[A\n",
            "Training:  56%|█████▌    | 1117/2000 [24:39<14:37,  1.01iteration/s, mean_rewards=-129] \u001b[A\n",
            "Training:  56%|█████▌    | 1118/2000 [24:40<15:34,  1.06s/iteration, mean_rewards=-129]\u001b[A\n",
            "Training:  56%|█████▌    | 1118/2000 [24:40<15:34,  1.06s/iteration, mean_rewards=-224]\u001b[A\n",
            "Training:  56%|█████▌    | 1119/2000 [24:41<15:44,  1.07s/iteration, mean_rewards=-224]\u001b[A\n",
            "Training:  56%|█████▌    | 1119/2000 [24:41<15:44,  1.07s/iteration, mean_rewards=-99.2]\u001b[A\n",
            "Training:  56%|█████▌    | 1120/2000 [24:42<15:19,  1.04s/iteration, mean_rewards=-99.2]\u001b[A\n",
            "Training:  56%|█████▌    | 1120/2000 [24:42<15:19,  1.04s/iteration, mean_rewards=-174] \u001b[A\n",
            "Training:  56%|█████▌    | 1121/2000 [24:42<13:44,  1.07iteration/s, mean_rewards=-174]\u001b[A\n",
            "Training:  56%|█████▌    | 1121/2000 [24:43<13:44,  1.07iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  56%|█████▌    | 1122/2000 [24:43<12:35,  1.16iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  56%|█████▌    | 1122/2000 [24:43<12:35,  1.16iteration/s, mean_rewards=-254]\u001b[A\n",
            "Training:  56%|█████▌    | 1123/2000 [24:44<13:34,  1.08iteration/s, mean_rewards=-254]\u001b[A\n",
            "Training:  56%|█████▌    | 1123/2000 [24:44<13:34,  1.08iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:  56%|█████▌    | 1124/2000 [24:45<13:31,  1.08iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:  56%|█████▌    | 1124/2000 [24:45<13:31,  1.08iteration/s, mean_rewards=-179]\u001b[A\n",
            "Training:  56%|█████▋    | 1125/2000 [24:46<12:56,  1.13iteration/s, mean_rewards=-179]\u001b[A\n",
            "Training:  56%|█████▋    | 1125/2000 [24:46<12:56,  1.13iteration/s, mean_rewards=-86.7]\u001b[A\n",
            "Training:  56%|█████▋    | 1126/2000 [24:47<12:33,  1.16iteration/s, mean_rewards=-86.7]\u001b[A\n",
            "Training:  56%|█████▋    | 1126/2000 [24:47<12:33,  1.16iteration/s, mean_rewards=-323] \u001b[A\n",
            "Training:  56%|█████▋    | 1127/2000 [24:48<14:58,  1.03s/iteration, mean_rewards=-323]\u001b[A\n",
            "Training:  56%|█████▋    | 1127/2000 [24:48<14:58,  1.03s/iteration, mean_rewards=-283]\u001b[A\n",
            "Training:  56%|█████▋    | 1128/2000 [24:49<15:19,  1.06s/iteration, mean_rewards=-283]\u001b[A\n",
            "Training:  56%|█████▋    | 1128/2000 [24:49<15:19,  1.06s/iteration, mean_rewards=-102]\u001b[A\n",
            "Training:  56%|█████▋    | 1129/2000 [24:50<14:20,  1.01iteration/s, mean_rewards=-102]\u001b[A\n",
            "Training:  56%|█████▋    | 1129/2000 [24:50<14:20,  1.01iteration/s, mean_rewards=-236]\u001b[A\n",
            "Training:  56%|█████▋    | 1130/2000 [24:51<13:26,  1.08iteration/s, mean_rewards=-236]\u001b[A\n",
            "Training:  56%|█████▋    | 1130/2000 [24:51<13:26,  1.08iteration/s, mean_rewards=-260]\u001b[A\n",
            "Training:  57%|█████▋    | 1131/2000 [24:52<12:55,  1.12iteration/s, mean_rewards=-260]\u001b[A\n",
            "Training:  57%|█████▋    | 1131/2000 [24:52<12:55,  1.12iteration/s, mean_rewards=-289]\u001b[A\n",
            "Training:  57%|█████▋    | 1132/2000 [24:52<13:03,  1.11iteration/s, mean_rewards=-289]\u001b[A\n",
            "Training:  57%|█████▋    | 1132/2000 [24:53<13:03,  1.11iteration/s, mean_rewards=-80] \u001b[A\n",
            "Training:  57%|█████▋    | 1133/2000 [24:53<13:22,  1.08iteration/s, mean_rewards=-80]\u001b[A\n",
            "Training:  57%|█████▋    | 1133/2000 [24:54<13:22,  1.08iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  57%|█████▋    | 1134/2000 [24:54<12:17,  1.17iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  57%|█████▋    | 1134/2000 [24:55<12:17,  1.17iteration/s, mean_rewards=-337]\u001b[A\n",
            "Training:  57%|█████▋    | 1135/2000 [24:55<12:36,  1.14iteration/s, mean_rewards=-337]\u001b[A\n",
            "Training:  57%|█████▋    | 1135/2000 [24:56<12:36,  1.14iteration/s, mean_rewards=-241]\u001b[A\n",
            "Training:  57%|█████▋    | 1136/2000 [24:56<13:21,  1.08iteration/s, mean_rewards=-241]\u001b[A\n",
            "Training:  57%|█████▋    | 1136/2000 [24:56<13:21,  1.08iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  57%|█████▋    | 1137/2000 [24:57<12:28,  1.15iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  57%|█████▋    | 1137/2000 [24:57<12:28,  1.15iteration/s, mean_rewards=-227]\u001b[A\n",
            "Training:  57%|█████▋    | 1138/2000 [24:58<14:32,  1.01s/iteration, mean_rewards=-227]\u001b[A\n",
            "Training:  57%|█████▋    | 1138/2000 [24:58<14:32,  1.01s/iteration, mean_rewards=-175]\u001b[A\n",
            "Training:  57%|█████▋    | 1139/2000 [24:59<13:26,  1.07iteration/s, mean_rewards=-175]\u001b[A\n",
            "Training:  57%|█████▋    | 1139/2000 [24:59<13:26,  1.07iteration/s, mean_rewards=-396]\u001b[A\n",
            "Training:  57%|█████▋    | 1140/2000 [25:00<14:16,  1.00iteration/s, mean_rewards=-396]\u001b[A\n",
            "Training:  57%|█████▋    | 1140/2000 [25:00<14:16,  1.00iteration/s, mean_rewards=-73.5]\u001b[A\n",
            "Training:  57%|█████▋    | 1141/2000 [25:01<13:57,  1.03iteration/s, mean_rewards=-73.5]\u001b[A\n",
            "Training:  57%|█████▋    | 1141/2000 [25:01<13:57,  1.03iteration/s, mean_rewards=-104] \u001b[A\n",
            "Training:  57%|█████▋    | 1142/2000 [25:02<13:28,  1.06iteration/s, mean_rewards=-104]\u001b[A\n",
            "Training:  57%|█████▋    | 1142/2000 [25:02<13:28,  1.06iteration/s, mean_rewards=-194]\u001b[A\n",
            "Training:  57%|█████▋    | 1143/2000 [25:03<12:55,  1.11iteration/s, mean_rewards=-194]\u001b[A\n",
            "Training:  57%|█████▋    | 1143/2000 [25:03<12:55,  1.11iteration/s, mean_rewards=-109]\u001b[A\n",
            "Training:  57%|█████▋    | 1144/2000 [25:04<12:28,  1.14iteration/s, mean_rewards=-109]\u001b[A\n",
            "Training:  57%|█████▋    | 1144/2000 [25:04<12:28,  1.14iteration/s, mean_rewards=-92.5]\u001b[A\n",
            "Training:  57%|█████▋    | 1145/2000 [25:04<12:34,  1.13iteration/s, mean_rewards=-92.5]\u001b[A\n",
            "Training:  57%|█████▋    | 1145/2000 [25:05<12:34,  1.13iteration/s, mean_rewards=-250] \u001b[A\n",
            "Training:  57%|█████▋    | 1146/2000 [25:05<12:29,  1.14iteration/s, mean_rewards=-250]\u001b[A\n",
            "Training:  57%|█████▋    | 1146/2000 [25:06<12:29,  1.14iteration/s, mean_rewards=-241]\u001b[A\n",
            "Training:  57%|█████▋    | 1147/2000 [25:06<12:10,  1.17iteration/s, mean_rewards=-241]\u001b[A\n",
            "Training:  57%|█████▋    | 1147/2000 [25:06<12:10,  1.17iteration/s, mean_rewards=-290]\u001b[A\n",
            "Training:  57%|█████▋    | 1148/2000 [25:07<12:24,  1.14iteration/s, mean_rewards=-290]\u001b[A\n",
            "Training:  57%|█████▋    | 1148/2000 [25:07<12:24,  1.14iteration/s, mean_rewards=-366]\u001b[A\n",
            "Training:  57%|█████▋    | 1149/2000 [25:08<12:15,  1.16iteration/s, mean_rewards=-366]\u001b[A\n",
            "Training:  57%|█████▋    | 1149/2000 [25:08<12:15,  1.16iteration/s, mean_rewards=-392]\u001b[A\n",
            "Training:  57%|█████▊    | 1150/2000 [25:09<13:09,  1.08iteration/s, mean_rewards=-392]\u001b[A\n",
            "Training:  57%|█████▊    | 1150/2000 [25:09<13:09,  1.08iteration/s, mean_rewards=-335]\u001b[A\n",
            "Training:  58%|█████▊    | 1151/2000 [25:10<12:34,  1.13iteration/s, mean_rewards=-335]\u001b[A\n",
            "Training:  58%|█████▊    | 1151/2000 [25:10<12:34,  1.13iteration/s, mean_rewards=-295]\u001b[A\n",
            "Training:  58%|█████▊    | 1152/2000 [25:11<12:25,  1.14iteration/s, mean_rewards=-295]\u001b[A\n",
            "Training:  58%|█████▊    | 1152/2000 [25:11<12:25,  1.14iteration/s, mean_rewards=-276]\u001b[A\n",
            "Training:  58%|█████▊    | 1153/2000 [25:11<12:31,  1.13iteration/s, mean_rewards=-276]\u001b[A\n",
            "Training:  58%|█████▊    | 1153/2000 [25:12<12:31,  1.13iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  58%|█████▊    | 1154/2000 [25:13<13:55,  1.01iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  58%|█████▊    | 1154/2000 [25:13<13:55,  1.01iteration/s, mean_rewards=-202]\u001b[A\n",
            "Training:  58%|█████▊    | 1155/2000 [25:14<16:16,  1.16s/iteration, mean_rewards=-202]\u001b[A\n",
            "Training:  58%|█████▊    | 1155/2000 [25:15<16:16,  1.16s/iteration, mean_rewards=-228]\u001b[A\n",
            "Training:  58%|█████▊    | 1156/2000 [25:15<16:30,  1.17s/iteration, mean_rewards=-228]\u001b[A\n",
            "Training:  58%|█████▊    | 1156/2000 [25:16<16:30,  1.17s/iteration, mean_rewards=-151]\u001b[A\n",
            "Training:  58%|█████▊    | 1157/2000 [25:16<14:54,  1.06s/iteration, mean_rewards=-151]\u001b[A\n",
            "Training:  58%|█████▊    | 1157/2000 [25:17<14:54,  1.06s/iteration, mean_rewards=-424]\u001b[A\n",
            "Training:  58%|█████▊    | 1158/2000 [25:17<15:01,  1.07s/iteration, mean_rewards=-424]\u001b[A\n",
            "Training:  58%|█████▊    | 1158/2000 [25:18<15:01,  1.07s/iteration, mean_rewards=-141]\u001b[A\n",
            "Training:  58%|█████▊    | 1159/2000 [25:18<13:55,  1.01iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  58%|█████▊    | 1159/2000 [25:19<13:55,  1.01iteration/s, mean_rewards=-262]\u001b[A\n",
            "Training:  58%|█████▊    | 1160/2000 [25:19<14:14,  1.02s/iteration, mean_rewards=-262]\u001b[A\n",
            "Training:  58%|█████▊    | 1160/2000 [25:20<14:14,  1.02s/iteration, mean_rewards=-213]\u001b[A\n",
            "Training:  58%|█████▊    | 1161/2000 [25:20<14:21,  1.03s/iteration, mean_rewards=-213]\u001b[A\n",
            "Training:  58%|█████▊    | 1161/2000 [25:21<14:21,  1.03s/iteration, mean_rewards=-271]\u001b[A\n",
            "Training:  58%|█████▊    | 1162/2000 [25:21<14:36,  1.05s/iteration, mean_rewards=-271]\u001b[A\n",
            "Training:  58%|█████▊    | 1162/2000 [25:22<14:36,  1.05s/iteration, mean_rewards=-118]\u001b[A\n",
            "Training:  58%|█████▊    | 1163/2000 [25:22<13:14,  1.05iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  58%|█████▊    | 1163/2000 [25:23<13:14,  1.05iteration/s, mean_rewards=-269]\u001b[A\n",
            "Training:  58%|█████▊    | 1164/2000 [25:23<13:44,  1.01iteration/s, mean_rewards=-269]\u001b[A\n",
            "Training:  58%|█████▊    | 1164/2000 [25:24<13:44,  1.01iteration/s, mean_rewards=-258]\u001b[A\n",
            "Training:  58%|█████▊    | 1165/2000 [25:24<13:04,  1.06iteration/s, mean_rewards=-258]\u001b[A\n",
            "Training:  58%|█████▊    | 1165/2000 [25:25<13:04,  1.06iteration/s, mean_rewards=-176]\u001b[A\n",
            "Training:  58%|█████▊    | 1166/2000 [25:25<15:01,  1.08s/iteration, mean_rewards=-176]\u001b[A\n",
            "Training:  58%|█████▊    | 1166/2000 [25:26<15:01,  1.08s/iteration, mean_rewards=-374]\u001b[A\n",
            "Training:  58%|█████▊    | 1167/2000 [25:26<14:58,  1.08s/iteration, mean_rewards=-374]\u001b[A\n",
            "Training:  58%|█████▊    | 1167/2000 [25:27<14:58,  1.08s/iteration, mean_rewards=-135]\u001b[A\n",
            "Training:  58%|█████▊    | 1168/2000 [25:28<15:26,  1.11s/iteration, mean_rewards=-135]\u001b[A\n",
            "Training:  58%|█████▊    | 1168/2000 [25:28<15:26,  1.11s/iteration, mean_rewards=-140]\u001b[A\n",
            "Training:  58%|█████▊    | 1169/2000 [25:29<15:46,  1.14s/iteration, mean_rewards=-140]\u001b[A\n",
            "Training:  58%|█████▊    | 1169/2000 [25:29<15:46,  1.14s/iteration, mean_rewards=-275]\u001b[A\n",
            "Training:  58%|█████▊    | 1170/2000 [25:30<14:27,  1.05s/iteration, mean_rewards=-275]\u001b[A\n",
            "Training:  58%|█████▊    | 1170/2000 [25:30<14:27,  1.05s/iteration, mean_rewards=-122]\u001b[A\n",
            "Training:  59%|█████▊    | 1171/2000 [25:31<13:32,  1.02iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  59%|█████▊    | 1171/2000 [25:31<13:32,  1.02iteration/s, mean_rewards=-187]\u001b[A\n",
            "Training:  59%|█████▊    | 1172/2000 [25:31<13:20,  1.03iteration/s, mean_rewards=-187]\u001b[A\n",
            "Training:  59%|█████▊    | 1172/2000 [25:32<13:20,  1.03iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  59%|█████▊    | 1173/2000 [25:32<12:09,  1.13iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  59%|█████▊    | 1173/2000 [25:33<12:09,  1.13iteration/s, mean_rewards=-83.9]\u001b[A\n",
            "Training:  59%|█████▊    | 1174/2000 [25:33<12:20,  1.12iteration/s, mean_rewards=-83.9]\u001b[A\n",
            "Training:  59%|█████▊    | 1174/2000 [25:33<12:20,  1.12iteration/s, mean_rewards=-124] \u001b[A\n",
            "Training:  59%|█████▉    | 1175/2000 [25:34<11:24,  1.21iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  59%|█████▉    | 1175/2000 [25:34<11:24,  1.21iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:  59%|█████▉    | 1176/2000 [25:34<10:43,  1.28iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:  59%|█████▉    | 1176/2000 [25:35<10:43,  1.28iteration/s, mean_rewards=-280]\u001b[A\n",
            "Training:  59%|█████▉    | 1177/2000 [25:35<10:51,  1.26iteration/s, mean_rewards=-280]\u001b[A\n",
            "Training:  59%|█████▉    | 1177/2000 [25:36<10:51,  1.26iteration/s, mean_rewards=-313]\u001b[A\n",
            "Training:  59%|█████▉    | 1178/2000 [25:36<11:00,  1.24iteration/s, mean_rewards=-313]\u001b[A\n",
            "Training:  59%|█████▉    | 1178/2000 [25:36<11:00,  1.24iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  59%|█████▉    | 1179/2000 [25:37<10:56,  1.25iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  59%|█████▉    | 1179/2000 [25:37<10:56,  1.25iteration/s, mean_rewards=-374]\u001b[A\n",
            "Training:  59%|█████▉    | 1180/2000 [25:38<11:29,  1.19iteration/s, mean_rewards=-374]\u001b[A\n",
            "Training:  59%|█████▉    | 1180/2000 [25:38<11:29,  1.19iteration/s, mean_rewards=-333]\u001b[A\n",
            "Training:  59%|█████▉    | 1181/2000 [25:39<12:15,  1.11iteration/s, mean_rewards=-333]\u001b[A\n",
            "Training:  59%|█████▉    | 1181/2000 [25:39<12:15,  1.11iteration/s, mean_rewards=-165]\u001b[A\n",
            "Training:  59%|█████▉    | 1182/2000 [25:40<14:19,  1.05s/iteration, mean_rewards=-165]\u001b[A\n",
            "Training:  59%|█████▉    | 1182/2000 [25:40<14:19,  1.05s/iteration, mean_rewards=-173]\u001b[A\n",
            "Training:  59%|█████▉    | 1183/2000 [25:41<12:46,  1.07iteration/s, mean_rewards=-173]\u001b[A\n",
            "Training:  59%|█████▉    | 1183/2000 [25:41<12:46,  1.07iteration/s, mean_rewards=-175]\u001b[A\n",
            "Training:  59%|█████▉    | 1184/2000 [25:42<12:49,  1.06iteration/s, mean_rewards=-175]\u001b[A\n",
            "Training:  59%|█████▉    | 1184/2000 [25:42<12:49,  1.06iteration/s, mean_rewards=-217]\u001b[A\n",
            "Training:  59%|█████▉    | 1185/2000 [25:43<13:20,  1.02iteration/s, mean_rewards=-217]\u001b[A\n",
            "Training:  59%|█████▉    | 1185/2000 [25:43<13:20,  1.02iteration/s, mean_rewards=-174]\u001b[A\n",
            "Training:  59%|█████▉    | 1186/2000 [25:44<12:31,  1.08iteration/s, mean_rewards=-174]\u001b[A\n",
            "Training:  59%|█████▉    | 1186/2000 [25:44<12:31,  1.08iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  59%|█████▉    | 1187/2000 [25:45<12:37,  1.07iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  59%|█████▉    | 1187/2000 [25:45<12:37,  1.07iteration/s, mean_rewards=-186]\u001b[A\n",
            "Training:  59%|█████▉    | 1188/2000 [25:46<12:33,  1.08iteration/s, mean_rewards=-186]\u001b[A\n",
            "Training:  59%|█████▉    | 1188/2000 [25:46<12:33,  1.08iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  59%|█████▉    | 1189/2000 [25:47<12:39,  1.07iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  59%|█████▉    | 1189/2000 [25:47<12:39,  1.07iteration/s, mean_rewards=-414]\u001b[A\n",
            "Training:  60%|█████▉    | 1190/2000 [25:47<12:20,  1.09iteration/s, mean_rewards=-414]\u001b[A\n",
            "Training:  60%|█████▉    | 1190/2000 [25:48<12:20,  1.09iteration/s, mean_rewards=-281]\u001b[A\n",
            "Training:  60%|█████▉    | 1191/2000 [25:48<12:20,  1.09iteration/s, mean_rewards=-281]\u001b[A\n",
            "Training:  60%|█████▉    | 1191/2000 [25:49<12:20,  1.09iteration/s, mean_rewards=-162]\u001b[A\n",
            "Training:  60%|█████▉    | 1192/2000 [25:49<11:53,  1.13iteration/s, mean_rewards=-162]\u001b[A\n",
            "Training:  60%|█████▉    | 1192/2000 [25:50<11:53,  1.13iteration/s, mean_rewards=-425]\u001b[A\n",
            "Training:  60%|█████▉    | 1193/2000 [25:50<12:00,  1.12iteration/s, mean_rewards=-425]\u001b[A\n",
            "Training:  60%|█████▉    | 1193/2000 [25:51<12:00,  1.12iteration/s, mean_rewards=-366]\u001b[A\n",
            "Training:  60%|█████▉    | 1194/2000 [25:51<13:45,  1.02s/iteration, mean_rewards=-366]\u001b[A\n",
            "Training:  60%|█████▉    | 1194/2000 [25:52<13:45,  1.02s/iteration, mean_rewards=-58.5]\u001b[A\n",
            "Training:  60%|█████▉    | 1195/2000 [25:53<14:34,  1.09s/iteration, mean_rewards=-58.5]\u001b[A\n",
            "Training:  60%|█████▉    | 1195/2000 [25:53<14:34,  1.09s/iteration, mean_rewards=-283] \u001b[A\n",
            "Training:  60%|█████▉    | 1196/2000 [25:53<13:36,  1.02s/iteration, mean_rewards=-283]\u001b[A\n",
            "Training:  60%|█████▉    | 1196/2000 [25:54<13:36,  1.02s/iteration, mean_rewards=-156]\u001b[A\n",
            "Training:  60%|█████▉    | 1197/2000 [25:54<13:17,  1.01iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  60%|█████▉    | 1197/2000 [25:55<13:17,  1.01iteration/s, mean_rewards=-200]\u001b[A\n",
            "Training:  60%|█████▉    | 1198/2000 [25:55<13:11,  1.01iteration/s, mean_rewards=-200]\u001b[A\n",
            "Training:  60%|█████▉    | 1198/2000 [25:56<13:11,  1.01iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  60%|█████▉    | 1199/2000 [25:56<12:37,  1.06iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  60%|█████▉    | 1199/2000 [25:57<12:37,  1.06iteration/s, mean_rewards=-199]\u001b[A\n",
            "Training:  60%|██████    | 1200/2000 [25:57<13:13,  1.01iteration/s, mean_rewards=-199]\u001b[A\n",
            "Training:  60%|██████    | 1200/2000 [25:58<13:13,  1.01iteration/s, mean_rewards=-248]\u001b[A\n",
            "Training:  60%|██████    | 1201/2000 [25:58<12:06,  1.10iteration/s, mean_rewards=-248]\u001b[A\n",
            "Training:  60%|██████    | 1201/2000 [25:59<12:06,  1.10iteration/s, mean_rewards=-80.2]\u001b[A\n",
            "Training:  60%|██████    | 1202/2000 [25:59<12:49,  1.04iteration/s, mean_rewards=-80.2]\u001b[A\n",
            "Training:  60%|██████    | 1202/2000 [26:00<12:49,  1.04iteration/s, mean_rewards=-305] \u001b[A\n",
            "Training:  60%|██████    | 1203/2000 [26:00<12:34,  1.06iteration/s, mean_rewards=-305]\u001b[A\n",
            "Training:  60%|██████    | 1203/2000 [26:00<12:34,  1.06iteration/s, mean_rewards=-192]\u001b[A\n",
            "Training:  60%|██████    | 1204/2000 [26:01<11:56,  1.11iteration/s, mean_rewards=-192]\u001b[A\n",
            "Training:  60%|██████    | 1204/2000 [26:01<11:56,  1.11iteration/s, mean_rewards=-249]\u001b[A\n",
            "Training:  60%|██████    | 1205/2000 [26:02<11:36,  1.14iteration/s, mean_rewards=-249]\u001b[A\n",
            "Training:  60%|██████    | 1205/2000 [26:02<11:36,  1.14iteration/s, mean_rewards=-400]\u001b[A\n",
            "Training:  60%|██████    | 1206/2000 [26:03<11:48,  1.12iteration/s, mean_rewards=-400]\u001b[A\n",
            "Training:  60%|██████    | 1206/2000 [26:03<11:48,  1.12iteration/s, mean_rewards=-239]\u001b[A\n",
            "Training:  60%|██████    | 1207/2000 [26:04<14:19,  1.08s/iteration, mean_rewards=-239]\u001b[A\n",
            "Training:  60%|██████    | 1207/2000 [26:05<14:19,  1.08s/iteration, mean_rewards=-104]\u001b[A\n",
            "Training:  60%|██████    | 1208/2000 [26:05<14:34,  1.10s/iteration, mean_rewards=-104]\u001b[A\n",
            "Training:  60%|██████    | 1208/2000 [26:06<14:34,  1.10s/iteration, mean_rewards=-94.1]\u001b[A\n",
            "Training:  60%|██████    | 1209/2000 [26:06<13:02,  1.01iteration/s, mean_rewards=-94.1]\u001b[A\n",
            "Training:  60%|██████    | 1209/2000 [26:06<13:02,  1.01iteration/s, mean_rewards=-147] \u001b[A\n",
            "Training:  60%|██████    | 1210/2000 [26:07<12:50,  1.02iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:  60%|██████    | 1210/2000 [26:07<12:50,  1.02iteration/s, mean_rewards=-106]\u001b[A\n",
            "Training:  61%|██████    | 1211/2000 [26:08<11:49,  1.11iteration/s, mean_rewards=-106]\u001b[A\n",
            "Training:  61%|██████    | 1211/2000 [26:08<11:49,  1.11iteration/s, mean_rewards=-163]\u001b[A\n",
            "Training:  61%|██████    | 1212/2000 [26:08<11:23,  1.15iteration/s, mean_rewards=-163]\u001b[A\n",
            "Training:  61%|██████    | 1212/2000 [26:09<11:23,  1.15iteration/s, mean_rewards=-105]\u001b[A\n",
            "Training:  61%|██████    | 1213/2000 [26:09<10:31,  1.25iteration/s, mean_rewards=-105]\u001b[A\n",
            "Training:  61%|██████    | 1213/2000 [26:09<10:31,  1.25iteration/s, mean_rewards=-310]\u001b[A\n",
            "Training:  61%|██████    | 1214/2000 [26:10<10:56,  1.20iteration/s, mean_rewards=-310]\u001b[A\n",
            "Training:  61%|██████    | 1214/2000 [26:10<10:56,  1.20iteration/s, mean_rewards=-319]\u001b[A\n",
            "Training:  61%|██████    | 1215/2000 [26:11<11:21,  1.15iteration/s, mean_rewards=-319]\u001b[A\n",
            "Training:  61%|██████    | 1215/2000 [26:11<11:21,  1.15iteration/s, mean_rewards=-285]\u001b[A\n",
            "Training:  61%|██████    | 1216/2000 [26:12<12:08,  1.08iteration/s, mean_rewards=-285]\u001b[A\n",
            "Training:  61%|██████    | 1216/2000 [26:12<12:08,  1.08iteration/s, mean_rewards=-347]\u001b[A\n",
            "Training:  61%|██████    | 1217/2000 [26:13<12:03,  1.08iteration/s, mean_rewards=-347]\u001b[A\n",
            "Training:  61%|██████    | 1217/2000 [26:13<12:03,  1.08iteration/s, mean_rewards=-190]\u001b[A\n",
            "Training:  61%|██████    | 1218/2000 [26:14<11:40,  1.12iteration/s, mean_rewards=-190]\u001b[A\n",
            "Training:  61%|██████    | 1218/2000 [26:14<11:40,  1.12iteration/s, mean_rewards=-183]\u001b[A\n",
            "Training:  61%|██████    | 1219/2000 [26:15<12:21,  1.05iteration/s, mean_rewards=-183]\u001b[A\n",
            "Training:  61%|██████    | 1219/2000 [26:15<12:21,  1.05iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  61%|██████    | 1220/2000 [26:16<12:25,  1.05iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  61%|██████    | 1220/2000 [26:16<12:25,  1.05iteration/s, mean_rewards=-291]\u001b[A\n",
            "Training:  61%|██████    | 1221/2000 [26:17<13:24,  1.03s/iteration, mean_rewards=-291]\u001b[A\n",
            "Training:  61%|██████    | 1221/2000 [26:17<13:24,  1.03s/iteration, mean_rewards=-213]\u001b[A\n",
            "Training:  61%|██████    | 1222/2000 [26:18<13:57,  1.08s/iteration, mean_rewards=-213]\u001b[A\n",
            "Training:  61%|██████    | 1222/2000 [26:19<13:57,  1.08s/iteration, mean_rewards=-153]\u001b[A\n",
            "Training:  61%|██████    | 1223/2000 [26:19<13:35,  1.05s/iteration, mean_rewards=-153]\u001b[A\n",
            "Training:  61%|██████    | 1223/2000 [26:20<13:35,  1.05s/iteration, mean_rewards=-88.5]\u001b[A\n",
            "Training:  61%|██████    | 1224/2000 [26:20<12:36,  1.03iteration/s, mean_rewards=-88.5]\u001b[A\n",
            "Training:  61%|██████    | 1224/2000 [26:20<12:36,  1.03iteration/s, mean_rewards=-137] \u001b[A\n",
            "Training:  61%|██████▏   | 1225/2000 [26:21<11:22,  1.14iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  61%|██████▏   | 1225/2000 [26:21<11:22,  1.14iteration/s, mean_rewards=-323]\u001b[A\n",
            "Training:  61%|██████▏   | 1226/2000 [26:22<12:06,  1.07iteration/s, mean_rewards=-323]\u001b[A\n",
            "Training:  61%|██████▏   | 1226/2000 [26:22<12:06,  1.07iteration/s, mean_rewards=-177]\u001b[A\n",
            "Training:  61%|██████▏   | 1227/2000 [26:23<12:04,  1.07iteration/s, mean_rewards=-177]\u001b[A\n",
            "Training:  61%|██████▏   | 1227/2000 [26:23<12:04,  1.07iteration/s, mean_rewards=-173]\u001b[A\n",
            "Training:  61%|██████▏   | 1228/2000 [26:24<12:31,  1.03iteration/s, mean_rewards=-173]\u001b[A\n",
            "Training:  61%|██████▏   | 1228/2000 [26:24<12:31,  1.03iteration/s, mean_rewards=-254]\u001b[A\n",
            "Training:  61%|██████▏   | 1229/2000 [26:25<11:55,  1.08iteration/s, mean_rewards=-254]\u001b[A\n",
            "Training:  61%|██████▏   | 1229/2000 [26:25<11:55,  1.08iteration/s, mean_rewards=-103]\u001b[A\n",
            "Training:  62%|██████▏   | 1230/2000 [26:25<11:26,  1.12iteration/s, mean_rewards=-103]\u001b[A\n",
            "Training:  62%|██████▏   | 1230/2000 [26:26<11:26,  1.12iteration/s, mean_rewards=-310]\u001b[A\n",
            "Training:  62%|██████▏   | 1231/2000 [26:26<11:09,  1.15iteration/s, mean_rewards=-310]\u001b[A\n",
            "Training:  62%|██████▏   | 1231/2000 [26:27<11:09,  1.15iteration/s, mean_rewards=-342]\u001b[A\n",
            "Training:  62%|██████▏   | 1232/2000 [26:27<11:01,  1.16iteration/s, mean_rewards=-342]\u001b[A\n",
            "Training:  62%|██████▏   | 1232/2000 [26:27<11:01,  1.16iteration/s, mean_rewards=-355]\u001b[A\n",
            "Training:  62%|██████▏   | 1233/2000 [26:28<11:56,  1.07iteration/s, mean_rewards=-355]\u001b[A\n",
            "Training:  62%|██████▏   | 1233/2000 [26:29<11:56,  1.07iteration/s, mean_rewards=-486]\u001b[A\n",
            "Training:  62%|██████▏   | 1234/2000 [26:29<12:26,  1.03iteration/s, mean_rewards=-486]\u001b[A\n",
            "Training:  62%|██████▏   | 1234/2000 [26:29<12:26,  1.03iteration/s, mean_rewards=-195]\u001b[A\n",
            "Training:  62%|██████▏   | 1235/2000 [26:30<11:50,  1.08iteration/s, mean_rewards=-195]\u001b[A\n",
            "Training:  62%|██████▏   | 1235/2000 [26:31<11:50,  1.08iteration/s, mean_rewards=-318]\u001b[A\n",
            "Training:  62%|██████▏   | 1236/2000 [26:32<14:19,  1.12s/iteration, mean_rewards=-318]\u001b[A\n",
            "Training:  62%|██████▏   | 1236/2000 [26:32<14:19,  1.12s/iteration, mean_rewards=-106]\u001b[A\n",
            "Training:  62%|██████▏   | 1237/2000 [26:32<12:42,  1.00iteration/s, mean_rewards=-106]\u001b[A\n",
            "Training:  62%|██████▏   | 1237/2000 [26:33<12:42,  1.00iteration/s, mean_rewards=-190]\u001b[A\n",
            "Training:  62%|██████▏   | 1238/2000 [26:33<11:30,  1.10iteration/s, mean_rewards=-190]\u001b[A\n",
            "Training:  62%|██████▏   | 1238/2000 [26:33<11:30,  1.10iteration/s, mean_rewards=-201]\u001b[A\n",
            "Training:  62%|██████▏   | 1239/2000 [26:34<12:03,  1.05iteration/s, mean_rewards=-201]\u001b[A\n",
            "Training:  62%|██████▏   | 1239/2000 [26:35<12:03,  1.05iteration/s, mean_rewards=-87.7]\u001b[A\n",
            "Training:  62%|██████▏   | 1240/2000 [26:35<13:01,  1.03s/iteration, mean_rewards=-87.7]\u001b[A\n",
            "Training:  62%|██████▏   | 1240/2000 [26:36<13:01,  1.03s/iteration, mean_rewards=-147] \u001b[A\n",
            "Training:  62%|██████▏   | 1241/2000 [26:36<12:46,  1.01s/iteration, mean_rewards=-147]\u001b[A\n",
            "Training:  62%|██████▏   | 1241/2000 [26:37<12:46,  1.01s/iteration, mean_rewards=-130]\u001b[A\n",
            "Training:  62%|██████▏   | 1242/2000 [26:37<12:28,  1.01iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  62%|██████▏   | 1242/2000 [26:37<12:28,  1.01iteration/s, mean_rewards=-216]\u001b[A\n",
            "Training:  62%|██████▏   | 1243/2000 [26:38<11:50,  1.07iteration/s, mean_rewards=-216]\u001b[A\n",
            "Training:  62%|██████▏   | 1243/2000 [26:38<11:50,  1.07iteration/s, mean_rewards=-189]\u001b[A\n",
            "Training:  62%|██████▏   | 1244/2000 [26:39<10:50,  1.16iteration/s, mean_rewards=-189]\u001b[A\n",
            "Training:  62%|██████▏   | 1244/2000 [26:39<10:50,  1.16iteration/s, mean_rewards=-261]\u001b[A\n",
            "Training:  62%|██████▏   | 1245/2000 [26:40<11:27,  1.10iteration/s, mean_rewards=-261]\u001b[A\n",
            "Training:  62%|██████▏   | 1245/2000 [26:40<11:27,  1.10iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  62%|██████▏   | 1246/2000 [26:41<11:34,  1.09iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  62%|██████▏   | 1246/2000 [26:41<11:34,  1.09iteration/s, mean_rewards=-259]\u001b[A\n",
            "Training:  62%|██████▏   | 1247/2000 [26:42<11:43,  1.07iteration/s, mean_rewards=-259]\u001b[A\n",
            "Training:  62%|██████▏   | 1247/2000 [26:42<11:43,  1.07iteration/s, mean_rewards=-212]\u001b[A\n",
            "Training:  62%|██████▏   | 1248/2000 [26:43<12:13,  1.02iteration/s, mean_rewards=-212]\u001b[A\n",
            "Training:  62%|██████▏   | 1248/2000 [26:43<12:13,  1.02iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  62%|██████▏   | 1249/2000 [26:44<13:03,  1.04s/iteration, mean_rewards=-155]\u001b[A\n",
            "Training:  62%|██████▏   | 1249/2000 [26:44<13:03,  1.04s/iteration, mean_rewards=-181]\u001b[A\n",
            "Training:  62%|██████▎   | 1250/2000 [26:45<12:06,  1.03iteration/s, mean_rewards=-181]\u001b[A\n",
            "Training:  62%|██████▎   | 1250/2000 [26:45<12:06,  1.03iteration/s, mean_rewards=-240]\u001b[A\n",
            "Training:  63%|██████▎   | 1251/2000 [26:46<11:51,  1.05iteration/s, mean_rewards=-240]\u001b[A\n",
            "Training:  63%|██████▎   | 1251/2000 [26:46<11:51,  1.05iteration/s, mean_rewards=-163]\u001b[A\n",
            "Training:  63%|██████▎   | 1252/2000 [26:46<11:45,  1.06iteration/s, mean_rewards=-163]\u001b[A\n",
            "Training:  63%|██████▎   | 1252/2000 [26:47<11:45,  1.06iteration/s, mean_rewards=-88.4]\u001b[A\n",
            "Training:  63%|██████▎   | 1253/2000 [26:47<11:10,  1.11iteration/s, mean_rewards=-88.4]\u001b[A\n",
            "Training:  63%|██████▎   | 1253/2000 [26:48<11:10,  1.11iteration/s, mean_rewards=-175] \u001b[A\n",
            "Training:  63%|██████▎   | 1254/2000 [26:48<10:44,  1.16iteration/s, mean_rewards=-175]\u001b[A\n",
            "Training:  63%|██████▎   | 1254/2000 [26:48<10:44,  1.16iteration/s, mean_rewards=-192]\u001b[A\n",
            "Training:  63%|██████▎   | 1255/2000 [26:49<10:05,  1.23iteration/s, mean_rewards=-192]\u001b[A\n",
            "Training:  63%|██████▎   | 1255/2000 [26:49<10:05,  1.23iteration/s, mean_rewards=-244]\u001b[A\n",
            "Training:  63%|██████▎   | 1256/2000 [26:49<09:31,  1.30iteration/s, mean_rewards=-244]\u001b[A\n",
            "Training:  63%|██████▎   | 1256/2000 [26:50<09:31,  1.30iteration/s, mean_rewards=-237]\u001b[A\n",
            "Training:  63%|██████▎   | 1257/2000 [26:50<09:46,  1.27iteration/s, mean_rewards=-237]\u001b[A\n",
            "Training:  63%|██████▎   | 1257/2000 [26:51<09:46,  1.27iteration/s, mean_rewards=-186]\u001b[A\n",
            "Training:  63%|██████▎   | 1258/2000 [26:51<09:55,  1.25iteration/s, mean_rewards=-186]\u001b[A\n",
            "Training:  63%|██████▎   | 1258/2000 [26:51<09:55,  1.25iteration/s, mean_rewards=-297]\u001b[A\n",
            "Training:  63%|██████▎   | 1259/2000 [26:52<10:05,  1.22iteration/s, mean_rewards=-297]\u001b[A\n",
            "Training:  63%|██████▎   | 1259/2000 [26:52<10:05,  1.22iteration/s, mean_rewards=-106]\u001b[A\n",
            "Training:  63%|██████▎   | 1260/2000 [26:53<10:15,  1.20iteration/s, mean_rewards=-106]\u001b[A\n",
            "Training:  63%|██████▎   | 1260/2000 [26:53<10:15,  1.20iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  63%|██████▎   | 1261/2000 [26:53<09:40,  1.27iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  63%|██████▎   | 1261/2000 [26:54<09:40,  1.27iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  63%|██████▎   | 1262/2000 [26:55<10:35,  1.16iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  63%|██████▎   | 1262/2000 [26:55<10:35,  1.16iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  63%|██████▎   | 1263/2000 [26:56<12:51,  1.05s/iteration, mean_rewards=-110]\u001b[A\n",
            "Training:  63%|██████▎   | 1263/2000 [26:56<12:51,  1.05s/iteration, mean_rewards=-164]\u001b[A\n",
            "Training:  63%|██████▎   | 1264/2000 [26:57<13:12,  1.08s/iteration, mean_rewards=-164]\u001b[A\n",
            "Training:  63%|██████▎   | 1264/2000 [26:57<13:12,  1.08s/iteration, mean_rewards=-153]\u001b[A\n",
            "Training:  63%|██████▎   | 1265/2000 [26:58<12:16,  1.00s/iteration, mean_rewards=-153]\u001b[A\n",
            "Training:  63%|██████▎   | 1265/2000 [26:58<12:16,  1.00s/iteration, mean_rewards=-187]\u001b[A\n",
            "Training:  63%|██████▎   | 1266/2000 [26:59<12:04,  1.01iteration/s, mean_rewards=-187]\u001b[A\n",
            "Training:  63%|██████▎   | 1266/2000 [26:59<12:04,  1.01iteration/s, mean_rewards=-240]\u001b[A\n",
            "Training:  63%|██████▎   | 1267/2000 [27:00<10:56,  1.12iteration/s, mean_rewards=-240]\u001b[A\n",
            "Training:  63%|██████▎   | 1267/2000 [27:00<10:56,  1.12iteration/s, mean_rewards=-284]\u001b[A\n",
            "Training:  63%|██████▎   | 1268/2000 [27:01<11:05,  1.10iteration/s, mean_rewards=-284]\u001b[A\n",
            "Training:  63%|██████▎   | 1268/2000 [27:01<11:05,  1.10iteration/s, mean_rewards=-188]\u001b[A\n",
            "Training:  63%|██████▎   | 1269/2000 [27:02<11:13,  1.09iteration/s, mean_rewards=-188]\u001b[A\n",
            "Training:  63%|██████▎   | 1269/2000 [27:02<11:13,  1.09iteration/s, mean_rewards=-160]\u001b[A\n",
            "Training:  64%|██████▎   | 1270/2000 [27:02<11:21,  1.07iteration/s, mean_rewards=-160]\u001b[A\n",
            "Training:  64%|██████▎   | 1270/2000 [27:03<11:21,  1.07iteration/s, mean_rewards=-43.1]\u001b[A\n",
            "Training:  64%|██████▎   | 1271/2000 [27:03<10:33,  1.15iteration/s, mean_rewards=-43.1]\u001b[A\n",
            "Training:  64%|██████▎   | 1271/2000 [27:03<10:33,  1.15iteration/s, mean_rewards=-153] \u001b[A\n",
            "Training:  64%|██████▎   | 1272/2000 [27:04<09:50,  1.23iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  64%|██████▎   | 1272/2000 [27:04<09:50,  1.23iteration/s, mean_rewards=-171]\u001b[A\n",
            "Training:  64%|██████▎   | 1273/2000 [27:05<10:46,  1.12iteration/s, mean_rewards=-171]\u001b[A\n",
            "Training:  64%|██████▎   | 1273/2000 [27:05<10:46,  1.12iteration/s, mean_rewards=-84.1]\u001b[A\n",
            "Training:  64%|██████▎   | 1274/2000 [27:06<11:20,  1.07iteration/s, mean_rewards=-84.1]\u001b[A\n",
            "Training:  64%|██████▎   | 1274/2000 [27:06<11:20,  1.07iteration/s, mean_rewards=-159] \u001b[A\n",
            "Training:  64%|██████▍   | 1275/2000 [27:07<10:57,  1.10iteration/s, mean_rewards=-159]\u001b[A\n",
            "Training:  64%|██████▍   | 1275/2000 [27:07<10:57,  1.10iteration/s, mean_rewards=-259]\u001b[A\n",
            "Training:  64%|██████▍   | 1276/2000 [27:08<11:20,  1.06iteration/s, mean_rewards=-259]\u001b[A\n",
            "Training:  64%|██████▍   | 1276/2000 [27:08<11:20,  1.06iteration/s, mean_rewards=-206]\u001b[A\n",
            "Training:  64%|██████▍   | 1277/2000 [27:09<12:19,  1.02s/iteration, mean_rewards=-206]\u001b[A\n",
            "Training:  64%|██████▍   | 1277/2000 [27:09<12:19,  1.02s/iteration, mean_rewards=-123]\u001b[A\n",
            "Training:  64%|██████▍   | 1278/2000 [27:10<12:45,  1.06s/iteration, mean_rewards=-123]\u001b[A\n",
            "Training:  64%|██████▍   | 1278/2000 [27:11<12:45,  1.06s/iteration, mean_rewards=-339]\u001b[A\n",
            "Training:  64%|██████▍   | 1279/2000 [27:11<12:09,  1.01s/iteration, mean_rewards=-339]\u001b[A\n",
            "Training:  64%|██████▍   | 1279/2000 [27:12<12:09,  1.01s/iteration, mean_rewards=-185]\u001b[A\n",
            "Training:  64%|██████▍   | 1280/2000 [27:12<12:01,  1.00s/iteration, mean_rewards=-185]\u001b[A\n",
            "Training:  64%|██████▍   | 1280/2000 [27:12<12:01,  1.00s/iteration, mean_rewards=-249]\u001b[A\n",
            "Training:  64%|██████▍   | 1281/2000 [27:13<11:42,  1.02iteration/s, mean_rewards=-249]\u001b[A\n",
            "Training:  64%|██████▍   | 1281/2000 [27:13<11:42,  1.02iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  64%|██████▍   | 1282/2000 [27:14<10:39,  1.12iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  64%|██████▍   | 1282/2000 [27:14<10:39,  1.12iteration/s, mean_rewards=-211]\u001b[A\n",
            "Training:  64%|██████▍   | 1283/2000 [27:15<10:50,  1.10iteration/s, mean_rewards=-211]\u001b[A\n",
            "Training:  64%|██████▍   | 1283/2000 [27:15<10:50,  1.10iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  64%|██████▍   | 1284/2000 [27:16<10:57,  1.09iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  64%|██████▍   | 1284/2000 [27:16<10:57,  1.09iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  64%|██████▍   | 1285/2000 [27:16<10:46,  1.11iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  64%|██████▍   | 1285/2000 [27:17<10:46,  1.11iteration/s, mean_rewards=-263]\u001b[A\n",
            "Training:  64%|██████▍   | 1286/2000 [27:17<10:25,  1.14iteration/s, mean_rewards=-263]\u001b[A\n",
            "Training:  64%|██████▍   | 1286/2000 [27:18<10:25,  1.14iteration/s, mean_rewards=-331]\u001b[A\n",
            "Training:  64%|██████▍   | 1287/2000 [27:18<10:38,  1.12iteration/s, mean_rewards=-331]\u001b[A\n",
            "Training:  64%|██████▍   | 1287/2000 [27:19<10:38,  1.12iteration/s, mean_rewards=-342]\u001b[A\n",
            "Training:  64%|██████▍   | 1288/2000 [27:19<11:13,  1.06iteration/s, mean_rewards=-342]\u001b[A\n",
            "Training:  64%|██████▍   | 1288/2000 [27:20<11:13,  1.06iteration/s, mean_rewards=-233]\u001b[A\n",
            "Training:  64%|██████▍   | 1289/2000 [27:20<11:10,  1.06iteration/s, mean_rewards=-233]\u001b[A\n",
            "Training:  64%|██████▍   | 1289/2000 [27:21<11:10,  1.06iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  64%|██████▍   | 1290/2000 [27:21<11:27,  1.03iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  64%|██████▍   | 1290/2000 [27:22<11:27,  1.03iteration/s, mean_rewards=-249]\u001b[A\n",
            "Training:  65%|██████▍   | 1291/2000 [27:22<11:11,  1.06iteration/s, mean_rewards=-249]\u001b[A\n",
            "Training:  65%|██████▍   | 1291/2000 [27:23<11:11,  1.06iteration/s, mean_rewards=-325]\u001b[A\n",
            "Training:  65%|██████▍   | 1292/2000 [27:23<12:28,  1.06s/iteration, mean_rewards=-325]\u001b[A\n",
            "Training:  65%|██████▍   | 1292/2000 [27:24<12:28,  1.06s/iteration, mean_rewards=-300]\u001b[A\n",
            "Training:  65%|██████▍   | 1293/2000 [27:24<12:25,  1.05s/iteration, mean_rewards=-300]\u001b[A\n",
            "Training:  65%|██████▍   | 1293/2000 [27:25<12:25,  1.05s/iteration, mean_rewards=-113]\u001b[A\n",
            "Training:  65%|██████▍   | 1294/2000 [27:25<11:31,  1.02iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  65%|██████▍   | 1294/2000 [27:26<11:31,  1.02iteration/s, mean_rewards=-266]\u001b[A\n",
            "Training:  65%|██████▍   | 1295/2000 [27:26<11:04,  1.06iteration/s, mean_rewards=-266]\u001b[A\n",
            "Training:  65%|██████▍   | 1295/2000 [27:26<11:04,  1.06iteration/s, mean_rewards=-92] \u001b[A\n",
            "Training:  65%|██████▍   | 1296/2000 [27:27<10:03,  1.17iteration/s, mean_rewards=-92]\u001b[A\n",
            "Training:  65%|██████▍   | 1296/2000 [27:27<10:03,  1.17iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  65%|██████▍   | 1297/2000 [27:28<09:34,  1.22iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  65%|██████▍   | 1297/2000 [27:28<09:34,  1.22iteration/s, mean_rewards=-271]\u001b[A\n",
            "Training:  65%|██████▍   | 1298/2000 [27:28<09:59,  1.17iteration/s, mean_rewards=-271]\u001b[A\n",
            "Training:  65%|██████▍   | 1298/2000 [27:29<09:59,  1.17iteration/s, mean_rewards=-204]\u001b[A\n",
            "Training:  65%|██████▍   | 1299/2000 [27:29<10:26,  1.12iteration/s, mean_rewards=-204]\u001b[A\n",
            "Training:  65%|██████▍   | 1299/2000 [27:30<10:26,  1.12iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  65%|██████▌   | 1300/2000 [27:31<11:06,  1.05iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  65%|██████▌   | 1300/2000 [27:31<11:06,  1.05iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  65%|██████▌   | 1301/2000 [27:32<11:06,  1.05iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  65%|██████▌   | 1301/2000 [27:32<11:06,  1.05iteration/s, mean_rewards=-260]\u001b[A\n",
            "Training:  65%|██████▌   | 1302/2000 [27:32<10:41,  1.09iteration/s, mean_rewards=-260]\u001b[A\n",
            "Training:  65%|██████▌   | 1302/2000 [27:33<10:41,  1.09iteration/s, mean_rewards=-157]\u001b[A\n",
            "Training:  65%|██████▌   | 1303/2000 [27:33<10:21,  1.12iteration/s, mean_rewards=-157]\u001b[A\n",
            "Training:  65%|██████▌   | 1303/2000 [27:34<10:21,  1.12iteration/s, mean_rewards=-291]\u001b[A\n",
            "Training:  65%|██████▌   | 1304/2000 [27:34<11:49,  1.02s/iteration, mean_rewards=-291]\u001b[A\n",
            "Training:  65%|██████▌   | 1304/2000 [27:35<11:49,  1.02s/iteration, mean_rewards=-237]\u001b[A\n",
            "Training:  65%|██████▌   | 1305/2000 [27:36<12:55,  1.12s/iteration, mean_rewards=-237]\u001b[A\n",
            "Training:  65%|██████▌   | 1305/2000 [27:36<12:55,  1.12s/iteration, mean_rewards=-352]\u001b[A\n",
            "Training:  65%|██████▌   | 1306/2000 [27:37<14:02,  1.21s/iteration, mean_rewards=-352]\u001b[A\n",
            "Training:  65%|██████▌   | 1306/2000 [27:38<14:02,  1.21s/iteration, mean_rewards=-217]\u001b[A\n",
            "Training:  65%|██████▌   | 1307/2000 [27:38<12:16,  1.06s/iteration, mean_rewards=-217]\u001b[A\n",
            "Training:  65%|██████▌   | 1307/2000 [27:38<12:16,  1.06s/iteration, mean_rewards=-116]\u001b[A\n",
            "Training:  65%|██████▌   | 1308/2000 [27:39<11:01,  1.05iteration/s, mean_rewards=-116]\u001b[A\n",
            "Training:  65%|██████▌   | 1308/2000 [27:39<11:01,  1.05iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  65%|██████▌   | 1309/2000 [27:39<10:01,  1.15iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  65%|██████▌   | 1309/2000 [27:40<10:01,  1.15iteration/s, mean_rewards=-243]\u001b[A\n",
            "Training:  66%|██████▌   | 1310/2000 [27:40<09:19,  1.23iteration/s, mean_rewards=-243]\u001b[A\n",
            "Training:  66%|██████▌   | 1310/2000 [27:40<09:19,  1.23iteration/s, mean_rewards=-96.9]\u001b[A\n",
            "Training:  66%|██████▌   | 1311/2000 [27:41<08:47,  1.31iteration/s, mean_rewards=-96.9]\u001b[A\n",
            "Training:  66%|██████▌   | 1311/2000 [27:41<08:47,  1.31iteration/s, mean_rewards=-120] \u001b[A\n",
            "Training:  66%|██████▌   | 1312/2000 [27:41<08:56,  1.28iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  66%|██████▌   | 1312/2000 [27:42<08:56,  1.28iteration/s, mean_rewards=-240]\u001b[A\n",
            "Training:  66%|██████▌   | 1313/2000 [27:42<08:57,  1.28iteration/s, mean_rewards=-240]\u001b[A\n",
            "Training:  66%|██████▌   | 1313/2000 [27:43<08:57,  1.28iteration/s, mean_rewards=-209]\u001b[A\n",
            "Training:  66%|██████▌   | 1314/2000 [27:43<09:32,  1.20iteration/s, mean_rewards=-209]\u001b[A\n",
            "Training:  66%|██████▌   | 1314/2000 [27:44<09:32,  1.20iteration/s, mean_rewards=-280]\u001b[A\n",
            "Training:  66%|██████▌   | 1315/2000 [27:44<09:47,  1.17iteration/s, mean_rewards=-280]\u001b[A\n",
            "Training:  66%|██████▌   | 1315/2000 [27:45<09:47,  1.17iteration/s, mean_rewards=-309]\u001b[A\n",
            "Training:  66%|██████▌   | 1316/2000 [27:45<10:07,  1.13iteration/s, mean_rewards=-309]\u001b[A\n",
            "Training:  66%|██████▌   | 1316/2000 [27:45<10:07,  1.13iteration/s, mean_rewards=-221]\u001b[A\n",
            "Training:  66%|██████▌   | 1317/2000 [27:46<09:50,  1.16iteration/s, mean_rewards=-221]\u001b[A\n",
            "Training:  66%|██████▌   | 1317/2000 [27:46<09:50,  1.16iteration/s, mean_rewards=-50.3]\u001b[A\n",
            "Training:  66%|██████▌   | 1318/2000 [27:47<09:40,  1.18iteration/s, mean_rewards=-50.3]\u001b[A\n",
            "Training:  66%|██████▌   | 1318/2000 [27:47<09:40,  1.18iteration/s, mean_rewards=-192] \u001b[A\n",
            "Training:  66%|██████▌   | 1319/2000 [27:48<10:30,  1.08iteration/s, mean_rewards=-192]\u001b[A\n",
            "Training:  66%|██████▌   | 1319/2000 [27:48<10:30,  1.08iteration/s, mean_rewards=-249]\u001b[A\n",
            "Training:  66%|██████▌   | 1320/2000 [27:49<12:30,  1.10s/iteration, mean_rewards=-249]\u001b[A\n",
            "Training:  66%|██████▌   | 1320/2000 [27:50<12:30,  1.10s/iteration, mean_rewards=-135]\u001b[A\n",
            "Training:  66%|██████▌   | 1321/2000 [27:50<11:32,  1.02s/iteration, mean_rewards=-135]\u001b[A\n",
            "Training:  66%|██████▌   | 1321/2000 [27:50<11:32,  1.02s/iteration, mean_rewards=-254]\u001b[A\n",
            "Training:  66%|██████▌   | 1322/2000 [27:51<10:20,  1.09iteration/s, mean_rewards=-254]\u001b[A\n",
            "Training:  66%|██████▌   | 1322/2000 [27:51<10:20,  1.09iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  66%|██████▌   | 1323/2000 [27:52<09:27,  1.19iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  66%|██████▌   | 1323/2000 [27:52<09:27,  1.19iteration/s, mean_rewards=-259]\u001b[A\n",
            "Training:  66%|██████▌   | 1324/2000 [27:53<10:13,  1.10iteration/s, mean_rewards=-259]\u001b[A\n",
            "Training:  66%|██████▌   | 1324/2000 [27:53<10:13,  1.10iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:  66%|██████▋   | 1325/2000 [27:54<10:18,  1.09iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:  66%|██████▋   | 1325/2000 [27:54<10:18,  1.09iteration/s, mean_rewards=-159]\u001b[A\n",
            "Training:  66%|██████▋   | 1326/2000 [27:54<10:04,  1.12iteration/s, mean_rewards=-159]\u001b[A\n",
            "Training:  66%|██████▋   | 1326/2000 [27:55<10:04,  1.12iteration/s, mean_rewards=-168]\u001b[A\n",
            "Training:  66%|██████▋   | 1327/2000 [27:55<09:17,  1.21iteration/s, mean_rewards=-168]\u001b[A\n",
            "Training:  66%|██████▋   | 1327/2000 [27:55<09:17,  1.21iteration/s, mean_rewards=-310]\u001b[A\n",
            "Training:  66%|██████▋   | 1328/2000 [27:56<09:34,  1.17iteration/s, mean_rewards=-310]\u001b[A\n",
            "Training:  66%|██████▋   | 1328/2000 [27:56<09:34,  1.17iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:  66%|██████▋   | 1329/2000 [27:57<09:19,  1.20iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:  66%|██████▋   | 1329/2000 [27:57<09:19,  1.20iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  66%|██████▋   | 1330/2000 [27:58<09:38,  1.16iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  66%|██████▋   | 1330/2000 [27:58<09:38,  1.16iteration/s, mean_rewards=-242]\u001b[A\n",
            "Training:  67%|██████▋   | 1331/2000 [27:59<09:52,  1.13iteration/s, mean_rewards=-242]\u001b[A\n",
            "Training:  67%|██████▋   | 1331/2000 [27:59<09:52,  1.13iteration/s, mean_rewards=-270]\u001b[A\n",
            "Training:  67%|██████▋   | 1332/2000 [27:59<09:46,  1.14iteration/s, mean_rewards=-270]\u001b[A\n",
            "Training:  67%|██████▋   | 1332/2000 [28:00<09:46,  1.14iteration/s, mean_rewards=-175]\u001b[A\n",
            "Training:  67%|██████▋   | 1333/2000 [28:01<10:54,  1.02iteration/s, mean_rewards=-175]\u001b[A\n",
            "Training:  67%|██████▋   | 1333/2000 [28:01<10:54,  1.02iteration/s, mean_rewards=-199]\u001b[A\n",
            "Training:  67%|██████▋   | 1334/2000 [28:02<11:45,  1.06s/iteration, mean_rewards=-199]\u001b[A\n",
            "Training:  67%|██████▋   | 1334/2000 [28:02<11:45,  1.06s/iteration, mean_rewards=-248]\u001b[A\n",
            "Training:  67%|██████▋   | 1335/2000 [28:03<11:26,  1.03s/iteration, mean_rewards=-248]\u001b[A\n",
            "Training:  67%|██████▋   | 1335/2000 [28:03<11:26,  1.03s/iteration, mean_rewards=-231]\u001b[A\n",
            "Training:  67%|██████▋   | 1336/2000 [28:04<10:20,  1.07iteration/s, mean_rewards=-231]\u001b[A\n",
            "Training:  67%|██████▋   | 1336/2000 [28:04<10:20,  1.07iteration/s, mean_rewards=-268]\u001b[A\n",
            "Training:  67%|██████▋   | 1337/2000 [28:04<09:58,  1.11iteration/s, mean_rewards=-268]\u001b[A\n",
            "Training:  67%|██████▋   | 1337/2000 [28:05<09:58,  1.11iteration/s, mean_rewards=-254]\u001b[A\n",
            "Training:  67%|██████▋   | 1338/2000 [28:05<10:19,  1.07iteration/s, mean_rewards=-254]\u001b[A\n",
            "Training:  67%|██████▋   | 1338/2000 [28:06<10:19,  1.07iteration/s, mean_rewards=-186]\u001b[A\n",
            "Training:  67%|██████▋   | 1339/2000 [28:06<09:57,  1.11iteration/s, mean_rewards=-186]\u001b[A\n",
            "Training:  67%|██████▋   | 1339/2000 [28:07<09:57,  1.11iteration/s, mean_rewards=-343]\u001b[A\n",
            "Training:  67%|██████▋   | 1340/2000 [28:07<10:02,  1.10iteration/s, mean_rewards=-343]\u001b[A\n",
            "Training:  67%|██████▋   | 1340/2000 [28:08<10:02,  1.10iteration/s, mean_rewards=-97] \u001b[A\n",
            "Training:  67%|██████▋   | 1341/2000 [28:08<09:19,  1.18iteration/s, mean_rewards=-97]\u001b[A\n",
            "Training:  67%|██████▋   | 1341/2000 [28:08<09:19,  1.18iteration/s, mean_rewards=-99.5]\u001b[A\n",
            "Training:  67%|██████▋   | 1342/2000 [28:09<09:09,  1.20iteration/s, mean_rewards=-99.5]\u001b[A\n",
            "Training:  67%|██████▋   | 1342/2000 [28:09<09:09,  1.20iteration/s, mean_rewards=-375] \u001b[A\n",
            "Training:  67%|██████▋   | 1343/2000 [28:10<09:27,  1.16iteration/s, mean_rewards=-375]\u001b[A\n",
            "Training:  67%|██████▋   | 1343/2000 [28:10<09:27,  1.16iteration/s, mean_rewards=-256]\u001b[A\n",
            "Training:  67%|██████▋   | 1344/2000 [28:10<09:07,  1.20iteration/s, mean_rewards=-256]\u001b[A\n",
            "Training:  67%|██████▋   | 1344/2000 [28:11<09:07,  1.20iteration/s, mean_rewards=-317]\u001b[A\n",
            "Training:  67%|██████▋   | 1345/2000 [28:11<09:33,  1.14iteration/s, mean_rewards=-317]\u001b[A\n",
            "Training:  67%|██████▋   | 1345/2000 [28:12<09:33,  1.14iteration/s, mean_rewards=-279]\u001b[A\n",
            "Training:  67%|██████▋   | 1346/2000 [28:12<08:56,  1.22iteration/s, mean_rewards=-279]\u001b[A\n",
            "Training:  67%|██████▋   | 1346/2000 [28:12<08:56,  1.22iteration/s, mean_rewards=-91.3]\u001b[A\n",
            "Training:  67%|██████▋   | 1347/2000 [28:13<09:56,  1.10iteration/s, mean_rewards=-91.3]\u001b[A\n",
            "Training:  67%|██████▋   | 1347/2000 [28:14<09:56,  1.10iteration/s, mean_rewards=-269] \u001b[A\n",
            "Training:  67%|██████▋   | 1348/2000 [28:14<11:06,  1.02s/iteration, mean_rewards=-269]\u001b[A\n",
            "Training:  67%|██████▋   | 1348/2000 [28:15<11:06,  1.02s/iteration, mean_rewards=-71] \u001b[A\n",
            "Training:  67%|██████▋   | 1349/2000 [28:15<10:48,  1.00iteration/s, mean_rewards=-71]\u001b[A\n",
            "Training:  67%|██████▋   | 1349/2000 [28:16<10:48,  1.00iteration/s, mean_rewards=-259]\u001b[A\n",
            "Training:  68%|██████▊   | 1350/2000 [28:16<10:07,  1.07iteration/s, mean_rewards=-259]\u001b[A\n",
            "Training:  68%|██████▊   | 1350/2000 [28:17<10:07,  1.07iteration/s, mean_rewards=-249]\u001b[A\n",
            "Training:  68%|██████▊   | 1351/2000 [28:17<10:00,  1.08iteration/s, mean_rewards=-249]\u001b[A\n",
            "Training:  68%|██████▊   | 1351/2000 [28:17<10:00,  1.08iteration/s, mean_rewards=-252]\u001b[A\n",
            "Training:  68%|██████▊   | 1352/2000 [28:18<09:36,  1.12iteration/s, mean_rewards=-252]\u001b[A\n",
            "Training:  68%|██████▊   | 1352/2000 [28:18<09:36,  1.12iteration/s, mean_rewards=-242]\u001b[A\n",
            "Training:  68%|██████▊   | 1353/2000 [28:19<08:54,  1.21iteration/s, mean_rewards=-242]\u001b[A\n",
            "Training:  68%|██████▊   | 1353/2000 [28:19<08:54,  1.21iteration/s, mean_rewards=-87.6]\u001b[A\n",
            "Training:  68%|██████▊   | 1354/2000 [28:19<08:41,  1.24iteration/s, mean_rewards=-87.6]\u001b[A\n",
            "Training:  68%|██████▊   | 1354/2000 [28:20<08:41,  1.24iteration/s, mean_rewards=-70.2]\u001b[A\n",
            "Training:  68%|██████▊   | 1355/2000 [28:20<08:16,  1.30iteration/s, mean_rewards=-70.2]\u001b[A\n",
            "Training:  68%|██████▊   | 1355/2000 [28:20<08:16,  1.30iteration/s, mean_rewards=-98.7]\u001b[A\n",
            "Training:  68%|██████▊   | 1356/2000 [28:21<07:57,  1.35iteration/s, mean_rewards=-98.7]\u001b[A\n",
            "Training:  68%|██████▊   | 1356/2000 [28:21<07:57,  1.35iteration/s, mean_rewards=-226] \u001b[A\n",
            "Training:  68%|██████▊   | 1357/2000 [28:22<09:05,  1.18iteration/s, mean_rewards=-226]\u001b[A\n",
            "Training:  68%|██████▊   | 1357/2000 [28:22<09:05,  1.18iteration/s, mean_rewards=-399]\u001b[A\n",
            "Training:  68%|██████▊   | 1358/2000 [28:23<08:56,  1.20iteration/s, mean_rewards=-399]\u001b[A\n",
            "Training:  68%|██████▊   | 1358/2000 [28:23<08:56,  1.20iteration/s, mean_rewards=-241]\u001b[A\n",
            "Training:  68%|██████▊   | 1359/2000 [28:24<09:24,  1.14iteration/s, mean_rewards=-241]\u001b[A\n",
            "Training:  68%|██████▊   | 1359/2000 [28:24<09:24,  1.14iteration/s, mean_rewards=-333]\u001b[A\n",
            "Training:  68%|██████▊   | 1360/2000 [28:25<09:29,  1.12iteration/s, mean_rewards=-333]\u001b[A\n",
            "Training:  68%|██████▊   | 1360/2000 [28:25<09:29,  1.12iteration/s, mean_rewards=-348]\u001b[A\n",
            "Training:  68%|██████▊   | 1361/2000 [28:25<09:05,  1.17iteration/s, mean_rewards=-348]\u001b[A\n",
            "Training:  68%|██████▊   | 1361/2000 [28:26<09:05,  1.17iteration/s, mean_rewards=-104]\u001b[A\n",
            "Training:  68%|██████▊   | 1362/2000 [28:27<10:28,  1.02iteration/s, mean_rewards=-104]\u001b[A\n",
            "Training:  68%|██████▊   | 1362/2000 [28:27<10:28,  1.02iteration/s, mean_rewards=-409]\u001b[A\n",
            "Training:  68%|██████▊   | 1363/2000 [28:28<11:39,  1.10s/iteration, mean_rewards=-409]\u001b[A\n",
            "Training:  68%|██████▊   | 1363/2000 [28:28<11:39,  1.10s/iteration, mean_rewards=-98.8]\u001b[A\n",
            "Training:  68%|██████▊   | 1364/2000 [28:29<11:18,  1.07s/iteration, mean_rewards=-98.8]\u001b[A\n",
            "Training:  68%|██████▊   | 1364/2000 [28:29<11:18,  1.07s/iteration, mean_rewards=-84.1]\u001b[A\n",
            "Training:  68%|██████▊   | 1365/2000 [28:30<10:07,  1.05iteration/s, mean_rewards=-84.1]\u001b[A\n",
            "Training:  68%|██████▊   | 1365/2000 [28:30<10:07,  1.05iteration/s, mean_rewards=-160] \u001b[A\n",
            "Training:  68%|██████▊   | 1366/2000 [28:30<09:17,  1.14iteration/s, mean_rewards=-160]\u001b[A\n",
            "Training:  68%|██████▊   | 1366/2000 [28:31<09:17,  1.14iteration/s, mean_rewards=-360]\u001b[A\n",
            "Training:  68%|██████▊   | 1367/2000 [28:31<09:55,  1.06iteration/s, mean_rewards=-360]\u001b[A\n",
            "Training:  68%|██████▊   | 1367/2000 [28:32<09:55,  1.06iteration/s, mean_rewards=-287]\u001b[A\n",
            "Training:  68%|██████▊   | 1368/2000 [28:32<09:59,  1.05iteration/s, mean_rewards=-287]\u001b[A\n",
            "Training:  68%|██████▊   | 1368/2000 [28:33<09:59,  1.05iteration/s, mean_rewards=-224]\u001b[A\n",
            "Training:  68%|██████▊   | 1369/2000 [28:33<09:58,  1.05iteration/s, mean_rewards=-224]\u001b[A\n",
            "Training:  68%|██████▊   | 1369/2000 [28:34<09:58,  1.05iteration/s, mean_rewards=-280]\u001b[A\n",
            "Training:  68%|██████▊   | 1370/2000 [28:34<10:16,  1.02iteration/s, mean_rewards=-280]\u001b[A\n",
            "Training:  68%|██████▊   | 1370/2000 [28:35<10:16,  1.02iteration/s, mean_rewards=-287]\u001b[A\n",
            "Training:  69%|██████▊   | 1371/2000 [28:35<10:33,  1.01s/iteration, mean_rewards=-287]\u001b[A\n",
            "Training:  69%|██████▊   | 1371/2000 [28:36<10:33,  1.01s/iteration, mean_rewards=-137]\u001b[A\n",
            "Training:  69%|██████▊   | 1372/2000 [28:36<10:22,  1.01iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  69%|██████▊   | 1372/2000 [28:37<10:22,  1.01iteration/s, mean_rewards=-197]\u001b[A\n",
            "Training:  69%|██████▊   | 1373/2000 [28:37<09:45,  1.07iteration/s, mean_rewards=-197]\u001b[A\n",
            "Training:  69%|██████▊   | 1373/2000 [28:37<09:45,  1.07iteration/s, mean_rewards=-98.5]\u001b[A\n",
            "Training:  69%|██████▊   | 1374/2000 [28:38<09:02,  1.15iteration/s, mean_rewards=-98.5]\u001b[A\n",
            "Training:  69%|██████▊   | 1374/2000 [28:38<09:02,  1.15iteration/s, mean_rewards=-263] \u001b[A\n",
            "Training:  69%|██████▉   | 1375/2000 [28:39<09:42,  1.07iteration/s, mean_rewards=-263]\u001b[A\n",
            "Training:  69%|██████▉   | 1375/2000 [28:39<09:42,  1.07iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  69%|██████▉   | 1376/2000 [28:40<10:17,  1.01iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  69%|██████▉   | 1376/2000 [28:41<10:17,  1.01iteration/s, mean_rewards=-239]\u001b[A\n",
            "Training:  69%|██████▉   | 1377/2000 [28:41<10:41,  1.03s/iteration, mean_rewards=-239]\u001b[A\n",
            "Training:  69%|██████▉   | 1377/2000 [28:42<10:41,  1.03s/iteration, mean_rewards=-166]\u001b[A\n",
            "Training:  69%|██████▉   | 1378/2000 [28:42<10:26,  1.01s/iteration, mean_rewards=-166]\u001b[A\n",
            "Training:  69%|██████▉   | 1378/2000 [28:42<10:26,  1.01s/iteration, mean_rewards=-163]\u001b[A\n",
            "Training:  69%|██████▉   | 1379/2000 [28:43<09:24,  1.10iteration/s, mean_rewards=-163]\u001b[A\n",
            "Training:  69%|██████▉   | 1379/2000 [28:43<09:24,  1.10iteration/s, mean_rewards=-180]\u001b[A\n",
            "Training:  69%|██████▉   | 1380/2000 [28:44<09:07,  1.13iteration/s, mean_rewards=-180]\u001b[A\n",
            "Training:  69%|██████▉   | 1380/2000 [28:44<09:07,  1.13iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  69%|██████▉   | 1381/2000 [28:44<08:45,  1.18iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  69%|██████▉   | 1381/2000 [28:45<08:45,  1.18iteration/s, mean_rewards=-57.5]\u001b[A\n",
            "Training:  69%|██████▉   | 1382/2000 [28:45<08:08,  1.26iteration/s, mean_rewards=-57.5]\u001b[A\n",
            "Training:  69%|██████▉   | 1382/2000 [28:45<08:08,  1.26iteration/s, mean_rewards=-79.4]\u001b[A\n",
            "Training:  69%|██████▉   | 1383/2000 [28:46<07:44,  1.33iteration/s, mean_rewards=-79.4]\u001b[A\n",
            "Training:  69%|██████▉   | 1383/2000 [28:46<07:44,  1.33iteration/s, mean_rewards=-117] \u001b[A\n",
            "Training:  69%|██████▉   | 1384/2000 [28:47<07:53,  1.30iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  69%|██████▉   | 1384/2000 [28:47<07:53,  1.30iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  69%|██████▉   | 1385/2000 [28:47<07:35,  1.35iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  69%|██████▉   | 1385/2000 [28:48<07:35,  1.35iteration/s, mean_rewards=-296]\u001b[A\n",
            "Training:  69%|██████▉   | 1386/2000 [28:48<07:46,  1.32iteration/s, mean_rewards=-296]\u001b[A\n",
            "Training:  69%|██████▉   | 1386/2000 [28:48<07:46,  1.32iteration/s, mean_rewards=-240]\u001b[A\n",
            "Training:  69%|██████▉   | 1387/2000 [28:49<07:50,  1.30iteration/s, mean_rewards=-240]\u001b[A\n",
            "Training:  69%|██████▉   | 1387/2000 [28:49<07:50,  1.30iteration/s, mean_rewards=-229]\u001b[A\n",
            "Training:  69%|██████▉   | 1388/2000 [28:50<07:58,  1.28iteration/s, mean_rewards=-229]\u001b[A\n",
            "Training:  69%|██████▉   | 1388/2000 [28:50<07:58,  1.28iteration/s, mean_rewards=-179]\u001b[A\n",
            "Training:  69%|██████▉   | 1389/2000 [28:50<07:55,  1.28iteration/s, mean_rewards=-179]\u001b[A\n",
            "Training:  69%|██████▉   | 1389/2000 [28:51<07:55,  1.28iteration/s, mean_rewards=-243]\u001b[A\n",
            "Training:  70%|██████▉   | 1390/2000 [28:51<08:25,  1.21iteration/s, mean_rewards=-243]\u001b[A\n",
            "Training:  70%|██████▉   | 1390/2000 [28:52<08:25,  1.21iteration/s, mean_rewards=-172]\u001b[A\n",
            "Training:  70%|██████▉   | 1391/2000 [28:52<08:54,  1.14iteration/s, mean_rewards=-172]\u001b[A\n",
            "Training:  70%|██████▉   | 1391/2000 [28:53<08:54,  1.14iteration/s, mean_rewards=-77.5]\u001b[A\n",
            "Training:  70%|██████▉   | 1392/2000 [28:53<08:50,  1.15iteration/s, mean_rewards=-77.5]\u001b[A\n",
            "Training:  70%|██████▉   | 1392/2000 [28:54<08:50,  1.15iteration/s, mean_rewards=-61.8]\u001b[A\n",
            "Training:  70%|██████▉   | 1393/2000 [28:54<09:10,  1.10iteration/s, mean_rewards=-61.8]\u001b[A\n",
            "Training:  70%|██████▉   | 1393/2000 [28:55<09:10,  1.10iteration/s, mean_rewards=-126] \u001b[A\n",
            "Training:  70%|██████▉   | 1394/2000 [28:55<08:39,  1.17iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  70%|██████▉   | 1394/2000 [28:55<08:39,  1.17iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  70%|██████▉   | 1395/2000 [28:56<08:45,  1.15iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  70%|██████▉   | 1395/2000 [28:56<08:45,  1.15iteration/s, mean_rewards=-356]\u001b[A\n",
            "Training:  70%|██████▉   | 1396/2000 [28:57<08:57,  1.12iteration/s, mean_rewards=-356]\u001b[A\n",
            "Training:  70%|██████▉   | 1396/2000 [28:57<08:57,  1.12iteration/s, mean_rewards=-112]\u001b[A\n",
            "Training:  70%|██████▉   | 1397/2000 [28:58<08:43,  1.15iteration/s, mean_rewards=-112]\u001b[A\n",
            "Training:  70%|██████▉   | 1397/2000 [28:58<08:43,  1.15iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  70%|██████▉   | 1398/2000 [28:58<08:08,  1.23iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  70%|██████▉   | 1398/2000 [28:59<08:08,  1.23iteration/s, mean_rewards=-94.5]\u001b[A\n",
            "Training:  70%|██████▉   | 1399/2000 [28:59<08:02,  1.25iteration/s, mean_rewards=-94.5]\u001b[A\n",
            "Training:  70%|██████▉   | 1399/2000 [28:59<08:02,  1.25iteration/s, mean_rewards=-158] \u001b[A\n",
            "Training:  70%|███████   | 1400/2000 [29:00<07:36,  1.31iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  70%|███████   | 1400/2000 [29:00<07:36,  1.31iteration/s, mean_rewards=-343]\u001b[A\n",
            "Training:  70%|███████   | 1401/2000 [29:01<08:06,  1.23iteration/s, mean_rewards=-343]\u001b[A\n",
            "Training:  70%|███████   | 1401/2000 [29:01<08:06,  1.23iteration/s, mean_rewards=-207]\u001b[A\n",
            "Training:  70%|███████   | 1402/2000 [29:02<08:05,  1.23iteration/s, mean_rewards=-207]\u001b[A\n",
            "Training:  70%|███████   | 1402/2000 [29:02<08:05,  1.23iteration/s, mean_rewards=-167]\u001b[A\n",
            "Training:  70%|███████   | 1403/2000 [29:02<08:33,  1.16iteration/s, mean_rewards=-167]\u001b[A\n",
            "Training:  70%|███████   | 1403/2000 [29:03<08:33,  1.16iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  70%|███████   | 1404/2000 [29:03<08:28,  1.17iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  70%|███████   | 1404/2000 [29:04<08:28,  1.17iteration/s, mean_rewards=-82.2]\u001b[A\n",
            "Training:  70%|███████   | 1405/2000 [29:04<08:17,  1.20iteration/s, mean_rewards=-82.2]\u001b[A\n",
            "Training:  70%|███████   | 1405/2000 [29:05<08:17,  1.20iteration/s, mean_rewards=-117] \u001b[A\n",
            "Training:  70%|███████   | 1406/2000 [29:06<10:04,  1.02s/iteration, mean_rewards=-117]\u001b[A\n",
            "Training:  70%|███████   | 1406/2000 [29:06<10:04,  1.02s/iteration, mean_rewards=-231]\u001b[A\n",
            "Training:  70%|███████   | 1407/2000 [29:07<11:05,  1.12s/iteration, mean_rewards=-231]\u001b[A\n",
            "Training:  70%|███████   | 1407/2000 [29:07<11:05,  1.12s/iteration, mean_rewards=-244]\u001b[A\n",
            "Training:  70%|███████   | 1408/2000 [29:08<10:18,  1.05s/iteration, mean_rewards=-244]\u001b[A\n",
            "Training:  70%|███████   | 1408/2000 [29:08<10:18,  1.05s/iteration, mean_rewards=-175]\u001b[A\n",
            "Training:  70%|███████   | 1409/2000 [29:09<09:19,  1.06iteration/s, mean_rewards=-175]\u001b[A\n",
            "Training:  70%|███████   | 1409/2000 [29:09<09:19,  1.06iteration/s, mean_rewards=-216]\u001b[A\n",
            "Training:  70%|███████   | 1410/2000 [29:09<09:03,  1.09iteration/s, mean_rewards=-216]\u001b[A\n",
            "Training:  70%|███████   | 1410/2000 [29:10<09:03,  1.09iteration/s, mean_rewards=-363]\u001b[A\n",
            "Training:  71%|███████   | 1411/2000 [29:10<09:01,  1.09iteration/s, mean_rewards=-363]\u001b[A\n",
            "Training:  71%|███████   | 1411/2000 [29:11<09:01,  1.09iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:  71%|███████   | 1412/2000 [29:11<08:18,  1.18iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:  71%|███████   | 1412/2000 [29:11<08:18,  1.18iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  71%|███████   | 1413/2000 [29:12<07:53,  1.24iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  71%|███████   | 1413/2000 [29:12<07:53,  1.24iteration/s, mean_rewards=-102]\u001b[A\n",
            "Training:  71%|███████   | 1414/2000 [29:12<07:52,  1.24iteration/s, mean_rewards=-102]\u001b[A\n",
            "Training:  71%|███████   | 1414/2000 [29:13<07:52,  1.24iteration/s, mean_rewards=-244]\u001b[A\n",
            "Training:  71%|███████   | 1415/2000 [29:13<08:16,  1.18iteration/s, mean_rewards=-244]\u001b[A\n",
            "Training:  71%|███████   | 1415/2000 [29:14<08:16,  1.18iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  71%|███████   | 1416/2000 [29:14<08:12,  1.19iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  71%|███████   | 1416/2000 [29:15<08:12,  1.19iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  71%|███████   | 1417/2000 [29:15<08:25,  1.15iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  71%|███████   | 1417/2000 [29:16<08:25,  1.15iteration/s, mean_rewards=-357]\u001b[A\n",
            "Training:  71%|███████   | 1418/2000 [29:16<08:30,  1.14iteration/s, mean_rewards=-357]\u001b[A\n",
            "Training:  71%|███████   | 1418/2000 [29:16<08:30,  1.14iteration/s, mean_rewards=-242]\u001b[A\n",
            "Training:  71%|███████   | 1419/2000 [29:17<08:17,  1.17iteration/s, mean_rewards=-242]\u001b[A\n",
            "Training:  71%|███████   | 1419/2000 [29:17<08:17,  1.17iteration/s, mean_rewards=-116]\u001b[A\n",
            "Training:  71%|███████   | 1420/2000 [29:18<08:54,  1.08iteration/s, mean_rewards=-116]\u001b[A\n",
            "Training:  71%|███████   | 1420/2000 [29:18<08:54,  1.08iteration/s, mean_rewards=-181]\u001b[A\n",
            "Training:  71%|███████   | 1421/2000 [29:19<08:51,  1.09iteration/s, mean_rewards=-181]\u001b[A\n",
            "Training:  71%|███████   | 1421/2000 [29:19<08:51,  1.09iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  71%|███████   | 1422/2000 [29:20<09:31,  1.01iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  71%|███████   | 1422/2000 [29:20<09:31,  1.01iteration/s, mean_rewards=-326]\u001b[A\n",
            "Training:  71%|███████   | 1423/2000 [29:21<09:13,  1.04iteration/s, mean_rewards=-326]\u001b[A\n",
            "Training:  71%|███████   | 1423/2000 [29:21<09:13,  1.04iteration/s, mean_rewards=-268]\u001b[A\n",
            "Training:  71%|███████   | 1424/2000 [29:22<08:50,  1.09iteration/s, mean_rewards=-268]\u001b[A\n",
            "Training:  71%|███████   | 1424/2000 [29:22<08:50,  1.09iteration/s, mean_rewards=-323]\u001b[A\n",
            "Training:  71%|███████▏  | 1425/2000 [29:23<09:39,  1.01s/iteration, mean_rewards=-323]\u001b[A\n",
            "Training:  71%|███████▏  | 1425/2000 [29:23<09:39,  1.01s/iteration, mean_rewards=-167]\u001b[A\n",
            "Training:  71%|███████▏  | 1426/2000 [29:24<08:41,  1.10iteration/s, mean_rewards=-167]\u001b[A\n",
            "Training:  71%|███████▏  | 1426/2000 [29:24<08:41,  1.10iteration/s, mean_rewards=-50] \u001b[A\n",
            "Training:  71%|███████▏  | 1427/2000 [29:24<07:59,  1.19iteration/s, mean_rewards=-50]\u001b[A\n",
            "Training:  71%|███████▏  | 1427/2000 [29:25<07:59,  1.19iteration/s, mean_rewards=-199]\u001b[A\n",
            "Training:  71%|███████▏  | 1428/2000 [29:25<07:09,  1.33iteration/s, mean_rewards=-199]\u001b[A\n",
            "Training:  71%|███████▏  | 1428/2000 [29:25<07:09,  1.33iteration/s, mean_rewards=-185]\u001b[A\n",
            "Training:  71%|███████▏  | 1429/2000 [29:26<07:12,  1.32iteration/s, mean_rewards=-185]\u001b[A\n",
            "Training:  71%|███████▏  | 1429/2000 [29:26<07:12,  1.32iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  72%|███████▏  | 1430/2000 [29:26<06:59,  1.36iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  72%|███████▏  | 1430/2000 [29:27<06:59,  1.36iteration/s, mean_rewards=-236]\u001b[A\n",
            "Training:  72%|███████▏  | 1431/2000 [29:27<07:36,  1.25iteration/s, mean_rewards=-236]\u001b[A\n",
            "Training:  72%|███████▏  | 1431/2000 [29:28<07:36,  1.25iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  72%|███████▏  | 1432/2000 [29:28<07:33,  1.25iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  72%|███████▏  | 1432/2000 [29:28<07:33,  1.25iteration/s, mean_rewards=-97.5]\u001b[A\n",
            "Training:  72%|███████▏  | 1433/2000 [29:29<07:30,  1.26iteration/s, mean_rewards=-97.5]\u001b[A\n",
            "Training:  72%|███████▏  | 1433/2000 [29:29<07:30,  1.26iteration/s, mean_rewards=-76.8]\u001b[A\n",
            "Training:  72%|███████▏  | 1434/2000 [29:30<07:29,  1.26iteration/s, mean_rewards=-76.8]\u001b[A\n",
            "Training:  72%|███████▏  | 1434/2000 [29:30<07:29,  1.26iteration/s, mean_rewards=-232] \u001b[A\n",
            "Training:  72%|███████▏  | 1435/2000 [29:30<07:31,  1.25iteration/s, mean_rewards=-232]\u001b[A\n",
            "Training:  72%|███████▏  | 1435/2000 [29:31<07:31,  1.25iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  72%|███████▏  | 1436/2000 [29:31<08:05,  1.16iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  72%|███████▏  | 1436/2000 [29:32<08:05,  1.16iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  72%|███████▏  | 1437/2000 [29:33<09:15,  1.01iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  72%|███████▏  | 1437/2000 [29:33<09:15,  1.01iteration/s, mean_rewards=-171]\u001b[A\n",
            "Training:  72%|███████▏  | 1438/2000 [29:34<09:31,  1.02s/iteration, mean_rewards=-171]\u001b[A\n",
            "Training:  72%|███████▏  | 1438/2000 [29:34<09:31,  1.02s/iteration, mean_rewards=-136]\u001b[A\n",
            "Training:  72%|███████▏  | 1439/2000 [29:35<08:53,  1.05iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  72%|███████▏  | 1439/2000 [29:35<08:53,  1.05iteration/s, mean_rewards=-277]\u001b[A\n",
            "Training:  72%|███████▏  | 1440/2000 [29:36<09:19,  1.00iteration/s, mean_rewards=-277]\u001b[A\n",
            "Training:  72%|███████▏  | 1440/2000 [29:36<09:19,  1.00iteration/s, mean_rewards=-235]\u001b[A\n",
            "Training:  72%|███████▏  | 1441/2000 [29:37<09:13,  1.01iteration/s, mean_rewards=-235]\u001b[A\n",
            "Training:  72%|███████▏  | 1441/2000 [29:37<09:13,  1.01iteration/s, mean_rewards=-152]\u001b[A\n",
            "Training:  72%|███████▏  | 1442/2000 [29:37<08:26,  1.10iteration/s, mean_rewards=-152]\u001b[A\n",
            "Training:  72%|███████▏  | 1442/2000 [29:38<08:26,  1.10iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  72%|███████▏  | 1443/2000 [29:39<09:08,  1.02iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  72%|███████▏  | 1443/2000 [29:39<09:08,  1.02iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  72%|███████▏  | 1444/2000 [29:39<08:22,  1.11iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  72%|███████▏  | 1444/2000 [29:40<08:22,  1.11iteration/s, mean_rewards=-270]\u001b[A\n",
            "Training:  72%|███████▏  | 1445/2000 [29:40<07:59,  1.16iteration/s, mean_rewards=-270]\u001b[A\n",
            "Training:  72%|███████▏  | 1445/2000 [29:40<07:59,  1.16iteration/s, mean_rewards=-199]\u001b[A\n",
            "Training:  72%|███████▏  | 1446/2000 [29:41<08:28,  1.09iteration/s, mean_rewards=-199]\u001b[A\n",
            "Training:  72%|███████▏  | 1446/2000 [29:41<08:28,  1.09iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  72%|███████▏  | 1447/2000 [29:42<07:48,  1.18iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  72%|███████▏  | 1447/2000 [29:42<07:48,  1.18iteration/s, mean_rewards=-86.5]\u001b[A\n",
            "Training:  72%|███████▏  | 1448/2000 [29:43<07:58,  1.15iteration/s, mean_rewards=-86.5]\u001b[A\n",
            "Training:  72%|███████▏  | 1448/2000 [29:43<07:58,  1.15iteration/s, mean_rewards=-234] \u001b[A\n",
            "Training:  72%|███████▏  | 1449/2000 [29:44<08:27,  1.09iteration/s, mean_rewards=-234]\u001b[A\n",
            "Training:  72%|███████▏  | 1449/2000 [29:44<08:27,  1.09iteration/s, mean_rewards=-206]\u001b[A\n",
            "Training:  72%|███████▎  | 1450/2000 [29:45<08:36,  1.06iteration/s, mean_rewards=-206]\u001b[A\n",
            "Training:  72%|███████▎  | 1450/2000 [29:45<08:36,  1.06iteration/s, mean_rewards=-232]\u001b[A\n",
            "Training:  73%|███████▎  | 1451/2000 [29:46<09:05,  1.01iteration/s, mean_rewards=-232]\u001b[A\n",
            "Training:  73%|███████▎  | 1451/2000 [29:47<09:05,  1.01iteration/s, mean_rewards=-119]\u001b[A\n",
            "Training:  73%|███████▎  | 1452/2000 [29:47<10:25,  1.14s/iteration, mean_rewards=-119]\u001b[A\n",
            "Training:  73%|███████▎  | 1452/2000 [29:48<10:25,  1.14s/iteration, mean_rewards=-118]\u001b[A\n",
            "Training:  73%|███████▎  | 1453/2000 [29:48<09:07,  1.00s/iteration, mean_rewards=-118]\u001b[A\n",
            "Training:  73%|███████▎  | 1453/2000 [29:48<09:07,  1.00s/iteration, mean_rewards=-219]\u001b[A\n",
            "Training:  73%|███████▎  | 1454/2000 [29:49<08:14,  1.10iteration/s, mean_rewards=-219]\u001b[A\n",
            "Training:  73%|███████▎  | 1454/2000 [29:49<08:14,  1.10iteration/s, mean_rewards=-370]\u001b[A\n",
            "Training:  73%|███████▎  | 1455/2000 [29:50<08:12,  1.11iteration/s, mean_rewards=-370]\u001b[A\n",
            "Training:  73%|███████▎  | 1455/2000 [29:50<08:12,  1.11iteration/s, mean_rewards=-181]\u001b[A\n",
            "Training:  73%|███████▎  | 1456/2000 [29:51<08:37,  1.05iteration/s, mean_rewards=-181]\u001b[A\n",
            "Training:  73%|███████▎  | 1456/2000 [29:51<08:37,  1.05iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  73%|███████▎  | 1457/2000 [29:52<08:31,  1.06iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  73%|███████▎  | 1457/2000 [29:52<08:31,  1.06iteration/s, mean_rewards=-217]\u001b[A\n",
            "Training:  73%|███████▎  | 1458/2000 [29:53<08:31,  1.06iteration/s, mean_rewards=-217]\u001b[A\n",
            "Training:  73%|███████▎  | 1458/2000 [29:53<08:31,  1.06iteration/s, mean_rewards=-304]\u001b[A\n",
            "Training:  73%|███████▎  | 1459/2000 [29:53<08:23,  1.07iteration/s, mean_rewards=-304]\u001b[A\n",
            "Training:  73%|███████▎  | 1459/2000 [29:54<08:23,  1.07iteration/s, mean_rewards=-259]\u001b[A\n",
            "Training:  73%|███████▎  | 1460/2000 [29:54<08:03,  1.12iteration/s, mean_rewards=-259]\u001b[A\n",
            "Training:  73%|███████▎  | 1460/2000 [29:55<08:03,  1.12iteration/s, mean_rewards=-231]\u001b[A\n",
            "Training:  73%|███████▎  | 1461/2000 [29:55<08:10,  1.10iteration/s, mean_rewards=-231]\u001b[A\n",
            "Training:  73%|███████▎  | 1461/2000 [29:56<08:10,  1.10iteration/s, mean_rewards=-337]\u001b[A\n",
            "Training:  73%|███████▎  | 1462/2000 [29:56<08:11,  1.10iteration/s, mean_rewards=-337]\u001b[A\n",
            "Training:  73%|███████▎  | 1462/2000 [29:56<08:11,  1.10iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  73%|███████▎  | 1463/2000 [29:57<07:32,  1.19iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  73%|███████▎  | 1463/2000 [29:57<07:32,  1.19iteration/s, mean_rewards=-86.1]\u001b[A\n",
            "Training:  73%|███████▎  | 1464/2000 [29:58<08:37,  1.04iteration/s, mean_rewards=-86.1]\u001b[A\n",
            "Training:  73%|███████▎  | 1464/2000 [29:58<08:37,  1.04iteration/s, mean_rewards=-98.8]\u001b[A\n",
            "Training:  73%|███████▎  | 1465/2000 [29:59<08:48,  1.01iteration/s, mean_rewards=-98.8]\u001b[A\n",
            "Training:  73%|███████▎  | 1465/2000 [30:00<08:48,  1.01iteration/s, mean_rewards=-240] \u001b[A\n",
            "Training:  73%|███████▎  | 1466/2000 [30:00<08:53,  1.00iteration/s, mean_rewards=-240]\u001b[A\n",
            "Training:  73%|███████▎  | 1466/2000 [30:00<08:53,  1.00iteration/s, mean_rewards=-84.9]\u001b[A\n",
            "Training:  73%|███████▎  | 1467/2000 [30:01<08:09,  1.09iteration/s, mean_rewards=-84.9]\u001b[A\n",
            "Training:  73%|███████▎  | 1467/2000 [30:01<08:09,  1.09iteration/s, mean_rewards=-114] \u001b[A\n",
            "Training:  73%|███████▎  | 1468/2000 [30:02<07:52,  1.13iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  73%|███████▎  | 1468/2000 [30:02<07:52,  1.13iteration/s, mean_rewards=-331]\u001b[A\n",
            "Training:  73%|███████▎  | 1469/2000 [30:02<07:32,  1.17iteration/s, mean_rewards=-331]\u001b[A\n",
            "Training:  73%|███████▎  | 1469/2000 [30:03<07:32,  1.17iteration/s, mean_rewards=-172]\u001b[A\n",
            "Training:  74%|███████▎  | 1470/2000 [30:03<07:04,  1.25iteration/s, mean_rewards=-172]\u001b[A\n",
            "Training:  74%|███████▎  | 1470/2000 [30:03<07:04,  1.25iteration/s, mean_rewards=-89.2]\u001b[A\n",
            "Training:  74%|███████▎  | 1471/2000 [30:04<07:27,  1.18iteration/s, mean_rewards=-89.2]\u001b[A\n",
            "Training:  74%|███████▎  | 1471/2000 [30:04<07:27,  1.18iteration/s, mean_rewards=-161] \u001b[A\n",
            "Training:  74%|███████▎  | 1472/2000 [30:05<07:40,  1.15iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:  74%|███████▎  | 1472/2000 [30:05<07:40,  1.15iteration/s, mean_rewards=-189]\u001b[A\n",
            "Training:  74%|███████▎  | 1473/2000 [30:06<07:29,  1.17iteration/s, mean_rewards=-189]\u001b[A\n",
            "Training:  74%|███████▎  | 1473/2000 [30:06<07:29,  1.17iteration/s, mean_rewards=-201]\u001b[A\n",
            "Training:  74%|███████▎  | 1474/2000 [30:07<08:08,  1.08iteration/s, mean_rewards=-201]\u001b[A\n",
            "Training:  74%|███████▎  | 1474/2000 [30:07<08:08,  1.08iteration/s, mean_rewards=-206]\u001b[A\n",
            "Training:  74%|███████▍  | 1475/2000 [30:08<08:09,  1.07iteration/s, mean_rewards=-206]\u001b[A\n",
            "Training:  74%|███████▍  | 1475/2000 [30:08<08:09,  1.07iteration/s, mean_rewards=-209]\u001b[A\n",
            "Training:  74%|███████▍  | 1476/2000 [30:09<07:53,  1.11iteration/s, mean_rewards=-209]\u001b[A\n",
            "Training:  74%|███████▍  | 1476/2000 [30:09<07:53,  1.11iteration/s, mean_rewards=-259]\u001b[A\n",
            "Training:  74%|███████▍  | 1477/2000 [30:10<08:20,  1.04iteration/s, mean_rewards=-259]\u001b[A\n",
            "Training:  74%|███████▍  | 1477/2000 [30:10<08:20,  1.04iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  74%|███████▍  | 1478/2000 [30:11<09:44,  1.12s/iteration, mean_rewards=-140]\u001b[A\n",
            "Training:  74%|███████▍  | 1478/2000 [30:12<09:44,  1.12s/iteration, mean_rewards=-268]\u001b[A\n",
            "Training:  74%|███████▍  | 1479/2000 [30:12<09:24,  1.08s/iteration, mean_rewards=-268]\u001b[A\n",
            "Training:  74%|███████▍  | 1479/2000 [30:13<09:24,  1.08s/iteration, mean_rewards=-112]\u001b[A\n",
            "Training:  74%|███████▍  | 1480/2000 [30:13<08:17,  1.04iteration/s, mean_rewards=-112]\u001b[A\n",
            "Training:  74%|███████▍  | 1480/2000 [30:13<08:17,  1.04iteration/s, mean_rewards=-189]\u001b[A\n",
            "Training:  74%|███████▍  | 1481/2000 [30:14<07:39,  1.13iteration/s, mean_rewards=-189]\u001b[A\n",
            "Training:  74%|███████▍  | 1481/2000 [30:14<07:39,  1.13iteration/s, mean_rewards=-105]\u001b[A\n",
            "Training:  74%|███████▍  | 1482/2000 [30:15<08:14,  1.05iteration/s, mean_rewards=-105]\u001b[A\n",
            "Training:  74%|███████▍  | 1482/2000 [30:15<08:14,  1.05iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  74%|███████▍  | 1483/2000 [30:15<07:34,  1.14iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  74%|███████▍  | 1483/2000 [30:16<07:34,  1.14iteration/s, mean_rewards=-71.9]\u001b[A\n",
            "Training:  74%|███████▍  | 1484/2000 [30:16<07:44,  1.11iteration/s, mean_rewards=-71.9]\u001b[A\n",
            "Training:  74%|███████▍  | 1484/2000 [30:17<07:44,  1.11iteration/s, mean_rewards=-113] \u001b[A\n",
            "Training:  74%|███████▍  | 1485/2000 [30:17<07:07,  1.21iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  74%|███████▍  | 1485/2000 [30:17<07:07,  1.21iteration/s, mean_rewards=-343]\u001b[A\n",
            "Training:  74%|███████▍  | 1486/2000 [30:18<07:28,  1.15iteration/s, mean_rewards=-343]\u001b[A\n",
            "Training:  74%|███████▍  | 1486/2000 [30:19<07:28,  1.15iteration/s, mean_rewards=-222]\u001b[A\n",
            "Training:  74%|███████▍  | 1487/2000 [30:19<08:19,  1.03iteration/s, mean_rewards=-222]\u001b[A\n",
            "Training:  74%|███████▍  | 1487/2000 [30:20<08:19,  1.03iteration/s, mean_rewards=-425]\u001b[A\n",
            "Training:  74%|███████▍  | 1488/2000 [30:20<08:13,  1.04iteration/s, mean_rewards=-425]\u001b[A\n",
            "Training:  74%|███████▍  | 1488/2000 [30:21<08:13,  1.04iteration/s, mean_rewards=-199]\u001b[A\n",
            "Training:  74%|███████▍  | 1489/2000 [30:21<07:48,  1.09iteration/s, mean_rewards=-199]\u001b[A\n",
            "Training:  74%|███████▍  | 1489/2000 [30:21<07:48,  1.09iteration/s, mean_rewards=-87.1]\u001b[A\n",
            "Training:  74%|███████▍  | 1490/2000 [30:22<08:13,  1.03iteration/s, mean_rewards=-87.1]\u001b[A\n",
            "Training:  74%|███████▍  | 1490/2000 [30:23<08:13,  1.03iteration/s, mean_rewards=-252] \u001b[A\n",
            "Training:  75%|███████▍  | 1491/2000 [30:23<09:00,  1.06s/iteration, mean_rewards=-252]\u001b[A\n",
            "Training:  75%|███████▍  | 1491/2000 [30:24<09:00,  1.06s/iteration, mean_rewards=-191]\u001b[A\n",
            "Training:  75%|███████▍  | 1492/2000 [30:25<09:18,  1.10s/iteration, mean_rewards=-191]\u001b[A\n",
            "Training:  75%|███████▍  | 1492/2000 [30:25<09:18,  1.10s/iteration, mean_rewards=-150]\u001b[A\n",
            "Training:  75%|███████▍  | 1493/2000 [30:26<09:04,  1.07s/iteration, mean_rewards=-150]\u001b[A\n",
            "Training:  75%|███████▍  | 1493/2000 [30:26<09:04,  1.07s/iteration, mean_rewards=-199]\u001b[A\n",
            "Training:  75%|███████▍  | 1494/2000 [30:26<08:21,  1.01iteration/s, mean_rewards=-199]\u001b[A\n",
            "Training:  75%|███████▍  | 1494/2000 [30:27<08:21,  1.01iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  75%|███████▍  | 1495/2000 [30:27<07:27,  1.13iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  75%|███████▍  | 1495/2000 [30:27<07:27,  1.13iteration/s, mean_rewards=-235]\u001b[A\n",
            "Training:  75%|███████▍  | 1496/2000 [30:28<07:33,  1.11iteration/s, mean_rewards=-235]\u001b[A\n",
            "Training:  75%|███████▍  | 1496/2000 [30:28<07:33,  1.11iteration/s, mean_rewards=-102]\u001b[A\n",
            "Training:  75%|███████▍  | 1497/2000 [30:29<06:58,  1.20iteration/s, mean_rewards=-102]\u001b[A\n",
            "Training:  75%|███████▍  | 1497/2000 [30:29<06:58,  1.20iteration/s, mean_rewards=-290]\u001b[A\n",
            "Training:  75%|███████▍  | 1498/2000 [30:30<07:12,  1.16iteration/s, mean_rewards=-290]\u001b[A\n",
            "Training:  75%|███████▍  | 1498/2000 [30:30<07:12,  1.16iteration/s, mean_rewards=-419]\u001b[A\n",
            "Training:  75%|███████▍  | 1499/2000 [30:31<07:27,  1.12iteration/s, mean_rewards=-419]\u001b[A\n",
            "Training:  75%|███████▍  | 1499/2000 [30:31<07:27,  1.12iteration/s, mean_rewards=-272]\u001b[A\n",
            "Training:  75%|███████▌  | 1500/2000 [30:32<07:42,  1.08iteration/s, mean_rewards=-272]\u001b[A\n",
            "Training:  75%|███████▌  | 1500/2000 [30:32<07:42,  1.08iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  75%|███████▌  | 1501/2000 [30:32<07:21,  1.13iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  75%|███████▌  | 1501/2000 [30:33<07:21,  1.13iteration/s, mean_rewards=-105]\u001b[A\n",
            "Training:  75%|███████▌  | 1502/2000 [30:33<06:50,  1.21iteration/s, mean_rewards=-105]\u001b[A\n",
            "Training:  75%|███████▌  | 1502/2000 [30:33<06:50,  1.21iteration/s, mean_rewards=-442]\u001b[A\n",
            "Training:  75%|███████▌  | 1503/2000 [30:34<07:08,  1.16iteration/s, mean_rewards=-442]\u001b[A\n",
            "Training:  75%|███████▌  | 1503/2000 [30:34<07:08,  1.16iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  75%|███████▌  | 1504/2000 [30:35<06:58,  1.19iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  75%|███████▌  | 1504/2000 [30:35<06:58,  1.19iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:  75%|███████▌  | 1505/2000 [30:36<07:14,  1.14iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:  75%|███████▌  | 1505/2000 [30:36<07:14,  1.14iteration/s, mean_rewards=-91.4]\u001b[A\n",
            "Training:  75%|███████▌  | 1506/2000 [30:37<07:43,  1.07iteration/s, mean_rewards=-91.4]\u001b[A\n",
            "Training:  75%|███████▌  | 1506/2000 [30:37<07:43,  1.07iteration/s, mean_rewards=-286] \u001b[A\n",
            "Training:  75%|███████▌  | 1507/2000 [30:38<07:51,  1.05iteration/s, mean_rewards=-286]\u001b[A\n",
            "Training:  75%|███████▌  | 1507/2000 [30:38<07:51,  1.05iteration/s, mean_rewards=-248]\u001b[A\n",
            "Training:  75%|███████▌  | 1508/2000 [30:39<07:47,  1.05iteration/s, mean_rewards=-248]\u001b[A\n",
            "Training:  75%|███████▌  | 1508/2000 [30:39<07:47,  1.05iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:  75%|███████▌  | 1509/2000 [30:40<07:29,  1.09iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:  75%|███████▌  | 1509/2000 [30:40<07:29,  1.09iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  76%|███████▌  | 1510/2000 [30:40<07:15,  1.13iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  76%|███████▌  | 1510/2000 [30:41<07:15,  1.13iteration/s, mean_rewards=-221]\u001b[A\n",
            "Training:  76%|███████▌  | 1511/2000 [30:41<07:24,  1.10iteration/s, mean_rewards=-221]\u001b[A\n",
            "Training:  76%|███████▌  | 1511/2000 [30:42<07:24,  1.10iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  76%|███████▌  | 1512/2000 [30:42<07:09,  1.14iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  76%|███████▌  | 1512/2000 [30:43<07:09,  1.14iteration/s, mean_rewards=-309]\u001b[A\n",
            "Training:  76%|███████▌  | 1513/2000 [30:43<07:30,  1.08iteration/s, mean_rewards=-309]\u001b[A\n",
            "Training:  76%|███████▌  | 1513/2000 [30:44<07:30,  1.08iteration/s, mean_rewards=-230]\u001b[A\n",
            "Training:  76%|███████▌  | 1514/2000 [30:44<07:26,  1.09iteration/s, mean_rewards=-230]\u001b[A\n",
            "Training:  76%|███████▌  | 1514/2000 [30:44<07:26,  1.09iteration/s, mean_rewards=-272]\u001b[A\n",
            "Training:  76%|███████▌  | 1515/2000 [30:45<07:06,  1.14iteration/s, mean_rewards=-272]\u001b[A\n",
            "Training:  76%|███████▌  | 1515/2000 [30:45<07:06,  1.14iteration/s, mean_rewards=-119]\u001b[A\n",
            "Training:  76%|███████▌  | 1516/2000 [30:46<06:56,  1.16iteration/s, mean_rewards=-119]\u001b[A\n",
            "Training:  76%|███████▌  | 1516/2000 [30:46<06:56,  1.16iteration/s, mean_rewards=-226]\u001b[A\n",
            "Training:  76%|███████▌  | 1517/2000 [30:47<07:03,  1.14iteration/s, mean_rewards=-226]\u001b[A\n",
            "Training:  76%|███████▌  | 1517/2000 [30:47<07:03,  1.14iteration/s, mean_rewards=-168]\u001b[A\n",
            "Training:  76%|███████▌  | 1518/2000 [30:48<07:13,  1.11iteration/s, mean_rewards=-168]\u001b[A\n",
            "Training:  76%|███████▌  | 1518/2000 [30:48<07:13,  1.11iteration/s, mean_rewards=-256]\u001b[A\n",
            "Training:  76%|███████▌  | 1519/2000 [30:49<08:23,  1.05s/iteration, mean_rewards=-256]\u001b[A\n",
            "Training:  76%|███████▌  | 1519/2000 [30:50<08:23,  1.05s/iteration, mean_rewards=-260]\u001b[A\n",
            "Training:  76%|███████▌  | 1520/2000 [30:50<09:34,  1.20s/iteration, mean_rewards=-260]\u001b[A\n",
            "Training:  76%|███████▌  | 1520/2000 [30:51<09:34,  1.20s/iteration, mean_rewards=-64.7]\u001b[A\n",
            "Training:  76%|███████▌  | 1521/2000 [30:51<09:04,  1.14s/iteration, mean_rewards=-64.7]\u001b[A\n",
            "Training:  76%|███████▌  | 1521/2000 [30:52<09:04,  1.14s/iteration, mean_rewards=-115] \u001b[A\n",
            "Training:  76%|███████▌  | 1522/2000 [30:53<09:00,  1.13s/iteration, mean_rewards=-115]\u001b[A\n",
            "Training:  76%|███████▌  | 1522/2000 [30:53<09:00,  1.13s/iteration, mean_rewards=-88.5]\u001b[A\n",
            "Training:  76%|███████▌  | 1523/2000 [30:53<07:57,  1.00s/iteration, mean_rewards=-88.5]\u001b[A\n",
            "Training:  76%|███████▌  | 1523/2000 [30:54<07:57,  1.00s/iteration, mean_rewards=-237] \u001b[A\n",
            "Training:  76%|███████▌  | 1524/2000 [30:54<08:07,  1.02s/iteration, mean_rewards=-237]\u001b[A\n",
            "Training:  76%|███████▌  | 1524/2000 [30:55<08:07,  1.02s/iteration, mean_rewards=-247]\u001b[A\n",
            "Training:  76%|███████▋  | 1525/2000 [30:55<07:20,  1.08iteration/s, mean_rewards=-247]\u001b[A\n",
            "Training:  76%|███████▋  | 1525/2000 [30:55<07:20,  1.08iteration/s, mean_rewards=-353]\u001b[A\n",
            "Training:  76%|███████▋  | 1526/2000 [30:56<07:16,  1.09iteration/s, mean_rewards=-353]\u001b[A\n",
            "Training:  76%|███████▋  | 1526/2000 [30:56<07:16,  1.09iteration/s, mean_rewards=-83.5]\u001b[A\n",
            "Training:  76%|███████▋  | 1527/2000 [30:57<06:56,  1.14iteration/s, mean_rewards=-83.5]\u001b[A\n",
            "Training:  76%|███████▋  | 1527/2000 [30:57<06:56,  1.14iteration/s, mean_rewards=-213] \u001b[A\n",
            "Training:  76%|███████▋  | 1528/2000 [30:58<06:52,  1.15iteration/s, mean_rewards=-213]\u001b[A\n",
            "Training:  76%|███████▋  | 1528/2000 [30:58<06:52,  1.15iteration/s, mean_rewards=-303]\u001b[A\n",
            "Training:  76%|███████▋  | 1529/2000 [30:58<06:44,  1.17iteration/s, mean_rewards=-303]\u001b[A\n",
            "Training:  76%|███████▋  | 1529/2000 [30:59<06:44,  1.17iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  76%|███████▋  | 1530/2000 [30:59<06:24,  1.22iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  76%|███████▋  | 1530/2000 [31:00<06:24,  1.22iteration/s, mean_rewards=-256]\u001b[A\n",
            "Training:  77%|███████▋  | 1531/2000 [31:00<07:02,  1.11iteration/s, mean_rewards=-256]\u001b[A\n",
            "Training:  77%|███████▋  | 1531/2000 [31:01<07:02,  1.11iteration/s, mean_rewards=-98.5]\u001b[A\n",
            "Training:  77%|███████▋  | 1532/2000 [31:01<06:48,  1.14iteration/s, mean_rewards=-98.5]\u001b[A\n",
            "Training:  77%|███████▋  | 1532/2000 [31:02<06:48,  1.14iteration/s, mean_rewards=-229] \u001b[A\n",
            "Training:  77%|███████▋  | 1533/2000 [31:03<08:07,  1.04s/iteration, mean_rewards=-229]\u001b[A\n",
            "Training:  77%|███████▋  | 1533/2000 [31:03<08:07,  1.04s/iteration, mean_rewards=-304]\u001b[A\n",
            "Training:  77%|███████▋  | 1534/2000 [31:04<09:08,  1.18s/iteration, mean_rewards=-304]\u001b[A\n",
            "Training:  77%|███████▋  | 1534/2000 [31:04<09:08,  1.18s/iteration, mean_rewards=-218]\u001b[A\n",
            "Training:  77%|███████▋  | 1535/2000 [31:05<08:35,  1.11s/iteration, mean_rewards=-218]\u001b[A\n",
            "Training:  77%|███████▋  | 1535/2000 [31:05<08:35,  1.11s/iteration, mean_rewards=-248]\u001b[A\n",
            "Training:  77%|███████▋  | 1536/2000 [31:06<07:47,  1.01s/iteration, mean_rewards=-248]\u001b[A\n",
            "Training:  77%|███████▋  | 1536/2000 [31:06<07:47,  1.01s/iteration, mean_rewards=-175]\u001b[A\n",
            "Training:  77%|███████▋  | 1537/2000 [31:06<06:59,  1.10iteration/s, mean_rewards=-175]\u001b[A\n",
            "Training:  77%|███████▋  | 1537/2000 [31:07<06:59,  1.10iteration/s, mean_rewards=-214]\u001b[A\n",
            "Training:  77%|███████▋  | 1538/2000 [31:07<07:04,  1.09iteration/s, mean_rewards=-214]\u001b[A\n",
            "Training:  77%|███████▋  | 1538/2000 [31:08<07:04,  1.09iteration/s, mean_rewards=-190]\u001b[A\n",
            "Training:  77%|███████▋  | 1539/2000 [31:08<06:31,  1.18iteration/s, mean_rewards=-190]\u001b[A\n",
            "Training:  77%|███████▋  | 1539/2000 [31:08<06:31,  1.18iteration/s, mean_rewards=-115]\u001b[A\n",
            "Training:  77%|███████▋  | 1540/2000 [31:09<06:26,  1.19iteration/s, mean_rewards=-115]\u001b[A\n",
            "Training:  77%|███████▋  | 1540/2000 [31:09<06:26,  1.19iteration/s, mean_rewards=-177]\u001b[A\n",
            "Training:  77%|███████▋  | 1541/2000 [31:10<06:25,  1.19iteration/s, mean_rewards=-177]\u001b[A\n",
            "Training:  77%|███████▋  | 1541/2000 [31:10<06:25,  1.19iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  77%|███████▋  | 1542/2000 [31:11<06:23,  1.20iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  77%|███████▋  | 1542/2000 [31:11<06:23,  1.20iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  77%|███████▋  | 1543/2000 [31:11<06:39,  1.14iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  77%|███████▋  | 1543/2000 [31:12<06:39,  1.14iteration/s, mean_rewards=-57.9]\u001b[A\n",
            "Training:  77%|███████▋  | 1544/2000 [31:12<05:59,  1.27iteration/s, mean_rewards=-57.9]\u001b[A\n",
            "Training:  77%|███████▋  | 1544/2000 [31:12<05:59,  1.27iteration/s, mean_rewards=-207] \u001b[A\n",
            "Training:  77%|███████▋  | 1545/2000 [31:13<06:01,  1.26iteration/s, mean_rewards=-207]\u001b[A\n",
            "Training:  77%|███████▋  | 1545/2000 [31:13<06:01,  1.26iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  77%|███████▋  | 1546/2000 [31:14<05:46,  1.31iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  77%|███████▋  | 1546/2000 [31:14<05:46,  1.31iteration/s, mean_rewards=-76.2]\u001b[A\n",
            "Training:  77%|███████▋  | 1547/2000 [31:15<06:47,  1.11iteration/s, mean_rewards=-76.2]\u001b[A\n",
            "Training:  77%|███████▋  | 1547/2000 [31:15<06:47,  1.11iteration/s, mean_rewards=-129] \u001b[A\n",
            "Training:  77%|███████▋  | 1548/2000 [31:16<06:48,  1.11iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  77%|███████▋  | 1548/2000 [31:16<06:48,  1.11iteration/s, mean_rewards=-215]\u001b[A\n",
            "Training:  77%|███████▋  | 1549/2000 [31:17<07:19,  1.03iteration/s, mean_rewards=-215]\u001b[A\n",
            "Training:  77%|███████▋  | 1549/2000 [31:17<07:19,  1.03iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  78%|███████▊  | 1550/2000 [31:18<07:52,  1.05s/iteration, mean_rewards=-121]\u001b[A\n",
            "Training:  78%|███████▊  | 1550/2000 [31:19<07:52,  1.05s/iteration, mean_rewards=-233]\u001b[A\n",
            "Training:  78%|███████▊  | 1551/2000 [31:19<07:54,  1.06s/iteration, mean_rewards=-233]\u001b[A\n",
            "Training:  78%|███████▊  | 1551/2000 [31:20<07:54,  1.06s/iteration, mean_rewards=-233]\u001b[A\n",
            "Training:  78%|███████▊  | 1552/2000 [31:20<07:33,  1.01s/iteration, mean_rewards=-233]\u001b[A\n",
            "Training:  78%|███████▊  | 1552/2000 [31:21<07:33,  1.01s/iteration, mean_rewards=-202]\u001b[A\n",
            "Training:  78%|███████▊  | 1553/2000 [31:21<07:54,  1.06s/iteration, mean_rewards=-202]\u001b[A\n",
            "Training:  78%|███████▊  | 1553/2000 [31:22<07:54,  1.06s/iteration, mean_rewards=-357]\u001b[A\n",
            "Training:  78%|███████▊  | 1554/2000 [31:22<08:14,  1.11s/iteration, mean_rewards=-357]\u001b[A\n",
            "Training:  78%|███████▊  | 1554/2000 [31:23<08:14,  1.11s/iteration, mean_rewards=-279]\u001b[A\n",
            "Training:  78%|███████▊  | 1555/2000 [31:24<08:09,  1.10s/iteration, mean_rewards=-279]\u001b[A\n",
            "Training:  78%|███████▊  | 1555/2000 [31:24<08:09,  1.10s/iteration, mean_rewards=-137]\u001b[A\n",
            "Training:  78%|███████▊  | 1556/2000 [31:24<07:32,  1.02s/iteration, mean_rewards=-137]\u001b[A\n",
            "Training:  78%|███████▊  | 1556/2000 [31:25<07:32,  1.02s/iteration, mean_rewards=-141]\u001b[A\n",
            "Training:  78%|███████▊  | 1557/2000 [31:25<06:46,  1.09iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  78%|███████▊  | 1557/2000 [31:25<06:46,  1.09iteration/s, mean_rewards=-217]\u001b[A\n",
            "Training:  78%|███████▊  | 1558/2000 [31:26<06:49,  1.08iteration/s, mean_rewards=-217]\u001b[A\n",
            "Training:  78%|███████▊  | 1558/2000 [31:26<06:49,  1.08iteration/s, mean_rewards=-229]\u001b[A\n",
            "Training:  78%|███████▊  | 1559/2000 [31:27<06:37,  1.11iteration/s, mean_rewards=-229]\u001b[A\n",
            "Training:  78%|███████▊  | 1559/2000 [31:27<06:37,  1.11iteration/s, mean_rewards=-396]\u001b[A\n",
            "Training:  78%|███████▊  | 1560/2000 [31:28<07:27,  1.02s/iteration, mean_rewards=-396]\u001b[A\n",
            "Training:  78%|███████▊  | 1560/2000 [31:29<07:27,  1.02s/iteration, mean_rewards=-206]\u001b[A\n",
            "Training:  78%|███████▊  | 1561/2000 [31:30<08:41,  1.19s/iteration, mean_rewards=-206]\u001b[A\n",
            "Training:  78%|███████▊  | 1561/2000 [31:30<08:41,  1.19s/iteration, mean_rewards=-164]\u001b[A\n",
            "Training:  78%|███████▊  | 1562/2000 [31:31<08:28,  1.16s/iteration, mean_rewards=-164]\u001b[A\n",
            "Training:  78%|███████▊  | 1562/2000 [31:31<08:28,  1.16s/iteration, mean_rewards=-153]\u001b[A\n",
            "Training:  78%|███████▊  | 1563/2000 [31:32<07:44,  1.06s/iteration, mean_rewards=-153]\u001b[A\n",
            "Training:  78%|███████▊  | 1563/2000 [31:32<07:44,  1.06s/iteration, mean_rewards=-335]\u001b[A\n",
            "Training:  78%|███████▊  | 1564/2000 [31:32<07:15,  1.00iteration/s, mean_rewards=-335]\u001b[A\n",
            "Training:  78%|███████▊  | 1564/2000 [31:33<07:15,  1.00iteration/s, mean_rewards=-328]\u001b[A\n",
            "Training:  78%|███████▊  | 1565/2000 [31:33<06:55,  1.05iteration/s, mean_rewards=-328]\u001b[A\n",
            "Training:  78%|███████▊  | 1565/2000 [31:34<06:55,  1.05iteration/s, mean_rewards=-384]\u001b[A\n",
            "Training:  78%|███████▊  | 1566/2000 [31:34<06:39,  1.09iteration/s, mean_rewards=-384]\u001b[A\n",
            "Training:  78%|███████▊  | 1566/2000 [31:35<06:39,  1.09iteration/s, mean_rewards=-54.7]\u001b[A\n",
            "Training:  78%|███████▊  | 1567/2000 [31:35<06:44,  1.07iteration/s, mean_rewards=-54.7]\u001b[A\n",
            "Training:  78%|███████▊  | 1567/2000 [31:36<06:44,  1.07iteration/s, mean_rewards=-108] \u001b[A\n",
            "Training:  78%|███████▊  | 1568/2000 [31:36<06:50,  1.05iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:  78%|███████▊  | 1568/2000 [31:37<06:50,  1.05iteration/s, mean_rewards=-204]\u001b[A\n",
            "Training:  78%|███████▊  | 1569/2000 [31:37<07:04,  1.02iteration/s, mean_rewards=-204]\u001b[A\n",
            "Training:  78%|███████▊  | 1569/2000 [31:38<07:04,  1.02iteration/s, mean_rewards=-208]\u001b[A\n",
            "Training:  78%|███████▊  | 1570/2000 [31:38<06:59,  1.02iteration/s, mean_rewards=-208]\u001b[A\n",
            "Training:  78%|███████▊  | 1570/2000 [31:39<06:59,  1.02iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  79%|███████▊  | 1571/2000 [31:39<07:05,  1.01iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  79%|███████▊  | 1571/2000 [31:39<07:05,  1.01iteration/s, mean_rewards=-283]\u001b[A\n",
            "Training:  79%|███████▊  | 1572/2000 [31:40<06:41,  1.07iteration/s, mean_rewards=-283]\u001b[A\n",
            "Training:  79%|███████▊  | 1572/2000 [31:40<06:41,  1.07iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  79%|███████▊  | 1573/2000 [31:41<06:51,  1.04iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  79%|███████▊  | 1573/2000 [31:41<06:51,  1.04iteration/s, mean_rewards=-208]\u001b[A\n",
            "Training:  79%|███████▊  | 1574/2000 [31:42<07:07,  1.00s/iteration, mean_rewards=-208]\u001b[A\n",
            "Training:  79%|███████▊  | 1574/2000 [31:42<07:07,  1.00s/iteration, mean_rewards=-72.3]\u001b[A\n",
            "Training:  79%|███████▉  | 1575/2000 [31:43<06:58,  1.02iteration/s, mean_rewards=-72.3]\u001b[A\n",
            "Training:  79%|███████▉  | 1575/2000 [31:44<06:58,  1.02iteration/s, mean_rewards=-347] \u001b[A\n",
            "Training:  79%|███████▉  | 1576/2000 [31:44<07:32,  1.07s/iteration, mean_rewards=-347]\u001b[A\n",
            "Training:  79%|███████▉  | 1576/2000 [31:45<07:32,  1.07s/iteration, mean_rewards=-92.1]\u001b[A\n",
            "Training:  79%|███████▉  | 1577/2000 [31:45<06:38,  1.06iteration/s, mean_rewards=-92.1]\u001b[A\n",
            "Training:  79%|███████▉  | 1577/2000 [31:45<06:38,  1.06iteration/s, mean_rewards=-233] \u001b[A\n",
            "Training:  79%|███████▉  | 1578/2000 [31:46<06:19,  1.11iteration/s, mean_rewards=-233]\u001b[A\n",
            "Training:  79%|███████▉  | 1578/2000 [31:46<06:19,  1.11iteration/s, mean_rewards=-234]\u001b[A\n",
            "Training:  79%|███████▉  | 1579/2000 [31:47<06:06,  1.15iteration/s, mean_rewards=-234]\u001b[A\n",
            "Training:  79%|███████▉  | 1579/2000 [31:47<06:06,  1.15iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  79%|███████▉  | 1580/2000 [31:47<06:02,  1.16iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  79%|███████▉  | 1580/2000 [31:48<06:02,  1.16iteration/s, mean_rewards=-188]\u001b[A\n",
            "Training:  79%|███████▉  | 1581/2000 [31:48<05:55,  1.18iteration/s, mean_rewards=-188]\u001b[A\n",
            "Training:  79%|███████▉  | 1581/2000 [31:49<05:55,  1.18iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  79%|███████▉  | 1582/2000 [31:49<05:54,  1.18iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  79%|███████▉  | 1582/2000 [31:49<05:54,  1.18iteration/s, mean_rewards=-364]\u001b[A\n",
            "Training:  79%|███████▉  | 1583/2000 [31:50<06:04,  1.14iteration/s, mean_rewards=-364]\u001b[A\n",
            "Training:  79%|███████▉  | 1583/2000 [31:50<06:04,  1.14iteration/s, mean_rewards=-239]\u001b[A\n",
            "Training:  79%|███████▉  | 1584/2000 [31:51<06:28,  1.07iteration/s, mean_rewards=-239]\u001b[A\n",
            "Training:  79%|███████▉  | 1584/2000 [31:51<06:28,  1.07iteration/s, mean_rewards=-287]\u001b[A\n",
            "Training:  79%|███████▉  | 1585/2000 [31:52<06:11,  1.12iteration/s, mean_rewards=-287]\u001b[A\n",
            "Training:  79%|███████▉  | 1585/2000 [31:52<06:11,  1.12iteration/s, mean_rewards=-91.1]\u001b[A\n",
            "Training:  79%|███████▉  | 1586/2000 [31:53<06:14,  1.11iteration/s, mean_rewards=-91.1]\u001b[A\n",
            "Training:  79%|███████▉  | 1586/2000 [31:53<06:14,  1.11iteration/s, mean_rewards=-251] \u001b[A\n",
            "Training:  79%|███████▉  | 1587/2000 [31:54<06:34,  1.05iteration/s, mean_rewards=-251]\u001b[A\n",
            "Training:  79%|███████▉  | 1587/2000 [31:54<06:34,  1.05iteration/s, mean_rewards=-297]\u001b[A\n",
            "Training:  79%|███████▉  | 1588/2000 [31:55<07:35,  1.11s/iteration, mean_rewards=-297]\u001b[A\n",
            "Training:  79%|███████▉  | 1588/2000 [31:56<07:35,  1.11s/iteration, mean_rewards=-79.1]\u001b[A\n",
            "Training:  79%|███████▉  | 1589/2000 [31:56<07:13,  1.05s/iteration, mean_rewards=-79.1]\u001b[A\n",
            "Training:  79%|███████▉  | 1589/2000 [31:57<07:13,  1.05s/iteration, mean_rewards=-109] \u001b[A\n",
            "Training:  80%|███████▉  | 1590/2000 [31:57<06:28,  1.06iteration/s, mean_rewards=-109]\u001b[A\n",
            "Training:  80%|███████▉  | 1590/2000 [31:57<06:28,  1.06iteration/s, mean_rewards=-109]\u001b[A\n",
            "Training:  80%|███████▉  | 1591/2000 [31:58<05:56,  1.15iteration/s, mean_rewards=-109]\u001b[A\n",
            "Training:  80%|███████▉  | 1591/2000 [31:58<05:56,  1.15iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  80%|███████▉  | 1592/2000 [31:59<05:58,  1.14iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  80%|███████▉  | 1592/2000 [31:59<05:58,  1.14iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  80%|███████▉  | 1593/2000 [31:59<06:04,  1.12iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  80%|███████▉  | 1593/2000 [32:00<06:04,  1.12iteration/s, mean_rewards=-67.3]\u001b[A\n",
            "Training:  80%|███████▉  | 1594/2000 [32:00<05:40,  1.19iteration/s, mean_rewards=-67.3]\u001b[A\n",
            "Training:  80%|███████▉  | 1594/2000 [32:01<05:40,  1.19iteration/s, mean_rewards=-69.6]\u001b[A\n",
            "Training:  80%|███████▉  | 1595/2000 [32:01<06:12,  1.09iteration/s, mean_rewards=-69.6]\u001b[A\n",
            "Training:  80%|███████▉  | 1595/2000 [32:02<06:12,  1.09iteration/s, mean_rewards=-107] \u001b[A\n",
            "Training:  80%|███████▉  | 1596/2000 [32:02<05:55,  1.14iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  80%|███████▉  | 1596/2000 [32:02<05:55,  1.14iteration/s, mean_rewards=-174]\u001b[A\n",
            "Training:  80%|███████▉  | 1597/2000 [32:03<05:47,  1.16iteration/s, mean_rewards=-174]\u001b[A\n",
            "Training:  80%|███████▉  | 1597/2000 [32:03<05:47,  1.16iteration/s, mean_rewards=-239]\u001b[A\n",
            "Training:  80%|███████▉  | 1598/2000 [32:04<05:55,  1.13iteration/s, mean_rewards=-239]\u001b[A\n",
            "Training:  80%|███████▉  | 1598/2000 [32:04<05:55,  1.13iteration/s, mean_rewards=-252]\u001b[A\n",
            "Training:  80%|███████▉  | 1599/2000 [32:05<05:45,  1.16iteration/s, mean_rewards=-252]\u001b[A\n",
            "Training:  80%|███████▉  | 1599/2000 [32:05<05:45,  1.16iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  80%|████████  | 1600/2000 [32:05<05:18,  1.25iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  80%|████████  | 1600/2000 [32:06<05:18,  1.25iteration/s, mean_rewards=-187]\u001b[A\n",
            "Training:  80%|████████  | 1601/2000 [32:06<05:04,  1.31iteration/s, mean_rewards=-187]\u001b[A\n",
            "Training:  80%|████████  | 1601/2000 [32:06<05:04,  1.31iteration/s, mean_rewards=-170]\u001b[A\n",
            "Training:  80%|████████  | 1602/2000 [32:07<06:03,  1.09iteration/s, mean_rewards=-170]\u001b[A\n",
            "Training:  80%|████████  | 1602/2000 [32:08<06:03,  1.09iteration/s, mean_rewards=-88] \u001b[A\n",
            "Training:  80%|████████  | 1603/2000 [32:09<06:57,  1.05s/iteration, mean_rewards=-88]\u001b[A\n",
            "Training:  80%|████████  | 1603/2000 [32:09<06:57,  1.05s/iteration, mean_rewards=-517]\u001b[A\n",
            "Training:  80%|████████  | 1604/2000 [32:10<07:31,  1.14s/iteration, mean_rewards=-517]\u001b[A\n",
            "Training:  80%|████████  | 1604/2000 [32:10<07:31,  1.14s/iteration, mean_rewards=-48.5]\u001b[A\n",
            "Training:  80%|████████  | 1605/2000 [32:11<06:47,  1.03s/iteration, mean_rewards=-48.5]\u001b[A\n",
            "Training:  80%|████████  | 1605/2000 [32:11<06:47,  1.03s/iteration, mean_rewards=-199] \u001b[A\n",
            "Training:  80%|████████  | 1606/2000 [32:12<06:17,  1.04iteration/s, mean_rewards=-199]\u001b[A\n",
            "Training:  80%|████████  | 1606/2000 [32:12<06:17,  1.04iteration/s, mean_rewards=-322]\u001b[A\n",
            "Training:  80%|████████  | 1607/2000 [32:12<06:14,  1.05iteration/s, mean_rewards=-322]\u001b[A\n",
            "Training:  80%|████████  | 1607/2000 [32:13<06:14,  1.05iteration/s, mean_rewards=-184]\u001b[A\n",
            "Training:  80%|████████  | 1608/2000 [32:13<05:58,  1.09iteration/s, mean_rewards=-184]\u001b[A\n",
            "Training:  80%|████████  | 1608/2000 [32:14<05:58,  1.09iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:  80%|████████  | 1609/2000 [32:14<05:46,  1.13iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:  80%|████████  | 1609/2000 [32:14<05:46,  1.13iteration/s, mean_rewards=-60.8]\u001b[A\n",
            "Training:  80%|████████  | 1610/2000 [32:15<05:17,  1.23iteration/s, mean_rewards=-60.8]\u001b[A\n",
            "Training:  80%|████████  | 1610/2000 [32:15<05:17,  1.23iteration/s, mean_rewards=-180] \u001b[A\n",
            "Training:  81%|████████  | 1611/2000 [32:16<05:17,  1.23iteration/s, mean_rewards=-180]\u001b[A\n",
            "Training:  81%|████████  | 1611/2000 [32:16<05:17,  1.23iteration/s, mean_rewards=-187]\u001b[A\n",
            "Training:  81%|████████  | 1612/2000 [32:16<05:21,  1.21iteration/s, mean_rewards=-187]\u001b[A\n",
            "Training:  81%|████████  | 1612/2000 [32:17<05:21,  1.21iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:  81%|████████  | 1613/2000 [32:17<05:21,  1.20iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:  81%|████████  | 1613/2000 [32:18<05:21,  1.20iteration/s, mean_rewards=-89.4]\u001b[A\n",
            "Training:  81%|████████  | 1614/2000 [32:18<05:31,  1.16iteration/s, mean_rewards=-89.4]\u001b[A\n",
            "Training:  81%|████████  | 1614/2000 [32:19<05:31,  1.16iteration/s, mean_rewards=-162] \u001b[A\n",
            "Training:  81%|████████  | 1615/2000 [32:19<05:24,  1.19iteration/s, mean_rewards=-162]\u001b[A\n",
            "Training:  81%|████████  | 1615/2000 [32:19<05:24,  1.19iteration/s, mean_rewards=-315]\u001b[A\n",
            "Training:  81%|████████  | 1616/2000 [32:20<05:37,  1.14iteration/s, mean_rewards=-315]\u001b[A\n",
            "Training:  81%|████████  | 1616/2000 [32:20<05:37,  1.14iteration/s, mean_rewards=-190]\u001b[A\n",
            "Training:  81%|████████  | 1617/2000 [32:21<06:37,  1.04s/iteration, mean_rewards=-190]\u001b[A\n",
            "Training:  81%|████████  | 1617/2000 [32:22<06:37,  1.04s/iteration, mean_rewards=-184]\u001b[A\n",
            "Training:  81%|████████  | 1618/2000 [32:22<06:28,  1.02s/iteration, mean_rewards=-184]\u001b[A\n",
            "Training:  81%|████████  | 1618/2000 [32:23<06:28,  1.02s/iteration, mean_rewards=-311]\u001b[A\n",
            "Training:  81%|████████  | 1619/2000 [32:23<06:21,  1.00s/iteration, mean_rewards=-311]\u001b[A\n",
            "Training:  81%|████████  | 1619/2000 [32:24<06:21,  1.00s/iteration, mean_rewards=-109]\u001b[A\n",
            "Training:  81%|████████  | 1620/2000 [32:24<06:01,  1.05iteration/s, mean_rewards=-109]\u001b[A\n",
            "Training:  81%|████████  | 1620/2000 [32:25<06:01,  1.05iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  81%|████████  | 1621/2000 [32:25<05:56,  1.06iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  81%|████████  | 1621/2000 [32:25<05:56,  1.06iteration/s, mean_rewards=-312]\u001b[A\n",
            "Training:  81%|████████  | 1622/2000 [32:26<05:56,  1.06iteration/s, mean_rewards=-312]\u001b[A\n",
            "Training:  81%|████████  | 1622/2000 [32:26<05:56,  1.06iteration/s, mean_rewards=-179]\u001b[A\n",
            "Training:  81%|████████  | 1623/2000 [32:27<06:22,  1.02s/iteration, mean_rewards=-179]\u001b[A\n",
            "Training:  81%|████████  | 1623/2000 [32:27<06:22,  1.02s/iteration, mean_rewards=-199]\u001b[A\n",
            "Training:  81%|████████  | 1624/2000 [32:28<05:56,  1.05iteration/s, mean_rewards=-199]\u001b[A\n",
            "Training:  81%|████████  | 1624/2000 [32:28<05:56,  1.05iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:  81%|████████▏ | 1625/2000 [32:29<05:35,  1.12iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:  81%|████████▏ | 1625/2000 [32:29<05:35,  1.12iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  81%|████████▏ | 1626/2000 [32:30<05:25,  1.15iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  81%|████████▏ | 1626/2000 [32:30<05:25,  1.15iteration/s, mean_rewards=-202]\u001b[A\n",
            "Training:  81%|████████▏ | 1627/2000 [32:30<05:17,  1.18iteration/s, mean_rewards=-202]\u001b[A\n",
            "Training:  81%|████████▏ | 1627/2000 [32:31<05:17,  1.18iteration/s, mean_rewards=-112]\u001b[A\n",
            "Training:  81%|████████▏ | 1628/2000 [32:31<05:11,  1.20iteration/s, mean_rewards=-112]\u001b[A\n",
            "Training:  81%|████████▏ | 1628/2000 [32:32<05:11,  1.20iteration/s, mean_rewards=-178]\u001b[A\n",
            "Training:  81%|████████▏ | 1629/2000 [32:32<05:06,  1.21iteration/s, mean_rewards=-178]\u001b[A\n",
            "Training:  81%|████████▏ | 1629/2000 [32:32<05:06,  1.21iteration/s, mean_rewards=-99.9]\u001b[A\n",
            "Training:  82%|████████▏ | 1630/2000 [32:33<05:18,  1.16iteration/s, mean_rewards=-99.9]\u001b[A\n",
            "Training:  82%|████████▏ | 1630/2000 [32:33<05:18,  1.16iteration/s, mean_rewards=-162] \u001b[A\n",
            "Training:  82%|████████▏ | 1631/2000 [32:34<05:22,  1.14iteration/s, mean_rewards=-162]\u001b[A\n",
            "Training:  82%|████████▏ | 1631/2000 [32:34<05:22,  1.14iteration/s, mean_rewards=-254]\u001b[A\n",
            "Training:  82%|████████▏ | 1632/2000 [32:35<05:50,  1.05iteration/s, mean_rewards=-254]\u001b[A\n",
            "Training:  82%|████████▏ | 1632/2000 [32:35<05:50,  1.05iteration/s, mean_rewards=-225]\u001b[A\n",
            "Training:  82%|████████▏ | 1633/2000 [32:36<05:46,  1.06iteration/s, mean_rewards=-225]\u001b[A\n",
            "Training:  82%|████████▏ | 1633/2000 [32:36<05:46,  1.06iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  82%|████████▏ | 1634/2000 [32:37<05:19,  1.15iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  82%|████████▏ | 1634/2000 [32:37<05:19,  1.15iteration/s, mean_rewards=-166]\u001b[A\n",
            "Training:  82%|████████▏ | 1635/2000 [32:37<05:13,  1.16iteration/s, mean_rewards=-166]\u001b[A\n",
            "Training:  82%|████████▏ | 1635/2000 [32:38<05:13,  1.16iteration/s, mean_rewards=-272]\u001b[A\n",
            "Training:  82%|████████▏ | 1636/2000 [32:38<05:24,  1.12iteration/s, mean_rewards=-272]\u001b[A\n",
            "Training:  82%|████████▏ | 1636/2000 [32:39<05:24,  1.12iteration/s, mean_rewards=-95.2]\u001b[A\n",
            "Training:  82%|████████▏ | 1637/2000 [32:39<05:31,  1.09iteration/s, mean_rewards=-95.2]\u001b[A\n",
            "Training:  82%|████████▏ | 1637/2000 [32:40<05:31,  1.09iteration/s, mean_rewards=-282] \u001b[A\n",
            "Training:  82%|████████▏ | 1638/2000 [32:40<05:31,  1.09iteration/s, mean_rewards=-282]\u001b[A\n",
            "Training:  82%|████████▏ | 1638/2000 [32:41<05:31,  1.09iteration/s, mean_rewards=-280]\u001b[A\n",
            "Training:  82%|████████▏ | 1639/2000 [32:41<05:21,  1.12iteration/s, mean_rewards=-280]\u001b[A\n",
            "Training:  82%|████████▏ | 1639/2000 [32:41<05:21,  1.12iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  82%|████████▏ | 1640/2000 [32:42<05:10,  1.16iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  82%|████████▏ | 1640/2000 [32:42<05:10,  1.16iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  82%|████████▏ | 1641/2000 [32:43<05:04,  1.18iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  82%|████████▏ | 1641/2000 [32:43<05:04,  1.18iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  82%|████████▏ | 1642/2000 [32:43<04:48,  1.24iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  82%|████████▏ | 1642/2000 [32:44<04:48,  1.24iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  82%|████████▏ | 1643/2000 [32:44<05:00,  1.19iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  82%|████████▏ | 1643/2000 [32:45<05:00,  1.19iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  82%|████████▏ | 1644/2000 [32:45<05:09,  1.15iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  82%|████████▏ | 1644/2000 [32:46<05:09,  1.15iteration/s, mean_rewards=-186]\u001b[A\n",
            "Training:  82%|████████▏ | 1645/2000 [32:46<05:28,  1.08iteration/s, mean_rewards=-186]\u001b[A\n",
            "Training:  82%|████████▏ | 1645/2000 [32:47<05:28,  1.08iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  82%|████████▏ | 1646/2000 [32:48<06:09,  1.04s/iteration, mean_rewards=-144]\u001b[A\n",
            "Training:  82%|████████▏ | 1646/2000 [32:48<06:09,  1.04s/iteration, mean_rewards=-153]\u001b[A\n",
            "Training:  82%|████████▏ | 1647/2000 [32:49<06:21,  1.08s/iteration, mean_rewards=-153]\u001b[A\n",
            "Training:  82%|████████▏ | 1647/2000 [32:49<06:21,  1.08s/iteration, mean_rewards=-424]\u001b[A\n",
            "Training:  82%|████████▏ | 1648/2000 [32:50<06:07,  1.04s/iteration, mean_rewards=-424]\u001b[A\n",
            "Training:  82%|████████▏ | 1648/2000 [32:50<06:07,  1.04s/iteration, mean_rewards=-295]\u001b[A\n",
            "Training:  82%|████████▏ | 1649/2000 [32:51<05:45,  1.02iteration/s, mean_rewards=-295]\u001b[A\n",
            "Training:  82%|████████▏ | 1649/2000 [32:51<05:45,  1.02iteration/s, mean_rewards=-289]\u001b[A\n",
            "Training:  82%|████████▎ | 1650/2000 [32:52<05:42,  1.02iteration/s, mean_rewards=-289]\u001b[A\n",
            "Training:  82%|████████▎ | 1650/2000 [32:52<05:42,  1.02iteration/s, mean_rewards=-177]\u001b[A\n",
            "Training:  83%|████████▎ | 1651/2000 [32:52<05:21,  1.08iteration/s, mean_rewards=-177]\u001b[A\n",
            "Training:  83%|████████▎ | 1651/2000 [32:53<05:21,  1.08iteration/s, mean_rewards=-112]\u001b[A\n",
            "Training:  83%|████████▎ | 1652/2000 [32:53<05:14,  1.11iteration/s, mean_rewards=-112]\u001b[A\n",
            "Training:  83%|████████▎ | 1652/2000 [32:54<05:14,  1.11iteration/s, mean_rewards=-104]\u001b[A\n",
            "Training:  83%|████████▎ | 1653/2000 [32:54<05:01,  1.15iteration/s, mean_rewards=-104]\u001b[A\n",
            "Training:  83%|████████▎ | 1653/2000 [32:54<05:01,  1.15iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:  83%|████████▎ | 1654/2000 [32:55<04:43,  1.22iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:  83%|████████▎ | 1654/2000 [32:55<04:43,  1.22iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  83%|████████▎ | 1655/2000 [32:56<05:22,  1.07iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  83%|████████▎ | 1655/2000 [32:56<05:22,  1.07iteration/s, mean_rewards=-334]\u001b[A\n",
            "Training:  83%|████████▎ | 1656/2000 [32:57<05:08,  1.11iteration/s, mean_rewards=-334]\u001b[A\n",
            "Training:  83%|████████▎ | 1656/2000 [32:57<05:08,  1.11iteration/s, mean_rewards=-101]\u001b[A\n",
            "Training:  83%|████████▎ | 1657/2000 [32:58<05:26,  1.05iteration/s, mean_rewards=-101]\u001b[A\n",
            "Training:  83%|████████▎ | 1657/2000 [32:58<05:26,  1.05iteration/s, mean_rewards=-199]\u001b[A\n",
            "Training:  83%|████████▎ | 1658/2000 [32:59<05:48,  1.02s/iteration, mean_rewards=-199]\u001b[A\n",
            "Training:  83%|████████▎ | 1658/2000 [32:59<05:48,  1.02s/iteration, mean_rewards=-154]\u001b[A\n",
            "Training:  83%|████████▎ | 1659/2000 [33:00<05:57,  1.05s/iteration, mean_rewards=-154]\u001b[A\n",
            "Training:  83%|████████▎ | 1659/2000 [33:01<05:57,  1.05s/iteration, mean_rewards=-169]\u001b[A\n",
            "Training:  83%|████████▎ | 1660/2000 [33:01<05:54,  1.04s/iteration, mean_rewards=-169]\u001b[A\n",
            "Training:  83%|████████▎ | 1660/2000 [33:02<05:54,  1.04s/iteration, mean_rewards=-113]\u001b[A\n",
            "Training:  83%|████████▎ | 1661/2000 [33:02<05:32,  1.02iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  83%|████████▎ | 1661/2000 [33:02<05:32,  1.02iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  83%|████████▎ | 1662/2000 [33:03<05:01,  1.12iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  83%|████████▎ | 1662/2000 [33:03<05:01,  1.12iteration/s, mean_rewards=-190]\u001b[A\n",
            "Training:  83%|████████▎ | 1663/2000 [33:03<04:35,  1.22iteration/s, mean_rewards=-190]\u001b[A\n",
            "Training:  83%|████████▎ | 1663/2000 [33:04<04:35,  1.22iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  83%|████████▎ | 1664/2000 [33:04<04:20,  1.29iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  83%|████████▎ | 1664/2000 [33:04<04:20,  1.29iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  83%|████████▎ | 1665/2000 [33:05<04:22,  1.27iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  83%|████████▎ | 1665/2000 [33:05<04:22,  1.27iteration/s, mean_rewards=-221]\u001b[A\n",
            "Training:  83%|████████▎ | 1666/2000 [33:06<04:52,  1.14iteration/s, mean_rewards=-221]\u001b[A\n",
            "Training:  83%|████████▎ | 1666/2000 [33:06<04:52,  1.14iteration/s, mean_rewards=-272]\u001b[A\n",
            "Training:  83%|████████▎ | 1667/2000 [33:07<04:47,  1.16iteration/s, mean_rewards=-272]\u001b[A\n",
            "Training:  83%|████████▎ | 1667/2000 [33:07<04:47,  1.16iteration/s, mean_rewards=-189]\u001b[A\n",
            "Training:  83%|████████▎ | 1668/2000 [33:08<05:03,  1.09iteration/s, mean_rewards=-189]\u001b[A\n",
            "Training:  83%|████████▎ | 1668/2000 [33:08<05:03,  1.09iteration/s, mean_rewards=-178]\u001b[A\n",
            "Training:  83%|████████▎ | 1669/2000 [33:09<04:56,  1.12iteration/s, mean_rewards=-178]\u001b[A\n",
            "Training:  83%|████████▎ | 1669/2000 [33:09<04:56,  1.12iteration/s, mean_rewards=-214]\u001b[A\n",
            "Training:  84%|████████▎ | 1670/2000 [33:10<05:14,  1.05iteration/s, mean_rewards=-214]\u001b[A\n",
            "Training:  84%|████████▎ | 1670/2000 [33:10<05:14,  1.05iteration/s, mean_rewards=-244]\u001b[A\n",
            "Training:  84%|████████▎ | 1671/2000 [33:11<04:58,  1.10iteration/s, mean_rewards=-244]\u001b[A\n",
            "Training:  84%|████████▎ | 1671/2000 [33:11<04:58,  1.10iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  84%|████████▎ | 1672/2000 [33:11<04:53,  1.12iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  84%|████████▎ | 1672/2000 [33:12<04:53,  1.12iteration/s, mean_rewards=-231]\u001b[A\n",
            "Training:  84%|████████▎ | 1673/2000 [33:13<05:33,  1.02s/iteration, mean_rewards=-231]\u001b[A\n",
            "Training:  84%|████████▎ | 1673/2000 [33:13<05:33,  1.02s/iteration, mean_rewards=-132]\u001b[A\n",
            "Training:  84%|████████▎ | 1674/2000 [33:14<05:42,  1.05s/iteration, mean_rewards=-132]\u001b[A\n",
            "Training:  84%|████████▎ | 1674/2000 [33:14<05:42,  1.05s/iteration, mean_rewards=-283]\u001b[A\n",
            "Training:  84%|████████▍ | 1675/2000 [33:15<05:17,  1.02iteration/s, mean_rewards=-283]\u001b[A\n",
            "Training:  84%|████████▍ | 1675/2000 [33:15<05:17,  1.02iteration/s, mean_rewards=-175]\u001b[A\n",
            "Training:  84%|████████▍ | 1676/2000 [33:16<05:11,  1.04iteration/s, mean_rewards=-175]\u001b[A\n",
            "Training:  84%|████████▍ | 1676/2000 [33:16<05:11,  1.04iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:  84%|████████▍ | 1677/2000 [33:16<04:55,  1.09iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:  84%|████████▍ | 1677/2000 [33:17<04:55,  1.09iteration/s, mean_rewards=-271]\u001b[A\n",
            "Training:  84%|████████▍ | 1678/2000 [33:17<04:53,  1.10iteration/s, mean_rewards=-271]\u001b[A\n",
            "Training:  84%|████████▍ | 1678/2000 [33:18<04:53,  1.10iteration/s, mean_rewards=-211]\u001b[A\n",
            "Training:  84%|████████▍ | 1679/2000 [33:18<04:55,  1.09iteration/s, mean_rewards=-211]\u001b[A\n",
            "Training:  84%|████████▍ | 1679/2000 [33:19<04:55,  1.09iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  84%|████████▍ | 1680/2000 [33:19<04:44,  1.12iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  84%|████████▍ | 1680/2000 [33:19<04:44,  1.12iteration/s, mean_rewards=-206]\u001b[A\n",
            "Training:  84%|████████▍ | 1681/2000 [33:20<04:35,  1.16iteration/s, mean_rewards=-206]\u001b[A\n",
            "Training:  84%|████████▍ | 1681/2000 [33:20<04:35,  1.16iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  84%|████████▍ | 1682/2000 [33:21<05:09,  1.03iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  84%|████████▍ | 1682/2000 [33:21<05:09,  1.03iteration/s, mean_rewards=-86.9]\u001b[A\n",
            "Training:  84%|████████▍ | 1683/2000 [33:22<04:51,  1.09iteration/s, mean_rewards=-86.9]\u001b[A\n",
            "Training:  84%|████████▍ | 1683/2000 [33:22<04:51,  1.09iteration/s, mean_rewards=-160] \u001b[A\n",
            "Training:  84%|████████▍ | 1684/2000 [33:23<04:27,  1.18iteration/s, mean_rewards=-160]\u001b[A\n",
            "Training:  84%|████████▍ | 1684/2000 [33:23<04:27,  1.18iteration/s, mean_rewards=-240]\u001b[A\n",
            "Training:  84%|████████▍ | 1685/2000 [33:24<04:46,  1.10iteration/s, mean_rewards=-240]\u001b[A\n",
            "Training:  84%|████████▍ | 1685/2000 [33:24<04:46,  1.10iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  84%|████████▍ | 1686/2000 [33:25<04:59,  1.05iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  84%|████████▍ | 1686/2000 [33:25<04:59,  1.05iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  84%|████████▍ | 1687/2000 [33:26<05:34,  1.07s/iteration, mean_rewards=-121]\u001b[A\n",
            "Training:  84%|████████▍ | 1687/2000 [33:26<05:34,  1.07s/iteration, mean_rewards=-224]\u001b[A\n",
            "Training:  84%|████████▍ | 1688/2000 [33:27<05:18,  1.02s/iteration, mean_rewards=-224]\u001b[A\n",
            "Training:  84%|████████▍ | 1688/2000 [33:27<05:18,  1.02s/iteration, mean_rewards=-132]\u001b[A\n",
            "Training:  84%|████████▍ | 1689/2000 [33:28<05:21,  1.03s/iteration, mean_rewards=-132]\u001b[A\n",
            "Training:  84%|████████▍ | 1689/2000 [33:28<05:21,  1.03s/iteration, mean_rewards=-114]\u001b[A\n",
            "Training:  84%|████████▍ | 1690/2000 [33:29<05:09,  1.00iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  84%|████████▍ | 1690/2000 [33:29<05:09,  1.00iteration/s, mean_rewards=-234]\u001b[A\n",
            "Training:  85%|████████▍ | 1691/2000 [33:30<04:51,  1.06iteration/s, mean_rewards=-234]\u001b[A\n",
            "Training:  85%|████████▍ | 1691/2000 [33:30<04:51,  1.06iteration/s, mean_rewards=-413]\u001b[A\n",
            "Training:  85%|████████▍ | 1692/2000 [33:31<04:43,  1.09iteration/s, mean_rewards=-413]\u001b[A\n",
            "Training:  85%|████████▍ | 1692/2000 [33:31<04:43,  1.09iteration/s, mean_rewards=-223]\u001b[A\n",
            "Training:  85%|████████▍ | 1693/2000 [33:32<04:56,  1.03iteration/s, mean_rewards=-223]\u001b[A\n",
            "Training:  85%|████████▍ | 1693/2000 [33:32<04:56,  1.03iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  85%|████████▍ | 1694/2000 [33:32<04:43,  1.08iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  85%|████████▍ | 1694/2000 [33:33<04:43,  1.08iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:  85%|████████▍ | 1695/2000 [33:33<04:31,  1.12iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:  85%|████████▍ | 1695/2000 [33:34<04:31,  1.12iteration/s, mean_rewards=-97.6]\u001b[A\n",
            "Training:  85%|████████▍ | 1696/2000 [33:34<04:11,  1.21iteration/s, mean_rewards=-97.6]\u001b[A\n",
            "Training:  85%|████████▍ | 1696/2000 [33:34<04:11,  1.21iteration/s, mean_rewards=-185] \u001b[A\n",
            "Training:  85%|████████▍ | 1697/2000 [33:35<04:33,  1.11iteration/s, mean_rewards=-185]\u001b[A\n",
            "Training:  85%|████████▍ | 1697/2000 [33:35<04:33,  1.11iteration/s, mean_rewards=-292]\u001b[A\n",
            "Training:  85%|████████▍ | 1698/2000 [33:36<04:25,  1.14iteration/s, mean_rewards=-292]\u001b[A\n",
            "Training:  85%|████████▍ | 1698/2000 [33:36<04:25,  1.14iteration/s, mean_rewards=-253]\u001b[A\n",
            "Training:  85%|████████▍ | 1699/2000 [33:37<04:20,  1.15iteration/s, mean_rewards=-253]\u001b[A\n",
            "Training:  85%|████████▍ | 1699/2000 [33:37<04:20,  1.15iteration/s, mean_rewards=-219]\u001b[A\n",
            "Training:  85%|████████▌ | 1700/2000 [33:38<05:32,  1.11s/iteration, mean_rewards=-219]\u001b[A\n",
            "Training:  85%|████████▌ | 1700/2000 [33:39<05:32,  1.11s/iteration, mean_rewards=-144]\u001b[A\n",
            "Training:  85%|████████▌ | 1701/2000 [33:40<05:43,  1.15s/iteration, mean_rewards=-144]\u001b[A\n",
            "Training:  85%|████████▌ | 1701/2000 [33:40<05:43,  1.15s/iteration, mean_rewards=-178]\u001b[A\n",
            "Training:  85%|████████▌ | 1702/2000 [33:41<06:08,  1.24s/iteration, mean_rewards=-178]\u001b[A\n",
            "Training:  85%|████████▌ | 1702/2000 [33:41<06:08,  1.24s/iteration, mean_rewards=-118]\u001b[A\n",
            "Training:  85%|████████▌ | 1703/2000 [33:42<05:08,  1.04s/iteration, mean_rewards=-118]\u001b[A\n",
            "Training:  85%|████████▌ | 1703/2000 [33:42<05:08,  1.04s/iteration, mean_rewards=-149]\u001b[A\n",
            "Training:  85%|████████▌ | 1704/2000 [33:42<04:49,  1.02iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  85%|████████▌ | 1704/2000 [33:43<04:49,  1.02iteration/s, mean_rewards=-73.2]\u001b[A\n",
            "Training:  85%|████████▌ | 1705/2000 [33:43<04:31,  1.09iteration/s, mean_rewards=-73.2]\u001b[A\n",
            "Training:  85%|████████▌ | 1705/2000 [33:44<04:31,  1.09iteration/s, mean_rewards=-86.8]\u001b[A\n",
            "Training:  85%|████████▌ | 1706/2000 [33:44<04:23,  1.12iteration/s, mean_rewards=-86.8]\u001b[A\n",
            "Training:  85%|████████▌ | 1706/2000 [33:44<04:23,  1.12iteration/s, mean_rewards=-244] \u001b[A\n",
            "Training:  85%|████████▌ | 1707/2000 [33:45<04:17,  1.14iteration/s, mean_rewards=-244]\u001b[A\n",
            "Training:  85%|████████▌ | 1707/2000 [33:45<04:17,  1.14iteration/s, mean_rewards=-226]\u001b[A\n",
            "Training:  85%|████████▌ | 1708/2000 [33:46<03:59,  1.22iteration/s, mean_rewards=-226]\u001b[A\n",
            "Training:  85%|████████▌ | 1708/2000 [33:46<03:59,  1.22iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  85%|████████▌ | 1709/2000 [33:47<04:08,  1.17iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  85%|████████▌ | 1709/2000 [33:47<04:08,  1.17iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  86%|████████▌ | 1710/2000 [33:47<03:43,  1.30iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  86%|████████▌ | 1710/2000 [33:47<03:43,  1.30iteration/s, mean_rewards=-69.8]\u001b[A\n",
            "Training:  86%|████████▌ | 1711/2000 [33:48<03:32,  1.36iteration/s, mean_rewards=-69.8]\u001b[A\n",
            "Training:  86%|████████▌ | 1711/2000 [33:48<03:32,  1.36iteration/s, mean_rewards=-261] \u001b[A\n",
            "Training:  86%|████████▌ | 1712/2000 [33:49<03:55,  1.23iteration/s, mean_rewards=-261]\u001b[A\n",
            "Training:  86%|████████▌ | 1712/2000 [33:49<03:55,  1.23iteration/s, mean_rewards=-64.6]\u001b[A\n",
            "Training:  86%|████████▌ | 1713/2000 [33:50<03:56,  1.22iteration/s, mean_rewards=-64.6]\u001b[A\n",
            "Training:  86%|████████▌ | 1713/2000 [33:50<03:56,  1.22iteration/s, mean_rewards=-138] \u001b[A\n",
            "Training:  86%|████████▌ | 1714/2000 [33:51<04:18,  1.11iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:  86%|████████▌ | 1714/2000 [33:51<04:18,  1.11iteration/s, mean_rewards=-420]\u001b[A\n",
            "Training:  86%|████████▌ | 1715/2000 [33:53<05:42,  1.20s/iteration, mean_rewards=-420]\u001b[A\n",
            "Training:  86%|████████▌ | 1715/2000 [33:53<05:42,  1.20s/iteration, mean_rewards=-147]\u001b[A\n",
            "Training:  86%|████████▌ | 1716/2000 [33:53<05:12,  1.10s/iteration, mean_rewards=-147]\u001b[A\n",
            "Training:  86%|████████▌ | 1716/2000 [33:54<05:12,  1.10s/iteration, mean_rewards=-166]\u001b[A\n",
            "Training:  86%|████████▌ | 1717/2000 [33:54<04:45,  1.01s/iteration, mean_rewards=-166]\u001b[A\n",
            "Training:  86%|████████▌ | 1717/2000 [33:55<04:45,  1.01s/iteration, mean_rewards=-281]\u001b[A\n",
            "Training:  86%|████████▌ | 1718/2000 [33:55<04:41,  1.00iteration/s, mean_rewards=-281]\u001b[A\n",
            "Training:  86%|████████▌ | 1718/2000 [33:55<04:41,  1.00iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:  86%|████████▌ | 1719/2000 [33:56<04:15,  1.10iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:  86%|████████▌ | 1719/2000 [33:56<04:15,  1.10iteration/s, mean_rewards=-217]\u001b[A\n",
            "Training:  86%|████████▌ | 1720/2000 [33:57<04:17,  1.09iteration/s, mean_rewards=-217]\u001b[A\n",
            "Training:  86%|████████▌ | 1720/2000 [33:57<04:17,  1.09iteration/s, mean_rewards=-220]\u001b[A\n",
            "Training:  86%|████████▌ | 1721/2000 [33:58<04:08,  1.12iteration/s, mean_rewards=-220]\u001b[A\n",
            "Training:  86%|████████▌ | 1721/2000 [33:58<04:08,  1.12iteration/s, mean_rewards=-383]\u001b[A\n",
            "Training:  86%|████████▌ | 1722/2000 [33:59<04:35,  1.01iteration/s, mean_rewards=-383]\u001b[A\n",
            "Training:  86%|████████▌ | 1722/2000 [33:59<04:35,  1.01iteration/s, mean_rewards=-109]\u001b[A\n",
            "Training:  86%|████████▌ | 1723/2000 [34:00<04:19,  1.07iteration/s, mean_rewards=-109]\u001b[A\n",
            "Training:  86%|████████▌ | 1723/2000 [34:00<04:19,  1.07iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  86%|████████▌ | 1724/2000 [34:01<04:17,  1.07iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  86%|████████▌ | 1724/2000 [34:01<04:17,  1.07iteration/s, mean_rewards=-97.5]\u001b[A\n",
            "Training:  86%|████████▋ | 1725/2000 [34:02<04:27,  1.03iteration/s, mean_rewards=-97.5]\u001b[A\n",
            "Training:  86%|████████▋ | 1725/2000 [34:02<04:27,  1.03iteration/s, mean_rewards=-187] \u001b[A\n",
            "Training:  86%|████████▋ | 1726/2000 [34:03<04:40,  1.02s/iteration, mean_rewards=-187]\u001b[A\n",
            "Training:  86%|████████▋ | 1726/2000 [34:03<04:40,  1.02s/iteration, mean_rewards=-116]\u001b[A\n",
            "Training:  86%|████████▋ | 1727/2000 [34:04<04:28,  1.02iteration/s, mean_rewards=-116]\u001b[A\n",
            "Training:  86%|████████▋ | 1727/2000 [34:04<04:28,  1.02iteration/s, mean_rewards=-313]\u001b[A\n",
            "Training:  86%|████████▋ | 1728/2000 [34:05<04:56,  1.09s/iteration, mean_rewards=-313]\u001b[A\n",
            "Training:  86%|████████▋ | 1728/2000 [34:05<04:56,  1.09s/iteration, mean_rewards=-96] \u001b[A\n",
            "Training:  86%|████████▋ | 1729/2000 [34:06<04:32,  1.00s/iteration, mean_rewards=-96]\u001b[A\n",
            "Training:  86%|████████▋ | 1729/2000 [34:06<04:32,  1.00s/iteration, mean_rewards=-60.7]\u001b[A\n",
            "Training:  86%|████████▋ | 1730/2000 [34:07<04:19,  1.04iteration/s, mean_rewards=-60.7]\u001b[A\n",
            "Training:  86%|████████▋ | 1730/2000 [34:07<04:19,  1.04iteration/s, mean_rewards=-192] \u001b[A\n",
            "Training:  87%|████████▋ | 1731/2000 [34:08<04:07,  1.08iteration/s, mean_rewards=-192]\u001b[A\n",
            "Training:  87%|████████▋ | 1731/2000 [34:08<04:07,  1.08iteration/s, mean_rewards=-95.4]\u001b[A\n",
            "Training:  87%|████████▋ | 1732/2000 [34:09<04:18,  1.04iteration/s, mean_rewards=-95.4]\u001b[A\n",
            "Training:  87%|████████▋ | 1732/2000 [34:09<04:18,  1.04iteration/s, mean_rewards=-331] \u001b[A\n",
            "Training:  87%|████████▋ | 1733/2000 [34:09<04:08,  1.08iteration/s, mean_rewards=-331]\u001b[A\n",
            "Training:  87%|████████▋ | 1733/2000 [34:10<04:08,  1.08iteration/s, mean_rewards=-176]\u001b[A\n",
            "Training:  87%|████████▋ | 1734/2000 [34:10<03:59,  1.11iteration/s, mean_rewards=-176]\u001b[A\n",
            "Training:  87%|████████▋ | 1734/2000 [34:11<03:59,  1.11iteration/s, mean_rewards=-26.3]\u001b[A\n",
            "Training:  87%|████████▋ | 1735/2000 [34:11<03:50,  1.15iteration/s, mean_rewards=-26.3]\u001b[A\n",
            "Training:  87%|████████▋ | 1735/2000 [34:12<03:50,  1.15iteration/s, mean_rewards=-301] \u001b[A\n",
            "Training:  87%|████████▋ | 1736/2000 [34:12<04:07,  1.07iteration/s, mean_rewards=-301]\u001b[A\n",
            "Training:  87%|████████▋ | 1736/2000 [34:13<04:07,  1.07iteration/s, mean_rewards=-220]\u001b[A\n",
            "Training:  87%|████████▋ | 1737/2000 [34:13<03:56,  1.11iteration/s, mean_rewards=-220]\u001b[A\n",
            "Training:  87%|████████▋ | 1737/2000 [34:13<03:56,  1.11iteration/s, mean_rewards=-164]\u001b[A\n",
            "Training:  87%|████████▋ | 1738/2000 [34:14<04:00,  1.09iteration/s, mean_rewards=-164]\u001b[A\n",
            "Training:  87%|████████▋ | 1738/2000 [34:14<04:00,  1.09iteration/s, mean_rewards=-93.3]\u001b[A\n",
            "Training:  87%|████████▋ | 1739/2000 [34:15<03:42,  1.18iteration/s, mean_rewards=-93.3]\u001b[A\n",
            "Training:  87%|████████▋ | 1739/2000 [34:15<03:42,  1.18iteration/s, mean_rewards=-315] \u001b[A\n",
            "Training:  87%|████████▋ | 1740/2000 [34:16<04:08,  1.05iteration/s, mean_rewards=-315]\u001b[A\n",
            "Training:  87%|████████▋ | 1740/2000 [34:16<04:08,  1.05iteration/s, mean_rewards=-184]\u001b[A\n",
            "Training:  87%|████████▋ | 1741/2000 [34:17<04:40,  1.08s/iteration, mean_rewards=-184]\u001b[A\n",
            "Training:  87%|████████▋ | 1741/2000 [34:18<04:40,  1.08s/iteration, mean_rewards=-125]\u001b[A\n",
            "Training:  87%|████████▋ | 1742/2000 [34:19<04:54,  1.14s/iteration, mean_rewards=-125]\u001b[A\n",
            "Training:  87%|████████▋ | 1742/2000 [34:19<04:54,  1.14s/iteration, mean_rewards=-241]\u001b[A\n",
            "Training:  87%|████████▋ | 1743/2000 [34:19<04:36,  1.08s/iteration, mean_rewards=-241]\u001b[A\n",
            "Training:  87%|████████▋ | 1743/2000 [34:20<04:36,  1.08s/iteration, mean_rewards=-80.5]\u001b[A\n",
            "Training:  87%|████████▋ | 1744/2000 [34:20<04:26,  1.04s/iteration, mean_rewards=-80.5]\u001b[A\n",
            "Training:  87%|████████▋ | 1744/2000 [34:21<04:26,  1.04s/iteration, mean_rewards=-199] \u001b[A\n",
            "Training:  87%|████████▋ | 1745/2000 [34:21<04:26,  1.05s/iteration, mean_rewards=-199]\u001b[A\n",
            "Training:  87%|████████▋ | 1745/2000 [34:22<04:26,  1.05s/iteration, mean_rewards=-260]\u001b[A\n",
            "Training:  87%|████████▋ | 1746/2000 [34:22<04:10,  1.02iteration/s, mean_rewards=-260]\u001b[A\n",
            "Training:  87%|████████▋ | 1746/2000 [34:23<04:10,  1.02iteration/s, mean_rewards=-183]\u001b[A\n",
            "Training:  87%|████████▋ | 1747/2000 [34:23<04:06,  1.03iteration/s, mean_rewards=-183]\u001b[A\n",
            "Training:  87%|████████▋ | 1747/2000 [34:24<04:06,  1.03iteration/s, mean_rewards=-170]\u001b[A\n",
            "Training:  87%|████████▋ | 1748/2000 [34:24<04:01,  1.04iteration/s, mean_rewards=-170]\u001b[A\n",
            "Training:  87%|████████▋ | 1748/2000 [34:25<04:01,  1.04iteration/s, mean_rewards=-267]\u001b[A\n",
            "Training:  87%|████████▋ | 1749/2000 [34:25<03:49,  1.09iteration/s, mean_rewards=-267]\u001b[A\n",
            "Training:  87%|████████▋ | 1749/2000 [34:25<03:49,  1.09iteration/s, mean_rewards=-177]\u001b[A\n",
            "Training:  88%|████████▊ | 1750/2000 [34:26<03:53,  1.07iteration/s, mean_rewards=-177]\u001b[A\n",
            "Training:  88%|████████▊ | 1750/2000 [34:26<03:53,  1.07iteration/s, mean_rewards=-174]\u001b[A\n",
            "Training:  88%|████████▊ | 1751/2000 [34:27<03:52,  1.07iteration/s, mean_rewards=-174]\u001b[A\n",
            "Training:  88%|████████▊ | 1751/2000 [34:27<03:52,  1.07iteration/s, mean_rewards=-189]\u001b[A\n",
            "Training:  88%|████████▊ | 1752/2000 [34:28<03:41,  1.12iteration/s, mean_rewards=-189]\u001b[A\n",
            "Training:  88%|████████▊ | 1752/2000 [34:28<03:41,  1.12iteration/s, mean_rewards=-187]\u001b[A\n",
            "Training:  88%|████████▊ | 1753/2000 [34:28<03:26,  1.20iteration/s, mean_rewards=-187]\u001b[A\n",
            "Training:  88%|████████▊ | 1753/2000 [34:29<03:26,  1.20iteration/s, mean_rewards=-278]\u001b[A\n",
            "Training:  88%|████████▊ | 1754/2000 [34:29<03:34,  1.15iteration/s, mean_rewards=-278]\u001b[A\n",
            "Training:  88%|████████▊ | 1754/2000 [34:30<03:34,  1.15iteration/s, mean_rewards=-212]\u001b[A\n",
            "Training:  88%|████████▊ | 1755/2000 [34:31<04:07,  1.01s/iteration, mean_rewards=-212]\u001b[A\n",
            "Training:  88%|████████▊ | 1755/2000 [34:31<04:07,  1.01s/iteration, mean_rewards=-122]\u001b[A\n",
            "Training:  88%|████████▊ | 1756/2000 [34:32<04:23,  1.08s/iteration, mean_rewards=-122]\u001b[A\n",
            "Training:  88%|████████▊ | 1756/2000 [34:32<04:23,  1.08s/iteration, mean_rewards=-132]\u001b[A\n",
            "Training:  88%|████████▊ | 1757/2000 [34:33<04:04,  1.01s/iteration, mean_rewards=-132]\u001b[A\n",
            "Training:  88%|████████▊ | 1757/2000 [34:33<04:04,  1.01s/iteration, mean_rewards=-134]\u001b[A\n",
            "Training:  88%|████████▊ | 1758/2000 [34:34<04:00,  1.01iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  88%|████████▊ | 1758/2000 [34:34<04:00,  1.01iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  88%|████████▊ | 1759/2000 [34:35<03:50,  1.05iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  88%|████████▊ | 1759/2000 [34:35<03:50,  1.05iteration/s, mean_rewards=-361]\u001b[A\n",
            "Training:  88%|████████▊ | 1760/2000 [34:35<03:40,  1.09iteration/s, mean_rewards=-361]\u001b[A\n",
            "Training:  88%|████████▊ | 1760/2000 [34:36<03:40,  1.09iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  88%|████████▊ | 1761/2000 [34:36<03:22,  1.18iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  88%|████████▊ | 1761/2000 [34:37<03:22,  1.18iteration/s, mean_rewards=-316]\u001b[A\n",
            "Training:  88%|████████▊ | 1762/2000 [34:37<03:31,  1.12iteration/s, mean_rewards=-316]\u001b[A\n",
            "Training:  88%|████████▊ | 1762/2000 [34:38<03:31,  1.12iteration/s, mean_rewards=-273]\u001b[A\n",
            "Training:  88%|████████▊ | 1763/2000 [34:38<03:39,  1.08iteration/s, mean_rewards=-273]\u001b[A\n",
            "Training:  88%|████████▊ | 1763/2000 [34:39<03:39,  1.08iteration/s, mean_rewards=-183]\u001b[A\n",
            "Training:  88%|████████▊ | 1764/2000 [34:39<03:39,  1.07iteration/s, mean_rewards=-183]\u001b[A\n",
            "Training:  88%|████████▊ | 1764/2000 [34:39<03:39,  1.07iteration/s, mean_rewards=-187]\u001b[A\n",
            "Training:  88%|████████▊ | 1765/2000 [34:40<03:33,  1.10iteration/s, mean_rewards=-187]\u001b[A\n",
            "Training:  88%|████████▊ | 1765/2000 [34:40<03:33,  1.10iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  88%|████████▊ | 1766/2000 [34:41<03:33,  1.09iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  88%|████████▊ | 1766/2000 [34:41<03:33,  1.09iteration/s, mean_rewards=-233]\u001b[A\n",
            "Training:  88%|████████▊ | 1767/2000 [34:42<03:31,  1.10iteration/s, mean_rewards=-233]\u001b[A\n",
            "Training:  88%|████████▊ | 1767/2000 [34:42<03:31,  1.10iteration/s, mean_rewards=-164]\u001b[A\n",
            "Training:  88%|████████▊ | 1768/2000 [34:43<03:39,  1.06iteration/s, mean_rewards=-164]\u001b[A\n",
            "Training:  88%|████████▊ | 1768/2000 [34:43<03:39,  1.06iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  88%|████████▊ | 1769/2000 [34:44<03:55,  1.02s/iteration, mean_rewards=-134]\u001b[A\n",
            "Training:  88%|████████▊ | 1769/2000 [34:44<03:55,  1.02s/iteration, mean_rewards=-101]\u001b[A\n",
            "Training:  88%|████████▊ | 1770/2000 [34:45<03:34,  1.07iteration/s, mean_rewards=-101]\u001b[A\n",
            "Training:  88%|████████▊ | 1770/2000 [34:45<03:34,  1.07iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  89%|████████▊ | 1771/2000 [34:45<03:24,  1.12iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  89%|████████▊ | 1771/2000 [34:46<03:24,  1.12iteration/s, mean_rewards=-277]\u001b[A\n",
            "Training:  89%|████████▊ | 1772/2000 [34:46<03:10,  1.20iteration/s, mean_rewards=-277]\u001b[A\n",
            "Training:  89%|████████▊ | 1772/2000 [34:46<03:10,  1.20iteration/s, mean_rewards=-157]\u001b[A\n",
            "Training:  89%|████████▊ | 1773/2000 [34:47<02:59,  1.27iteration/s, mean_rewards=-157]\u001b[A\n",
            "Training:  89%|████████▊ | 1773/2000 [34:47<02:59,  1.27iteration/s, mean_rewards=-328]\u001b[A\n",
            "Training:  89%|████████▊ | 1774/2000 [34:48<03:07,  1.21iteration/s, mean_rewards=-328]\u001b[A\n",
            "Training:  89%|████████▊ | 1774/2000 [34:48<03:07,  1.21iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  89%|████████▉ | 1775/2000 [34:49<03:03,  1.23iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  89%|████████▉ | 1775/2000 [34:49<03:03,  1.23iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:  89%|████████▉ | 1776/2000 [34:49<03:01,  1.23iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:  89%|████████▉ | 1776/2000 [34:50<03:01,  1.23iteration/s, mean_rewards=7.86]\u001b[A\n",
            "Training:  89%|████████▉ | 1777/2000 [34:50<03:09,  1.18iteration/s, mean_rewards=7.86]\u001b[A\n",
            "Training:  89%|████████▉ | 1777/2000 [34:51<03:09,  1.18iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  89%|████████▉ | 1778/2000 [34:51<02:58,  1.25iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  89%|████████▉ | 1778/2000 [34:51<02:58,  1.25iteration/s, mean_rewards=-152]\u001b[A\n",
            "Training:  89%|████████▉ | 1779/2000 [34:52<03:08,  1.17iteration/s, mean_rewards=-152]\u001b[A\n",
            "Training:  89%|████████▉ | 1779/2000 [34:52<03:08,  1.17iteration/s, mean_rewards=-25.5]\u001b[A\n",
            "Training:  89%|████████▉ | 1780/2000 [34:53<03:13,  1.13iteration/s, mean_rewards=-25.5]\u001b[A\n",
            "Training:  89%|████████▉ | 1780/2000 [34:53<03:13,  1.13iteration/s, mean_rewards=-251] \u001b[A\n",
            "Training:  89%|████████▉ | 1781/2000 [34:54<03:15,  1.12iteration/s, mean_rewards=-251]\u001b[A\n",
            "Training:  89%|████████▉ | 1781/2000 [34:54<03:15,  1.12iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:  89%|████████▉ | 1782/2000 [34:55<03:46,  1.04s/iteration, mean_rewards=-139]\u001b[A\n",
            "Training:  89%|████████▉ | 1782/2000 [34:56<03:46,  1.04s/iteration, mean_rewards=-22.6]\u001b[A\n",
            "Training:  89%|████████▉ | 1783/2000 [34:56<03:53,  1.08s/iteration, mean_rewards=-22.6]\u001b[A\n",
            "Training:  89%|████████▉ | 1783/2000 [34:57<03:53,  1.08s/iteration, mean_rewards=-125] \u001b[A\n",
            "Training:  89%|████████▉ | 1784/2000 [34:57<03:33,  1.01iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  89%|████████▉ | 1784/2000 [34:58<03:33,  1.01iteration/s, mean_rewards=-292]\u001b[A\n",
            "Training:  89%|████████▉ | 1785/2000 [34:58<03:28,  1.03iteration/s, mean_rewards=-292]\u001b[A\n",
            "Training:  89%|████████▉ | 1785/2000 [34:58<03:28,  1.03iteration/s, mean_rewards=-248]\u001b[A\n",
            "Training:  89%|████████▉ | 1786/2000 [34:59<03:15,  1.09iteration/s, mean_rewards=-248]\u001b[A\n",
            "Training:  89%|████████▉ | 1786/2000 [34:59<03:15,  1.09iteration/s, mean_rewards=-333]\u001b[A\n",
            "Training:  89%|████████▉ | 1787/2000 [35:00<03:22,  1.05iteration/s, mean_rewards=-333]\u001b[A\n",
            "Training:  89%|████████▉ | 1787/2000 [35:00<03:22,  1.05iteration/s, mean_rewards=-198]\u001b[A\n",
            "Training:  89%|████████▉ | 1788/2000 [35:01<03:27,  1.02iteration/s, mean_rewards=-198]\u001b[A\n",
            "Training:  89%|████████▉ | 1788/2000 [35:01<03:27,  1.02iteration/s, mean_rewards=-49] \u001b[A\n",
            "Training:  89%|████████▉ | 1789/2000 [35:02<03:30,  1.00iteration/s, mean_rewards=-49]\u001b[A\n",
            "Training:  89%|████████▉ | 1789/2000 [35:02<03:30,  1.00iteration/s, mean_rewards=-216]\u001b[A\n",
            "Training:  90%|████████▉ | 1790/2000 [35:03<03:18,  1.06iteration/s, mean_rewards=-216]\u001b[A\n",
            "Training:  90%|████████▉ | 1790/2000 [35:03<03:18,  1.06iteration/s, mean_rewards=-212]\u001b[A\n",
            "Training:  90%|████████▉ | 1791/2000 [35:04<03:18,  1.05iteration/s, mean_rewards=-212]\u001b[A\n",
            "Training:  90%|████████▉ | 1791/2000 [35:04<03:18,  1.05iteration/s, mean_rewards=-234]\u001b[A\n",
            "Training:  90%|████████▉ | 1792/2000 [35:05<03:10,  1.09iteration/s, mean_rewards=-234]\u001b[A\n",
            "Training:  90%|████████▉ | 1792/2000 [35:05<03:10,  1.09iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  90%|████████▉ | 1793/2000 [35:06<03:11,  1.08iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  90%|████████▉ | 1793/2000 [35:06<03:11,  1.08iteration/s, mean_rewards=-326]\u001b[A\n",
            "Training:  90%|████████▉ | 1794/2000 [35:07<03:13,  1.07iteration/s, mean_rewards=-326]\u001b[A\n",
            "Training:  90%|████████▉ | 1794/2000 [35:07<03:13,  1.07iteration/s, mean_rewards=-416]\u001b[A\n",
            "Training:  90%|████████▉ | 1795/2000 [35:08<03:33,  1.04s/iteration, mean_rewards=-416]\u001b[A\n",
            "Training:  90%|████████▉ | 1795/2000 [35:08<03:33,  1.04s/iteration, mean_rewards=-185]\u001b[A\n",
            "Training:  90%|████████▉ | 1796/2000 [35:09<03:44,  1.10s/iteration, mean_rewards=-185]\u001b[A\n",
            "Training:  90%|████████▉ | 1796/2000 [35:10<03:44,  1.10s/iteration, mean_rewards=-219]\u001b[A\n",
            "Training:  90%|████████▉ | 1797/2000 [35:10<03:49,  1.13s/iteration, mean_rewards=-219]\u001b[A\n",
            "Training:  90%|████████▉ | 1797/2000 [35:11<03:49,  1.13s/iteration, mean_rewards=-120]\u001b[A\n",
            "Training:  90%|████████▉ | 1798/2000 [35:11<03:27,  1.03s/iteration, mean_rewards=-120]\u001b[A\n",
            "Training:  90%|████████▉ | 1798/2000 [35:11<03:27,  1.03s/iteration, mean_rewards=-175]\u001b[A\n",
            "Training:  90%|████████▉ | 1799/2000 [35:12<03:20,  1.00iteration/s, mean_rewards=-175]\u001b[A\n",
            "Training:  90%|████████▉ | 1799/2000 [35:12<03:20,  1.00iteration/s, mean_rewards=-207]\u001b[A\n",
            "Training:  90%|█████████ | 1800/2000 [35:13<03:13,  1.03iteration/s, mean_rewards=-207]\u001b[A\n",
            "Training:  90%|█████████ | 1800/2000 [35:13<03:13,  1.03iteration/s, mean_rewards=-260]\u001b[A\n",
            "Training:  90%|█████████ | 1801/2000 [35:14<03:00,  1.10iteration/s, mean_rewards=-260]\u001b[A\n",
            "Training:  90%|█████████ | 1801/2000 [35:14<03:00,  1.10iteration/s, mean_rewards=-173]\u001b[A\n",
            "Training:  90%|█████████ | 1802/2000 [35:15<03:00,  1.10iteration/s, mean_rewards=-173]\u001b[A\n",
            "Training:  90%|█████████ | 1802/2000 [35:15<03:00,  1.10iteration/s, mean_rewards=-316]\u001b[A\n",
            "Training:  90%|█████████ | 1803/2000 [35:16<03:02,  1.08iteration/s, mean_rewards=-316]\u001b[A\n",
            "Training:  90%|█████████ | 1803/2000 [35:16<03:02,  1.08iteration/s, mean_rewards=-307]\u001b[A\n",
            "Training:  90%|█████████ | 1804/2000 [35:16<03:03,  1.07iteration/s, mean_rewards=-307]\u001b[A\n",
            "Training:  90%|█████████ | 1804/2000 [35:17<03:03,  1.07iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  90%|█████████ | 1805/2000 [35:17<02:54,  1.12iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  90%|█████████ | 1805/2000 [35:18<02:54,  1.12iteration/s, mean_rewards=-359]\u001b[A\n",
            "Training:  90%|█████████ | 1806/2000 [35:18<02:59,  1.08iteration/s, mean_rewards=-359]\u001b[A\n",
            "Training:  90%|█████████ | 1806/2000 [35:19<02:59,  1.08iteration/s, mean_rewards=-102]\u001b[A\n",
            "Training:  90%|█████████ | 1807/2000 [35:19<02:51,  1.12iteration/s, mean_rewards=-102]\u001b[A\n",
            "Training:  90%|█████████ | 1807/2000 [35:20<02:51,  1.12iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  90%|█████████ | 1808/2000 [35:20<03:02,  1.05iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  90%|█████████ | 1808/2000 [35:21<03:02,  1.05iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:  90%|█████████ | 1809/2000 [35:22<03:25,  1.07s/iteration, mean_rewards=-138]\u001b[A\n",
            "Training:  90%|█████████ | 1809/2000 [35:22<03:25,  1.07s/iteration, mean_rewards=-248]\u001b[A\n",
            "Training:  90%|█████████ | 1810/2000 [35:23<03:21,  1.06s/iteration, mean_rewards=-248]\u001b[A\n",
            "Training:  90%|█████████ | 1810/2000 [35:23<03:21,  1.06s/iteration, mean_rewards=-228]\u001b[A\n",
            "Training:  91%|█████████ | 1811/2000 [35:23<03:04,  1.02iteration/s, mean_rewards=-228]\u001b[A\n",
            "Training:  91%|█████████ | 1811/2000 [35:24<03:04,  1.02iteration/s, mean_rewards=-369]\u001b[A\n",
            "Training:  91%|█████████ | 1812/2000 [35:24<03:00,  1.04iteration/s, mean_rewards=-369]\u001b[A\n",
            "Training:  91%|█████████ | 1812/2000 [35:25<03:00,  1.04iteration/s, mean_rewards=-157]\u001b[A\n",
            "Training:  91%|█████████ | 1813/2000 [35:25<02:52,  1.08iteration/s, mean_rewards=-157]\u001b[A\n",
            "Training:  91%|█████████ | 1813/2000 [35:25<02:52,  1.08iteration/s, mean_rewards=-94.5]\u001b[A\n",
            "Training:  91%|█████████ | 1814/2000 [35:26<02:38,  1.17iteration/s, mean_rewards=-94.5]\u001b[A\n",
            "Training:  91%|█████████ | 1814/2000 [35:26<02:38,  1.17iteration/s, mean_rewards=-324] \u001b[A\n",
            "Training:  91%|█████████ | 1815/2000 [35:27<02:42,  1.14iteration/s, mean_rewards=-324]\u001b[A\n",
            "Training:  91%|█████████ | 1815/2000 [35:27<02:42,  1.14iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  91%|█████████ | 1816/2000 [35:28<03:02,  1.01iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  91%|█████████ | 1816/2000 [35:28<03:02,  1.01iteration/s, mean_rewards=-228]\u001b[A\n",
            "Training:  91%|█████████ | 1817/2000 [35:29<02:57,  1.03iteration/s, mean_rewards=-228]\u001b[A\n",
            "Training:  91%|█████████ | 1817/2000 [35:29<02:57,  1.03iteration/s, mean_rewards=-208]\u001b[A\n",
            "Training:  91%|█████████ | 1818/2000 [35:30<03:09,  1.04s/iteration, mean_rewards=-208]\u001b[A\n",
            "Training:  91%|█████████ | 1818/2000 [35:31<03:09,  1.04s/iteration, mean_rewards=-238]\u001b[A\n",
            "Training:  91%|█████████ | 1819/2000 [35:31<03:04,  1.02s/iteration, mean_rewards=-238]\u001b[A\n",
            "Training:  91%|█████████ | 1819/2000 [35:32<03:04,  1.02s/iteration, mean_rewards=-251]\u001b[A\n",
            "Training:  91%|█████████ | 1820/2000 [35:32<03:16,  1.09s/iteration, mean_rewards=-251]\u001b[A\n",
            "Training:  91%|█████████ | 1820/2000 [35:33<03:16,  1.09s/iteration, mean_rewards=-200]\u001b[A\n",
            "Training:  91%|█████████ | 1821/2000 [35:34<03:28,  1.16s/iteration, mean_rewards=-200]\u001b[A\n",
            "Training:  91%|█████████ | 1821/2000 [35:34<03:28,  1.16s/iteration, mean_rewards=-138]\u001b[A\n",
            "Training:  91%|█████████ | 1822/2000 [35:35<03:19,  1.12s/iteration, mean_rewards=-138]\u001b[A\n",
            "Training:  91%|█████████ | 1822/2000 [35:35<03:19,  1.12s/iteration, mean_rewards=-128]\u001b[A\n",
            "Training:  91%|█████████ | 1823/2000 [35:36<03:23,  1.15s/iteration, mean_rewards=-128]\u001b[A\n",
            "Training:  91%|█████████ | 1823/2000 [35:36<03:23,  1.15s/iteration, mean_rewards=-177]\u001b[A\n",
            "Training:  91%|█████████ | 1824/2000 [35:37<03:24,  1.16s/iteration, mean_rewards=-177]\u001b[A\n",
            "Training:  91%|█████████ | 1824/2000 [35:37<03:24,  1.16s/iteration, mean_rewards=-310]\u001b[A\n",
            "Training:  91%|█████████▏| 1825/2000 [35:38<03:06,  1.06s/iteration, mean_rewards=-310]\u001b[A\n",
            "Training:  91%|█████████▏| 1825/2000 [35:38<03:06,  1.06s/iteration, mean_rewards=-110]\u001b[A\n",
            "Training:  91%|█████████▏| 1826/2000 [35:39<02:59,  1.03s/iteration, mean_rewards=-110]\u001b[A\n",
            "Training:  91%|█████████▏| 1826/2000 [35:39<02:59,  1.03s/iteration, mean_rewards=-97.5]\u001b[A\n",
            "Training:  91%|█████████▏| 1827/2000 [35:40<02:57,  1.03s/iteration, mean_rewards=-97.5]\u001b[A\n",
            "Training:  91%|█████████▏| 1827/2000 [35:40<02:57,  1.03s/iteration, mean_rewards=-204] \u001b[A\n",
            "Training:  91%|█████████▏| 1828/2000 [35:41<02:52,  1.00s/iteration, mean_rewards=-204]\u001b[A\n",
            "Training:  91%|█████████▏| 1828/2000 [35:41<02:52,  1.00s/iteration, mean_rewards=-295]\u001b[A\n",
            "Training:  91%|█████████▏| 1829/2000 [35:42<02:40,  1.06iteration/s, mean_rewards=-295]\u001b[A\n",
            "Training:  91%|█████████▏| 1829/2000 [35:42<02:40,  1.06iteration/s, mean_rewards=-357]\u001b[A\n",
            "Training:  92%|█████████▏| 1830/2000 [35:43<02:47,  1.01iteration/s, mean_rewards=-357]\u001b[A\n",
            "Training:  92%|█████████▏| 1830/2000 [35:43<02:47,  1.01iteration/s, mean_rewards=-213]\u001b[A\n",
            "Training:  92%|█████████▏| 1831/2000 [35:44<02:36,  1.08iteration/s, mean_rewards=-213]\u001b[A\n",
            "Training:  92%|█████████▏| 1831/2000 [35:44<02:36,  1.08iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:  92%|█████████▏| 1832/2000 [35:45<02:40,  1.05iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:  92%|█████████▏| 1832/2000 [35:45<02:40,  1.05iteration/s, mean_rewards=-241]\u001b[A\n",
            "Training:  92%|█████████▏| 1833/2000 [35:46<03:03,  1.10s/iteration, mean_rewards=-241]\u001b[A\n",
            "Training:  92%|█████████▏| 1833/2000 [35:47<03:03,  1.10s/iteration, mean_rewards=-232]\u001b[A\n",
            "Training:  92%|█████████▏| 1834/2000 [35:47<03:19,  1.20s/iteration, mean_rewards=-232]\u001b[A\n",
            "Training:  92%|█████████▏| 1834/2000 [35:48<03:19,  1.20s/iteration, mean_rewards=-94.5]\u001b[A\n",
            "Training:  92%|█████████▏| 1835/2000 [35:49<03:31,  1.28s/iteration, mean_rewards=-94.5]\u001b[A\n",
            "Training:  92%|█████████▏| 1835/2000 [35:49<03:31,  1.28s/iteration, mean_rewards=-87.1]\u001b[A\n",
            "Training:  92%|█████████▏| 1836/2000 [35:50<03:07,  1.14s/iteration, mean_rewards=-87.1]\u001b[A\n",
            "Training:  92%|█████████▏| 1836/2000 [35:50<03:07,  1.14s/iteration, mean_rewards=-289] \u001b[A\n",
            "Training:  92%|█████████▏| 1837/2000 [35:50<02:43,  1.00s/iteration, mean_rewards=-289]\u001b[A\n",
            "Training:  92%|█████████▏| 1837/2000 [35:51<02:43,  1.00s/iteration, mean_rewards=-226]\u001b[A\n",
            "Training:  92%|█████████▏| 1838/2000 [35:52<02:47,  1.03s/iteration, mean_rewards=-226]\u001b[A\n",
            "Training:  92%|█████████▏| 1838/2000 [35:52<02:47,  1.03s/iteration, mean_rewards=-273]\u001b[A\n",
            "Training:  92%|█████████▏| 1839/2000 [35:52<02:31,  1.06iteration/s, mean_rewards=-273]\u001b[A\n",
            "Training:  92%|█████████▏| 1839/2000 [35:53<02:31,  1.06iteration/s, mean_rewards=-355]\u001b[A\n",
            "Training:  92%|█████████▏| 1840/2000 [35:53<02:33,  1.04iteration/s, mean_rewards=-355]\u001b[A\n",
            "Training:  92%|█████████▏| 1840/2000 [35:54<02:33,  1.04iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  92%|█████████▏| 1841/2000 [35:54<02:24,  1.10iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  92%|█████████▏| 1841/2000 [35:54<02:24,  1.10iteration/s, mean_rewards=-281]\u001b[A\n",
            "Training:  92%|█████████▏| 1842/2000 [35:55<02:24,  1.09iteration/s, mean_rewards=-281]\u001b[A\n",
            "Training:  92%|█████████▏| 1842/2000 [35:55<02:24,  1.09iteration/s, mean_rewards=-187]\u001b[A\n",
            "Training:  92%|█████████▏| 1843/2000 [35:56<02:29,  1.05iteration/s, mean_rewards=-187]\u001b[A\n",
            "Training:  92%|█████████▏| 1843/2000 [35:56<02:29,  1.05iteration/s, mean_rewards=-64.9]\u001b[A\n",
            "Training:  92%|█████████▏| 1844/2000 [35:57<02:21,  1.10iteration/s, mean_rewards=-64.9]\u001b[A\n",
            "Training:  92%|█████████▏| 1844/2000 [35:57<02:21,  1.10iteration/s, mean_rewards=-240] \u001b[A\n",
            "Training:  92%|█████████▏| 1845/2000 [35:58<02:22,  1.09iteration/s, mean_rewards=-240]\u001b[A\n",
            "Training:  92%|█████████▏| 1845/2000 [35:58<02:22,  1.09iteration/s, mean_rewards=-191]\u001b[A\n",
            "Training:  92%|█████████▏| 1846/2000 [35:59<02:37,  1.02s/iteration, mean_rewards=-191]\u001b[A\n",
            "Training:  92%|█████████▏| 1846/2000 [36:00<02:37,  1.02s/iteration, mean_rewards=-249]\u001b[A\n",
            "Training:  92%|█████████▏| 1847/2000 [36:00<02:53,  1.13s/iteration, mean_rewards=-249]\u001b[A\n",
            "Training:  92%|█████████▏| 1847/2000 [36:01<02:53,  1.13s/iteration, mean_rewards=-155]\u001b[A\n",
            "Training:  92%|█████████▏| 1848/2000 [36:01<02:37,  1.04s/iteration, mean_rewards=-155]\u001b[A\n",
            "Training:  92%|█████████▏| 1848/2000 [36:02<02:37,  1.04s/iteration, mean_rewards=-126]\u001b[A\n",
            "Training:  92%|█████████▏| 1849/2000 [36:02<02:26,  1.03iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  92%|█████████▏| 1849/2000 [36:02<02:26,  1.03iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  92%|█████████▎| 1850/2000 [36:03<02:24,  1.03iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  92%|█████████▎| 1850/2000 [36:03<02:24,  1.03iteration/s, mean_rewards=-260]\u001b[A\n",
            "Training:  93%|█████████▎| 1851/2000 [36:04<02:22,  1.04iteration/s, mean_rewards=-260]\u001b[A\n",
            "Training:  93%|█████████▎| 1851/2000 [36:04<02:22,  1.04iteration/s, mean_rewards=-294]\u001b[A\n",
            "Training:  93%|█████████▎| 1852/2000 [36:05<02:22,  1.04iteration/s, mean_rewards=-294]\u001b[A\n",
            "Training:  93%|█████████▎| 1852/2000 [36:05<02:22,  1.04iteration/s, mean_rewards=-188]\u001b[A\n",
            "Training:  93%|█████████▎| 1853/2000 [36:06<02:20,  1.04iteration/s, mean_rewards=-188]\u001b[A\n",
            "Training:  93%|█████████▎| 1853/2000 [36:06<02:20,  1.04iteration/s, mean_rewards=-229]\u001b[A\n",
            "Training:  93%|█████████▎| 1854/2000 [36:07<02:12,  1.10iteration/s, mean_rewards=-229]\u001b[A\n",
            "Training:  93%|█████████▎| 1854/2000 [36:07<02:12,  1.10iteration/s, mean_rewards=-181]\u001b[A\n",
            "Training:  93%|█████████▎| 1855/2000 [36:07<02:08,  1.13iteration/s, mean_rewards=-181]\u001b[A\n",
            "Training:  93%|█████████▎| 1855/2000 [36:08<02:08,  1.13iteration/s, mean_rewards=-284]\u001b[A\n",
            "Training:  93%|█████████▎| 1856/2000 [36:08<02:12,  1.09iteration/s, mean_rewards=-284]\u001b[A\n",
            "Training:  93%|█████████▎| 1856/2000 [36:09<02:12,  1.09iteration/s, mean_rewards=-253]\u001b[A\n",
            "Training:  93%|█████████▎| 1857/2000 [36:09<02:02,  1.17iteration/s, mean_rewards=-253]\u001b[A\n",
            "Training:  93%|█████████▎| 1857/2000 [36:10<02:02,  1.17iteration/s, mean_rewards=-209]\u001b[A\n",
            "Training:  93%|█████████▎| 1858/2000 [36:11<02:23,  1.01s/iteration, mean_rewards=-209]\u001b[A\n",
            "Training:  93%|█████████▎| 1858/2000 [36:11<02:23,  1.01s/iteration, mean_rewards=-230]\u001b[A\n",
            "Training:  93%|█████████▎| 1859/2000 [36:12<02:27,  1.04s/iteration, mean_rewards=-230]\u001b[A\n",
            "Training:  93%|█████████▎| 1859/2000 [36:12<02:27,  1.04s/iteration, mean_rewards=-162]\u001b[A\n",
            "Training:  93%|█████████▎| 1860/2000 [36:13<02:36,  1.12s/iteration, mean_rewards=-162]\u001b[A\n",
            "Training:  93%|█████████▎| 1860/2000 [36:13<02:36,  1.12s/iteration, mean_rewards=-239]\u001b[A\n",
            "Training:  93%|█████████▎| 1861/2000 [36:14<02:22,  1.03s/iteration, mean_rewards=-239]\u001b[A\n",
            "Training:  93%|█████████▎| 1861/2000 [36:14<02:22,  1.03s/iteration, mean_rewards=-74] \u001b[A\n",
            "Training:  93%|█████████▎| 1862/2000 [36:14<02:06,  1.09iteration/s, mean_rewards=-74]\u001b[A\n",
            "Training:  93%|█████████▎| 1862/2000 [36:15<02:06,  1.09iteration/s, mean_rewards=-82.1]\u001b[A\n",
            "Training:  93%|█████████▎| 1863/2000 [36:15<01:57,  1.17iteration/s, mean_rewards=-82.1]\u001b[A\n",
            "Training:  93%|█████████▎| 1863/2000 [36:16<01:57,  1.17iteration/s, mean_rewards=-150] \u001b[A\n",
            "Training:  93%|█████████▎| 1864/2000 [36:16<02:06,  1.08iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  93%|█████████▎| 1864/2000 [36:17<02:06,  1.08iteration/s, mean_rewards=-180]\u001b[A\n",
            "Training:  93%|█████████▎| 1865/2000 [36:17<02:06,  1.07iteration/s, mean_rewards=-180]\u001b[A\n",
            "Training:  93%|█████████▎| 1865/2000 [36:18<02:06,  1.07iteration/s, mean_rewards=-63.4]\u001b[A\n",
            "Training:  93%|█████████▎| 1866/2000 [36:18<02:05,  1.07iteration/s, mean_rewards=-63.4]\u001b[A\n",
            "Training:  93%|█████████▎| 1866/2000 [36:19<02:05,  1.07iteration/s, mean_rewards=-213] \u001b[A\n",
            "Training:  93%|█████████▎| 1867/2000 [36:19<02:16,  1.03s/iteration, mean_rewards=-213]\u001b[A\n",
            "Training:  93%|█████████▎| 1867/2000 [36:20<02:16,  1.03s/iteration, mean_rewards=-160]\u001b[A\n",
            "Training:  93%|█████████▎| 1868/2000 [36:20<02:07,  1.04iteration/s, mean_rewards=-160]\u001b[A\n",
            "Training:  93%|█████████▎| 1868/2000 [36:21<02:07,  1.04iteration/s, mean_rewards=-269]\u001b[A\n",
            "Training:  93%|█████████▎| 1869/2000 [36:21<02:06,  1.03iteration/s, mean_rewards=-269]\u001b[A\n",
            "Training:  93%|█████████▎| 1869/2000 [36:22<02:06,  1.03iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  94%|█████████▎| 1870/2000 [36:22<02:01,  1.07iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  94%|█████████▎| 1870/2000 [36:22<02:01,  1.07iteration/s, mean_rewards=-293]\u001b[A\n",
            "Training:  94%|█████████▎| 1871/2000 [36:23<02:11,  1.02s/iteration, mean_rewards=-293]\u001b[A\n",
            "Training:  94%|█████████▎| 1871/2000 [36:24<02:11,  1.02s/iteration, mean_rewards=-269]\u001b[A\n",
            "Training:  94%|█████████▎| 1872/2000 [36:24<02:08,  1.00s/iteration, mean_rewards=-269]\u001b[A\n",
            "Training:  94%|█████████▎| 1872/2000 [36:25<02:08,  1.00s/iteration, mean_rewards=-228]\u001b[A\n",
            "Training:  94%|█████████▎| 1873/2000 [36:26<02:21,  1.11s/iteration, mean_rewards=-228]\u001b[A\n",
            "Training:  94%|█████████▎| 1873/2000 [36:26<02:21,  1.11s/iteration, mean_rewards=-206]\u001b[A\n",
            "Training:  94%|█████████▎| 1874/2000 [36:26<02:08,  1.02s/iteration, mean_rewards=-206]\u001b[A\n",
            "Training:  94%|█████████▎| 1874/2000 [36:27<02:08,  1.02s/iteration, mean_rewards=-353]\u001b[A\n",
            "Training:  94%|█████████▍| 1875/2000 [36:27<02:04,  1.01iteration/s, mean_rewards=-353]\u001b[A\n",
            "Training:  94%|█████████▍| 1875/2000 [36:28<02:04,  1.01iteration/s, mean_rewards=-333]\u001b[A\n",
            "Training:  94%|█████████▍| 1876/2000 [36:28<02:02,  1.01iteration/s, mean_rewards=-333]\u001b[A\n",
            "Training:  94%|█████████▍| 1876/2000 [36:29<02:02,  1.01iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  94%|█████████▍| 1877/2000 [36:29<01:50,  1.11iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  94%|█████████▍| 1877/2000 [36:29<01:50,  1.11iteration/s, mean_rewards=-196]\u001b[A\n",
            "Training:  94%|█████████▍| 1878/2000 [36:30<01:47,  1.14iteration/s, mean_rewards=-196]\u001b[A\n",
            "Training:  94%|█████████▍| 1878/2000 [36:30<01:47,  1.14iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  94%|█████████▍| 1879/2000 [36:31<01:45,  1.15iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  94%|█████████▍| 1879/2000 [36:31<01:45,  1.15iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  94%|█████████▍| 1880/2000 [36:31<01:38,  1.22iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  94%|█████████▍| 1880/2000 [36:32<01:38,  1.22iteration/s, mean_rewards=-102]\u001b[A\n",
            "Training:  94%|█████████▍| 1881/2000 [36:32<01:32,  1.28iteration/s, mean_rewards=-102]\u001b[A\n",
            "Training:  94%|█████████▍| 1881/2000 [36:32<01:32,  1.28iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  94%|█████████▍| 1882/2000 [36:33<01:32,  1.27iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  94%|█████████▍| 1882/2000 [36:33<01:32,  1.27iteration/s, mean_rewards=-96.9]\u001b[A\n",
            "Training:  94%|█████████▍| 1883/2000 [36:34<01:37,  1.20iteration/s, mean_rewards=-96.9]\u001b[A\n",
            "Training:  94%|█████████▍| 1883/2000 [36:34<01:37,  1.20iteration/s, mean_rewards=-96.8]\u001b[A\n",
            "Training:  94%|█████████▍| 1884/2000 [36:35<01:39,  1.17iteration/s, mean_rewards=-96.8]\u001b[A\n",
            "Training:  94%|█████████▍| 1884/2000 [36:35<01:39,  1.17iteration/s, mean_rewards=-177] \u001b[A\n",
            "Training:  94%|█████████▍| 1885/2000 [36:36<01:36,  1.19iteration/s, mean_rewards=-177]\u001b[A\n",
            "Training:  94%|█████████▍| 1885/2000 [36:36<01:36,  1.19iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  94%|█████████▍| 1886/2000 [36:36<01:37,  1.17iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  94%|█████████▍| 1886/2000 [36:37<01:37,  1.17iteration/s, mean_rewards=-80.1]\u001b[A\n",
            "Training:  94%|█████████▍| 1887/2000 [36:37<01:39,  1.13iteration/s, mean_rewards=-80.1]\u001b[A\n",
            "Training:  94%|█████████▍| 1887/2000 [36:38<01:39,  1.13iteration/s, mean_rewards=-241] \u001b[A\n",
            "Training:  94%|█████████▍| 1888/2000 [36:39<01:53,  1.01s/iteration, mean_rewards=-241]\u001b[A\n",
            "Training:  94%|█████████▍| 1888/2000 [36:39<01:53,  1.01s/iteration, mean_rewards=-107]\u001b[A\n",
            "Training:  94%|█████████▍| 1889/2000 [36:39<01:45,  1.05iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  94%|█████████▍| 1889/2000 [36:40<01:45,  1.05iteration/s, mean_rewards=-209]\u001b[A\n",
            "Training:  94%|█████████▍| 1890/2000 [36:40<01:40,  1.10iteration/s, mean_rewards=-209]\u001b[A\n",
            "Training:  94%|█████████▍| 1890/2000 [36:41<01:40,  1.10iteration/s, mean_rewards=-176]\u001b[A\n",
            "Training:  95%|█████████▍| 1891/2000 [36:41<01:41,  1.07iteration/s, mean_rewards=-176]\u001b[A\n",
            "Training:  95%|█████████▍| 1891/2000 [36:42<01:41,  1.07iteration/s, mean_rewards=-427]\u001b[A\n",
            "Training:  95%|█████████▍| 1892/2000 [36:42<01:41,  1.06iteration/s, mean_rewards=-427]\u001b[A\n",
            "Training:  95%|█████████▍| 1892/2000 [36:43<01:41,  1.06iteration/s, mean_rewards=-311]\u001b[A\n",
            "Training:  95%|█████████▍| 1893/2000 [36:43<01:36,  1.11iteration/s, mean_rewards=-311]\u001b[A\n",
            "Training:  95%|█████████▍| 1893/2000 [36:43<01:36,  1.11iteration/s, mean_rewards=-257]\u001b[A\n",
            "Training:  95%|█████████▍| 1894/2000 [36:44<01:37,  1.08iteration/s, mean_rewards=-257]\u001b[A\n",
            "Training:  95%|█████████▍| 1894/2000 [36:44<01:37,  1.08iteration/s, mean_rewards=-195]\u001b[A\n",
            "Training:  95%|█████████▍| 1895/2000 [36:45<01:38,  1.06iteration/s, mean_rewards=-195]\u001b[A\n",
            "Training:  95%|█████████▍| 1895/2000 [36:45<01:38,  1.06iteration/s, mean_rewards=-191]\u001b[A\n",
            "Training:  95%|█████████▍| 1896/2000 [36:46<01:40,  1.03iteration/s, mean_rewards=-191]\u001b[A\n",
            "Training:  95%|█████████▍| 1896/2000 [36:46<01:40,  1.03iteration/s, mean_rewards=-175]\u001b[A\n",
            "Training:  95%|█████████▍| 1897/2000 [36:47<01:41,  1.01iteration/s, mean_rewards=-175]\u001b[A\n",
            "Training:  95%|█████████▍| 1897/2000 [36:47<01:41,  1.01iteration/s, mean_rewards=-303]\u001b[A\n",
            "Training:  95%|█████████▍| 1898/2000 [36:48<01:34,  1.08iteration/s, mean_rewards=-303]\u001b[A\n",
            "Training:  95%|█████████▍| 1898/2000 [36:48<01:34,  1.08iteration/s, mean_rewards=-194]\u001b[A\n",
            "Training:  95%|█████████▍| 1899/2000 [36:49<01:30,  1.12iteration/s, mean_rewards=-194]\u001b[A\n",
            "Training:  95%|█████████▍| 1899/2000 [36:49<01:30,  1.12iteration/s, mean_rewards=-272]\u001b[A\n",
            "Training:  95%|█████████▌| 1900/2000 [36:50<01:49,  1.09s/iteration, mean_rewards=-272]\u001b[A\n",
            "Training:  95%|█████████▌| 1900/2000 [36:51<01:49,  1.09s/iteration, mean_rewards=-67.6]\u001b[A\n",
            "Training:  95%|█████████▌| 1901/2000 [36:51<01:48,  1.09s/iteration, mean_rewards=-67.6]\u001b[A\n",
            "Training:  95%|█████████▌| 1901/2000 [36:52<01:48,  1.09s/iteration, mean_rewards=-162] \u001b[A\n",
            "Training:  95%|█████████▌| 1902/2000 [36:52<01:41,  1.04s/iteration, mean_rewards=-162]\u001b[A\n",
            "Training:  95%|█████████▌| 1902/2000 [36:53<01:41,  1.04s/iteration, mean_rewards=-101]\u001b[A\n",
            "Training:  95%|█████████▌| 1903/2000 [36:53<01:34,  1.03iteration/s, mean_rewards=-101]\u001b[A\n",
            "Training:  95%|█████████▌| 1903/2000 [36:53<01:34,  1.03iteration/s, mean_rewards=-261]\u001b[A\n",
            "Training:  95%|█████████▌| 1904/2000 [36:54<01:30,  1.06iteration/s, mean_rewards=-261]\u001b[A\n",
            "Training:  95%|█████████▌| 1904/2000 [36:54<01:30,  1.06iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  95%|█████████▌| 1905/2000 [36:55<01:25,  1.11iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  95%|█████████▌| 1905/2000 [36:55<01:25,  1.11iteration/s, mean_rewards=-89.8]\u001b[A\n",
            "Training:  95%|█████████▌| 1906/2000 [36:55<01:19,  1.19iteration/s, mean_rewards=-89.8]\u001b[A\n",
            "Training:  95%|█████████▌| 1906/2000 [36:56<01:19,  1.19iteration/s, mean_rewards=-115] \u001b[A\n",
            "Training:  95%|█████████▌| 1907/2000 [36:56<01:18,  1.18iteration/s, mean_rewards=-115]\u001b[A\n",
            "Training:  95%|█████████▌| 1907/2000 [36:57<01:18,  1.18iteration/s, mean_rewards=-296]\u001b[A\n",
            "Training:  95%|█████████▌| 1908/2000 [36:57<01:16,  1.21iteration/s, mean_rewards=-296]\u001b[A\n",
            "Training:  95%|█████████▌| 1908/2000 [36:57<01:16,  1.21iteration/s, mean_rewards=-87.3]\u001b[A\n",
            "Training:  95%|█████████▌| 1909/2000 [36:58<01:14,  1.22iteration/s, mean_rewards=-87.3]\u001b[A\n",
            "Training:  95%|█████████▌| 1909/2000 [36:58<01:14,  1.22iteration/s, mean_rewards=-166] \u001b[A\n",
            "Training:  96%|█████████▌| 1910/2000 [36:59<01:11,  1.27iteration/s, mean_rewards=-166]\u001b[A\n",
            "Training:  96%|█████████▌| 1910/2000 [36:59<01:11,  1.27iteration/s, mean_rewards=-191]\u001b[A\n",
            "Training:  96%|█████████▌| 1911/2000 [37:00<01:14,  1.19iteration/s, mean_rewards=-191]\u001b[A\n",
            "Training:  96%|█████████▌| 1911/2000 [37:00<01:14,  1.19iteration/s, mean_rewards=-175]\u001b[A\n",
            "Training:  96%|█████████▌| 1912/2000 [37:00<01:16,  1.15iteration/s, mean_rewards=-175]\u001b[A\n",
            "Training:  96%|█████████▌| 1912/2000 [37:01<01:16,  1.15iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  96%|█████████▌| 1913/2000 [37:01<01:17,  1.13iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  96%|█████████▌| 1913/2000 [37:02<01:17,  1.13iteration/s, mean_rewards=-310]\u001b[A\n",
            "Training:  96%|█████████▌| 1914/2000 [37:03<01:22,  1.04iteration/s, mean_rewards=-310]\u001b[A\n",
            "Training:  96%|█████████▌| 1914/2000 [37:03<01:22,  1.04iteration/s, mean_rewards=-236]\u001b[A\n",
            "Training:  96%|█████████▌| 1915/2000 [37:04<01:30,  1.06s/iteration, mean_rewards=-236]\u001b[A\n",
            "Training:  96%|█████████▌| 1915/2000 [37:04<01:30,  1.06s/iteration, mean_rewards=-78.4]\u001b[A\n",
            "Training:  96%|█████████▌| 1916/2000 [37:05<01:27,  1.04s/iteration, mean_rewards=-78.4]\u001b[A\n",
            "Training:  96%|█████████▌| 1916/2000 [37:05<01:27,  1.04s/iteration, mean_rewards=-201] \u001b[A\n",
            "Training:  96%|█████████▌| 1917/2000 [37:06<01:24,  1.02s/iteration, mean_rewards=-201]\u001b[A\n",
            "Training:  96%|█████████▌| 1917/2000 [37:06<01:24,  1.02s/iteration, mean_rewards=-147]\u001b[A\n",
            "Training:  96%|█████████▌| 1918/2000 [37:07<01:22,  1.01s/iteration, mean_rewards=-147]\u001b[A\n",
            "Training:  96%|█████████▌| 1918/2000 [37:07<01:22,  1.01s/iteration, mean_rewards=-369]\u001b[A\n",
            "Training:  96%|█████████▌| 1919/2000 [37:08<01:17,  1.04iteration/s, mean_rewards=-369]\u001b[A\n",
            "Training:  96%|█████████▌| 1919/2000 [37:08<01:17,  1.04iteration/s, mean_rewards=-109]\u001b[A\n",
            "Training:  96%|█████████▌| 1920/2000 [37:08<01:10,  1.13iteration/s, mean_rewards=-109]\u001b[A\n",
            "Training:  96%|█████████▌| 1920/2000 [37:09<01:10,  1.13iteration/s, mean_rewards=-175]\u001b[A\n",
            "Training:  96%|█████████▌| 1921/2000 [37:09<01:05,  1.21iteration/s, mean_rewards=-175]\u001b[A\n",
            "Training:  96%|█████████▌| 1921/2000 [37:09<01:05,  1.21iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  96%|█████████▌| 1922/2000 [37:10<01:05,  1.19iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  96%|█████████▌| 1922/2000 [37:10<01:05,  1.19iteration/s, mean_rewards=-166]\u001b[A\n",
            "Training:  96%|█████████▌| 1923/2000 [37:11<01:05,  1.18iteration/s, mean_rewards=-166]\u001b[A\n",
            "Training:  96%|█████████▌| 1923/2000 [37:11<01:05,  1.18iteration/s, mean_rewards=-224]\u001b[A\n",
            "Training:  96%|█████████▌| 1924/2000 [37:12<01:11,  1.07iteration/s, mean_rewards=-224]\u001b[A\n",
            "Training:  96%|█████████▌| 1924/2000 [37:12<01:11,  1.07iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  96%|█████████▋| 1925/2000 [37:13<01:10,  1.07iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  96%|█████████▋| 1925/2000 [37:13<01:10,  1.07iteration/s, mean_rewards=-206]\u001b[A\n",
            "Training:  96%|█████████▋| 1926/2000 [37:14<01:14,  1.01s/iteration, mean_rewards=-206]\u001b[A\n",
            "Training:  96%|█████████▋| 1926/2000 [37:15<01:14,  1.01s/iteration, mean_rewards=-191]\u001b[A\n",
            "Training:  96%|█████████▋| 1927/2000 [37:15<01:20,  1.11s/iteration, mean_rewards=-191]\u001b[A\n",
            "Training:  96%|█████████▋| 1927/2000 [37:16<01:20,  1.11s/iteration, mean_rewards=-128]\u001b[A\n",
            "Training:  96%|█████████▋| 1928/2000 [37:16<01:15,  1.05s/iteration, mean_rewards=-128]\u001b[A\n",
            "Training:  96%|█████████▋| 1928/2000 [37:17<01:15,  1.05s/iteration, mean_rewards=-106]\u001b[A\n",
            "Training:  96%|█████████▋| 1929/2000 [37:17<01:17,  1.08s/iteration, mean_rewards=-106]\u001b[A\n",
            "Training:  96%|█████████▋| 1929/2000 [37:18<01:17,  1.08s/iteration, mean_rewards=-365]\u001b[A\n",
            "Training:  96%|█████████▋| 1930/2000 [37:19<01:20,  1.15s/iteration, mean_rewards=-365]\u001b[A\n",
            "Training:  96%|█████████▋| 1930/2000 [37:19<01:20,  1.15s/iteration, mean_rewards=-203]\u001b[A\n",
            "Training:  97%|█████████▋| 1931/2000 [37:20<01:16,  1.10s/iteration, mean_rewards=-203]\u001b[A\n",
            "Training:  97%|█████████▋| 1931/2000 [37:20<01:16,  1.10s/iteration, mean_rewards=-126]\u001b[A\n",
            "Training:  97%|█████████▋| 1932/2000 [37:21<01:09,  1.02s/iteration, mean_rewards=-126]\u001b[A\n",
            "Training:  97%|█████████▋| 1932/2000 [37:21<01:09,  1.02s/iteration, mean_rewards=-97.2]\u001b[A\n",
            "Training:  97%|█████████▋| 1933/2000 [37:21<01:04,  1.03iteration/s, mean_rewards=-97.2]\u001b[A\n",
            "Training:  97%|█████████▋| 1933/2000 [37:22<01:04,  1.03iteration/s, mean_rewards=-259] \u001b[A\n",
            "Training:  97%|█████████▋| 1934/2000 [37:22<01:04,  1.03iteration/s, mean_rewards=-259]\u001b[A\n",
            "Training:  97%|█████████▋| 1934/2000 [37:23<01:04,  1.03iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  97%|█████████▋| 1935/2000 [37:24<01:05,  1.01s/iteration, mean_rewards=-107]\u001b[A\n",
            "Training:  97%|█████████▋| 1935/2000 [37:24<01:05,  1.01s/iteration, mean_rewards=-110]\u001b[A\n",
            "Training:  97%|█████████▋| 1936/2000 [37:24<01:01,  1.05iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  97%|█████████▋| 1936/2000 [37:25<01:01,  1.05iteration/s, mean_rewards=-291]\u001b[A\n",
            "Training:  97%|█████████▋| 1937/2000 [37:25<00:58,  1.08iteration/s, mean_rewards=-291]\u001b[A\n",
            "Training:  97%|█████████▋| 1937/2000 [37:25<00:58,  1.08iteration/s, mean_rewards=-98.2]\u001b[A\n",
            "Training:  97%|█████████▋| 1938/2000 [37:26<00:53,  1.16iteration/s, mean_rewards=-98.2]\u001b[A\n",
            "Training:  97%|█████████▋| 1938/2000 [37:26<00:53,  1.16iteration/s, mean_rewards=-270] \u001b[A\n",
            "Training:  97%|█████████▋| 1939/2000 [37:27<00:54,  1.12iteration/s, mean_rewards=-270]\u001b[A\n",
            "Training:  97%|█████████▋| 1939/2000 [37:27<00:54,  1.12iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  97%|█████████▋| 1940/2000 [37:28<00:55,  1.09iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  97%|█████████▋| 1940/2000 [37:28<00:55,  1.09iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  97%|█████████▋| 1941/2000 [37:29<00:58,  1.01iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  97%|█████████▋| 1941/2000 [37:30<00:58,  1.01iteration/s, mean_rewards=-219]\u001b[A\n",
            "Training:  97%|█████████▋| 1942/2000 [37:30<01:03,  1.09s/iteration, mean_rewards=-219]\u001b[A\n",
            "Training:  97%|█████████▋| 1942/2000 [37:31<01:03,  1.09s/iteration, mean_rewards=-113]\u001b[A\n",
            "Training:  97%|█████████▋| 1943/2000 [37:31<01:02,  1.10s/iteration, mean_rewards=-113]\u001b[A\n",
            "Training:  97%|█████████▋| 1943/2000 [37:32<01:02,  1.10s/iteration, mean_rewards=-348]\u001b[A\n",
            "Training:  97%|█████████▋| 1944/2000 [37:32<00:57,  1.03s/iteration, mean_rewards=-348]\u001b[A\n",
            "Training:  97%|█████████▋| 1944/2000 [37:33<00:57,  1.03s/iteration, mean_rewards=-231]\u001b[A\n",
            "Training:  97%|█████████▋| 1945/2000 [37:33<00:52,  1.04iteration/s, mean_rewards=-231]\u001b[A\n",
            "Training:  97%|█████████▋| 1945/2000 [37:34<00:52,  1.04iteration/s, mean_rewards=-351]\u001b[A\n",
            "Training:  97%|█████████▋| 1946/2000 [37:34<00:54,  1.01s/iteration, mean_rewards=-351]\u001b[A\n",
            "Training:  97%|█████████▋| 1946/2000 [37:35<00:54,  1.01s/iteration, mean_rewards=-90.3]\u001b[A\n",
            "Training:  97%|█████████▋| 1947/2000 [37:35<00:48,  1.09iteration/s, mean_rewards=-90.3]\u001b[A\n",
            "Training:  97%|█████████▋| 1947/2000 [37:35<00:48,  1.09iteration/s, mean_rewards=-139] \u001b[A\n",
            "Training:  97%|█████████▋| 1948/2000 [37:36<00:46,  1.12iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:  97%|█████████▋| 1948/2000 [37:36<00:46,  1.12iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:  97%|█████████▋| 1949/2000 [37:37<00:46,  1.10iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:  97%|█████████▋| 1949/2000 [37:37<00:46,  1.10iteration/s, mean_rewards=-276]\u001b[A\n",
            "Training:  98%|█████████▊| 1950/2000 [37:38<00:49,  1.00iteration/s, mean_rewards=-276]\u001b[A\n",
            "Training:  98%|█████████▊| 1950/2000 [37:38<00:49,  1.00iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  98%|█████████▊| 1951/2000 [37:39<00:46,  1.05iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  98%|█████████▊| 1951/2000 [37:39<00:46,  1.05iteration/s, mean_rewards=-63.1]\u001b[A\n",
            "Training:  98%|█████████▊| 1952/2000 [37:40<00:44,  1.08iteration/s, mean_rewards=-63.1]\u001b[A\n",
            "Training:  98%|█████████▊| 1952/2000 [37:40<00:44,  1.08iteration/s, mean_rewards=-273] \u001b[A\n",
            "Training:  98%|█████████▊| 1953/2000 [37:41<00:46,  1.02iteration/s, mean_rewards=-273]\u001b[A\n",
            "Training:  98%|█████████▊| 1953/2000 [37:41<00:46,  1.02iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:  98%|█████████▊| 1954/2000 [37:42<00:43,  1.05iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:  98%|█████████▊| 1954/2000 [37:42<00:43,  1.05iteration/s, mean_rewards=-191]\u001b[A\n",
            "Training:  98%|█████████▊| 1955/2000 [37:43<00:47,  1.06s/iteration, mean_rewards=-191]\u001b[A\n",
            "Training:  98%|█████████▊| 1955/2000 [37:43<00:47,  1.06s/iteration, mean_rewards=-239]\u001b[A\n",
            "Training:  98%|█████████▊| 1956/2000 [37:44<00:47,  1.09s/iteration, mean_rewards=-239]\u001b[A\n",
            "Training:  98%|█████████▊| 1956/2000 [37:45<00:47,  1.09s/iteration, mean_rewards=-329]\u001b[A\n",
            "Training:  98%|█████████▊| 1957/2000 [37:45<00:50,  1.16s/iteration, mean_rewards=-329]\u001b[A\n",
            "Training:  98%|█████████▊| 1957/2000 [37:46<00:50,  1.16s/iteration, mean_rewards=-112]\u001b[A\n",
            "Training:  98%|█████████▊| 1958/2000 [37:46<00:44,  1.06s/iteration, mean_rewards=-112]\u001b[A\n",
            "Training:  98%|█████████▊| 1958/2000 [37:47<00:44,  1.06s/iteration, mean_rewards=-102]\u001b[A\n",
            "Training:  98%|█████████▊| 1959/2000 [37:47<00:39,  1.05iteration/s, mean_rewards=-102]\u001b[A\n",
            "Training:  98%|█████████▊| 1959/2000 [37:47<00:39,  1.05iteration/s, mean_rewards=-179]\u001b[A\n",
            "Training:  98%|█████████▊| 1960/2000 [37:48<00:41,  1.03s/iteration, mean_rewards=-179]\u001b[A\n",
            "Training:  98%|█████████▊| 1960/2000 [37:48<00:41,  1.03s/iteration, mean_rewards=-124]\u001b[A\n",
            "Training:  98%|█████████▊| 1961/2000 [37:49<00:36,  1.07iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  98%|█████████▊| 1961/2000 [37:49<00:36,  1.07iteration/s, mean_rewards=-213]\u001b[A\n",
            "Training:  98%|█████████▊| 1962/2000 [37:50<00:36,  1.03iteration/s, mean_rewards=-213]\u001b[A\n",
            "Training:  98%|█████████▊| 1962/2000 [37:50<00:36,  1.03iteration/s, mean_rewards=-65.4]\u001b[A\n",
            "Training:  98%|█████████▊| 1963/2000 [37:51<00:32,  1.14iteration/s, mean_rewards=-65.4]\u001b[A\n",
            "Training:  98%|█████████▊| 1963/2000 [37:51<00:32,  1.14iteration/s, mean_rewards=-174] \u001b[A\n",
            "Training:  98%|█████████▊| 1964/2000 [37:52<00:32,  1.12iteration/s, mean_rewards=-174]\u001b[A\n",
            "Training:  98%|█████████▊| 1964/2000 [37:52<00:32,  1.12iteration/s, mean_rewards=-352]\u001b[A\n",
            "Training:  98%|█████████▊| 1965/2000 [37:53<00:32,  1.08iteration/s, mean_rewards=-352]\u001b[A\n",
            "Training:  98%|█████████▊| 1965/2000 [37:53<00:32,  1.08iteration/s, mean_rewards=-324]\u001b[A\n",
            "Training:  98%|█████████▊| 1966/2000 [37:53<00:30,  1.10iteration/s, mean_rewards=-324]\u001b[A\n",
            "Training:  98%|█████████▊| 1966/2000 [37:54<00:30,  1.10iteration/s, mean_rewards=-173]\u001b[A\n",
            "Training:  98%|█████████▊| 1967/2000 [37:54<00:30,  1.09iteration/s, mean_rewards=-173]\u001b[A\n",
            "Training:  98%|█████████▊| 1967/2000 [37:55<00:30,  1.09iteration/s, mean_rewards=-197]\u001b[A\n",
            "Training:  98%|█████████▊| 1968/2000 [37:55<00:30,  1.03iteration/s, mean_rewards=-197]\u001b[A\n",
            "Training:  98%|█████████▊| 1968/2000 [37:56<00:30,  1.03iteration/s, mean_rewards=-102]\u001b[A\n",
            "Training:  98%|█████████▊| 1969/2000 [37:57<00:32,  1.06s/iteration, mean_rewards=-102]\u001b[A\n",
            "Training:  98%|█████████▊| 1969/2000 [37:57<00:32,  1.06s/iteration, mean_rewards=-127]\u001b[A\n",
            "Training:  98%|█████████▊| 1970/2000 [37:58<00:34,  1.16s/iteration, mean_rewards=-127]\u001b[A\n",
            "Training:  98%|█████████▊| 1970/2000 [37:58<00:34,  1.16s/iteration, mean_rewards=-106]\u001b[A\n",
            "Training:  99%|█████████▊| 1971/2000 [37:59<00:30,  1.06s/iteration, mean_rewards=-106]\u001b[A\n",
            "Training:  99%|█████████▊| 1971/2000 [37:59<00:30,  1.06s/iteration, mean_rewards=-65.1]\u001b[A\n",
            "Training:  99%|█████████▊| 1972/2000 [38:00<00:28,  1.03s/iteration, mean_rewards=-65.1]\u001b[A\n",
            "Training:  99%|█████████▊| 1972/2000 [38:00<00:28,  1.03s/iteration, mean_rewards=-204] \u001b[A\n",
            "Training:  99%|█████████▊| 1973/2000 [38:01<00:25,  1.07iteration/s, mean_rewards=-204]\u001b[A\n",
            "Training:  99%|█████████▊| 1973/2000 [38:01<00:25,  1.07iteration/s, mean_rewards=-87] \u001b[A\n",
            "Training:  99%|█████████▊| 1974/2000 [38:01<00:23,  1.11iteration/s, mean_rewards=-87]\u001b[A\n",
            "Training:  99%|█████████▊| 1974/2000 [38:02<00:23,  1.11iteration/s, mean_rewards=-178]\u001b[A\n",
            "Training:  99%|█████████▉| 1975/2000 [38:02<00:21,  1.18iteration/s, mean_rewards=-178]\u001b[A\n",
            "Training:  99%|█████████▉| 1975/2000 [38:03<00:21,  1.18iteration/s, mean_rewards=-199]\u001b[A\n",
            "Training:  99%|█████████▉| 1976/2000 [38:03<00:21,  1.13iteration/s, mean_rewards=-199]\u001b[A\n",
            "Training:  99%|█████████▉| 1976/2000 [38:04<00:21,  1.13iteration/s, mean_rewards=-260]\u001b[A\n",
            "Training:  99%|█████████▉| 1977/2000 [38:04<00:20,  1.12iteration/s, mean_rewards=-260]\u001b[A\n",
            "Training:  99%|█████████▉| 1977/2000 [38:04<00:20,  1.12iteration/s, mean_rewards=-175]\u001b[A\n",
            "Training:  99%|█████████▉| 1978/2000 [38:05<00:21,  1.05iteration/s, mean_rewards=-175]\u001b[A\n",
            "Training:  99%|█████████▉| 1978/2000 [38:05<00:21,  1.05iteration/s, mean_rewards=-174]\u001b[A\n",
            "Training:  99%|█████████▉| 1979/2000 [38:06<00:18,  1.13iteration/s, mean_rewards=-174]\u001b[A\n",
            "Training:  99%|█████████▉| 1979/2000 [38:06<00:18,  1.13iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  99%|█████████▉| 1980/2000 [38:07<00:17,  1.11iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  99%|█████████▉| 1980/2000 [38:07<00:17,  1.11iteration/s, mean_rewards=-235]\u001b[A\n",
            "Training:  99%|█████████▉| 1981/2000 [38:08<00:18,  1.02iteration/s, mean_rewards=-235]\u001b[A\n",
            "Training:  99%|█████████▉| 1981/2000 [38:08<00:18,  1.02iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  99%|█████████▉| 1982/2000 [38:09<00:18,  1.05s/iteration, mean_rewards=-123]\u001b[A\n",
            "Training:  99%|█████████▉| 1982/2000 [38:10<00:18,  1.05s/iteration, mean_rewards=-210]\u001b[A\n",
            "Training:  99%|█████████▉| 1983/2000 [38:11<00:19,  1.14s/iteration, mean_rewards=-210]\u001b[A\n",
            "Training:  99%|█████████▉| 1983/2000 [38:11<00:19,  1.14s/iteration, mean_rewards=-402]\u001b[A\n",
            "Training:  99%|█████████▉| 1984/2000 [38:12<00:17,  1.10s/iteration, mean_rewards=-402]\u001b[A\n",
            "Training:  99%|█████████▉| 1984/2000 [38:12<00:17,  1.10s/iteration, mean_rewards=-197]\u001b[A\n",
            "Training:  99%|█████████▉| 1985/2000 [38:13<00:16,  1.08s/iteration, mean_rewards=-197]\u001b[A\n",
            "Training:  99%|█████████▉| 1985/2000 [38:13<00:16,  1.08s/iteration, mean_rewards=-269]\u001b[A\n",
            "Training:  99%|█████████▉| 1986/2000 [38:14<00:15,  1.09s/iteration, mean_rewards=-269]\u001b[A\n",
            "Training:  99%|█████████▉| 1986/2000 [38:14<00:15,  1.09s/iteration, mean_rewards=-71.9]\u001b[A\n",
            "Training:  99%|█████████▉| 1987/2000 [38:14<00:12,  1.02iteration/s, mean_rewards=-71.9]\u001b[A\n",
            "Training:  99%|█████████▉| 1987/2000 [38:15<00:12,  1.02iteration/s, mean_rewards=-222] \u001b[A\n",
            "Training:  99%|█████████▉| 1988/2000 [38:15<00:10,  1.11iteration/s, mean_rewards=-222]\u001b[A\n",
            "Training:  99%|█████████▉| 1988/2000 [38:15<00:10,  1.11iteration/s, mean_rewards=-202]\u001b[A\n",
            "Training:  99%|█████████▉| 1989/2000 [38:16<00:09,  1.14iteration/s, mean_rewards=-202]\u001b[A\n",
            "Training:  99%|█████████▉| 1989/2000 [38:16<00:09,  1.14iteration/s, mean_rewards=-112]\u001b[A\n",
            "Training: 100%|█████████▉| 1990/2000 [38:17<00:09,  1.08iteration/s, mean_rewards=-112]\u001b[A\n",
            "Training: 100%|█████████▉| 1990/2000 [38:17<00:09,  1.08iteration/s, mean_rewards=-218]\u001b[A\n",
            "Training: 100%|█████████▉| 1991/2000 [38:18<00:08,  1.12iteration/s, mean_rewards=-218]\u001b[A\n",
            "Training: 100%|█████████▉| 1991/2000 [38:18<00:08,  1.12iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training: 100%|█████████▉| 1992/2000 [38:19<00:06,  1.19iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training: 100%|█████████▉| 1992/2000 [38:19<00:06,  1.19iteration/s, mean_rewards=-257]\u001b[A\n",
            "Training: 100%|█████████▉| 1993/2000 [38:19<00:06,  1.14iteration/s, mean_rewards=-257]\u001b[A\n",
            "Training: 100%|█████████▉| 1993/2000 [38:20<00:06,  1.14iteration/s, mean_rewards=-204]\u001b[A\n",
            "Training: 100%|█████████▉| 1994/2000 [38:20<00:05,  1.16iteration/s, mean_rewards=-204]\u001b[A\n",
            "Training: 100%|█████████▉| 1994/2000 [38:21<00:05,  1.16iteration/s, mean_rewards=-391]\u001b[A\n",
            "Training: 100%|█████████▉| 1995/2000 [38:22<00:05,  1.12s/iteration, mean_rewards=-391]\u001b[A\n",
            "Training: 100%|█████████▉| 1995/2000 [38:23<00:05,  1.12s/iteration, mean_rewards=-78.5]\u001b[A\n",
            "Training: 100%|█████████▉| 1996/2000 [38:24<00:05,  1.31s/iteration, mean_rewards=-78.5]\u001b[A\n",
            "Training: 100%|█████████▉| 1996/2000 [38:24<00:05,  1.31s/iteration, mean_rewards=-214] \u001b[A\n",
            "Training: 100%|█████████▉| 1997/2000 [38:25<00:03,  1.22s/iteration, mean_rewards=-214]\u001b[A\n",
            "Training: 100%|█████████▉| 1997/2000 [38:25<00:03,  1.22s/iteration, mean_rewards=-423]\u001b[A\n",
            "Training: 100%|█████████▉| 1998/2000 [38:26<00:02,  1.23s/iteration, mean_rewards=-423]\u001b[A\n",
            "Training: 100%|█████████▉| 1998/2000 [38:26<00:02,  1.23s/iteration, mean_rewards=-147]\u001b[A\n",
            "Training: 100%|█████████▉| 1999/2000 [38:27<00:01,  1.10s/iteration, mean_rewards=-147]\u001b[A\n",
            "Training: 100%|█████████▉| 1999/2000 [38:27<00:01,  1.10s/iteration, mean_rewards=-213]\u001b[A\n",
            "Training: 100%|██████████| 2000/2000 [38:28<00:00,  1.15s/iteration, mean_rewards=-213]\n"
          ]
        }
      ],
      "source": [
        "opt = \"TRAC\"\n",
        "train(env, opt, peturbations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cns3O9h59MxI"
      },
      "source": [
        "## Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "M8HLRgLk9OCT",
        "outputId": "02ff9ffb-db4e-4004-e8c2-7ff41331bf5b"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot(env,seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
