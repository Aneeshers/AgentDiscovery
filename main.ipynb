{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbYsqcZiCps9",
        "outputId": "39f4e4a4-ffa1-4210-a8d1-4f7353bdd185"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: swig in /usr/local/lib/python3.10/dist-packages (4.2.1)\n",
            "Requirement already satisfied: gym[box2d] in /usr/local/lib/python3.10/dist-packages (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym[box2d]) (1.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym[box2d]) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym[box2d]) (0.0.8)\n",
            "Requirement already satisfied: box2d-py==2.3.5 in /usr/local/lib/python3.10/dist-packages (from gym[box2d]) (2.3.5)\n",
            "Requirement already satisfied: pygame==2.1.0 in /usr/local/lib/python3.10/dist-packages (from gym[box2d]) (2.1.0)\n",
            "Requirement already satisfied: swig==4.* in /usr/local/lib/python3.10/dist-packages (from gym[box2d]) (4.2.1)\n"
          ]
        }
      ],
      "source": [
        "#Update Gym\n",
        "!pip install swig\n",
        "!pip install gym[box2d] --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sffYfT8yO1s",
        "outputId": "248afbf0-d10a-4b91-bb21-08f1e485f472"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.26.2\n"
          ]
        }
      ],
      "source": [
        "import gym\n",
        "print(gym.__version__)\n",
        "# NOTE: Version should be 0.26.02"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3-P-T38BFfm"
      },
      "source": [
        "# Define PPO Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bgaZBJlxBDrW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.distributions import Categorical\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "class PolicyNetwork(torch.nn.Module):\n",
        "    def __init__(self, n=4, in_dim=128):\n",
        "        super(PolicyNetwork, self).__init__()\n",
        "\n",
        "        self.fc1 = torch.nn.Linear(in_dim, 128)\n",
        "        self.fc2 = torch.nn.Linear(128, 128)\n",
        "        self.fc3 = torch.nn.Linear(128, 128)\n",
        "        self.fc4 = torch.nn.Linear(128, n)\n",
        "        self.l_relu = torch.nn.LeakyReLU(0.1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.l_relu(self.fc1(x))\n",
        "        x = self.l_relu(self.fc2(x))\n",
        "        x = self.l_relu(self.fc3(x))\n",
        "        y = self.fc4(x)\n",
        "        y = F.softmax(y, dim=-1)\n",
        "        return y\n",
        "\n",
        "    def sample_action(self, state):\n",
        "\n",
        "        if not state is torch.Tensor:\n",
        "            state = torch.from_numpy(state).float().to(device)\n",
        "\n",
        "        if len(state.size()) == 1:\n",
        "            state = state.unsqueeze(0)\n",
        "\n",
        "        y = self(state)\n",
        "        dist = Categorical(y)\n",
        "        action = dist.sample()\n",
        "        log_probability = dist.log_prob(action)\n",
        "\n",
        "        return action.item(), log_probability.item()\n",
        "\n",
        "    def best_action(self, state):\n",
        "\n",
        "        if not state is torch.Tensor:\n",
        "            state = torch.from_numpy(state).float().to(device)\n",
        "\n",
        "        if len(state.size()) == 1:\n",
        "            state = state.unsqueeze(0)\n",
        "\n",
        "        y = self(state).squeeze()\n",
        "        action = torch.argmax(y)\n",
        "\n",
        "        return action.item()\n",
        "\n",
        "    def evaluate_actions(self, states, actions):\n",
        "        y = self(states)\n",
        "        dist = Categorical(y)\n",
        "        entropy = dist.entropy()\n",
        "        log_probabilities = dist.log_prob(actions)\n",
        "\n",
        "        return log_probabilities, entropy\n",
        "\n",
        "\n",
        "class ValueNetwork(torch.nn.Module):\n",
        "    def __init__(self, in_dim=128):\n",
        "        super(ValueNetwork, self).__init__()\n",
        "\n",
        "        self.fc1 = torch.nn.Linear(in_dim, 128)\n",
        "        self.fc2 = torch.nn.Linear(128, 128)\n",
        "        self.fc3 = torch.nn.Linear(128, 128)\n",
        "        self.fc4 = torch.nn.Linear(128, 1)\n",
        "        self.l_relu = torch.nn.LeakyReLU(0.1)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.l_relu(self.fc1(x))\n",
        "        x = self.l_relu(self.fc2(x))\n",
        "        x = self.l_relu(self.fc3(x))\n",
        "        y = self.fc4(x)\n",
        "\n",
        "        return y.squeeze(1)\n",
        "\n",
        "    def state_value(self, state):\n",
        "\n",
        "        if not state is torch.Tensor:\n",
        "            state = torch.from_numpy(state).float().to(device)\n",
        "\n",
        "        if len(state.size()) == 1:\n",
        "            state = state.unsqueeze(0)\n",
        "\n",
        "        y = self(state)\n",
        "\n",
        "        return y.item()\n",
        "\n",
        "\n",
        "def ac_loss_clipped(new_log_probabilities, old_log_probabilities, advantages, epsilon_clip=0.2):\n",
        "    probability_ratios = torch.exp(new_log_probabilities - old_log_probabilities)\n",
        "    clipped_probabiliy_ratios = torch.clamp(\n",
        "        probability_ratios, 1 - epsilon_clip, 1 + epsilon_clip\n",
        "    )\n",
        "\n",
        "    surrogate_1 = probability_ratios * advantages\n",
        "    surrogate_2 = clipped_probabiliy_ratios * advantages\n",
        "\n",
        "    return -torch.min(surrogate_1, surrogate_2)\n",
        "\n",
        "def train_combined_networks(policy_model, value_model, combined_optimizer, data_loader, epochs=40, clip=0.2):\n",
        "    c1 = 0.01  # Coefficient for entropy regularization\n",
        "    c2 = 0.5   # Coefficient for value loss weight\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        policy_losses = []\n",
        "        value_losses = []\n",
        "\n",
        "        for observations, actions, advantages, log_probabilities, rewards_to_go in data_loader:\n",
        "            observations = observations.float().to(device)\n",
        "            actions = actions.long().to(device)\n",
        "            advantages = advantages.float().to(device)\n",
        "            old_log_probabilities = log_probabilities.float().to(device)\n",
        "            rewards_to_go = rewards_to_go.float().to(device)\n",
        "\n",
        "            combined_optimizer.zero_grad()\n",
        "\n",
        "            new_log_probabilities, entropy = policy_model.evaluate_actions(observations, actions)\n",
        "            policy_loss = (\n",
        "                ac_loss_clipped(\n",
        "                    new_log_probabilities,\n",
        "                    old_log_probabilities,\n",
        "                    advantages,\n",
        "                    epsilon_clip=clip,\n",
        "                ).mean()\n",
        "                - c1 * entropy.mean()\n",
        "            )\n",
        "            policy_losses.append(policy_loss.item())\n",
        "\n",
        "            values = value_model(observations)\n",
        "            value_loss = c2 * F.mse_loss(values, rewards_to_go)\n",
        "            value_losses.append(value_loss.item())\n",
        "\n",
        "            total_loss = policy_loss + value_loss\n",
        "\n",
        "            total_loss.backward()\n",
        "            combined_optimizer.step()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pgY5fBlQBL3X"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "def cumulative_sum(array, gamma=1.0):\n",
        "    curr = 0\n",
        "    cumulative_array = []\n",
        "\n",
        "    for a in array[::-1]:\n",
        "        curr = a + gamma * curr\n",
        "        cumulative_array.append(curr)\n",
        "\n",
        "    return cumulative_array[::-1]\n",
        "\n",
        "\n",
        "class Episode:\n",
        "    def __init__(self, gamma=0.99, lambd=0.95):\n",
        "        self.observations = []\n",
        "        self.actions = []\n",
        "        self.advantages = []\n",
        "        self.rewards = []\n",
        "        self.rewards_to_go = []\n",
        "        self.values = []\n",
        "        self.log_probabilities = []\n",
        "        self.gamma = gamma\n",
        "        self.lambd = lambd\n",
        "\n",
        "    def append(\n",
        "        self, observation, action, reward, value, log_probability, reward_scale=20\n",
        "    ):\n",
        "        self.observations.append(observation)\n",
        "        self.actions.append(action)\n",
        "        self.rewards.append(reward / reward_scale)\n",
        "        self.values.append(value)\n",
        "        self.log_probabilities.append(log_probability)\n",
        "\n",
        "    def end_episode(self, last_value):\n",
        "        rewards = np.array(self.rewards + [last_value])\n",
        "        values = np.array(self.values + [last_value])\n",
        "        deltas = rewards[:-1] + self.gamma * values[1:] - values[:-1]\n",
        "        self.advantages = cumulative_sum(deltas.tolist(), gamma=self.gamma * self.lambd)\n",
        "        self.rewards_to_go = cumulative_sum(rewards.tolist(), gamma=self.gamma)[:-1]\n",
        "\n",
        "\n",
        "def normalize_list(array):\n",
        "    array = np.array(array)\n",
        "    array = (array - np.mean(array)) / (np.std(array) + 1e-5)\n",
        "    return array.tolist()\n",
        "\n",
        "\n",
        "class History(Dataset):\n",
        "    def __init__(self):\n",
        "        self.episodes = []\n",
        "        self.observations = []\n",
        "        self.actions = []\n",
        "        self.advantages = []\n",
        "        self.rewards = []\n",
        "        self.rewards_to_go = []\n",
        "        self.log_probabilities = []\n",
        "\n",
        "    def free_memory(self):\n",
        "        del self.episodes[:]\n",
        "        del self.observations[:]\n",
        "        del self.actions[:]\n",
        "        del self.advantages[:]\n",
        "        del self.rewards[:]\n",
        "        del self.rewards_to_go[:]\n",
        "        del self.log_probabilities[:]\n",
        "\n",
        "    def add_episode(self, episode):\n",
        "        self.episodes.append(episode)\n",
        "\n",
        "    def build_dataset(self):\n",
        "        for episode in self.episodes:\n",
        "            self.observations += episode.observations\n",
        "            self.actions += episode.actions\n",
        "            self.advantages += episode.advantages\n",
        "            self.rewards += episode.rewards\n",
        "            self.rewards_to_go += episode.rewards_to_go\n",
        "            self.log_probabilities += episode.log_probabilities\n",
        "\n",
        "        assert (\n",
        "            len(\n",
        "                {\n",
        "                    len(self.observations),\n",
        "                    len(self.actions),\n",
        "                    len(self.advantages),\n",
        "                    len(self.rewards),\n",
        "                    len(self.rewards_to_go),\n",
        "                    len(self.log_probabilities),\n",
        "                }\n",
        "            )\n",
        "            == 1\n",
        "        )\n",
        "\n",
        "        self.advantages = normalize_list(self.advantages)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.observations)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return (\n",
        "            self.observations[idx],\n",
        "            self.actions[idx],\n",
        "            self.advantages[idx],\n",
        "            self.log_probabilities[idx],\n",
        "            self.rewards_to_go[idx],\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSRo2IPxBQQy"
      },
      "source": [
        "# PACE Optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyERnJ0idJI9"
      },
      "source": [
        "## Define Erfi function in Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xN5ZOV0BSEo"
      },
      "outputs": [],
      "source": [
        "import scipy.special as sp\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.special import erfi as scipy_erfi\n",
        "import torch\n",
        "\n",
        "# We depend on Erfi function, but python.special currently has no implementation.\n",
        "# We instead modify and rely on https://github.com/redsnic/torch_erf\n",
        "\n",
        "def polyval(x,coeffs):\n",
        "    \"\"\"Implementation of the Horner scheme to evaluate a polynomial\n",
        "\n",
        "    taken from https://discuss.pytorch.org/t/polynomial-evaluation-by-horner-rule/67124\n",
        "\n",
        "    Args:\n",
        "        x (torch.Tensor): variable\n",
        "        coeffs (torch.Tensor): coefficients of the polynomial\n",
        "    \"\"\"\n",
        "    curVal=0\n",
        "    for curValIndex in range(len(coeffs)-1):\n",
        "        curVal=(curVal+coeffs[curValIndex])*x[0]\n",
        "    return(curVal+coeffs[len(coeffs)-1])\n",
        "\n",
        "\n",
        "class ERF_1994(torch.nn.Module):\n",
        "    \"\"\"Class to compute the error function of a complex number (extends torch.special.erf behavior)\n",
        "\n",
        "    This class is based on the algorithm proposed in:\n",
        "    Weideman, J. Andre C. \"Computation of the complex error function.\" SIAM Journal on Numerical Analysis 31.5 (1994): 1497-1518\n",
        "    \"\"\"\n",
        "    def __init__(self, n_coefs):\n",
        "        \"\"\"Defaul constructor\n",
        "\n",
        "        Args:\n",
        "            n_coefs (integer): The number of polynomial coefficients to use in the approximation\n",
        "        \"\"\"\n",
        "        super(ERF_1994, self).__init__()\n",
        "        # compute polynomial coefficients and other constants\n",
        "        self.N = n_coefs\n",
        "        self.i = torch.complex(torch.tensor(0.),torch.tensor(1.))\n",
        "        self.M = 2*self.N\n",
        "        self.M2 = 2*self.M\n",
        "        self.k = torch.linspace(-self.M+1, self.M-1, self.M2-1)\n",
        "        self.L = torch.sqrt(self.N/torch.sqrt(torch.tensor(2.)))\n",
        "        self.theta = self.k*torch.pi/self.M\n",
        "        self.t = self.L*torch.tan(self.theta/2)\n",
        "        self.f = torch.exp(-self.t**2)*(self.L**2 + self.t**2)\n",
        "        self.a = torch.fft.fft(torch.fft.fftshift(self.f)).real/self.M2\n",
        "        self.a = torch.flipud(self.a[1:self.N+1])\n",
        "\n",
        "    def w_algorithm(self, z):\n",
        "        \"\"\"Compute the Faddeeva function of a complex number\n",
        "\n",
        "        The constant coefficients are computed in the constructor of the class.\n",
        "\n",
        "        Weideman, J. Andre C. \"Computation of the complex error function.\" SIAM Journal on Numerical Analysis 31.5 (1994): 1497-1518\n",
        "\n",
        "        Args:\n",
        "            z (torch.Tensor): A tensor of complex numbers (any shape is allowed)\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: w(z) for each element of z\n",
        "        \"\"\"\n",
        "        Z = (self.L+self.i*z)/(self.L-self.i*z)\n",
        "        p = polyval(Z.unsqueeze(0), self.a)\n",
        "        w = 2*p/(self.L-self.i*z)**2+(1/torch.sqrt(torch.tensor(torch.pi)))/(self.L-self.i*z)\n",
        "        return w\n",
        "\n",
        "    def forward(self, z):\n",
        "        \"\"\"Compute the error function of a complex number\n",
        "\n",
        "        The result is computed by manipulating the Faddeeva function.\n",
        "\n",
        "        Args:\n",
        "            z (torch.Tensor): A tensor of complex numbers (any shape is allowed)\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: erf(z) for each element of z\n",
        "        \"\"\"\n",
        "        # exploit the symmetry of the error function\n",
        "        # find the sign of the real part\n",
        "        sign_r = torch.sign(z.real)\n",
        "        sign_i = torch.sign(z.imag)\n",
        "        # flip sign of imaginary part if negative\n",
        "        z = torch.complex(torch.abs(z.real), torch.abs(z.imag))\n",
        "        out = -torch.exp(torch.log(self.w_algorithm(z*self.i)) - z**2) + 1\n",
        "        return torch.complex(out.real*sign_r, out.imag*sign_i)\n",
        "\n",
        "    def backward(self, z):\n",
        "        \"\"\"Compute the gradient of the error function of a complex number.\n",
        "\n",
        "        As we know the analytical derivative of the the error function, we can use it directly.\n",
        "\n",
        "        Args:\n",
        "            z (torch.Tensor): A tensor of complex numbers (any shape is allowed)\n",
        "        Returns:\n",
        "            torch.Tensor: grad(erf(z)) for each element of x\n",
        "        \"\"\"\n",
        "        return 2/torch.sqrt(torch.tensor(torch.pi))*torch.exp(-z**2)\n",
        "\n",
        "erf_torch = ERF_1994(128)\n",
        "\n",
        "def erfi(x):\n",
        "    if not torch.is_floating_point(x):\n",
        "        x = x.to(torch.float32)\n",
        "\n",
        "    # Convert x to a complex tensor where the real part is zero\n",
        "    ix = torch.complex(torch.zeros_like(x), x)\n",
        "\n",
        "    # Compute erf(ix) / i\n",
        "    erfi_x = erf_torch(ix).imag  # Extract the imaginary part of erf(ix)\n",
        "    return erfi_x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3zE2Hd0dZJm"
      },
      "source": [
        "## PACE Wrapper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xccOJBKdTRU"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "from typing import Tuple, Any, Callable, Dict\n",
        "import torch\n",
        "\n",
        "# We closely follow the meta-optimizer structure from the code in\n",
        "# Cutkosky et. al 2023\n",
        "\n",
        "def _init_state(\n",
        "        optimizer: torch.optim.Optimizer,\n",
        "        theta_ref: Dict[torch.Tensor, torch.Tensor],\n",
        "        betas: Tuple[float],\n",
        "        s_prev: float,\n",
        "        eps: float):\n",
        "    if '_pace' not in optimizer.state:\n",
        "        optimizer.state['_pace'] = {\n",
        "            'betas': torch.tensor(betas),\n",
        "            's_prev': torch.tensor(s_prev),\n",
        "            'eps': eps,\n",
        "            's': torch.zeros(len(betas)),\n",
        "            'theta_ref': {},\n",
        "            'variance': torch.zeros(len(betas)),\n",
        "            'sigma': torch.full((len(betas),), 1e-8),\n",
        "            'iter_count': 0,\n",
        "        }\n",
        "        _init_reference(optimizer, theta_ref)\n",
        "\n",
        "def _init_reference(\n",
        "        optimizer: torch.optim.Optimizer,\n",
        "        theta_ref: Dict[torch.Tensor, torch.Tensor],):\n",
        "    '''\n",
        "    Args:\n",
        "        optimizer: optimizer instance to store reference for.\n",
        "        theta_ref: mapping of parameters to their initial values at the start of optimization.\n",
        "    '''\n",
        "    for group in optimizer.param_groups:\n",
        "        for p in group['params']:\n",
        "            optimizer.state['_pace'][p] = {\n",
        "                'ref': theta_ref[p].clone(),\n",
        "            }\n",
        "\n",
        "\n",
        "def _step(\n",
        "        optimizer: torch.optim.Optimizer,\n",
        "        base_step: Callable,\n",
        "        betas: Tuple[float],\n",
        "        s_prev: float,\n",
        "        eps: float,\n",
        "        ):\n",
        "    '''\n",
        "    Args:\n",
        "        optimizer: pace optimizer instance\n",
        "        base_step: The \"step\" function of the base optimizer\n",
        "        betas: list of beta values.\n",
        "        s_init: initial scale value.\n",
        "        eps: epsilon value.\n",
        "    '''\n",
        "\n",
        "    prev_grad = torch.is_grad_enabled()\n",
        "\n",
        "\n",
        "    torch.set_grad_enabled(False)\n",
        "    updates = {}\n",
        "    grads = {}\n",
        "    deltas = {}\n",
        "\n",
        "    for group in optimizer.param_groups:\n",
        "        for p in group['params']:\n",
        "\n",
        "            if p.grad is None:\n",
        "                grads[p] = None\n",
        "            else:\n",
        "                grads[p] = p.grad.clone()\n",
        "            updates[p] = p.data.clone()\n",
        "\n",
        "    torch.set_grad_enabled(prev_grad)\n",
        "    result = base_step(None)\n",
        "    torch.set_grad_enabled(False)\n",
        "\n",
        "    _init_state(optimizer, updates, betas, s_prev, eps)\n",
        "    pace_state = optimizer.state['_pace']\n",
        "\n",
        "\n",
        "    for group in optimizer.param_groups:\n",
        "        for p in group['params']:\n",
        "            if grads[p] is None:\n",
        "                continue\n",
        "\n",
        "            theta_ref = pace_state[p]['ref']\n",
        "\n",
        "            deltas[p] = (updates[p] - theta_ref)/(torch.sum(pace_state['s']) + pace_state['eps'])\n",
        "\n",
        "            updates[p].copy_(p-updates[p])\n",
        "\n",
        "    h = 0.0\n",
        "    for group in optimizer.param_groups:\n",
        "        for p in group['params']:\n",
        "\n",
        "            if grads[p] is None:\n",
        "                continue\n",
        "\n",
        "            grad = grads[p]\n",
        "\n",
        "            delta = deltas[p]\n",
        "            product = torch.dot(delta.flatten(), grad.flatten())\n",
        "            if product.isnan():\n",
        "                raise ValueError(\"NaNs in product\")\n",
        "            h += product\n",
        "\n",
        "            delta.add_(updates[p])\n",
        "\n",
        "    device = h.device\n",
        "\n",
        "    for key in pace_state:\n",
        "        try:\n",
        "            if pace_state[key].device != device:\n",
        "                pace_state[key] = pace_state[key].to(device)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    s = pace_state['s']\n",
        "    s_prev = pace_state['s_prev']\n",
        "    betas = pace_state['betas']\n",
        "    eps = pace_state['eps']\n",
        "    variance = pace_state['variance']\n",
        "    sigma = pace_state['sigma']\n",
        "    pace_state['iter_count'] += 1\n",
        "\n",
        "    variance.mul_(\n",
        "        betas**2).add_(torch.square(h))\n",
        "    sigma.mul_(betas).sub_(h)\n",
        "    f_term = s_prev / (erfi(torch.tensor(1.0) / torch.sqrt(torch.tensor(2.0))))\n",
        "    s_term = erfi(sigma / (torch.sqrt(torch.tensor(2.0)) * torch.sqrt(variance) + eps))\n",
        "    if (f_term * s_term).isnan().any():\n",
        "        raise ValueError(\"NaNs in s\")\n",
        "    s.copy_(f_term * s_term)\n",
        "\n",
        "    for group in optimizer.param_groups:\n",
        "        for p in group['params']:\n",
        "\n",
        "            if grads[p] is None:\n",
        "                continue\n",
        "\n",
        "            theta_ref = pace_state[p]['ref']\n",
        "            delta = deltas[p]\n",
        "            s_sum = torch.sum(s)\n",
        "\n",
        "            scale = max(s_sum, 0.0)\n",
        "            p.copy_(theta_ref + delta * scale)\n",
        "\n",
        "    log_data = {\n",
        "        'iter_count': pace_state['iter_count'],\n",
        "        's': torch.sum(s).item(),\n",
        "    }\n",
        "\n",
        "    torch.set_grad_enabled(prev_grad)\n",
        "    return result, log_data\n",
        "\n",
        "\n",
        "class pace:\n",
        "    pass\n",
        "\n",
        "def is_pace(opt):\n",
        "    return isinstance(opt, pace)\n",
        "\n",
        "def start_pace(\n",
        "        log_file,\n",
        "        Base: Any,\n",
        "        betas: Tuple[float] = (0.9, 0.99, 0.999, 0.9999,\n",
        "                               0.99999, 0.999999),\n",
        "        s_prev: float = 1e-8,\n",
        "        eps: float = 1e-8,\n",
        "        ):\n",
        "\n",
        "    class PACEOPT(Base, pace):\n",
        "        '''\n",
        "        Wraps the base opt with PACE.\n",
        "\n",
        "        '''\n",
        "\n",
        "        def step(self):\n",
        "            result, log_data = _step(self, super().step, betas, s_prev, eps)\n",
        "            with open (log_file, 'a') as f:\n",
        "                f.write(str(log_data) + '\\n')\n",
        "            return result\n",
        "\n",
        "    PACEOPT.__name__ += Base.__name__\n",
        "\n",
        "    return PACEOPT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZJjCxSEBqIn"
      },
      "source": [
        "# Lifelong Control Setting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qXh9tafBtrn"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from tqdm import tqdm\n",
        "import random\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XcILqsPSDdQO"
      },
      "outputs": [],
      "source": [
        "# SET THE SEED\n",
        "seed = 2024\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "\n",
        "# num distribution shifts\n",
        "levels = 10\n",
        "\n",
        "# Hyperparameters\n",
        "lr = 0.01\n",
        "max_episodes = 2\n",
        "train_epochs = 5\n",
        "max_timesteps = 400\n",
        "state_scale = 1.0\n",
        "reward_scale = 20.0\n",
        "batch_size = 32\n",
        "\n",
        "# when to introduce distribution shift\n",
        "level_switch = 200\n",
        "max_iterations = levels * level_switch\n",
        "\n",
        "# peturbation range\n",
        "rp_range = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ITlv3qL1B0Q7"
      },
      "outputs": [],
      "source": [
        "def get_peturbations(env_name, seed):\n",
        "  env = gym.make(env_name, render_mode=\"rgb_array\")\n",
        "  observation = env.reset()[0]\n",
        "  random_perturbations = [\n",
        "        np.random.normal(0, rp_range, observation.shape) for _ in range(levels)\n",
        "    ]\n",
        "  # make the first random perturbation zero\n",
        "  random_perturbations[0] = np.zeros(observation.shape)\n",
        "  return random_perturbations\n",
        "def train(env_name, opt_choice, random_perturbations):\n",
        "\n",
        "    # Create log txt files\n",
        "    pace_reward_log_file = f'logs/pace_reward_log_{env_name}_{seed}.txt'\n",
        "    base_reward_log_file = f'logs/base_reward_log_{env_name}_{seed}.txt'\n",
        "\n",
        "    # Setup env\n",
        "    env = gym.make(env_name, render_mode=\"rgb_array\")\n",
        "    observation = env.reset()[0]\n",
        "    n_actions = env.action_space.n\n",
        "    feature_dim = observation.size\n",
        "\n",
        "    tqdm_bar = tqdm(range(max_iterations), desc=\"Training\", unit=\"iteration\")\n",
        "\n",
        "    value_model = ValueNetwork(in_dim=feature_dim).to(device)\n",
        "    policy_model = PolicyNetwork(in_dim=feature_dim, n=n_actions).to(device)\n",
        "\n",
        "    pace_combined_optimizer = start_pace(log_file=f'logs/pace_{env_name}.text', Base=optim.Adam)(\n",
        "        [\n",
        "            {\"params\": policy_model.parameters(), \"lr\": lr},\n",
        "            {\"params\": value_model.parameters(), \"lr\": lr},\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    base_combined_optimizer = torch.optim.Adam(\n",
        "        [\n",
        "            {\"params\": policy_model.parameters(), \"lr\": lr},\n",
        "            {\"params\": value_model.parameters(), \"lr\": lr},\n",
        "        ]\n",
        "    )\n",
        "    if opt_choice == \"PACE\":\n",
        "        combined_optimizer = pace_combined_optimizer\n",
        "        reward_log_file = pace_reward_log_file\n",
        "        print(\"USING PACE.\")\n",
        "    if opt_choice == \"base\":\n",
        "        combined_optimizer = base_combined_optimizer\n",
        "        reward_log_file = base_reward_log_file\n",
        "    history = History()\n",
        "    level = 0\n",
        "    for ite in tqdm_bar:\n",
        "        # Switch perturbation level\n",
        "        if ite % level_switch == 0:\n",
        "            random_perturbation = random_perturbations[level]\n",
        "            level += 1\n",
        "\n",
        "        episodes_reward = []\n",
        "\n",
        "        for episode_i in range(max_episodes):\n",
        "            observation = env.reset()[0]\n",
        "            observation += random_perturbation\n",
        "            episode = Episode()\n",
        "\n",
        "            for timestep in range(max_timesteps):\n",
        "                action, log_probability = policy_model.sample_action(observation / state_scale)\n",
        "                value = value_model.state_value(observation / state_scale)\n",
        "\n",
        "                new_observation, reward, done, truncated, info = env.step(action)\n",
        "                new_observation += random_perturbation\n",
        "\n",
        "                episode.append(\n",
        "                    observation=observation / state_scale,\n",
        "                    action=action,\n",
        "                    reward=reward,\n",
        "                    value=value,\n",
        "                    log_probability=log_probability,\n",
        "                    reward_scale=reward_scale,\n",
        "                )\n",
        "\n",
        "                observation = new_observation\n",
        "\n",
        "                if done:\n",
        "                    episode.end_episode(last_value=0)\n",
        "                    break\n",
        "\n",
        "                if timestep == max_timesteps - 1:\n",
        "                    value = value_model.state_value(observation / state_scale)\n",
        "                    episode.end_episode(last_value=value)\n",
        "\n",
        "            episodes_reward.append(reward_scale * np.sum(episode.rewards))\n",
        "            history.add_episode(episode)\n",
        "\n",
        "        mean_rewards = np.mean(episodes_reward)\n",
        "        tqdm_bar.set_postfix(mean_rewards=mean_rewards)\n",
        "\n",
        "        with open(reward_log_file, 'a') as f:\n",
        "            f.write(str(mean_rewards) + '\\n')\n",
        "        history.build_dataset()\n",
        "        data_loader = DataLoader(history, batch_size=batch_size, shuffle=True)\n",
        "        train_combined_networks(policy_model, value_model, combined_optimizer, data_loader, train_epochs)\n",
        "        history.free_memory()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iBE7Qhs-Fuw"
      },
      "source": [
        "### Plotting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4H3Ws0v-Da8"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def read_data(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        data = file.readlines()\n",
        "    return data\n",
        "\n",
        "def plot(env_name, seed):\n",
        "    # Read data from files\n",
        "    pace_data = read_data(f'logs/pace_reward_log_{env_name}_{seed}.txt')\n",
        "    base_data = read_data(f'logs/base_reward_log_{env_name}_{seed}.txt')\n",
        "\n",
        "    # Convert data to float\n",
        "    pace_data = [float(i) for i in pace_data]\n",
        "    base_data = [float(i) for i in base_data]\n",
        "\n",
        "\n",
        "    # Smooth pace and base data\n",
        "    window = 5\n",
        "    pace_data = np.convolve(pace_data, np.ones(window) / window, mode='valid')\n",
        "    base_data = np.convolve(base_data, np.ones(window) / window, mode='valid')\n",
        "\n",
        "    # Create a plot with seaborn\n",
        "    sns.set(style=\"darkgrid\")\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    plt.plot(base_data, label='base', color='#4a69bd')\n",
        "    plt.plot(pace_data, label='PACE', color='#b71540')\n",
        "\n",
        "    plt.xlabel('Timesteps')\n",
        "    plt.ylabel('Mean Episode Reward')\n",
        "    plt.title(f'{env_name}', fontsize=24)\n",
        "    plt.legend()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pF8BK3-B6-_2"
      },
      "source": [
        "# Compare one seed results for Acrobot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kjeR_wo7DxW"
      },
      "source": [
        "## Train Base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjGAMqwk7F6R",
        "outputId": "566868e2-157d-4a13-a3a4-8fc7e5c7c5d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Online Peturbations are\n",
            "[array([0., 0., 0., 0., 0., 0.]), array([ 2.17157788,  0.34053703,  2.23921071, -1.31344863, -5.58455019,\n",
            "       -1.31314464]), array([ 0.64917973, -3.78084544, -0.22526347,  1.38430828, -2.41044139,\n",
            "        0.2959818 ]), array([ 1.38837342, -0.41074039,  4.29486731, -1.89647011,  0.57554351,\n",
            "       -0.2898865 ]), array([ 0.69971711, -0.74984953,  1.69061481,  1.49414689, -2.87732306,\n",
            "       -1.74682857]), array([-2.14713326,  0.4396411 ,  0.69225986,  2.16534063,  2.05933155,\n",
            "        1.17132279]), array([ 0.59946581,  0.86106039,  2.59435245, -2.60952034, -1.13732226,\n",
            "       -2.84250946]), array([ 6.13985793,  0.84625234, -1.09965102, -3.67620658, -2.38453755,\n",
            "       -0.92809013]), array([ 2.8292598 ,  3.0283006 ,  2.54238781, -0.29499719, -1.99801052,\n",
            "        3.57734236]), array([ 1.31372917, -0.01099749, -0.65765122,  1.81880701, -1.59662735,\n",
            "       -1.40798752])]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2000/2000 [1:06:24<00:00,  1.99s/iteration, mean_rewards=-400]\n"
          ]
        }
      ],
      "source": [
        "peturbations = get_peturbations(\"Acrobot-v1\", seed)\n",
        "print(\"Online Peturbations are\")\n",
        "print(peturbations)\n",
        "env = \"Acrobot-v1\"\n",
        "opt = \"base\"\n",
        "train(env, opt, peturbations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyCzCOmh7L6Z"
      },
      "source": [
        "## Train PACE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JieNwXI7NWy",
        "outputId": "e8c51e39-a390-4484-b04c-1f65f3993499"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Online Peturbations are\n",
            "[array([0., 0., 0., 0., 0., 0.]), array([ 2.17157788,  0.34053703,  2.23921071, -1.31344863, -5.58455019,\n",
            "       -1.31314464]), array([ 0.64917973, -3.78084544, -0.22526347,  1.38430828, -2.41044139,\n",
            "        0.2959818 ]), array([ 1.38837342, -0.41074039,  4.29486731, -1.89647011,  0.57554351,\n",
            "       -0.2898865 ]), array([ 0.69971711, -0.74984953,  1.69061481,  1.49414689, -2.87732306,\n",
            "       -1.74682857]), array([-2.14713326,  0.4396411 ,  0.69225986,  2.16534063,  2.05933155,\n",
            "        1.17132279]), array([ 0.59946581,  0.86106039,  2.59435245, -2.60952034, -1.13732226,\n",
            "       -2.84250946]), array([ 6.13985793,  0.84625234, -1.09965102, -3.67620658, -2.38453755,\n",
            "       -0.92809013]), array([ 2.8292598 ,  3.0283006 ,  2.54238781, -0.29499719, -1.99801052,\n",
            "        3.57734236]), array([ 1.31372917, -0.01099749, -0.65765122,  1.81880701, -1.59662735,\n",
            "       -1.40798752])]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:   0%|          | 0/2000 [00:00<?, ?iteration/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "USING PACE.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2000/2000 [1:01:54<00:00,  1.86s/iteration, mean_rewards=-400]\n"
          ]
        }
      ],
      "source": [
        "print(\"Online Peturbations are\")\n",
        "print(peturbations)\n",
        "opt = \"PACE\"\n",
        "train(env, opt, peturbations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAkxrtxr7Pad"
      },
      "source": [
        "## Plot Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 584
        },
        "id": "xZGOsa1H7Q3Y",
        "outputId": "0007d167-694f-4524-dc51-a7da12b13d3e"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot(env,seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptPG30C4-R2J"
      },
      "source": [
        "# Compare one seed results for CartPole"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cf69AqiBCUaN"
      },
      "source": [
        "# Train Base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJPMtCpNCT4K",
        "outputId": "2ad36023-85e4-4995-9e3c-c94ceca9ec2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Online Peturbations are\n",
            "[array([0., 0., 0., 0.]), array([ 1.83210361,  2.32065927, -5.239924  , -2.65058914]), array([0.91997724, 0.20410329, 2.10710556, 3.24808522]), array([-3.00127004, -0.55566338,  2.38799004,  1.72363065]), array([-0.83409209, -0.49907283,  1.88735471, -1.53262128]), array([ 0.41645746,  2.81744585, -2.97820802, -2.95161707]), array([ 1.98169263, -1.76646085, -0.73236775, -3.06941007]), array([-0.70315102,  1.27983623,  1.37847833,  1.51450473]), array([-2.86109954, -0.8577586 , -1.37002372, -0.25128173]), array([ 2.28917448,  0.65441957, -0.27345488,  0.35838783])]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/2000 [00:00<?, ?iteration/s]/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  if not isinstance(terminated, (bool, np.bool8)):\n",
            "Training: 100%|██████████| 2000/2000 [03:44<00:00,  8.92iteration/s, mean_rewards=9.5]\n"
          ]
        }
      ],
      "source": [
        "peturbations = get_peturbations(\"CartPole-v1\", seed)\n",
        "print(\"Online Peturbations are\")\n",
        "print(peturbations)\n",
        "env = \"CartPole-v1\"\n",
        "opt = \"base\"\n",
        "train(env, opt, peturbations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_ZKyg2MDQ5j"
      },
      "source": [
        "# Train PACE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsc96nqxCZ9_",
        "outputId": "1cd1bfcb-c2ae-44fd-e3ad-8b4eb015ec7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Online Peturbations are\n",
            "[array([0., 0., 0., 0.]), array([ 1.83210361,  2.32065927, -5.239924  , -2.65058914]), array([0.91997724, 0.20410329, 2.10710556, 3.24808522]), array([-3.00127004, -0.55566338,  2.38799004,  1.72363065]), array([-0.83409209, -0.49907283,  1.88735471, -1.53262128]), array([ 0.41645746,  2.81744585, -2.97820802, -2.95161707]), array([ 1.98169263, -1.76646085, -0.73236775, -3.06941007]), array([-0.70315102,  1.27983623,  1.37847833,  1.51450473]), array([-2.86109954, -0.8577586 , -1.37002372, -0.25128173]), array([ 2.28917448,  0.65441957, -0.27345488,  0.35838783])]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/2000 [00:00<?, ?iteration/s, mean_rewards=26]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "USING PACE.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2000/2000 [23:24<00:00,  1.42iteration/s, mean_rewards=303]\n"
          ]
        }
      ],
      "source": [
        "print(\"Online Peturbations are\")\n",
        "print(peturbations)\n",
        "opt = \"PACE\"\n",
        "train(env, opt, peturbations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGj9Xlva-gZ_"
      },
      "source": [
        "## Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 584
        },
        "id": "BF41I9hz-hxl",
        "outputId": "2489d1f3-20d5-47ba-dd05-82ab01197469"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot(env,seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvrCDPnp8vhW"
      },
      "source": [
        "# Compare one seed results for LunarLander"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zl_ZQ9yy9JFc"
      },
      "source": [
        "## Train Base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "FP3apiGk8ym1",
        "outputId": "56181e99-3b0c-4763-f0cd-fb677c13fda0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Online Peturbations are\n",
            "[array([0., 0., 0., 0., 0., 0., 0., 0.]), array([-2.0079268 ,  0.65043091,  2.79887304, -0.89485782, -2.45459832,\n",
            "       -2.20658831, -1.69573544, -1.09117524]), array([ 0.17443612,  0.20773286,  1.37988336,  0.94118602, -3.22100874,\n",
            "        2.25633408, -1.40989297, -3.26433332]), array([ 0.80256681, -0.28995543, -1.23964918, -1.00915434,  1.83726094,\n",
            "       -0.04131756, -0.34566563,  0.43507223]), array([-2.61347919,  0.16253191, -0.49465057,  1.62261508,  0.21936038,\n",
            "        3.78905087,  1.18040223,  0.366775  ]), array([-1.25746734, -2.2225763 , -1.90403545,  3.55554009,  1.10756424,\n",
            "       -0.72152412,  2.56358724, -4.10257526]), array([-1.76960483, -0.40704985, -5.2108199 ,  3.25156089,  2.9457686 ,\n",
            "       -1.01028411,  0.08907027, -0.38054472]), array([ 2.60647874,  1.77401358,  0.10560635,  4.91972652, -1.88837331,\n",
            "       -0.7740599 ,  1.03906547,  0.74652167]), array([ 1.38343614, -0.10384657,  2.18803684,  1.92105522,  1.92164754,\n",
            "        0.52874226,  2.21652274, -1.1928955 ]), array([ 3.20886394,  0.88459322,  1.30593826, -2.89332244, -2.83006294,\n",
            "       -2.53234813,  2.85362429, -0.73383654])]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:   0%|          | 0/2000 [00:00<?, ?iteration/s]\u001b[A/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  if not isinstance(terminated, (bool, np.bool8)):\n",
            "\n",
            "Training:   0%|          | 0/2000 [00:01<?, ?iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:   0%|          | 1/2000 [00:02<1:13:24,  2.20s/iteration, mean_rewards=-147]\u001b[A\n",
            "Training:   0%|          | 1/2000 [00:02<1:13:24,  2.20s/iteration, mean_rewards=-178]\u001b[A\n",
            "Training:   0%|          | 2/2000 [00:02<41:50,  1.26s/iteration, mean_rewards=-178]  \u001b[A\n",
            "Training:   0%|          | 2/2000 [00:03<41:50,  1.26s/iteration, mean_rewards=-112]\u001b[A\n",
            "Training:   0%|          | 3/2000 [00:03<31:22,  1.06iteration/s, mean_rewards=-112]\u001b[A\n",
            "Training:   0%|          | 3/2000 [00:03<31:22,  1.06iteration/s, mean_rewards=-53] \u001b[A\n",
            "Training:   0%|          | 4/2000 [00:04<28:02,  1.19iteration/s, mean_rewards=-53]\u001b[A\n",
            "Training:   0%|          | 4/2000 [00:04<28:02,  1.19iteration/s, mean_rewards=-278]\u001b[A\n",
            "Training:   0%|          | 5/2000 [00:04<25:51,  1.29iteration/s, mean_rewards=-278]\u001b[A\n",
            "Training:   0%|          | 5/2000 [00:05<25:51,  1.29iteration/s, mean_rewards=-32.1]\u001b[A\n",
            "Training:   0%|          | 6/2000 [00:05<22:44,  1.46iteration/s, mean_rewards=-32.1]\u001b[A\n",
            "Training:   0%|          | 6/2000 [00:05<22:44,  1.46iteration/s, mean_rewards=-594] \u001b[A\n",
            "Training:   0%|          | 7/2000 [00:05<22:11,  1.50iteration/s, mean_rewards=-594]\u001b[A\n",
            "Training:   0%|          | 7/2000 [00:06<22:11,  1.50iteration/s, mean_rewards=-476]\u001b[A\n",
            "Training:   0%|          | 8/2000 [00:06<21:05,  1.57iteration/s, mean_rewards=-476]\u001b[A\n",
            "Training:   0%|          | 8/2000 [00:06<21:05,  1.57iteration/s, mean_rewards=-532]\u001b[A\n",
            "Training:   0%|          | 9/2000 [00:06<19:56,  1.66iteration/s, mean_rewards=-532]\u001b[A\n",
            "Training:   0%|          | 9/2000 [00:07<19:56,  1.66iteration/s, mean_rewards=-406]\u001b[A\n",
            "Training:   0%|          | 10/2000 [00:07<18:23,  1.80iteration/s, mean_rewards=-406]\u001b[A\n",
            "Training:   0%|          | 10/2000 [00:07<18:23,  1.80iteration/s, mean_rewards=-201]\u001b[A\n",
            "Training:   1%|          | 11/2000 [00:07<16:28,  2.01iteration/s, mean_rewards=-201]\u001b[A\n",
            "Training:   1%|          | 11/2000 [00:08<16:28,  2.01iteration/s, mean_rewards=-373]\u001b[A\n",
            "Training:   1%|          | 12/2000 [00:08<15:57,  2.08iteration/s, mean_rewards=-373]\u001b[A\n",
            "Training:   1%|          | 12/2000 [00:08<15:57,  2.08iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:   1%|          | 13/2000 [00:08<15:02,  2.20iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:   1%|          | 13/2000 [00:08<15:02,  2.20iteration/s, mean_rewards=-254]\u001b[A\n",
            "Training:   1%|          | 14/2000 [00:09<15:30,  2.13iteration/s, mean_rewards=-254]\u001b[A\n",
            "Training:   1%|          | 14/2000 [00:09<15:30,  2.13iteration/s, mean_rewards=-258]\u001b[A\n",
            "Training:   1%|          | 15/2000 [00:09<15:17,  2.16iteration/s, mean_rewards=-258]\u001b[A\n",
            "Training:   1%|          | 15/2000 [00:09<15:17,  2.16iteration/s, mean_rewards=-94.2]\u001b[A\n",
            "Training:   1%|          | 16/2000 [00:09<15:08,  2.18iteration/s, mean_rewards=-94.2]\u001b[A\n",
            "Training:   1%|          | 16/2000 [00:10<15:08,  2.18iteration/s, mean_rewards=-175] \u001b[A\n",
            "Training:   1%|          | 17/2000 [00:10<16:32,  2.00iteration/s, mean_rewards=-175]\u001b[A\n",
            "Training:   1%|          | 17/2000 [00:10<16:32,  2.00iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:   1%|          | 18/2000 [00:11<16:09,  2.04iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:   1%|          | 18/2000 [00:11<16:09,  2.04iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:   1%|          | 19/2000 [00:11<16:39,  1.98iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:   1%|          | 19/2000 [00:11<16:39,  1.98iteration/s, mean_rewards=-167]\u001b[A\n",
            "Training:   1%|          | 20/2000 [00:12<15:39,  2.11iteration/s, mean_rewards=-167]\u001b[A\n",
            "Training:   1%|          | 20/2000 [00:12<15:39,  2.11iteration/s, mean_rewards=-179]\u001b[A\n",
            "Training:   1%|          | 21/2000 [00:12<15:30,  2.13iteration/s, mean_rewards=-179]\u001b[A\n",
            "Training:   1%|          | 21/2000 [00:12<15:30,  2.13iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:   1%|          | 22/2000 [00:12<15:32,  2.12iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:   1%|          | 22/2000 [00:13<15:32,  2.12iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:   1%|          | 23/2000 [00:13<17:08,  1.92iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:   1%|          | 23/2000 [00:13<17:08,  1.92iteration/s, mean_rewards=-191]\u001b[A\n",
            "Training:   1%|          | 24/2000 [00:14<17:03,  1.93iteration/s, mean_rewards=-191]\u001b[A\n",
            "Training:   1%|          | 24/2000 [00:14<17:03,  1.93iteration/s, mean_rewards=-222]\u001b[A\n",
            "Training:   1%|▏         | 25/2000 [00:14<15:40,  2.10iteration/s, mean_rewards=-222]\u001b[A\n",
            "Training:   1%|▏         | 25/2000 [00:14<15:40,  2.10iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:   1%|▏         | 26/2000 [00:14<14:11,  2.32iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:   1%|▏         | 26/2000 [00:15<14:11,  2.32iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:   1%|▏         | 27/2000 [00:15<13:10,  2.50iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:   1%|▏         | 27/2000 [00:15<13:10,  2.50iteration/s, mean_rewards=-254]\u001b[A\n",
            "Training:   1%|▏         | 28/2000 [00:15<12:53,  2.55iteration/s, mean_rewards=-254]\u001b[A\n",
            "Training:   1%|▏         | 28/2000 [00:15<12:53,  2.55iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:   1%|▏         | 29/2000 [00:15<12:13,  2.69iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:   1%|▏         | 29/2000 [00:16<12:13,  2.69iteration/s, mean_rewards=-178]\u001b[A\n",
            "Training:   2%|▏         | 30/2000 [00:16<13:09,  2.49iteration/s, mean_rewards=-178]\u001b[A\n",
            "Training:   2%|▏         | 30/2000 [00:16<13:09,  2.49iteration/s, mean_rewards=-293]\u001b[A\n",
            "Training:   2%|▏         | 31/2000 [00:16<14:19,  2.29iteration/s, mean_rewards=-293]\u001b[A\n",
            "Training:   2%|▏         | 31/2000 [00:17<14:19,  2.29iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:   2%|▏         | 32/2000 [00:17<14:31,  2.26iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:   2%|▏         | 32/2000 [00:17<14:31,  2.26iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:   2%|▏         | 33/2000 [00:17<14:51,  2.21iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:   2%|▏         | 33/2000 [00:18<14:51,  2.21iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:   2%|▏         | 34/2000 [00:18<16:20,  2.01iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:   2%|▏         | 34/2000 [00:18<16:20,  2.01iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:   2%|▏         | 35/2000 [00:18<15:32,  2.11iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:   2%|▏         | 35/2000 [00:19<15:32,  2.11iteration/s, mean_rewards=-339]\u001b[A\n",
            "Training:   2%|▏         | 36/2000 [00:19<16:08,  2.03iteration/s, mean_rewards=-339]\u001b[A\n",
            "Training:   2%|▏         | 36/2000 [00:19<16:08,  2.03iteration/s, mean_rewards=-172]\u001b[A\n",
            "Training:   2%|▏         | 37/2000 [00:19<14:48,  2.21iteration/s, mean_rewards=-172]\u001b[A\n",
            "Training:   2%|▏         | 37/2000 [00:19<14:48,  2.21iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:   2%|▏         | 38/2000 [00:20<14:04,  2.32iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:   2%|▏         | 38/2000 [00:20<14:04,  2.32iteration/s, mean_rewards=-313]\u001b[A\n",
            "Training:   2%|▏         | 39/2000 [00:20<13:43,  2.38iteration/s, mean_rewards=-313]\u001b[A\n",
            "Training:   2%|▏         | 39/2000 [00:20<13:43,  2.38iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:   2%|▏         | 40/2000 [00:20<13:26,  2.43iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:   2%|▏         | 40/2000 [00:21<13:26,  2.43iteration/s, mean_rewards=-112]\u001b[A\n",
            "Training:   2%|▏         | 41/2000 [00:21<13:00,  2.51iteration/s, mean_rewards=-112]\u001b[A\n",
            "Training:   2%|▏         | 41/2000 [00:21<13:00,  2.51iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:   2%|▏         | 42/2000 [00:21<12:22,  2.64iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:   2%|▏         | 42/2000 [00:21<12:22,  2.64iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:   2%|▏         | 43/2000 [00:21<12:30,  2.61iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:   2%|▏         | 43/2000 [00:22<12:30,  2.61iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:   2%|▏         | 44/2000 [00:22<13:49,  2.36iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:   2%|▏         | 44/2000 [00:22<13:49,  2.36iteration/s, mean_rewards=-258]\u001b[A\n",
            "Training:   2%|▏         | 45/2000 [00:23<15:12,  2.14iteration/s, mean_rewards=-258]\u001b[A\n",
            "Training:   2%|▏         | 45/2000 [00:23<15:12,  2.14iteration/s, mean_rewards=-167]\u001b[A\n",
            "Training:   2%|▏         | 46/2000 [00:23<14:07,  2.31iteration/s, mean_rewards=-167]\u001b[A\n",
            "Training:   2%|▏         | 46/2000 [00:23<14:07,  2.31iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:   2%|▏         | 47/2000 [00:23<13:34,  2.40iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:   2%|▏         | 47/2000 [00:24<13:34,  2.40iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:   2%|▏         | 48/2000 [00:24<13:35,  2.39iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:   2%|▏         | 48/2000 [00:24<13:35,  2.39iteration/s, mean_rewards=-197]\u001b[A\n",
            "Training:   2%|▏         | 49/2000 [00:24<14:09,  2.30iteration/s, mean_rewards=-197]\u001b[A\n",
            "Training:   2%|▏         | 49/2000 [00:24<14:09,  2.30iteration/s, mean_rewards=-231]\u001b[A\n",
            "Training:   2%|▎         | 50/2000 [00:25<14:00,  2.32iteration/s, mean_rewards=-231]\u001b[A\n",
            "Training:   2%|▎         | 50/2000 [00:25<14:00,  2.32iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:   3%|▎         | 51/2000 [00:25<13:21,  2.43iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:   3%|▎         | 51/2000 [00:25<13:21,  2.43iteration/s, mean_rewards=-95.2]\u001b[A\n",
            "Training:   3%|▎         | 52/2000 [00:25<12:47,  2.54iteration/s, mean_rewards=-95.2]\u001b[A\n",
            "Training:   3%|▎         | 52/2000 [00:26<12:47,  2.54iteration/s, mean_rewards=-230] \u001b[A\n",
            "Training:   3%|▎         | 53/2000 [00:26<13:36,  2.38iteration/s, mean_rewards=-230]\u001b[A\n",
            "Training:   3%|▎         | 53/2000 [00:26<13:36,  2.38iteration/s, mean_rewards=-185]\u001b[A\n",
            "Training:   3%|▎         | 54/2000 [00:26<13:21,  2.43iteration/s, mean_rewards=-185]\u001b[A\n",
            "Training:   3%|▎         | 54/2000 [00:27<13:21,  2.43iteration/s, mean_rewards=-435]\u001b[A\n",
            "Training:   3%|▎         | 55/2000 [00:27<15:12,  2.13iteration/s, mean_rewards=-435]\u001b[A\n",
            "Training:   3%|▎         | 55/2000 [00:27<15:12,  2.13iteration/s, mean_rewards=-166]\u001b[A\n",
            "Training:   3%|▎         | 56/2000 [00:27<15:23,  2.11iteration/s, mean_rewards=-166]\u001b[A\n",
            "Training:   3%|▎         | 56/2000 [00:27<15:23,  2.11iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:   3%|▎         | 57/2000 [00:28<14:22,  2.25iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:   3%|▎         | 57/2000 [00:28<14:22,  2.25iteration/s, mean_rewards=-252]\u001b[A\n",
            "Training:   3%|▎         | 58/2000 [00:28<13:24,  2.41iteration/s, mean_rewards=-252]\u001b[A\n",
            "Training:   3%|▎         | 58/2000 [00:28<13:24,  2.41iteration/s, mean_rewards=-347]\u001b[A\n",
            "Training:   3%|▎         | 59/2000 [00:28<13:25,  2.41iteration/s, mean_rewards=-347]\u001b[A\n",
            "Training:   3%|▎         | 59/2000 [00:29<13:25,  2.41iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:   3%|▎         | 60/2000 [00:29<12:53,  2.51iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:   3%|▎         | 60/2000 [00:29<12:53,  2.51iteration/s, mean_rewards=-92.2]\u001b[A\n",
            "Training:   3%|▎         | 61/2000 [00:30<18:58,  1.70iteration/s, mean_rewards=-92.2]\u001b[A\n",
            "Training:   3%|▎         | 61/2000 [00:30<18:58,  1.70iteration/s, mean_rewards=-133] \u001b[A\n",
            "Training:   3%|▎         | 62/2000 [00:31<20:41,  1.56iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:   3%|▎         | 62/2000 [00:31<20:41,  1.56iteration/s, mean_rewards=-59.2]\u001b[A\n",
            "Training:   3%|▎         | 63/2000 [00:32<24:26,  1.32iteration/s, mean_rewards=-59.2]\u001b[A\n",
            "Training:   3%|▎         | 63/2000 [00:33<24:26,  1.32iteration/s, mean_rewards=-240] \u001b[A\n",
            "Training:   3%|▎         | 64/2000 [00:33<29:03,  1.11iteration/s, mean_rewards=-240]\u001b[A\n",
            "Training:   3%|▎         | 64/2000 [00:33<29:03,  1.11iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:   3%|▎         | 65/2000 [00:33<23:12,  1.39iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:   3%|▎         | 65/2000 [00:33<23:12,  1.39iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:   3%|▎         | 66/2000 [00:33<19:53,  1.62iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:   3%|▎         | 66/2000 [00:34<19:53,  1.62iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:   3%|▎         | 67/2000 [00:34<17:13,  1.87iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:   3%|▎         | 67/2000 [00:34<17:13,  1.87iteration/s, mean_rewards=-104]\u001b[A\n",
            "Training:   3%|▎         | 68/2000 [00:34<15:19,  2.10iteration/s, mean_rewards=-104]\u001b[A\n",
            "Training:   3%|▎         | 68/2000 [00:34<15:19,  2.10iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:   3%|▎         | 69/2000 [00:34<14:04,  2.29iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:   3%|▎         | 69/2000 [00:35<14:04,  2.29iteration/s, mean_rewards=-45.5]\u001b[A\n",
            "Training:   4%|▎         | 70/2000 [00:35<13:03,  2.46iteration/s, mean_rewards=-45.5]\u001b[A\n",
            "Training:   4%|▎         | 70/2000 [00:35<13:03,  2.46iteration/s, mean_rewards=-196] \u001b[A\n",
            "Training:   4%|▎         | 71/2000 [00:35<12:28,  2.58iteration/s, mean_rewards=-196]\u001b[A\n",
            "Training:   4%|▎         | 71/2000 [00:35<12:28,  2.58iteration/s, mean_rewards=-162]\u001b[A\n",
            "Training:   4%|▎         | 72/2000 [00:36<12:04,  2.66iteration/s, mean_rewards=-162]\u001b[A\n",
            "Training:   4%|▎         | 72/2000 [00:36<12:04,  2.66iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:   4%|▎         | 73/2000 [00:36<12:35,  2.55iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:   4%|▎         | 73/2000 [00:36<12:35,  2.55iteration/s, mean_rewards=-82.3]\u001b[A\n",
            "Training:   4%|▎         | 74/2000 [00:36<12:05,  2.66iteration/s, mean_rewards=-82.3]\u001b[A\n",
            "Training:   4%|▎         | 74/2000 [00:36<12:05,  2.66iteration/s, mean_rewards=-116] \u001b[A\n",
            "Training:   4%|▍         | 75/2000 [00:37<11:20,  2.83iteration/s, mean_rewards=-116]\u001b[A\n",
            "Training:   4%|▍         | 75/2000 [00:37<11:20,  2.83iteration/s, mean_rewards=-173]\u001b[A\n",
            "Training:   4%|▍         | 76/2000 [00:37<11:32,  2.78iteration/s, mean_rewards=-173]\u001b[A\n",
            "Training:   4%|▍         | 76/2000 [00:37<11:32,  2.78iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:   4%|▍         | 77/2000 [00:37<11:13,  2.86iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:   4%|▍         | 77/2000 [00:37<11:13,  2.86iteration/s, mean_rewards=-68.1]\u001b[A\n",
            "Training:   4%|▍         | 78/2000 [00:38<10:44,  2.98iteration/s, mean_rewards=-68.1]\u001b[A\n",
            "Training:   4%|▍         | 78/2000 [00:38<10:44,  2.98iteration/s, mean_rewards=-145] \u001b[A\n",
            "Training:   4%|▍         | 79/2000 [00:38<11:00,  2.91iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:   4%|▍         | 79/2000 [00:38<11:00,  2.91iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:   4%|▍         | 80/2000 [00:38<11:11,  2.86iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:   4%|▍         | 80/2000 [00:39<11:11,  2.86iteration/s, mean_rewards=-88.7]\u001b[A\n",
            "Training:   4%|▍         | 81/2000 [00:39<11:15,  2.84iteration/s, mean_rewards=-88.7]\u001b[A\n",
            "Training:   4%|▍         | 81/2000 [00:39<11:15,  2.84iteration/s, mean_rewards=-151] \u001b[A\n",
            "Training:   4%|▍         | 82/2000 [00:39<11:24,  2.80iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:   4%|▍         | 82/2000 [00:39<11:24,  2.80iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:   4%|▍         | 83/2000 [00:39<11:19,  2.82iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:   4%|▍         | 83/2000 [00:40<11:19,  2.82iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:   4%|▍         | 84/2000 [00:40<11:29,  2.78iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:   4%|▍         | 84/2000 [00:40<11:29,  2.78iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:   4%|▍         | 85/2000 [00:40<11:22,  2.80iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:   4%|▍         | 85/2000 [00:40<11:22,  2.80iteration/s, mean_rewards=-75.5]\u001b[A\n",
            "Training:   4%|▍         | 86/2000 [00:40<11:20,  2.81iteration/s, mean_rewards=-75.5]\u001b[A\n",
            "Training:   4%|▍         | 86/2000 [00:41<11:20,  2.81iteration/s, mean_rewards=-195] \u001b[A\n",
            "Training:   4%|▍         | 87/2000 [00:41<11:27,  2.78iteration/s, mean_rewards=-195]\u001b[A\n",
            "Training:   4%|▍         | 87/2000 [00:41<11:27,  2.78iteration/s, mean_rewards=-231]\u001b[A\n",
            "Training:   4%|▍         | 88/2000 [00:41<12:10,  2.62iteration/s, mean_rewards=-231]\u001b[A\n",
            "Training:   4%|▍         | 88/2000 [00:41<12:10,  2.62iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:   4%|▍         | 89/2000 [00:42<11:36,  2.74iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:   4%|▍         | 89/2000 [00:42<11:36,  2.74iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:   4%|▍         | 90/2000 [00:42<12:07,  2.63iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:   4%|▍         | 90/2000 [00:42<12:07,  2.63iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:   5%|▍         | 91/2000 [00:42<11:43,  2.71iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:   5%|▍         | 91/2000 [00:43<11:43,  2.71iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:   5%|▍         | 92/2000 [00:43<11:42,  2.72iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:   5%|▍         | 92/2000 [00:43<11:42,  2.72iteration/s, mean_rewards=-70.5]\u001b[A\n",
            "Training:   5%|▍         | 93/2000 [00:43<13:34,  2.34iteration/s, mean_rewards=-70.5]\u001b[A\n",
            "Training:   5%|▍         | 93/2000 [00:44<13:34,  2.34iteration/s, mean_rewards=-131] \u001b[A\n",
            "Training:   5%|▍         | 94/2000 [00:44<13:25,  2.37iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:   5%|▍         | 94/2000 [00:44<13:25,  2.37iteration/s, mean_rewards=-101]\u001b[A\n",
            "Training:   5%|▍         | 95/2000 [00:44<14:18,  2.22iteration/s, mean_rewards=-101]\u001b[A\n",
            "Training:   5%|▍         | 95/2000 [00:45<14:18,  2.22iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:   5%|▍         | 96/2000 [00:45<14:37,  2.17iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:   5%|▍         | 96/2000 [00:45<14:37,  2.17iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:   5%|▍         | 97/2000 [00:45<14:58,  2.12iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:   5%|▍         | 97/2000 [00:45<14:58,  2.12iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:   5%|▍         | 98/2000 [00:46<13:22,  2.37iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:   5%|▍         | 98/2000 [00:46<13:22,  2.37iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:   5%|▍         | 99/2000 [00:46<12:15,  2.59iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:   5%|▍         | 99/2000 [00:46<12:15,  2.59iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:   5%|▌         | 100/2000 [00:46<11:28,  2.76iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:   5%|▌         | 100/2000 [00:46<11:28,  2.76iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:   5%|▌         | 101/2000 [00:46<11:19,  2.80iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:   5%|▌         | 101/2000 [00:47<11:19,  2.80iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:   5%|▌         | 102/2000 [00:47<10:28,  3.02iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:   5%|▌         | 102/2000 [00:47<10:28,  3.02iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:   5%|▌         | 103/2000 [00:47<10:26,  3.03iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:   5%|▌         | 103/2000 [00:47<10:26,  3.03iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:   5%|▌         | 104/2000 [00:47<10:29,  3.01iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:   5%|▌         | 104/2000 [00:48<10:29,  3.01iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:   5%|▌         | 105/2000 [00:48<10:16,  3.08iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:   5%|▌         | 105/2000 [00:48<10:16,  3.08iteration/s, mean_rewards=-103]\u001b[A\n",
            "Training:   5%|▌         | 106/2000 [00:48<10:40,  2.96iteration/s, mean_rewards=-103]\u001b[A\n",
            "Training:   5%|▌         | 106/2000 [00:48<10:40,  2.96iteration/s, mean_rewards=-166]\u001b[A\n",
            "Training:   5%|▌         | 107/2000 [00:48<10:51,  2.91iteration/s, mean_rewards=-166]\u001b[A\n",
            "Training:   5%|▌         | 107/2000 [00:49<10:51,  2.91iteration/s, mean_rewards=-85.6]\u001b[A\n",
            "Training:   5%|▌         | 108/2000 [00:49<10:27,  3.02iteration/s, mean_rewards=-85.6]\u001b[A\n",
            "Training:   5%|▌         | 108/2000 [00:49<10:27,  3.02iteration/s, mean_rewards=-123] \u001b[A\n",
            "Training:   5%|▌         | 109/2000 [00:49<10:00,  3.15iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:   5%|▌         | 109/2000 [00:49<10:00,  3.15iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:   6%|▌         | 110/2000 [00:49<09:58,  3.16iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:   6%|▌         | 110/2000 [00:50<09:58,  3.16iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:   6%|▌         | 111/2000 [00:50<10:23,  3.03iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:   6%|▌         | 111/2000 [00:50<10:23,  3.03iteration/s, mean_rewards=-55.2]\u001b[A\n",
            "Training:   6%|▌         | 112/2000 [00:50<09:59,  3.15iteration/s, mean_rewards=-55.2]\u001b[A\n",
            "Training:   6%|▌         | 112/2000 [00:50<09:59,  3.15iteration/s, mean_rewards=-128] \u001b[A\n",
            "Training:   6%|▌         | 113/2000 [00:50<10:06,  3.11iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:   6%|▌         | 113/2000 [00:51<10:06,  3.11iteration/s, mean_rewards=-164]\u001b[A\n",
            "Training:   6%|▌         | 114/2000 [00:51<09:53,  3.18iteration/s, mean_rewards=-164]\u001b[A\n",
            "Training:   6%|▌         | 114/2000 [00:51<09:53,  3.18iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:   6%|▌         | 115/2000 [00:51<10:09,  3.09iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:   6%|▌         | 115/2000 [00:51<10:09,  3.09iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:   6%|▌         | 116/2000 [00:51<10:22,  3.03iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:   6%|▌         | 116/2000 [00:52<10:22,  3.03iteration/s, mean_rewards=-75.1]\u001b[A\n",
            "Training:   6%|▌         | 117/2000 [00:52<10:37,  2.95iteration/s, mean_rewards=-75.1]\u001b[A\n",
            "Training:   6%|▌         | 117/2000 [00:52<10:37,  2.95iteration/s, mean_rewards=-135] \u001b[A\n",
            "Training:   6%|▌         | 118/2000 [00:52<11:18,  2.77iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:   6%|▌         | 118/2000 [00:52<11:18,  2.77iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:   6%|▌         | 119/2000 [00:52<11:19,  2.77iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:   6%|▌         | 119/2000 [00:53<11:19,  2.77iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:   6%|▌         | 120/2000 [00:53<11:33,  2.71iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:   6%|▌         | 120/2000 [00:53<11:33,  2.71iteration/s, mean_rewards=-179]\u001b[A\n",
            "Training:   6%|▌         | 121/2000 [00:53<11:56,  2.62iteration/s, mean_rewards=-179]\u001b[A\n",
            "Training:   6%|▌         | 121/2000 [00:53<11:56,  2.62iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:   6%|▌         | 122/2000 [00:54<11:42,  2.67iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:   6%|▌         | 122/2000 [00:54<11:42,  2.67iteration/s, mean_rewards=-67.7]\u001b[A\n",
            "Training:   6%|▌         | 123/2000 [00:54<11:42,  2.67iteration/s, mean_rewards=-67.7]\u001b[A\n",
            "Training:   6%|▌         | 123/2000 [00:54<11:42,  2.67iteration/s, mean_rewards=-91.6]\u001b[A\n",
            "Training:   6%|▌         | 124/2000 [00:54<11:53,  2.63iteration/s, mean_rewards=-91.6]\u001b[A\n",
            "Training:   6%|▌         | 124/2000 [00:55<11:53,  2.63iteration/s, mean_rewards=-46.6]\u001b[A\n",
            "Training:   6%|▋         | 125/2000 [00:55<12:17,  2.54iteration/s, mean_rewards=-46.6]\u001b[A\n",
            "Training:   6%|▋         | 125/2000 [00:55<12:17,  2.54iteration/s, mean_rewards=-129] \u001b[A\n",
            "Training:   6%|▋         | 126/2000 [00:55<11:48,  2.64iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:   6%|▋         | 126/2000 [00:55<11:48,  2.64iteration/s, mean_rewards=-160]\u001b[A\n",
            "Training:   6%|▋         | 127/2000 [00:56<12:57,  2.41iteration/s, mean_rewards=-160]\u001b[A\n",
            "Training:   6%|▋         | 127/2000 [00:56<12:57,  2.41iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:   6%|▋         | 128/2000 [00:56<13:17,  2.35iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:   6%|▋         | 128/2000 [00:56<13:17,  2.35iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:   6%|▋         | 129/2000 [00:56<12:50,  2.43iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:   6%|▋         | 129/2000 [00:57<12:50,  2.43iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:   6%|▋         | 130/2000 [00:57<13:27,  2.32iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:   6%|▋         | 130/2000 [00:57<13:27,  2.32iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:   7%|▋         | 131/2000 [00:57<13:58,  2.23iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:   7%|▋         | 131/2000 [00:58<13:58,  2.23iteration/s, mean_rewards=-94.4]\u001b[A\n",
            "Training:   7%|▋         | 132/2000 [00:58<13:43,  2.27iteration/s, mean_rewards=-94.4]\u001b[A\n",
            "Training:   7%|▋         | 132/2000 [00:58<13:43,  2.27iteration/s, mean_rewards=-34.3]\u001b[A\n",
            "Training:   7%|▋         | 133/2000 [00:58<14:29,  2.15iteration/s, mean_rewards=-34.3]\u001b[A\n",
            "Training:   7%|▋         | 133/2000 [00:59<14:29,  2.15iteration/s, mean_rewards=-139] \u001b[A\n",
            "Training:   7%|▋         | 134/2000 [00:59<13:06,  2.37iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:   7%|▋         | 134/2000 [00:59<13:06,  2.37iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:   7%|▋         | 135/2000 [00:59<12:34,  2.47iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:   7%|▋         | 135/2000 [00:59<12:34,  2.47iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:   7%|▋         | 136/2000 [00:59<11:30,  2.70iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:   7%|▋         | 136/2000 [01:00<11:30,  2.70iteration/s, mean_rewards=-59.3]\u001b[A\n",
            "Training:   7%|▋         | 137/2000 [01:00<11:43,  2.65iteration/s, mean_rewards=-59.3]\u001b[A\n",
            "Training:   7%|▋         | 137/2000 [01:00<11:43,  2.65iteration/s, mean_rewards=-121] \u001b[A\n",
            "Training:   7%|▋         | 138/2000 [01:00<11:21,  2.73iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:   7%|▋         | 138/2000 [01:00<11:21,  2.73iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:   7%|▋         | 139/2000 [01:00<11:26,  2.71iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:   7%|▋         | 139/2000 [01:01<11:26,  2.71iteration/s, mean_rewards=-106]\u001b[A\n",
            "Training:   7%|▋         | 140/2000 [01:01<10:47,  2.87iteration/s, mean_rewards=-106]\u001b[A\n",
            "Training:   7%|▋         | 140/2000 [01:01<10:47,  2.87iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:   7%|▋         | 141/2000 [01:01<10:46,  2.88iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:   7%|▋         | 141/2000 [01:01<10:46,  2.88iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:   7%|▋         | 142/2000 [01:01<10:55,  2.83iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:   7%|▋         | 142/2000 [01:02<10:55,  2.83iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:   7%|▋         | 143/2000 [01:02<11:22,  2.72iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:   7%|▋         | 143/2000 [01:02<11:22,  2.72iteration/s, mean_rewards=-174]\u001b[A\n",
            "Training:   7%|▋         | 144/2000 [01:02<11:09,  2.77iteration/s, mean_rewards=-174]\u001b[A\n",
            "Training:   7%|▋         | 144/2000 [01:02<11:09,  2.77iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:   7%|▋         | 145/2000 [01:03<10:45,  2.87iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:   7%|▋         | 145/2000 [01:03<10:45,  2.87iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:   7%|▋         | 146/2000 [01:03<11:08,  2.77iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:   7%|▋         | 146/2000 [01:03<11:08,  2.77iteration/s, mean_rewards=-205]\u001b[A\n",
            "Training:   7%|▋         | 147/2000 [01:03<11:13,  2.75iteration/s, mean_rewards=-205]\u001b[A\n",
            "Training:   7%|▋         | 147/2000 [01:03<11:13,  2.75iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:   7%|▋         | 148/2000 [01:04<10:31,  2.93iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:   7%|▋         | 148/2000 [01:04<10:31,  2.93iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:   7%|▋         | 149/2000 [01:04<10:47,  2.86iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:   7%|▋         | 149/2000 [01:04<10:47,  2.86iteration/s, mean_rewards=-65] \u001b[A\n",
            "Training:   8%|▊         | 150/2000 [01:04<10:55,  2.82iteration/s, mean_rewards=-65]\u001b[A\n",
            "Training:   8%|▊         | 150/2000 [01:05<10:55,  2.82iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:   8%|▊         | 151/2000 [01:05<11:44,  2.62iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:   8%|▊         | 151/2000 [01:05<11:44,  2.62iteration/s, mean_rewards=-101]\u001b[A\n",
            "Training:   8%|▊         | 152/2000 [01:05<11:45,  2.62iteration/s, mean_rewards=-101]\u001b[A\n",
            "Training:   8%|▊         | 152/2000 [01:05<11:45,  2.62iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:   8%|▊         | 153/2000 [01:06<11:44,  2.62iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:   8%|▊         | 153/2000 [01:06<11:44,  2.62iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:   8%|▊         | 154/2000 [01:06<11:28,  2.68iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:   8%|▊         | 154/2000 [01:06<11:28,  2.68iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:   8%|▊         | 155/2000 [01:06<11:07,  2.76iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:   8%|▊         | 155/2000 [01:06<11:07,  2.76iteration/s, mean_rewards=-157]\u001b[A\n",
            "Training:   8%|▊         | 156/2000 [01:07<11:04,  2.78iteration/s, mean_rewards=-157]\u001b[A\n",
            "Training:   8%|▊         | 156/2000 [01:07<11:04,  2.78iteration/s, mean_rewards=-173]\u001b[A\n",
            "Training:   8%|▊         | 157/2000 [01:07<11:10,  2.75iteration/s, mean_rewards=-173]\u001b[A\n",
            "Training:   8%|▊         | 157/2000 [01:07<11:10,  2.75iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:   8%|▊         | 158/2000 [01:07<10:44,  2.86iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:   8%|▊         | 158/2000 [01:07<10:44,  2.86iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:   8%|▊         | 159/2000 [01:08<10:21,  2.96iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:   8%|▊         | 159/2000 [01:08<10:21,  2.96iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:   8%|▊         | 160/2000 [01:08<09:55,  3.09iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:   8%|▊         | 160/2000 [01:08<09:55,  3.09iteration/s, mean_rewards=-84.9]\u001b[A\n",
            "Training:   8%|▊         | 161/2000 [01:08<09:55,  3.09iteration/s, mean_rewards=-84.9]\u001b[A\n",
            "Training:   8%|▊         | 161/2000 [01:08<09:55,  3.09iteration/s, mean_rewards=-148] \u001b[A\n",
            "Training:   8%|▊         | 162/2000 [01:09<11:11,  2.74iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:   8%|▊         | 162/2000 [01:09<11:11,  2.74iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:   8%|▊         | 163/2000 [01:09<11:53,  2.57iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:   8%|▊         | 163/2000 [01:09<11:53,  2.57iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:   8%|▊         | 164/2000 [01:09<12:01,  2.55iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:   8%|▊         | 164/2000 [01:10<12:01,  2.55iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:   8%|▊         | 165/2000 [01:10<12:57,  2.36iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:   8%|▊         | 165/2000 [01:10<12:57,  2.36iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:   8%|▊         | 166/2000 [01:11<14:01,  2.18iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:   8%|▊         | 166/2000 [01:11<14:01,  2.18iteration/s, mean_rewards=-119]\u001b[A\n",
            "Training:   8%|▊         | 167/2000 [01:11<13:35,  2.25iteration/s, mean_rewards=-119]\u001b[A\n",
            "Training:   8%|▊         | 167/2000 [01:11<13:35,  2.25iteration/s, mean_rewards=-96.9]\u001b[A\n",
            "Training:   8%|▊         | 168/2000 [01:11<12:54,  2.37iteration/s, mean_rewards=-96.9]\u001b[A\n",
            "Training:   8%|▊         | 168/2000 [01:12<12:54,  2.37iteration/s, mean_rewards=-163] \u001b[A\n",
            "Training:   8%|▊         | 169/2000 [01:12<12:11,  2.50iteration/s, mean_rewards=-163]\u001b[A\n",
            "Training:   8%|▊         | 169/2000 [01:12<12:11,  2.50iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:   8%|▊         | 170/2000 [01:12<11:19,  2.69iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:   8%|▊         | 170/2000 [01:12<11:19,  2.69iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:   9%|▊         | 171/2000 [01:12<11:10,  2.73iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:   9%|▊         | 171/2000 [01:13<11:10,  2.73iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:   9%|▊         | 172/2000 [01:13<11:06,  2.74iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:   9%|▊         | 172/2000 [01:13<11:06,  2.74iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:   9%|▊         | 173/2000 [01:13<10:31,  2.89iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:   9%|▊         | 173/2000 [01:13<10:31,  2.89iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:   9%|▊         | 174/2000 [01:13<10:33,  2.88iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:   9%|▊         | 174/2000 [01:14<10:33,  2.88iteration/s, mean_rewards=-119]\u001b[A\n",
            "Training:   9%|▉         | 175/2000 [01:14<10:06,  3.01iteration/s, mean_rewards=-119]\u001b[A\n",
            "Training:   9%|▉         | 175/2000 [01:14<10:06,  3.01iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:   9%|▉         | 176/2000 [01:14<09:57,  3.05iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:   9%|▉         | 176/2000 [01:14<09:57,  3.05iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:   9%|▉         | 177/2000 [01:14<09:41,  3.13iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:   9%|▉         | 177/2000 [01:14<09:41,  3.13iteration/s, mean_rewards=-182]\u001b[A\n",
            "Training:   9%|▉         | 178/2000 [01:15<10:04,  3.01iteration/s, mean_rewards=-182]\u001b[A\n",
            "Training:   9%|▉         | 178/2000 [01:15<10:04,  3.01iteration/s, mean_rewards=-69.6]\u001b[A\n",
            "Training:   9%|▉         | 179/2000 [01:15<10:36,  2.86iteration/s, mean_rewards=-69.6]\u001b[A\n",
            "Training:   9%|▉         | 179/2000 [01:15<10:36,  2.86iteration/s, mean_rewards=-241] \u001b[A\n",
            "Training:   9%|▉         | 180/2000 [01:15<10:49,  2.80iteration/s, mean_rewards=-241]\u001b[A\n",
            "Training:   9%|▉         | 180/2000 [01:16<10:49,  2.80iteration/s, mean_rewards=-106]\u001b[A\n",
            "Training:   9%|▉         | 181/2000 [01:16<10:56,  2.77iteration/s, mean_rewards=-106]\u001b[A\n",
            "Training:   9%|▉         | 181/2000 [01:16<10:56,  2.77iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:   9%|▉         | 182/2000 [01:16<10:58,  2.76iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:   9%|▉         | 182/2000 [01:16<10:58,  2.76iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:   9%|▉         | 183/2000 [01:16<10:28,  2.89iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:   9%|▉         | 183/2000 [01:17<10:28,  2.89iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:   9%|▉         | 184/2000 [01:17<10:25,  2.90iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:   9%|▉         | 184/2000 [01:17<10:25,  2.90iteration/s, mean_rewards=-167]\u001b[A\n",
            "Training:   9%|▉         | 185/2000 [01:17<10:42,  2.82iteration/s, mean_rewards=-167]\u001b[A\n",
            "Training:   9%|▉         | 185/2000 [01:17<10:42,  2.82iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:   9%|▉         | 186/2000 [01:18<11:35,  2.61iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:   9%|▉         | 186/2000 [01:18<11:35,  2.61iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:   9%|▉         | 187/2000 [01:18<11:18,  2.67iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:   9%|▉         | 187/2000 [01:18<11:18,  2.67iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:   9%|▉         | 188/2000 [01:18<10:47,  2.80iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:   9%|▉         | 188/2000 [01:19<10:47,  2.80iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:   9%|▉         | 189/2000 [01:19<11:18,  2.67iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:   9%|▉         | 189/2000 [01:19<11:18,  2.67iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  10%|▉         | 190/2000 [01:19<10:30,  2.87iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  10%|▉         | 190/2000 [01:19<10:30,  2.87iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  10%|▉         | 191/2000 [01:19<10:00,  3.01iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  10%|▉         | 191/2000 [01:19<10:00,  3.01iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  10%|▉         | 192/2000 [01:20<10:22,  2.91iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  10%|▉         | 192/2000 [01:20<10:22,  2.91iteration/s, mean_rewards=-65.9]\u001b[A\n",
            "Training:  10%|▉         | 193/2000 [01:20<10:37,  2.83iteration/s, mean_rewards=-65.9]\u001b[A\n",
            "Training:  10%|▉         | 193/2000 [01:20<10:37,  2.83iteration/s, mean_rewards=-165] \u001b[A\n",
            "Training:  10%|▉         | 194/2000 [01:20<10:46,  2.79iteration/s, mean_rewards=-165]\u001b[A\n",
            "Training:  10%|▉         | 194/2000 [01:21<10:46,  2.79iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  10%|▉         | 195/2000 [01:21<10:07,  2.97iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  10%|▉         | 195/2000 [01:21<10:07,  2.97iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  10%|▉         | 196/2000 [01:21<12:03,  2.49iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  10%|▉         | 196/2000 [01:21<12:03,  2.49iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  10%|▉         | 197/2000 [01:22<12:21,  2.43iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  10%|▉         | 197/2000 [01:22<12:21,  2.43iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  10%|▉         | 198/2000 [01:22<12:04,  2.49iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  10%|▉         | 198/2000 [01:22<12:04,  2.49iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  10%|▉         | 199/2000 [01:23<12:57,  2.32iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  10%|▉         | 199/2000 [01:23<12:57,  2.32iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  10%|█         | 200/2000 [01:23<13:18,  2.25iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  10%|█         | 200/2000 [01:23<13:18,  2.25iteration/s, mean_rewards=-684]\u001b[A\n",
            "Training:  10%|█         | 201/2000 [01:24<15:11,  1.97iteration/s, mean_rewards=-684]\u001b[A\n",
            "Training:  10%|█         | 201/2000 [01:24<15:11,  1.97iteration/s, mean_rewards=-969]\u001b[A\n",
            "Training:  10%|█         | 202/2000 [01:24<17:01,  1.76iteration/s, mean_rewards=-969]\u001b[A\n",
            "Training:  10%|█         | 202/2000 [01:25<17:01,  1.76iteration/s, mean_rewards=-553]\u001b[A\n",
            "Training:  10%|█         | 203/2000 [01:25<17:16,  1.73iteration/s, mean_rewards=-553]\u001b[A\n",
            "Training:  10%|█         | 203/2000 [01:26<17:16,  1.73iteration/s, mean_rewards=-958]\u001b[A\n",
            "Training:  10%|█         | 204/2000 [01:26<19:10,  1.56iteration/s, mean_rewards=-958]\u001b[A\n",
            "Training:  10%|█         | 204/2000 [01:26<19:10,  1.56iteration/s, mean_rewards=-508]\u001b[A\n",
            "Training:  10%|█         | 205/2000 [01:26<17:19,  1.73iteration/s, mean_rewards=-508]\u001b[A\n",
            "Training:  10%|█         | 205/2000 [01:27<17:19,  1.73iteration/s, mean_rewards=-1.17e+3]\u001b[A\n",
            "Training:  10%|█         | 206/2000 [01:27<19:06,  1.57iteration/s, mean_rewards=-1.17e+3]\u001b[A\n",
            "Training:  10%|█         | 206/2000 [01:27<19:06,  1.57iteration/s, mean_rewards=-559]    \u001b[A\n",
            "Training:  10%|█         | 207/2000 [01:27<17:35,  1.70iteration/s, mean_rewards=-559]\u001b[A\n",
            "Training:  10%|█         | 207/2000 [01:28<17:35,  1.70iteration/s, mean_rewards=-1.08e+3]\u001b[A\n",
            "Training:  10%|█         | 208/2000 [01:28<20:03,  1.49iteration/s, mean_rewards=-1.08e+3]\u001b[A\n",
            "Training:  10%|█         | 208/2000 [01:29<20:03,  1.49iteration/s, mean_rewards=-1.34e+3]\u001b[A\n",
            "Training:  10%|█         | 209/2000 [01:29<22:52,  1.30iteration/s, mean_rewards=-1.34e+3]\u001b[A\n",
            "Training:  10%|█         | 209/2000 [01:30<22:52,  1.30iteration/s, mean_rewards=-1.54e+3]\u001b[A\n",
            "Training:  10%|█         | 210/2000 [01:30<25:24,  1.17iteration/s, mean_rewards=-1.54e+3]\u001b[A\n",
            "Training:  10%|█         | 210/2000 [01:31<25:24,  1.17iteration/s, mean_rewards=-818]    \u001b[A\n",
            "Training:  11%|█         | 211/2000 [01:31<22:41,  1.31iteration/s, mean_rewards=-818]\u001b[A\n",
            "Training:  11%|█         | 211/2000 [01:31<22:41,  1.31iteration/s, mean_rewards=-1.01e+3]\u001b[A\n",
            "Training:  11%|█         | 212/2000 [01:32<22:25,  1.33iteration/s, mean_rewards=-1.01e+3]\u001b[A\n",
            "Training:  11%|█         | 212/2000 [01:32<22:25,  1.33iteration/s, mean_rewards=-897]    \u001b[A\n",
            "Training:  11%|█         | 213/2000 [01:32<21:23,  1.39iteration/s, mean_rewards=-897]\u001b[A\n",
            "Training:  11%|█         | 213/2000 [01:33<21:23,  1.39iteration/s, mean_rewards=-548]\u001b[A\n",
            "Training:  11%|█         | 214/2000 [01:33<19:06,  1.56iteration/s, mean_rewards=-548]\u001b[A\n",
            "Training:  11%|█         | 214/2000 [01:33<19:06,  1.56iteration/s, mean_rewards=-979]\u001b[A\n",
            "Training:  11%|█         | 215/2000 [01:34<20:29,  1.45iteration/s, mean_rewards=-979]\u001b[A\n",
            "Training:  11%|█         | 215/2000 [01:34<20:29,  1.45iteration/s, mean_rewards=-653]\u001b[A\n",
            "Training:  11%|█         | 216/2000 [01:34<20:13,  1.47iteration/s, mean_rewards=-653]\u001b[A\n",
            "Training:  11%|█         | 216/2000 [01:35<20:13,  1.47iteration/s, mean_rewards=-562]\u001b[A\n",
            "Training:  11%|█         | 217/2000 [01:35<18:49,  1.58iteration/s, mean_rewards=-562]\u001b[A\n",
            "Training:  11%|█         | 217/2000 [01:35<18:49,  1.58iteration/s, mean_rewards=-597]\u001b[A\n",
            "Training:  11%|█         | 218/2000 [01:35<18:38,  1.59iteration/s, mean_rewards=-597]\u001b[A\n",
            "Training:  11%|█         | 218/2000 [01:36<18:38,  1.59iteration/s, mean_rewards=-621]\u001b[A\n",
            "Training:  11%|█         | 219/2000 [01:36<20:06,  1.48iteration/s, mean_rewards=-621]\u001b[A\n",
            "Training:  11%|█         | 219/2000 [01:37<20:06,  1.48iteration/s, mean_rewards=-655]\u001b[A\n",
            "Training:  11%|█         | 220/2000 [01:37<20:24,  1.45iteration/s, mean_rewards=-655]\u001b[A\n",
            "Training:  11%|█         | 220/2000 [01:37<20:24,  1.45iteration/s, mean_rewards=-1.1e+3]\u001b[A\n",
            "Training:  11%|█         | 221/2000 [01:38<22:12,  1.34iteration/s, mean_rewards=-1.1e+3]\u001b[A\n",
            "Training:  11%|█         | 221/2000 [01:38<22:12,  1.34iteration/s, mean_rewards=-468]   \u001b[A\n",
            "Training:  11%|█         | 222/2000 [01:38<21:05,  1.41iteration/s, mean_rewards=-468]\u001b[A\n",
            "Training:  11%|█         | 222/2000 [01:39<21:05,  1.41iteration/s, mean_rewards=-550]\u001b[A\n",
            "Training:  11%|█         | 223/2000 [01:39<18:45,  1.58iteration/s, mean_rewards=-550]\u001b[A\n",
            "Training:  11%|█         | 223/2000 [01:39<18:45,  1.58iteration/s, mean_rewards=-676]\u001b[A\n",
            "Training:  11%|█         | 224/2000 [01:39<18:08,  1.63iteration/s, mean_rewards=-676]\u001b[A\n",
            "Training:  11%|█         | 224/2000 [01:40<18:08,  1.63iteration/s, mean_rewards=-519]\u001b[A\n",
            "Training:  11%|█▏        | 225/2000 [01:40<16:25,  1.80iteration/s, mean_rewards=-519]\u001b[A\n",
            "Training:  11%|█▏        | 225/2000 [01:40<16:25,  1.80iteration/s, mean_rewards=-603]\u001b[A\n",
            "Training:  11%|█▏        | 226/2000 [01:40<15:37,  1.89iteration/s, mean_rewards=-603]\u001b[A\n",
            "Training:  11%|█▏        | 226/2000 [01:41<15:37,  1.89iteration/s, mean_rewards=-502]\u001b[A\n",
            "Training:  11%|█▏        | 227/2000 [01:41<15:18,  1.93iteration/s, mean_rewards=-502]\u001b[A\n",
            "Training:  11%|█▏        | 227/2000 [01:41<15:18,  1.93iteration/s, mean_rewards=-1.02e+3]\u001b[A\n",
            "Training:  11%|█▏        | 228/2000 [01:42<18:11,  1.62iteration/s, mean_rewards=-1.02e+3]\u001b[A\n",
            "Training:  11%|█▏        | 228/2000 [01:42<18:11,  1.62iteration/s, mean_rewards=-625]    \u001b[A\n",
            "Training:  11%|█▏        | 229/2000 [01:42<17:42,  1.67iteration/s, mean_rewards=-625]\u001b[A\n",
            "Training:  11%|█▏        | 229/2000 [01:42<17:42,  1.67iteration/s, mean_rewards=-623]\u001b[A\n",
            "Training:  12%|█▏        | 230/2000 [01:43<16:33,  1.78iteration/s, mean_rewards=-623]\u001b[A\n",
            "Training:  12%|█▏        | 230/2000 [01:43<16:33,  1.78iteration/s, mean_rewards=-552]\u001b[A\n",
            "Training:  12%|█▏        | 231/2000 [01:43<15:16,  1.93iteration/s, mean_rewards=-552]\u001b[A\n",
            "Training:  12%|█▏        | 231/2000 [01:43<15:16,  1.93iteration/s, mean_rewards=-903]\u001b[A\n",
            "Training:  12%|█▏        | 232/2000 [01:44<16:04,  1.83iteration/s, mean_rewards=-903]\u001b[A\n",
            "Training:  12%|█▏        | 232/2000 [01:44<16:04,  1.83iteration/s, mean_rewards=-454]\u001b[A\n",
            "Training:  12%|█▏        | 233/2000 [01:44<15:30,  1.90iteration/s, mean_rewards=-454]\u001b[A\n",
            "Training:  12%|█▏        | 233/2000 [01:45<15:30,  1.90iteration/s, mean_rewards=-800]\u001b[A\n",
            "Training:  12%|█▏        | 234/2000 [01:45<15:50,  1.86iteration/s, mean_rewards=-800]\u001b[A\n",
            "Training:  12%|█▏        | 234/2000 [01:45<15:50,  1.86iteration/s, mean_rewards=-794]\u001b[A\n",
            "Training:  12%|█▏        | 235/2000 [01:45<17:10,  1.71iteration/s, mean_rewards=-794]\u001b[A\n",
            "Training:  12%|█▏        | 235/2000 [01:46<17:10,  1.71iteration/s, mean_rewards=-746]\u001b[A\n",
            "Training:  12%|█▏        | 236/2000 [01:46<18:16,  1.61iteration/s, mean_rewards=-746]\u001b[A\n",
            "Training:  12%|█▏        | 236/2000 [01:47<18:16,  1.61iteration/s, mean_rewards=-1.25e+3]\u001b[A\n",
            "Training:  12%|█▏        | 237/2000 [01:47<22:25,  1.31iteration/s, mean_rewards=-1.25e+3]\u001b[A\n",
            "Training:  12%|█▏        | 237/2000 [01:48<22:25,  1.31iteration/s, mean_rewards=-966]    \u001b[A\n",
            "Training:  12%|█▏        | 238/2000 [01:48<23:37,  1.24iteration/s, mean_rewards=-966]\u001b[A\n",
            "Training:  12%|█▏        | 238/2000 [01:49<23:37,  1.24iteration/s, mean_rewards=-688]\u001b[A\n",
            "Training:  12%|█▏        | 239/2000 [01:49<23:31,  1.25iteration/s, mean_rewards=-688]\u001b[A\n",
            "Training:  12%|█▏        | 239/2000 [01:49<23:31,  1.25iteration/s, mean_rewards=-725]\u001b[A\n",
            "Training:  12%|█▏        | 240/2000 [01:50<23:22,  1.25iteration/s, mean_rewards=-725]\u001b[A\n",
            "Training:  12%|█▏        | 240/2000 [01:50<23:22,  1.25iteration/s, mean_rewards=-490]\u001b[A\n",
            "Training:  12%|█▏        | 241/2000 [01:50<20:30,  1.43iteration/s, mean_rewards=-490]\u001b[A\n",
            "Training:  12%|█▏        | 241/2000 [01:51<20:30,  1.43iteration/s, mean_rewards=-1.1e+3]\u001b[A\n",
            "Training:  12%|█▏        | 242/2000 [01:51<21:38,  1.35iteration/s, mean_rewards=-1.1e+3]\u001b[A\n",
            "Training:  12%|█▏        | 242/2000 [01:51<21:38,  1.35iteration/s, mean_rewards=-696]   \u001b[A\n",
            "Training:  12%|█▏        | 243/2000 [01:52<20:07,  1.46iteration/s, mean_rewards=-696]\u001b[A\n",
            "Training:  12%|█▏        | 243/2000 [01:52<20:07,  1.46iteration/s, mean_rewards=-587]\u001b[A\n",
            "Training:  12%|█▏        | 244/2000 [01:52<18:06,  1.62iteration/s, mean_rewards=-587]\u001b[A\n",
            "Training:  12%|█▏        | 244/2000 [01:52<18:06,  1.62iteration/s, mean_rewards=-590]\u001b[A\n",
            "Training:  12%|█▏        | 245/2000 [01:52<17:06,  1.71iteration/s, mean_rewards=-590]\u001b[A\n",
            "Training:  12%|█▏        | 245/2000 [01:53<17:06,  1.71iteration/s, mean_rewards=-693]\u001b[A\n",
            "Training:  12%|█▏        | 246/2000 [01:53<17:38,  1.66iteration/s, mean_rewards=-693]\u001b[A\n",
            "Training:  12%|█▏        | 246/2000 [01:53<17:38,  1.66iteration/s, mean_rewards=-473]\u001b[A\n",
            "Training:  12%|█▏        | 247/2000 [01:54<16:26,  1.78iteration/s, mean_rewards=-473]\u001b[A\n",
            "Training:  12%|█▏        | 247/2000 [01:54<16:26,  1.78iteration/s, mean_rewards=-525]\u001b[A\n",
            "Training:  12%|█▏        | 248/2000 [01:54<14:55,  1.96iteration/s, mean_rewards=-525]\u001b[A\n",
            "Training:  12%|█▏        | 248/2000 [01:54<14:55,  1.96iteration/s, mean_rewards=-657]\u001b[A\n",
            "Training:  12%|█▏        | 249/2000 [01:55<15:07,  1.93iteration/s, mean_rewards=-657]\u001b[A\n",
            "Training:  12%|█▏        | 249/2000 [01:55<15:07,  1.93iteration/s, mean_rewards=-680]\u001b[A\n",
            "Training:  12%|█▎        | 250/2000 [01:55<16:06,  1.81iteration/s, mean_rewards=-680]\u001b[A\n",
            "Training:  12%|█▎        | 250/2000 [01:56<16:06,  1.81iteration/s, mean_rewards=-482]\u001b[A\n",
            "Training:  13%|█▎        | 251/2000 [01:56<15:44,  1.85iteration/s, mean_rewards=-482]\u001b[A\n",
            "Training:  13%|█▎        | 251/2000 [01:56<15:44,  1.85iteration/s, mean_rewards=-1.05e+3]\u001b[A\n",
            "Training:  13%|█▎        | 252/2000 [01:56<18:01,  1.62iteration/s, mean_rewards=-1.05e+3]\u001b[A\n",
            "Training:  13%|█▎        | 252/2000 [01:57<18:01,  1.62iteration/s, mean_rewards=-853]    \u001b[A\n",
            "Training:  13%|█▎        | 253/2000 [01:57<18:20,  1.59iteration/s, mean_rewards=-853]\u001b[A\n",
            "Training:  13%|█▎        | 253/2000 [01:58<18:20,  1.59iteration/s, mean_rewards=-1.29e+3]\u001b[A\n",
            "Training:  13%|█▎        | 254/2000 [01:58<20:32,  1.42iteration/s, mean_rewards=-1.29e+3]\u001b[A\n",
            "Training:  13%|█▎        | 254/2000 [01:58<20:32,  1.42iteration/s, mean_rewards=-534]    \u001b[A\n",
            "Training:  13%|█▎        | 255/2000 [01:58<18:31,  1.57iteration/s, mean_rewards=-534]\u001b[A\n",
            "Training:  13%|█▎        | 255/2000 [01:59<18:31,  1.57iteration/s, mean_rewards=-1.26e+3]\u001b[A\n",
            "Training:  13%|█▎        | 256/2000 [01:59<20:57,  1.39iteration/s, mean_rewards=-1.26e+3]\u001b[A\n",
            "Training:  13%|█▎        | 256/2000 [02:00<20:57,  1.39iteration/s, mean_rewards=-939]    \u001b[A\n",
            "Training:  13%|█▎        | 257/2000 [02:00<22:54,  1.27iteration/s, mean_rewards=-939]\u001b[A\n",
            "Training:  13%|█▎        | 257/2000 [02:01<22:54,  1.27iteration/s, mean_rewards=-654]\u001b[A\n",
            "Training:  13%|█▎        | 258/2000 [02:01<21:38,  1.34iteration/s, mean_rewards=-654]\u001b[A\n",
            "Training:  13%|█▎        | 258/2000 [02:02<21:38,  1.34iteration/s, mean_rewards=-782]\u001b[A\n",
            "Training:  13%|█▎        | 259/2000 [02:02<23:01,  1.26iteration/s, mean_rewards=-782]\u001b[A\n",
            "Training:  13%|█▎        | 259/2000 [02:02<23:01,  1.26iteration/s, mean_rewards=-494]\u001b[A\n",
            "Training:  13%|█▎        | 260/2000 [02:03<21:57,  1.32iteration/s, mean_rewards=-494]\u001b[A\n",
            "Training:  13%|█▎        | 260/2000 [02:03<21:57,  1.32iteration/s, mean_rewards=-668]\u001b[A\n",
            "Training:  13%|█▎        | 261/2000 [02:03<20:06,  1.44iteration/s, mean_rewards=-668]\u001b[A\n",
            "Training:  13%|█▎        | 261/2000 [02:04<20:06,  1.44iteration/s, mean_rewards=-690]\u001b[A\n",
            "Training:  13%|█▎        | 262/2000 [02:04<19:31,  1.48iteration/s, mean_rewards=-690]\u001b[A\n",
            "Training:  13%|█▎        | 262/2000 [02:04<19:31,  1.48iteration/s, mean_rewards=-536]\u001b[A\n",
            "Training:  13%|█▎        | 263/2000 [02:04<17:40,  1.64iteration/s, mean_rewards=-536]\u001b[A\n",
            "Training:  13%|█▎        | 263/2000 [02:05<17:40,  1.64iteration/s, mean_rewards=-913]\u001b[A\n",
            "Training:  13%|█▎        | 264/2000 [02:05<17:43,  1.63iteration/s, mean_rewards=-913]\u001b[A\n",
            "Training:  13%|█▎        | 264/2000 [02:05<17:43,  1.63iteration/s, mean_rewards=-540]\u001b[A\n",
            "Training:  13%|█▎        | 265/2000 [02:05<16:41,  1.73iteration/s, mean_rewards=-540]\u001b[A\n",
            "Training:  13%|█▎        | 265/2000 [02:06<16:41,  1.73iteration/s, mean_rewards=-542]\u001b[A\n",
            "Training:  13%|█▎        | 266/2000 [02:06<16:02,  1.80iteration/s, mean_rewards=-542]\u001b[A\n",
            "Training:  13%|█▎        | 266/2000 [02:06<16:02,  1.80iteration/s, mean_rewards=-467]\u001b[A\n",
            "Training:  13%|█▎        | 267/2000 [02:06<15:19,  1.88iteration/s, mean_rewards=-467]\u001b[A\n",
            "Training:  13%|█▎        | 267/2000 [02:07<15:19,  1.88iteration/s, mean_rewards=-542]\u001b[A\n",
            "Training:  13%|█▎        | 268/2000 [02:07<15:13,  1.90iteration/s, mean_rewards=-542]\u001b[A\n",
            "Training:  13%|█▎        | 268/2000 [02:07<15:13,  1.90iteration/s, mean_rewards=-503]\u001b[A\n",
            "Training:  13%|█▎        | 269/2000 [02:07<14:36,  1.97iteration/s, mean_rewards=-503]\u001b[A\n",
            "Training:  13%|█▎        | 269/2000 [02:08<14:36,  1.97iteration/s, mean_rewards=-757]\u001b[A\n",
            "Training:  14%|█▎        | 270/2000 [02:08<15:36,  1.85iteration/s, mean_rewards=-757]\u001b[A\n",
            "Training:  14%|█▎        | 270/2000 [02:08<15:36,  1.85iteration/s, mean_rewards=-740]\u001b[A\n",
            "Training:  14%|█▎        | 271/2000 [02:08<15:59,  1.80iteration/s, mean_rewards=-740]\u001b[A\n",
            "Training:  14%|█▎        | 271/2000 [02:09<15:59,  1.80iteration/s, mean_rewards=-641]\u001b[A\n",
            "Training:  14%|█▎        | 272/2000 [02:09<16:05,  1.79iteration/s, mean_rewards=-641]\u001b[A\n",
            "Training:  14%|█▎        | 272/2000 [02:09<16:05,  1.79iteration/s, mean_rewards=-550]\u001b[A\n",
            "Training:  14%|█▎        | 273/2000 [02:09<14:56,  1.93iteration/s, mean_rewards=-550]\u001b[A\n",
            "Training:  14%|█▎        | 273/2000 [02:10<14:56,  1.93iteration/s, mean_rewards=-2.12e+3]\u001b[A\n",
            "Training:  14%|█▎        | 274/2000 [02:11<21:41,  1.33iteration/s, mean_rewards=-2.12e+3]\u001b[A\n",
            "Training:  14%|█▎        | 274/2000 [02:11<21:41,  1.33iteration/s, mean_rewards=-833]    \u001b[A\n",
            "Training:  14%|█▍        | 275/2000 [02:11<21:03,  1.37iteration/s, mean_rewards=-833]\u001b[A\n",
            "Training:  14%|█▍        | 275/2000 [02:12<21:03,  1.37iteration/s, mean_rewards=-458]\u001b[A\n",
            "Training:  14%|█▍        | 276/2000 [02:12<18:32,  1.55iteration/s, mean_rewards=-458]\u001b[A\n",
            "Training:  14%|█▍        | 276/2000 [02:12<18:32,  1.55iteration/s, mean_rewards=-1.02e+3]\u001b[A\n",
            "Training:  14%|█▍        | 277/2000 [02:13<20:07,  1.43iteration/s, mean_rewards=-1.02e+3]\u001b[A\n",
            "Training:  14%|█▍        | 277/2000 [02:13<20:07,  1.43iteration/s, mean_rewards=-935]    \u001b[A\n",
            "Training:  14%|█▍        | 278/2000 [02:14<21:16,  1.35iteration/s, mean_rewards=-935]\u001b[A\n",
            "Training:  14%|█▍        | 278/2000 [02:14<21:16,  1.35iteration/s, mean_rewards=-717]\u001b[A\n",
            "Training:  14%|█▍        | 279/2000 [02:14<22:41,  1.26iteration/s, mean_rewards=-717]\u001b[A\n",
            "Training:  14%|█▍        | 279/2000 [02:15<22:41,  1.26iteration/s, mean_rewards=-677]\u001b[A\n",
            "Training:  14%|█▍        | 280/2000 [02:15<22:06,  1.30iteration/s, mean_rewards=-677]\u001b[A\n",
            "Training:  14%|█▍        | 280/2000 [02:16<22:06,  1.30iteration/s, mean_rewards=-724]\u001b[A\n",
            "Training:  14%|█▍        | 281/2000 [02:16<20:18,  1.41iteration/s, mean_rewards=-724]\u001b[A\n",
            "Training:  14%|█▍        | 281/2000 [02:16<20:18,  1.41iteration/s, mean_rewards=-1.17e+3]\u001b[A\n",
            "Training:  14%|█▍        | 282/2000 [02:17<21:07,  1.36iteration/s, mean_rewards=-1.17e+3]\u001b[A\n",
            "Training:  14%|█▍        | 282/2000 [02:17<21:07,  1.36iteration/s, mean_rewards=-560]    \u001b[A\n",
            "Training:  14%|█▍        | 283/2000 [02:17<18:40,  1.53iteration/s, mean_rewards=-560]\u001b[A\n",
            "Training:  14%|█▍        | 283/2000 [02:18<18:40,  1.53iteration/s, mean_rewards=-716]\u001b[A\n",
            "Training:  14%|█▍        | 284/2000 [02:18<18:50,  1.52iteration/s, mean_rewards=-716]\u001b[A\n",
            "Training:  14%|█▍        | 284/2000 [02:18<18:50,  1.52iteration/s, mean_rewards=-567]\u001b[A\n",
            "Training:  14%|█▍        | 285/2000 [02:18<17:45,  1.61iteration/s, mean_rewards=-567]\u001b[A\n",
            "Training:  14%|█▍        | 285/2000 [02:19<17:45,  1.61iteration/s, mean_rewards=-728]\u001b[A\n",
            "Training:  14%|█▍        | 286/2000 [02:19<17:04,  1.67iteration/s, mean_rewards=-728]\u001b[A\n",
            "Training:  14%|█▍        | 286/2000 [02:19<17:04,  1.67iteration/s, mean_rewards=-781]\u001b[A\n",
            "Training:  14%|█▍        | 287/2000 [02:19<16:19,  1.75iteration/s, mean_rewards=-781]\u001b[A\n",
            "Training:  14%|█▍        | 287/2000 [02:20<16:19,  1.75iteration/s, mean_rewards=-712]\u001b[A\n",
            "Training:  14%|█▍        | 288/2000 [02:20<16:54,  1.69iteration/s, mean_rewards=-712]\u001b[A\n",
            "Training:  14%|█▍        | 288/2000 [02:20<16:54,  1.69iteration/s, mean_rewards=-631]\u001b[A\n",
            "Training:  14%|█▍        | 289/2000 [02:20<15:35,  1.83iteration/s, mean_rewards=-631]\u001b[A\n",
            "Training:  14%|█▍        | 289/2000 [02:21<15:35,  1.83iteration/s, mean_rewards=-630]\u001b[A\n",
            "Training:  14%|█▍        | 290/2000 [02:21<15:30,  1.84iteration/s, mean_rewards=-630]\u001b[A\n",
            "Training:  14%|█▍        | 290/2000 [02:22<15:30,  1.84iteration/s, mean_rewards=-2.09e+3]\u001b[A\n",
            "Training:  15%|█▍        | 291/2000 [02:22<21:44,  1.31iteration/s, mean_rewards=-2.09e+3]\u001b[A\n",
            "Training:  15%|█▍        | 291/2000 [02:22<21:44,  1.31iteration/s, mean_rewards=-545]    \u001b[A\n",
            "Training:  15%|█▍        | 292/2000 [02:23<19:01,  1.50iteration/s, mean_rewards=-545]\u001b[A\n",
            "Training:  15%|█▍        | 292/2000 [02:23<19:01,  1.50iteration/s, mean_rewards=-518]\u001b[A\n",
            "Training:  15%|█▍        | 293/2000 [02:23<17:26,  1.63iteration/s, mean_rewards=-518]\u001b[A\n",
            "Training:  15%|█▍        | 293/2000 [02:23<17:26,  1.63iteration/s, mean_rewards=-587]\u001b[A\n",
            "Training:  15%|█▍        | 294/2000 [02:24<15:40,  1.81iteration/s, mean_rewards=-587]\u001b[A\n",
            "Training:  15%|█▍        | 294/2000 [02:24<15:40,  1.81iteration/s, mean_rewards=-656]\u001b[A\n",
            "Training:  15%|█▍        | 295/2000 [02:24<15:49,  1.80iteration/s, mean_rewards=-656]\u001b[A\n",
            "Training:  15%|█▍        | 295/2000 [02:24<15:49,  1.80iteration/s, mean_rewards=-622]\u001b[A\n",
            "Training:  15%|█▍        | 296/2000 [02:25<14:45,  1.92iteration/s, mean_rewards=-622]\u001b[A\n",
            "Training:  15%|█▍        | 296/2000 [02:25<14:45,  1.92iteration/s, mean_rewards=-1.5e+3]\u001b[A\n",
            "Training:  15%|█▍        | 297/2000 [02:26<21:29,  1.32iteration/s, mean_rewards=-1.5e+3]\u001b[A\n",
            "Training:  15%|█▍        | 297/2000 [02:26<21:29,  1.32iteration/s, mean_rewards=-750]   \u001b[A\n",
            "Training:  15%|█▍        | 298/2000 [02:27<22:23,  1.27iteration/s, mean_rewards=-750]\u001b[A\n",
            "Training:  15%|█▍        | 298/2000 [02:27<22:23,  1.27iteration/s, mean_rewards=-968]\u001b[A\n",
            "Training:  15%|█▍        | 299/2000 [02:28<23:51,  1.19iteration/s, mean_rewards=-968]\u001b[A\n",
            "Training:  15%|█▍        | 299/2000 [02:28<23:51,  1.19iteration/s, mean_rewards=-675]\u001b[A\n",
            "Training:  15%|█▌        | 300/2000 [02:28<20:51,  1.36iteration/s, mean_rewards=-675]\u001b[A\n",
            "Training:  15%|█▌        | 300/2000 [02:28<20:51,  1.36iteration/s, mean_rewards=-572]\u001b[A\n",
            "Training:  15%|█▌        | 301/2000 [02:29<18:30,  1.53iteration/s, mean_rewards=-572]\u001b[A\n",
            "Training:  15%|█▌        | 301/2000 [02:29<18:30,  1.53iteration/s, mean_rewards=-826]\u001b[A\n",
            "Training:  15%|█▌        | 302/2000 [02:29<17:51,  1.58iteration/s, mean_rewards=-826]\u001b[A\n",
            "Training:  15%|█▌        | 302/2000 [02:30<17:51,  1.58iteration/s, mean_rewards=-554]\u001b[A\n",
            "Training:  15%|█▌        | 303/2000 [02:30<16:19,  1.73iteration/s, mean_rewards=-554]\u001b[A\n",
            "Training:  15%|█▌        | 303/2000 [02:30<16:19,  1.73iteration/s, mean_rewards=-1.09e+3]\u001b[A\n",
            "Training:  15%|█▌        | 304/2000 [02:31<19:05,  1.48iteration/s, mean_rewards=-1.09e+3]\u001b[A\n",
            "Training:  15%|█▌        | 304/2000 [02:31<19:05,  1.48iteration/s, mean_rewards=-837]    \u001b[A\n",
            "Training:  15%|█▌        | 305/2000 [02:31<18:45,  1.51iteration/s, mean_rewards=-837]\u001b[A\n",
            "Training:  15%|█▌        | 305/2000 [02:32<18:45,  1.51iteration/s, mean_rewards=-584]\u001b[A\n",
            "Training:  15%|█▌        | 306/2000 [02:32<17:53,  1.58iteration/s, mean_rewards=-584]\u001b[A\n",
            "Training:  15%|█▌        | 306/2000 [02:32<17:53,  1.58iteration/s, mean_rewards=-538]\u001b[A\n",
            "Training:  15%|█▌        | 307/2000 [02:32<17:05,  1.65iteration/s, mean_rewards=-538]\u001b[A\n",
            "Training:  15%|█▌        | 307/2000 [02:33<17:05,  1.65iteration/s, mean_rewards=-2e+3]\u001b[A\n",
            "Training:  15%|█▌        | 308/2000 [02:34<22:16,  1.27iteration/s, mean_rewards=-2e+3]\u001b[A\n",
            "Training:  15%|█▌        | 308/2000 [02:34<22:16,  1.27iteration/s, mean_rewards=-619] \u001b[A\n",
            "Training:  15%|█▌        | 309/2000 [02:34<19:50,  1.42iteration/s, mean_rewards=-619]\u001b[A\n",
            "Training:  15%|█▌        | 309/2000 [02:34<19:50,  1.42iteration/s, mean_rewards=-568]\u001b[A\n",
            "Training:  16%|█▌        | 310/2000 [02:34<17:58,  1.57iteration/s, mean_rewards=-568]\u001b[A\n",
            "Training:  16%|█▌        | 310/2000 [02:35<17:58,  1.57iteration/s, mean_rewards=-1.64e+3]\u001b[A\n",
            "Training:  16%|█▌        | 311/2000 [02:36<23:04,  1.22iteration/s, mean_rewards=-1.64e+3]\u001b[A\n",
            "Training:  16%|█▌        | 311/2000 [02:37<23:04,  1.22iteration/s, mean_rewards=-2.57e+3]\u001b[A\n",
            "Training:  16%|█▌        | 312/2000 [02:37<29:17,  1.04s/iteration, mean_rewards=-2.57e+3]\u001b[A\n",
            "Training:  16%|█▌        | 312/2000 [02:38<29:17,  1.04s/iteration, mean_rewards=-573]    \u001b[A\n",
            "Training:  16%|█▌        | 313/2000 [02:38<26:04,  1.08iteration/s, mean_rewards=-573]\u001b[A\n",
            "Training:  16%|█▌        | 313/2000 [02:38<26:04,  1.08iteration/s, mean_rewards=-634]\u001b[A\n",
            "Training:  16%|█▌        | 314/2000 [02:39<23:46,  1.18iteration/s, mean_rewards=-634]\u001b[A\n",
            "Training:  16%|█▌        | 314/2000 [02:39<23:46,  1.18iteration/s, mean_rewards=-633]\u001b[A\n",
            "Training:  16%|█▌        | 315/2000 [02:39<22:27,  1.25iteration/s, mean_rewards=-633]\u001b[A\n",
            "Training:  16%|█▌        | 315/2000 [02:40<22:27,  1.25iteration/s, mean_rewards=-858]\u001b[A\n",
            "Training:  16%|█▌        | 316/2000 [02:40<24:25,  1.15iteration/s, mean_rewards=-858]\u001b[A\n",
            "Training:  16%|█▌        | 316/2000 [02:41<24:25,  1.15iteration/s, mean_rewards=-563]\u001b[A\n",
            "Training:  16%|█▌        | 317/2000 [02:41<20:56,  1.34iteration/s, mean_rewards=-563]\u001b[A\n",
            "Training:  16%|█▌        | 317/2000 [02:42<20:56,  1.34iteration/s, mean_rewards=-1.87e+3]\u001b[A\n",
            "Training:  16%|█▌        | 318/2000 [02:42<23:37,  1.19iteration/s, mean_rewards=-1.87e+3]\u001b[A\n",
            "Training:  16%|█▌        | 318/2000 [02:42<23:37,  1.19iteration/s, mean_rewards=-668]    \u001b[A\n",
            "Training:  16%|█▌        | 319/2000 [02:42<20:53,  1.34iteration/s, mean_rewards=-668]\u001b[A\n",
            "Training:  16%|█▌        | 319/2000 [02:43<20:53,  1.34iteration/s, mean_rewards=-1.01e+3]\u001b[A\n",
            "Training:  16%|█▌        | 320/2000 [02:43<21:13,  1.32iteration/s, mean_rewards=-1.01e+3]\u001b[A\n",
            "Training:  16%|█▌        | 320/2000 [02:44<21:13,  1.32iteration/s, mean_rewards=-1.1e+3] \u001b[A\n",
            "Training:  16%|█▌        | 321/2000 [02:44<20:50,  1.34iteration/s, mean_rewards=-1.1e+3]\u001b[A\n",
            "Training:  16%|█▌        | 321/2000 [02:44<20:50,  1.34iteration/s, mean_rewards=-471]   \u001b[A\n",
            "Training:  16%|█▌        | 322/2000 [02:44<18:48,  1.49iteration/s, mean_rewards=-471]\u001b[A\n",
            "Training:  16%|█▌        | 322/2000 [02:45<18:48,  1.49iteration/s, mean_rewards=-760]\u001b[A\n",
            "Training:  16%|█▌        | 323/2000 [02:45<18:29,  1.51iteration/s, mean_rewards=-760]\u001b[A\n",
            "Training:  16%|█▌        | 323/2000 [02:46<18:29,  1.51iteration/s, mean_rewards=-852]\u001b[A\n",
            "Training:  16%|█▌        | 324/2000 [02:46<18:45,  1.49iteration/s, mean_rewards=-852]\u001b[A\n",
            "Training:  16%|█▌        | 324/2000 [02:46<18:45,  1.49iteration/s, mean_rewards=-1.63e+3]\u001b[A\n",
            "Training:  16%|█▋        | 325/2000 [02:47<20:57,  1.33iteration/s, mean_rewards=-1.63e+3]\u001b[A\n",
            "Training:  16%|█▋        | 325/2000 [02:47<20:57,  1.33iteration/s, mean_rewards=-603]    \u001b[A\n",
            "Training:  16%|█▋        | 326/2000 [02:47<18:41,  1.49iteration/s, mean_rewards=-603]\u001b[A\n",
            "Training:  16%|█▋        | 326/2000 [02:48<18:41,  1.49iteration/s, mean_rewards=-661]\u001b[A\n",
            "Training:  16%|█▋        | 327/2000 [02:48<17:51,  1.56iteration/s, mean_rewards=-661]\u001b[A\n",
            "Training:  16%|█▋        | 327/2000 [02:48<17:51,  1.56iteration/s, mean_rewards=-719]\u001b[A\n",
            "Training:  16%|█▋        | 328/2000 [02:48<17:32,  1.59iteration/s, mean_rewards=-719]\u001b[A\n",
            "Training:  16%|█▋        | 328/2000 [02:49<17:32,  1.59iteration/s, mean_rewards=-1.1e+3]\u001b[A\n",
            "Training:  16%|█▋        | 329/2000 [02:49<18:59,  1.47iteration/s, mean_rewards=-1.1e+3]\u001b[A\n",
            "Training:  16%|█▋        | 329/2000 [02:49<18:59,  1.47iteration/s, mean_rewards=-537]   \u001b[A\n",
            "Training:  16%|█▋        | 330/2000 [02:50<17:25,  1.60iteration/s, mean_rewards=-537]\u001b[A\n",
            "Training:  16%|█▋        | 330/2000 [02:50<17:25,  1.60iteration/s, mean_rewards=-712]\u001b[A\n",
            "Training:  17%|█▋        | 331/2000 [02:50<17:30,  1.59iteration/s, mean_rewards=-712]\u001b[A\n",
            "Training:  17%|█▋        | 331/2000 [02:51<17:30,  1.59iteration/s, mean_rewards=-870]\u001b[A\n",
            "Training:  17%|█▋        | 332/2000 [02:51<20:11,  1.38iteration/s, mean_rewards=-870]\u001b[A\n",
            "Training:  17%|█▋        | 332/2000 [02:52<20:11,  1.38iteration/s, mean_rewards=-627]\u001b[A\n",
            "Training:  17%|█▋        | 333/2000 [02:52<19:47,  1.40iteration/s, mean_rewards=-627]\u001b[A\n",
            "Training:  17%|█▋        | 333/2000 [02:52<19:47,  1.40iteration/s, mean_rewards=-665]\u001b[A\n",
            "Training:  17%|█▋        | 334/2000 [02:53<19:27,  1.43iteration/s, mean_rewards=-665]\u001b[A\n",
            "Training:  17%|█▋        | 334/2000 [02:53<19:27,  1.43iteration/s, mean_rewards=-1.55e+3]\u001b[A\n",
            "Training:  17%|█▋        | 335/2000 [02:54<22:18,  1.24iteration/s, mean_rewards=-1.55e+3]\u001b[A\n",
            "Training:  17%|█▋        | 335/2000 [02:54<22:18,  1.24iteration/s, mean_rewards=-1.04e+3]\u001b[A\n",
            "Training:  17%|█▋        | 336/2000 [02:55<23:12,  1.19iteration/s, mean_rewards=-1.04e+3]\u001b[A\n",
            "Training:  17%|█▋        | 336/2000 [02:55<23:12,  1.19iteration/s, mean_rewards=-591]    \u001b[A\n",
            "Training:  17%|█▋        | 337/2000 [02:55<21:01,  1.32iteration/s, mean_rewards=-591]\u001b[A\n",
            "Training:  17%|█▋        | 337/2000 [02:56<21:01,  1.32iteration/s, mean_rewards=-822]\u001b[A\n",
            "Training:  17%|█▋        | 338/2000 [02:56<20:23,  1.36iteration/s, mean_rewards=-822]\u001b[A\n",
            "Training:  17%|█▋        | 338/2000 [02:56<20:23,  1.36iteration/s, mean_rewards=-911]\u001b[A\n",
            "Training:  17%|█▋        | 339/2000 [02:56<20:12,  1.37iteration/s, mean_rewards=-911]\u001b[A\n",
            "Training:  17%|█▋        | 339/2000 [02:57<20:12,  1.37iteration/s, mean_rewards=-797]\u001b[A\n",
            "Training:  17%|█▋        | 340/2000 [02:57<19:08,  1.44iteration/s, mean_rewards=-797]\u001b[A\n",
            "Training:  17%|█▋        | 340/2000 [02:57<19:08,  1.44iteration/s, mean_rewards=-732]\u001b[A\n",
            "Training:  17%|█▋        | 341/2000 [02:58<17:49,  1.55iteration/s, mean_rewards=-732]\u001b[A\n",
            "Training:  17%|█▋        | 341/2000 [02:58<17:49,  1.55iteration/s, mean_rewards=-1.09e+3]\u001b[A\n",
            "Training:  17%|█▋        | 342/2000 [02:58<19:22,  1.43iteration/s, mean_rewards=-1.09e+3]\u001b[A\n",
            "Training:  17%|█▋        | 342/2000 [02:59<19:22,  1.43iteration/s, mean_rewards=-703]    \u001b[A\n",
            "Training:  17%|█▋        | 343/2000 [02:59<18:03,  1.53iteration/s, mean_rewards=-703]\u001b[A\n",
            "Training:  17%|█▋        | 343/2000 [02:59<18:03,  1.53iteration/s, mean_rewards=-536]\u001b[A\n",
            "Training:  17%|█▋        | 344/2000 [02:59<16:22,  1.69iteration/s, mean_rewards=-536]\u001b[A\n",
            "Training:  17%|█▋        | 344/2000 [03:00<16:22,  1.69iteration/s, mean_rewards=-645]\u001b[A\n",
            "Training:  17%|█▋        | 345/2000 [03:00<16:05,  1.71iteration/s, mean_rewards=-645]\u001b[A\n",
            "Training:  17%|█▋        | 345/2000 [03:01<16:05,  1.71iteration/s, mean_rewards=-1.03e+3]\u001b[A\n",
            "Training:  17%|█▋        | 346/2000 [03:01<17:08,  1.61iteration/s, mean_rewards=-1.03e+3]\u001b[A\n",
            "Training:  17%|█▋        | 346/2000 [03:01<17:08,  1.61iteration/s, mean_rewards=-808]    \u001b[A\n",
            "Training:  17%|█▋        | 347/2000 [03:01<16:40,  1.65iteration/s, mean_rewards=-808]\u001b[A\n",
            "Training:  17%|█▋        | 347/2000 [03:02<16:40,  1.65iteration/s, mean_rewards=-797]\u001b[A\n",
            "Training:  17%|█▋        | 348/2000 [03:02<17:02,  1.62iteration/s, mean_rewards=-797]\u001b[A\n",
            "Training:  17%|█▋        | 348/2000 [03:02<17:02,  1.62iteration/s, mean_rewards=-632]\u001b[A\n",
            "Training:  17%|█▋        | 349/2000 [03:02<16:11,  1.70iteration/s, mean_rewards=-632]\u001b[A\n",
            "Training:  17%|█▋        | 349/2000 [03:03<16:11,  1.70iteration/s, mean_rewards=-726]\u001b[A\n",
            "Training:  18%|█▊        | 350/2000 [03:03<17:37,  1.56iteration/s, mean_rewards=-726]\u001b[A\n",
            "Training:  18%|█▊        | 350/2000 [03:04<17:37,  1.56iteration/s, mean_rewards=-1.3e+3]\u001b[A\n",
            "Training:  18%|█▊        | 351/2000 [03:04<22:14,  1.24iteration/s, mean_rewards=-1.3e+3]\u001b[A\n",
            "Training:  18%|█▊        | 351/2000 [03:06<22:14,  1.24iteration/s, mean_rewards=-2.54e+3]\u001b[A\n",
            "Training:  18%|█▊        | 352/2000 [03:06<30:50,  1.12s/iteration, mean_rewards=-2.54e+3]\u001b[A\n",
            "Training:  18%|█▊        | 352/2000 [03:07<30:50,  1.12s/iteration, mean_rewards=-734]    \u001b[A\n",
            "Training:  18%|█▊        | 353/2000 [03:07<26:31,  1.03iteration/s, mean_rewards=-734]\u001b[A\n",
            "Training:  18%|█▊        | 353/2000 [03:07<26:31,  1.03iteration/s, mean_rewards=-673]\u001b[A\n",
            "Training:  18%|█▊        | 354/2000 [03:08<23:45,  1.16iteration/s, mean_rewards=-673]\u001b[A\n",
            "Training:  18%|█▊        | 354/2000 [03:08<23:45,  1.16iteration/s, mean_rewards=-1.31e+3]\u001b[A\n",
            "Training:  18%|█▊        | 355/2000 [03:08<23:59,  1.14iteration/s, mean_rewards=-1.31e+3]\u001b[A\n",
            "Training:  18%|█▊        | 355/2000 [03:09<23:59,  1.14iteration/s, mean_rewards=-1.7e+3] \u001b[A\n",
            "Training:  18%|█▊        | 356/2000 [03:10<27:02,  1.01iteration/s, mean_rewards=-1.7e+3]\u001b[A\n",
            "Training:  18%|█▊        | 356/2000 [03:10<27:02,  1.01iteration/s, mean_rewards=-1.01e+3]\u001b[A\n",
            "Training:  18%|█▊        | 357/2000 [03:10<25:33,  1.07iteration/s, mean_rewards=-1.01e+3]\u001b[A\n",
            "Training:  18%|█▊        | 357/2000 [03:11<25:33,  1.07iteration/s, mean_rewards=-498]    \u001b[A\n",
            "Training:  18%|█▊        | 358/2000 [03:11<21:41,  1.26iteration/s, mean_rewards=-498]\u001b[A\n",
            "Training:  18%|█▊        | 358/2000 [03:12<21:41,  1.26iteration/s, mean_rewards=-1.24e+3]\u001b[A\n",
            "Training:  18%|█▊        | 359/2000 [03:12<23:15,  1.18iteration/s, mean_rewards=-1.24e+3]\u001b[A\n",
            "Training:  18%|█▊        | 359/2000 [03:12<23:15,  1.18iteration/s, mean_rewards=-668]    \u001b[A\n",
            "Training:  18%|█▊        | 360/2000 [03:12<20:43,  1.32iteration/s, mean_rewards=-668]\u001b[A\n",
            "Training:  18%|█▊        | 360/2000 [03:13<20:43,  1.32iteration/s, mean_rewards=-585]\u001b[A\n",
            "Training:  18%|█▊        | 361/2000 [03:13<18:59,  1.44iteration/s, mean_rewards=-585]\u001b[A\n",
            "Training:  18%|█▊        | 361/2000 [03:13<18:59,  1.44iteration/s, mean_rewards=-719]\u001b[A\n",
            "Training:  18%|█▊        | 362/2000 [03:14<17:54,  1.52iteration/s, mean_rewards=-719]\u001b[A\n",
            "Training:  18%|█▊        | 362/2000 [03:14<17:54,  1.52iteration/s, mean_rewards=-627]\u001b[A\n",
            "Training:  18%|█▊        | 363/2000 [03:14<16:57,  1.61iteration/s, mean_rewards=-627]\u001b[A\n",
            "Training:  18%|█▊        | 363/2000 [03:14<16:57,  1.61iteration/s, mean_rewards=-514]\u001b[A\n",
            "Training:  18%|█▊        | 364/2000 [03:15<15:45,  1.73iteration/s, mean_rewards=-514]\u001b[A\n",
            "Training:  18%|█▊        | 364/2000 [03:15<15:45,  1.73iteration/s, mean_rewards=-991]\u001b[A\n",
            "Training:  18%|█▊        | 365/2000 [03:16<19:47,  1.38iteration/s, mean_rewards=-991]\u001b[A\n",
            "Training:  18%|█▊        | 365/2000 [03:16<19:47,  1.38iteration/s, mean_rewards=-618]\u001b[A\n",
            "Training:  18%|█▊        | 366/2000 [03:16<18:38,  1.46iteration/s, mean_rewards=-618]\u001b[A\n",
            "Training:  18%|█▊        | 366/2000 [03:17<18:38,  1.46iteration/s, mean_rewards=-595]\u001b[A\n",
            "Training:  18%|█▊        | 367/2000 [03:17<17:50,  1.53iteration/s, mean_rewards=-595]\u001b[A\n",
            "Training:  18%|█▊        | 367/2000 [03:17<17:50,  1.53iteration/s, mean_rewards=-583]\u001b[A\n",
            "Training:  18%|█▊        | 368/2000 [03:18<18:30,  1.47iteration/s, mean_rewards=-583]\u001b[A\n",
            "Training:  18%|█▊        | 368/2000 [03:18<18:30,  1.47iteration/s, mean_rewards=-605]\u001b[A\n",
            "Training:  18%|█▊        | 369/2000 [03:18<17:53,  1.52iteration/s, mean_rewards=-605]\u001b[A\n",
            "Training:  18%|█▊        | 369/2000 [03:19<17:53,  1.52iteration/s, mean_rewards=-677]\u001b[A\n",
            "Training:  18%|█▊        | 370/2000 [03:19<17:04,  1.59iteration/s, mean_rewards=-677]\u001b[A\n",
            "Training:  18%|█▊        | 370/2000 [03:20<17:04,  1.59iteration/s, mean_rewards=-2.54e+3]\u001b[A\n",
            "Training:  19%|█▊        | 371/2000 [03:20<23:44,  1.14iteration/s, mean_rewards=-2.54e+3]\u001b[A\n",
            "Training:  19%|█▊        | 371/2000 [03:21<23:44,  1.14iteration/s, mean_rewards=-590]    \u001b[A\n",
            "Training:  19%|█▊        | 372/2000 [03:21<21:44,  1.25iteration/s, mean_rewards=-590]\u001b[A\n",
            "Training:  19%|█▊        | 372/2000 [03:21<21:44,  1.25iteration/s, mean_rewards=-425]\u001b[A\n",
            "Training:  19%|█▊        | 373/2000 [03:21<18:48,  1.44iteration/s, mean_rewards=-425]\u001b[A\n",
            "Training:  19%|█▊        | 373/2000 [03:22<18:48,  1.44iteration/s, mean_rewards=-773]\u001b[A\n",
            "Training:  19%|█▊        | 374/2000 [03:22<17:46,  1.52iteration/s, mean_rewards=-773]\u001b[A\n",
            "Training:  19%|█▊        | 374/2000 [03:22<17:46,  1.52iteration/s, mean_rewards=-835]\u001b[A\n",
            "Training:  19%|█▉        | 375/2000 [03:23<18:46,  1.44iteration/s, mean_rewards=-835]\u001b[A\n",
            "Training:  19%|█▉        | 375/2000 [03:23<18:46,  1.44iteration/s, mean_rewards=-510]\u001b[A\n",
            "Training:  19%|█▉        | 376/2000 [03:23<16:42,  1.62iteration/s, mean_rewards=-510]\u001b[A\n",
            "Training:  19%|█▉        | 376/2000 [03:23<16:42,  1.62iteration/s, mean_rewards=-740]\u001b[A\n",
            "Training:  19%|█▉        | 377/2000 [03:24<15:55,  1.70iteration/s, mean_rewards=-740]\u001b[A\n",
            "Training:  19%|█▉        | 377/2000 [03:24<15:55,  1.70iteration/s, mean_rewards=-887]\u001b[A\n",
            "Training:  19%|█▉        | 378/2000 [03:24<16:34,  1.63iteration/s, mean_rewards=-887]\u001b[A\n",
            "Training:  19%|█▉        | 378/2000 [03:25<16:34,  1.63iteration/s, mean_rewards=-724]\u001b[A\n",
            "Training:  19%|█▉        | 379/2000 [03:25<15:31,  1.74iteration/s, mean_rewards=-724]\u001b[A\n",
            "Training:  19%|█▉        | 379/2000 [03:25<15:31,  1.74iteration/s, mean_rewards=-924]\u001b[A\n",
            "Training:  19%|█▉        | 380/2000 [03:26<17:14,  1.57iteration/s, mean_rewards=-924]\u001b[A\n",
            "Training:  19%|█▉        | 380/2000 [03:26<17:14,  1.57iteration/s, mean_rewards=-710]\u001b[A\n",
            "Training:  19%|█▉        | 381/2000 [03:26<16:00,  1.69iteration/s, mean_rewards=-710]\u001b[A\n",
            "Training:  19%|█▉        | 381/2000 [03:27<16:00,  1.69iteration/s, mean_rewards=-1.43e+3]\u001b[A\n",
            "Training:  19%|█▉        | 382/2000 [03:27<19:09,  1.41iteration/s, mean_rewards=-1.43e+3]\u001b[A\n",
            "Training:  19%|█▉        | 382/2000 [03:27<19:09,  1.41iteration/s, mean_rewards=-775]    \u001b[A\n",
            "Training:  19%|█▉        | 383/2000 [03:28<19:30,  1.38iteration/s, mean_rewards=-775]\u001b[A\n",
            "Training:  19%|█▉        | 383/2000 [03:28<19:30,  1.38iteration/s, mean_rewards=-575]\u001b[A\n",
            "Training:  19%|█▉        | 384/2000 [03:28<19:21,  1.39iteration/s, mean_rewards=-575]\u001b[A\n",
            "Training:  19%|█▉        | 384/2000 [03:29<19:21,  1.39iteration/s, mean_rewards=-574]\u001b[A\n",
            "Training:  19%|█▉        | 385/2000 [03:29<19:37,  1.37iteration/s, mean_rewards=-574]\u001b[A\n",
            "Training:  19%|█▉        | 385/2000 [03:30<19:37,  1.37iteration/s, mean_rewards=-635]\u001b[A\n",
            "Training:  19%|█▉        | 386/2000 [03:30<19:55,  1.35iteration/s, mean_rewards=-635]\u001b[A\n",
            "Training:  19%|█▉        | 386/2000 [03:30<19:55,  1.35iteration/s, mean_rewards=-663]\u001b[A\n",
            "Training:  19%|█▉        | 387/2000 [03:31<18:41,  1.44iteration/s, mean_rewards=-663]\u001b[A\n",
            "Training:  19%|█▉        | 387/2000 [03:31<18:41,  1.44iteration/s, mean_rewards=-660]\u001b[A\n",
            "Training:  19%|█▉        | 388/2000 [03:31<17:36,  1.53iteration/s, mean_rewards=-660]\u001b[A\n",
            "Training:  19%|█▉        | 388/2000 [03:31<17:36,  1.53iteration/s, mean_rewards=-489]\u001b[A\n",
            "Training:  19%|█▉        | 389/2000 [03:32<15:32,  1.73iteration/s, mean_rewards=-489]\u001b[A\n",
            "Training:  19%|█▉        | 389/2000 [03:32<15:32,  1.73iteration/s, mean_rewards=-562]\u001b[A\n",
            "Training:  20%|█▉        | 390/2000 [03:32<15:10,  1.77iteration/s, mean_rewards=-562]\u001b[A\n",
            "Training:  20%|█▉        | 390/2000 [03:32<15:10,  1.77iteration/s, mean_rewards=-504]\u001b[A\n",
            "Training:  20%|█▉        | 391/2000 [03:33<14:20,  1.87iteration/s, mean_rewards=-504]\u001b[A\n",
            "Training:  20%|█▉        | 391/2000 [03:33<14:20,  1.87iteration/s, mean_rewards=-836]\u001b[A\n",
            "Training:  20%|█▉        | 392/2000 [03:33<15:46,  1.70iteration/s, mean_rewards=-836]\u001b[A\n",
            "Training:  20%|█▉        | 392/2000 [03:34<15:46,  1.70iteration/s, mean_rewards=-544]\u001b[A\n",
            "Training:  20%|█▉        | 393/2000 [03:34<15:37,  1.71iteration/s, mean_rewards=-544]\u001b[A\n",
            "Training:  20%|█▉        | 393/2000 [03:34<15:37,  1.71iteration/s, mean_rewards=-797]\u001b[A\n",
            "Training:  20%|█▉        | 394/2000 [03:34<16:23,  1.63iteration/s, mean_rewards=-797]\u001b[A\n",
            "Training:  20%|█▉        | 394/2000 [03:35<16:23,  1.63iteration/s, mean_rewards=-551]\u001b[A\n",
            "Training:  20%|█▉        | 395/2000 [03:35<15:47,  1.69iteration/s, mean_rewards=-551]\u001b[A\n",
            "Training:  20%|█▉        | 395/2000 [03:35<15:47,  1.69iteration/s, mean_rewards=-661]\u001b[A\n",
            "Training:  20%|█▉        | 396/2000 [03:36<15:54,  1.68iteration/s, mean_rewards=-661]\u001b[A\n",
            "Training:  20%|█▉        | 396/2000 [03:36<15:54,  1.68iteration/s, mean_rewards=-555]\u001b[A\n",
            "Training:  20%|█▉        | 397/2000 [03:36<14:39,  1.82iteration/s, mean_rewards=-555]\u001b[A\n",
            "Training:  20%|█▉        | 397/2000 [03:36<14:39,  1.82iteration/s, mean_rewards=-566]\u001b[A\n",
            "Training:  20%|█▉        | 398/2000 [03:37<14:27,  1.85iteration/s, mean_rewards=-566]\u001b[A\n",
            "Training:  20%|█▉        | 398/2000 [03:37<14:27,  1.85iteration/s, mean_rewards=-515]\u001b[A\n",
            "Training:  20%|█▉        | 399/2000 [03:37<14:06,  1.89iteration/s, mean_rewards=-515]\u001b[A\n",
            "Training:  20%|█▉        | 399/2000 [03:38<14:06,  1.89iteration/s, mean_rewards=-2.33e+3]\u001b[A\n",
            "Training:  20%|██        | 400/2000 [03:38<20:15,  1.32iteration/s, mean_rewards=-2.33e+3]\u001b[A\n",
            "Training:  20%|██        | 400/2000 [03:39<20:15,  1.32iteration/s, mean_rewards=-763]    \u001b[A\n",
            "Training:  20%|██        | 401/2000 [03:39<18:33,  1.44iteration/s, mean_rewards=-763]\u001b[A\n",
            "Training:  20%|██        | 401/2000 [03:39<18:33,  1.44iteration/s, mean_rewards=-929]\u001b[A\n",
            "Training:  20%|██        | 402/2000 [03:40<19:11,  1.39iteration/s, mean_rewards=-929]\u001b[A\n",
            "Training:  20%|██        | 402/2000 [03:40<19:11,  1.39iteration/s, mean_rewards=-978]\u001b[A\n",
            "Training:  20%|██        | 403/2000 [03:41<21:24,  1.24iteration/s, mean_rewards=-978]\u001b[A\n",
            "Training:  20%|██        | 403/2000 [03:41<21:24,  1.24iteration/s, mean_rewards=-671]\u001b[A\n",
            "Training:  20%|██        | 404/2000 [03:41<21:00,  1.27iteration/s, mean_rewards=-671]\u001b[A\n",
            "Training:  20%|██        | 404/2000 [03:42<21:00,  1.27iteration/s, mean_rewards=-805]\u001b[A\n",
            "Training:  20%|██        | 405/2000 [03:42<22:25,  1.19iteration/s, mean_rewards=-805]\u001b[A\n",
            "Training:  20%|██        | 405/2000 [03:43<22:25,  1.19iteration/s, mean_rewards=-776]\u001b[A\n",
            "Training:  20%|██        | 406/2000 [03:43<21:16,  1.25iteration/s, mean_rewards=-776]\u001b[A\n",
            "Training:  20%|██        | 406/2000 [03:44<21:16,  1.25iteration/s, mean_rewards=-1.16e+3]\u001b[A\n",
            "Training:  20%|██        | 407/2000 [03:44<21:25,  1.24iteration/s, mean_rewards=-1.16e+3]\u001b[A\n",
            "Training:  20%|██        | 407/2000 [03:45<21:25,  1.24iteration/s, mean_rewards=-935]    \u001b[A\n",
            "Training:  20%|██        | 408/2000 [03:45<21:26,  1.24iteration/s, mean_rewards=-935]\u001b[A\n",
            "Training:  20%|██        | 408/2000 [03:45<21:26,  1.24iteration/s, mean_rewards=-509]\u001b[A\n",
            "Training:  20%|██        | 409/2000 [03:45<18:53,  1.40iteration/s, mean_rewards=-509]\u001b[A\n",
            "Training:  20%|██        | 409/2000 [03:46<18:53,  1.40iteration/s, mean_rewards=-425]\u001b[A\n",
            "Training:  20%|██        | 410/2000 [03:46<16:38,  1.59iteration/s, mean_rewards=-425]\u001b[A\n",
            "Training:  20%|██        | 410/2000 [03:46<16:38,  1.59iteration/s, mean_rewards=-1.48e+3]\u001b[A\n",
            "Training:  21%|██        | 411/2000 [03:47<19:32,  1.36iteration/s, mean_rewards=-1.48e+3]\u001b[A\n",
            "Training:  21%|██        | 411/2000 [03:48<19:32,  1.36iteration/s, mean_rewards=-1.93e+3]\u001b[A\n",
            "Training:  21%|██        | 412/2000 [03:48<23:51,  1.11iteration/s, mean_rewards=-1.93e+3]\u001b[A\n",
            "Training:  21%|██        | 412/2000 [03:48<23:51,  1.11iteration/s, mean_rewards=-880]    \u001b[A\n",
            "Training:  21%|██        | 413/2000 [03:49<21:46,  1.21iteration/s, mean_rewards=-880]\u001b[A\n",
            "Training:  21%|██        | 413/2000 [03:49<21:46,  1.21iteration/s, mean_rewards=-900]\u001b[A\n",
            "Training:  21%|██        | 414/2000 [03:49<21:15,  1.24iteration/s, mean_rewards=-900]\u001b[A\n",
            "Training:  21%|██        | 414/2000 [03:50<21:15,  1.24iteration/s, mean_rewards=-714]\u001b[A\n",
            "Training:  21%|██        | 415/2000 [03:50<20:07,  1.31iteration/s, mean_rewards=-714]\u001b[A\n",
            "Training:  21%|██        | 415/2000 [03:51<20:07,  1.31iteration/s, mean_rewards=-2.09e+3]\u001b[A\n",
            "Training:  21%|██        | 416/2000 [03:51<24:16,  1.09iteration/s, mean_rewards=-2.09e+3]\u001b[A\n",
            "Training:  21%|██        | 416/2000 [03:52<24:16,  1.09iteration/s, mean_rewards=-1.14e+3]\u001b[A\n",
            "Training:  21%|██        | 417/2000 [03:52<22:49,  1.16iteration/s, mean_rewards=-1.14e+3]\u001b[A\n",
            "Training:  21%|██        | 417/2000 [03:52<22:49,  1.16iteration/s, mean_rewards=-762]    \u001b[A\n",
            "Training:  21%|██        | 418/2000 [03:53<20:31,  1.28iteration/s, mean_rewards=-762]\u001b[A\n",
            "Training:  21%|██        | 418/2000 [03:53<20:31,  1.28iteration/s, mean_rewards=-956]\u001b[A\n",
            "Training:  21%|██        | 419/2000 [03:54<21:23,  1.23iteration/s, mean_rewards=-956]\u001b[A\n",
            "Training:  21%|██        | 419/2000 [03:54<21:23,  1.23iteration/s, mean_rewards=-1.14e+3]\u001b[A\n",
            "Training:  21%|██        | 420/2000 [03:55<23:32,  1.12iteration/s, mean_rewards=-1.14e+3]\u001b[A\n",
            "Training:  21%|██        | 420/2000 [03:55<23:32,  1.12iteration/s, mean_rewards=-641]    \u001b[A\n",
            "Training:  21%|██        | 421/2000 [03:55<23:09,  1.14iteration/s, mean_rewards=-641]\u001b[A\n",
            "Training:  21%|██        | 421/2000 [03:56<23:09,  1.14iteration/s, mean_rewards=-572]\u001b[A\n",
            "Training:  21%|██        | 422/2000 [03:56<21:14,  1.24iteration/s, mean_rewards=-572]\u001b[A\n",
            "Training:  21%|██        | 422/2000 [03:56<21:14,  1.24iteration/s, mean_rewards=-601]\u001b[A\n",
            "Training:  21%|██        | 423/2000 [03:57<18:31,  1.42iteration/s, mean_rewards=-601]\u001b[A\n",
            "Training:  21%|██        | 423/2000 [03:57<18:31,  1.42iteration/s, mean_rewards=-625]\u001b[A\n",
            "Training:  21%|██        | 424/2000 [03:57<17:33,  1.50iteration/s, mean_rewards=-625]\u001b[A\n",
            "Training:  21%|██        | 424/2000 [03:58<17:33,  1.50iteration/s, mean_rewards=-772]\u001b[A\n",
            "Training:  21%|██▏       | 425/2000 [03:58<17:21,  1.51iteration/s, mean_rewards=-772]\u001b[A\n",
            "Training:  21%|██▏       | 425/2000 [03:58<17:21,  1.51iteration/s, mean_rewards=-621]\u001b[A\n",
            "Training:  21%|██▏       | 426/2000 [03:58<16:17,  1.61iteration/s, mean_rewards=-621]\u001b[A\n",
            "Training:  21%|██▏       | 426/2000 [03:59<16:17,  1.61iteration/s, mean_rewards=-750]\u001b[A\n",
            "Training:  21%|██▏       | 427/2000 [03:59<16:11,  1.62iteration/s, mean_rewards=-750]\u001b[A\n",
            "Training:  21%|██▏       | 427/2000 [03:59<16:11,  1.62iteration/s, mean_rewards=-678]\u001b[A\n",
            "Training:  21%|██▏       | 428/2000 [03:59<15:32,  1.69iteration/s, mean_rewards=-678]\u001b[A\n",
            "Training:  21%|██▏       | 428/2000 [04:00<15:32,  1.69iteration/s, mean_rewards=-744]\u001b[A\n",
            "Training:  21%|██▏       | 429/2000 [04:00<15:46,  1.66iteration/s, mean_rewards=-744]\u001b[A\n",
            "Training:  21%|██▏       | 429/2000 [04:01<15:46,  1.66iteration/s, mean_rewards=-694]\u001b[A\n",
            "Training:  22%|██▏       | 430/2000 [04:01<16:00,  1.63iteration/s, mean_rewards=-694]\u001b[A\n",
            "Training:  22%|██▏       | 430/2000 [04:02<16:00,  1.63iteration/s, mean_rewards=-2.87e+3]\u001b[A\n",
            "Training:  22%|██▏       | 431/2000 [04:02<23:11,  1.13iteration/s, mean_rewards=-2.87e+3]\u001b[A\n",
            "Training:  22%|██▏       | 431/2000 [04:03<23:11,  1.13iteration/s, mean_rewards=-1.49e+3]\u001b[A\n",
            "Training:  22%|██▏       | 432/2000 [04:03<24:09,  1.08iteration/s, mean_rewards=-1.49e+3]\u001b[A\n",
            "Training:  22%|██▏       | 432/2000 [04:04<24:09,  1.08iteration/s, mean_rewards=-1.18e+3]\u001b[A\n",
            "Training:  22%|██▏       | 433/2000 [04:04<23:01,  1.13iteration/s, mean_rewards=-1.18e+3]\u001b[A\n",
            "Training:  22%|██▏       | 433/2000 [04:05<23:01,  1.13iteration/s, mean_rewards=-3.27e+3]\u001b[A\n",
            "Training:  22%|██▏       | 434/2000 [04:06<31:20,  1.20s/iteration, mean_rewards=-3.27e+3]\u001b[A\n",
            "Training:  22%|██▏       | 434/2000 [04:07<31:20,  1.20s/iteration, mean_rewards=-775]    \u001b[A\n",
            "Training:  22%|██▏       | 435/2000 [04:07<28:10,  1.08s/iteration, mean_rewards=-775]\u001b[A\n",
            "Training:  22%|██▏       | 435/2000 [04:08<28:10,  1.08s/iteration, mean_rewards=-1.28e+3]\u001b[A\n",
            "Training:  22%|██▏       | 436/2000 [04:08<30:13,  1.16s/iteration, mean_rewards=-1.28e+3]\u001b[A\n",
            "Training:  22%|██▏       | 436/2000 [04:09<30:13,  1.16s/iteration, mean_rewards=-992]    \u001b[A\n",
            "Training:  22%|██▏       | 437/2000 [04:09<27:43,  1.06s/iteration, mean_rewards=-992]\u001b[A\n",
            "Training:  22%|██▏       | 437/2000 [04:09<27:43,  1.06s/iteration, mean_rewards=-894]\u001b[A\n",
            "Training:  22%|██▏       | 438/2000 [04:10<24:37,  1.06iteration/s, mean_rewards=-894]\u001b[A\n",
            "Training:  22%|██▏       | 438/2000 [04:10<24:37,  1.06iteration/s, mean_rewards=-686]\u001b[A\n",
            "Training:  22%|██▏       | 439/2000 [04:10<22:16,  1.17iteration/s, mean_rewards=-686]\u001b[A\n",
            "Training:  22%|██▏       | 439/2000 [04:11<22:16,  1.17iteration/s, mean_rewards=-564]\u001b[A\n",
            "Training:  22%|██▏       | 440/2000 [04:11<19:42,  1.32iteration/s, mean_rewards=-564]\u001b[A\n",
            "Training:  22%|██▏       | 440/2000 [04:11<19:42,  1.32iteration/s, mean_rewards=-1.19e+3]\u001b[A\n",
            "Training:  22%|██▏       | 441/2000 [04:12<20:45,  1.25iteration/s, mean_rewards=-1.19e+3]\u001b[A\n",
            "Training:  22%|██▏       | 441/2000 [04:12<20:45,  1.25iteration/s, mean_rewards=-980]    \u001b[A\n",
            "Training:  22%|██▏       | 442/2000 [04:12<20:02,  1.30iteration/s, mean_rewards=-980]\u001b[A\n",
            "Training:  22%|██▏       | 442/2000 [04:13<20:02,  1.30iteration/s, mean_rewards=-607]\u001b[A\n",
            "Training:  22%|██▏       | 443/2000 [04:13<18:23,  1.41iteration/s, mean_rewards=-607]\u001b[A\n",
            "Training:  22%|██▏       | 443/2000 [04:14<18:23,  1.41iteration/s, mean_rewards=-1.18e+3]\u001b[A\n",
            "Training:  22%|██▏       | 444/2000 [04:14<19:08,  1.35iteration/s, mean_rewards=-1.18e+3]\u001b[A\n",
            "Training:  22%|██▏       | 444/2000 [04:14<19:08,  1.35iteration/s, mean_rewards=-1.35e+3]\u001b[A\n",
            "Training:  22%|██▏       | 445/2000 [04:15<20:13,  1.28iteration/s, mean_rewards=-1.35e+3]\u001b[A\n",
            "Training:  22%|██▏       | 445/2000 [04:15<20:13,  1.28iteration/s, mean_rewards=-571]    \u001b[A\n",
            "Training:  22%|██▏       | 446/2000 [04:15<17:52,  1.45iteration/s, mean_rewards=-571]\u001b[A\n",
            "Training:  22%|██▏       | 446/2000 [04:15<17:52,  1.45iteration/s, mean_rewards=-662]\u001b[A\n",
            "Training:  22%|██▏       | 447/2000 [04:16<16:17,  1.59iteration/s, mean_rewards=-662]\u001b[A\n",
            "Training:  22%|██▏       | 447/2000 [04:16<16:17,  1.59iteration/s, mean_rewards=-640]\u001b[A\n",
            "Training:  22%|██▏       | 448/2000 [04:16<14:58,  1.73iteration/s, mean_rewards=-640]\u001b[A\n",
            "Training:  22%|██▏       | 448/2000 [04:17<14:58,  1.73iteration/s, mean_rewards=-725]\u001b[A\n",
            "Training:  22%|██▏       | 449/2000 [04:17<15:17,  1.69iteration/s, mean_rewards=-725]\u001b[A\n",
            "Training:  22%|██▏       | 449/2000 [04:17<15:17,  1.69iteration/s, mean_rewards=-818]\u001b[A\n",
            "Training:  22%|██▎       | 450/2000 [04:17<15:50,  1.63iteration/s, mean_rewards=-818]\u001b[A\n",
            "Training:  22%|██▎       | 450/2000 [04:18<15:50,  1.63iteration/s, mean_rewards=-880]\u001b[A\n",
            "Training:  23%|██▎       | 451/2000 [04:18<17:11,  1.50iteration/s, mean_rewards=-880]\u001b[A\n",
            "Training:  23%|██▎       | 451/2000 [04:19<17:11,  1.50iteration/s, mean_rewards=-1.25e+3]\u001b[A\n",
            "Training:  23%|██▎       | 452/2000 [04:19<21:12,  1.22iteration/s, mean_rewards=-1.25e+3]\u001b[A\n",
            "Training:  23%|██▎       | 452/2000 [04:21<21:12,  1.22iteration/s, mean_rewards=-1.93e+3]\u001b[A\n",
            "Training:  23%|██▎       | 453/2000 [04:21<28:33,  1.11s/iteration, mean_rewards=-1.93e+3]\u001b[A\n",
            "Training:  23%|██▎       | 453/2000 [04:22<28:33,  1.11s/iteration, mean_rewards=-851]    \u001b[A\n",
            "Training:  23%|██▎       | 454/2000 [04:22<25:26,  1.01iteration/s, mean_rewards=-851]\u001b[A\n",
            "Training:  23%|██▎       | 454/2000 [04:22<25:26,  1.01iteration/s, mean_rewards=-486]\u001b[A\n",
            "Training:  23%|██▎       | 455/2000 [04:22<21:12,  1.21iteration/s, mean_rewards=-486]\u001b[A\n",
            "Training:  23%|██▎       | 455/2000 [04:23<21:12,  1.21iteration/s, mean_rewards=-642]\u001b[A\n",
            "Training:  23%|██▎       | 456/2000 [04:23<18:28,  1.39iteration/s, mean_rewards=-642]\u001b[A\n",
            "Training:  23%|██▎       | 456/2000 [04:23<18:28,  1.39iteration/s, mean_rewards=-906]\u001b[A\n",
            "Training:  23%|██▎       | 457/2000 [04:23<17:45,  1.45iteration/s, mean_rewards=-906]\u001b[A\n",
            "Training:  23%|██▎       | 457/2000 [04:24<17:45,  1.45iteration/s, mean_rewards=-2.01e+3]\u001b[A\n",
            "Training:  23%|██▎       | 458/2000 [04:25<22:49,  1.13iteration/s, mean_rewards=-2.01e+3]\u001b[A\n",
            "Training:  23%|██▎       | 458/2000 [04:25<22:49,  1.13iteration/s, mean_rewards=-588]    \u001b[A\n",
            "Training:  23%|██▎       | 459/2000 [04:25<19:28,  1.32iteration/s, mean_rewards=-588]\u001b[A\n",
            "Training:  23%|██▎       | 459/2000 [04:26<19:28,  1.32iteration/s, mean_rewards=-618]\u001b[A\n",
            "Training:  23%|██▎       | 460/2000 [04:26<17:51,  1.44iteration/s, mean_rewards=-618]\u001b[A\n",
            "Training:  23%|██▎       | 460/2000 [04:26<17:51,  1.44iteration/s, mean_rewards=-486]\u001b[A\n",
            "Training:  23%|██▎       | 461/2000 [04:26<16:26,  1.56iteration/s, mean_rewards=-486]\u001b[A\n",
            "Training:  23%|██▎       | 461/2000 [04:27<16:26,  1.56iteration/s, mean_rewards=-1.39e+3]\u001b[A\n",
            "Training:  23%|██▎       | 462/2000 [04:27<19:07,  1.34iteration/s, mean_rewards=-1.39e+3]\u001b[A\n",
            "Training:  23%|██▎       | 462/2000 [04:28<19:07,  1.34iteration/s, mean_rewards=-574]    \u001b[A\n",
            "Training:  23%|██▎       | 463/2000 [04:28<16:58,  1.51iteration/s, mean_rewards=-574]\u001b[A\n",
            "Training:  23%|██▎       | 463/2000 [04:28<16:58,  1.51iteration/s, mean_rewards=-609]\u001b[A\n",
            "Training:  23%|██▎       | 464/2000 [04:28<15:32,  1.65iteration/s, mean_rewards=-609]\u001b[A\n",
            "Training:  23%|██▎       | 464/2000 [04:29<15:32,  1.65iteration/s, mean_rewards=-891]\u001b[A\n",
            "Training:  23%|██▎       | 465/2000 [04:29<15:39,  1.63iteration/s, mean_rewards=-891]\u001b[A\n",
            "Training:  23%|██▎       | 465/2000 [04:29<15:39,  1.63iteration/s, mean_rewards=-810]\u001b[A\n",
            "Training:  23%|██▎       | 466/2000 [04:29<15:50,  1.61iteration/s, mean_rewards=-810]\u001b[A\n",
            "Training:  23%|██▎       | 466/2000 [04:30<15:50,  1.61iteration/s, mean_rewards=-531]\u001b[A\n",
            "Training:  23%|██▎       | 467/2000 [04:30<14:07,  1.81iteration/s, mean_rewards=-531]\u001b[A\n",
            "Training:  23%|██▎       | 467/2000 [04:30<14:07,  1.81iteration/s, mean_rewards=-1.08e+3]\u001b[A\n",
            "Training:  23%|██▎       | 468/2000 [04:31<16:38,  1.53iteration/s, mean_rewards=-1.08e+3]\u001b[A\n",
            "Training:  23%|██▎       | 468/2000 [04:31<16:38,  1.53iteration/s, mean_rewards=-488]    \u001b[A\n",
            "Training:  23%|██▎       | 469/2000 [04:31<15:51,  1.61iteration/s, mean_rewards=-488]\u001b[A\n",
            "Training:  23%|██▎       | 469/2000 [04:32<15:51,  1.61iteration/s, mean_rewards=-605]\u001b[A\n",
            "Training:  24%|██▎       | 470/2000 [04:32<15:33,  1.64iteration/s, mean_rewards=-605]\u001b[A\n",
            "Training:  24%|██▎       | 470/2000 [04:32<15:33,  1.64iteration/s, mean_rewards=-607]\u001b[A\n",
            "Training:  24%|██▎       | 471/2000 [04:33<16:30,  1.54iteration/s, mean_rewards=-607]\u001b[A\n",
            "Training:  24%|██▎       | 471/2000 [04:33<16:30,  1.54iteration/s, mean_rewards=-667]\u001b[A\n",
            "Training:  24%|██▎       | 472/2000 [04:33<17:42,  1.44iteration/s, mean_rewards=-667]\u001b[A\n",
            "Training:  24%|██▎       | 472/2000 [04:34<17:42,  1.44iteration/s, mean_rewards=-632]\u001b[A\n",
            "Training:  24%|██▎       | 473/2000 [04:34<17:07,  1.49iteration/s, mean_rewards=-632]\u001b[A\n",
            "Training:  24%|██▎       | 473/2000 [04:35<17:07,  1.49iteration/s, mean_rewards=-2.74e+3]\u001b[A\n",
            "Training:  24%|██▎       | 474/2000 [04:36<24:50,  1.02iteration/s, mean_rewards=-2.74e+3]\u001b[A\n",
            "Training:  24%|██▎       | 474/2000 [04:36<24:50,  1.02iteration/s, mean_rewards=-546]    \u001b[A\n",
            "Training:  24%|██▍       | 475/2000 [04:36<21:30,  1.18iteration/s, mean_rewards=-546]\u001b[A\n",
            "Training:  24%|██▍       | 475/2000 [04:37<21:30,  1.18iteration/s, mean_rewards=-477]\u001b[A\n",
            "Training:  24%|██▍       | 476/2000 [04:37<18:40,  1.36iteration/s, mean_rewards=-477]\u001b[A\n",
            "Training:  24%|██▍       | 476/2000 [04:37<18:40,  1.36iteration/s, mean_rewards=-1.37e+3]\u001b[A\n",
            "Training:  24%|██▍       | 477/2000 [04:38<20:05,  1.26iteration/s, mean_rewards=-1.37e+3]\u001b[A\n",
            "Training:  24%|██▍       | 477/2000 [04:38<20:05,  1.26iteration/s, mean_rewards=-1.09e+3]\u001b[A\n",
            "Training:  24%|██▍       | 478/2000 [04:38<20:21,  1.25iteration/s, mean_rewards=-1.09e+3]\u001b[A\n",
            "Training:  24%|██▍       | 478/2000 [04:39<20:21,  1.25iteration/s, mean_rewards=-1.11e+3]\u001b[A\n",
            "Training:  24%|██▍       | 479/2000 [04:39<20:23,  1.24iteration/s, mean_rewards=-1.11e+3]\u001b[A\n",
            "Training:  24%|██▍       | 479/2000 [04:40<20:23,  1.24iteration/s, mean_rewards=-727]    \u001b[A\n",
            "Training:  24%|██▍       | 480/2000 [04:40<19:03,  1.33iteration/s, mean_rewards=-727]\u001b[A\n",
            "Training:  24%|██▍       | 480/2000 [04:40<19:03,  1.33iteration/s, mean_rewards=-539]\u001b[A\n",
            "Training:  24%|██▍       | 481/2000 [04:40<16:41,  1.52iteration/s, mean_rewards=-539]\u001b[A\n",
            "Training:  24%|██▍       | 481/2000 [04:41<16:41,  1.52iteration/s, mean_rewards=-512]\u001b[A\n",
            "Training:  24%|██▍       | 482/2000 [04:41<14:46,  1.71iteration/s, mean_rewards=-512]\u001b[A\n",
            "Training:  24%|██▍       | 482/2000 [04:41<14:46,  1.71iteration/s, mean_rewards=-721]\u001b[A\n",
            "Training:  24%|██▍       | 483/2000 [04:41<14:36,  1.73iteration/s, mean_rewards=-721]\u001b[A\n",
            "Training:  24%|██▍       | 483/2000 [04:42<14:36,  1.73iteration/s, mean_rewards=-652]\u001b[A\n",
            "Training:  24%|██▍       | 484/2000 [04:42<14:07,  1.79iteration/s, mean_rewards=-652]\u001b[A\n",
            "Training:  24%|██▍       | 484/2000 [04:42<14:07,  1.79iteration/s, mean_rewards=-706]\u001b[A\n",
            "Training:  24%|██▍       | 485/2000 [04:43<14:50,  1.70iteration/s, mean_rewards=-706]\u001b[A\n",
            "Training:  24%|██▍       | 485/2000 [04:43<14:50,  1.70iteration/s, mean_rewards=-893]\u001b[A\n",
            "Training:  24%|██▍       | 486/2000 [04:43<16:24,  1.54iteration/s, mean_rewards=-893]\u001b[A\n",
            "Training:  24%|██▍       | 486/2000 [04:44<16:24,  1.54iteration/s, mean_rewards=-985]\u001b[A\n",
            "Training:  24%|██▍       | 487/2000 [04:44<17:26,  1.45iteration/s, mean_rewards=-985]\u001b[A\n",
            "Training:  24%|██▍       | 487/2000 [04:45<17:26,  1.45iteration/s, mean_rewards=-796]\u001b[A\n",
            "Training:  24%|██▍       | 488/2000 [04:45<18:30,  1.36iteration/s, mean_rewards=-796]\u001b[A\n",
            "Training:  24%|██▍       | 488/2000 [04:45<18:30,  1.36iteration/s, mean_rewards=-674]\u001b[A\n",
            "Training:  24%|██▍       | 489/2000 [04:46<18:36,  1.35iteration/s, mean_rewards=-674]\u001b[A\n",
            "Training:  24%|██▍       | 489/2000 [04:46<18:36,  1.35iteration/s, mean_rewards=-665]\u001b[A\n",
            "Training:  24%|██▍       | 490/2000 [04:46<18:47,  1.34iteration/s, mean_rewards=-665]\u001b[A\n",
            "Training:  24%|██▍       | 490/2000 [04:47<18:47,  1.34iteration/s, mean_rewards=-633]\u001b[A\n",
            "Training:  25%|██▍       | 491/2000 [04:47<18:07,  1.39iteration/s, mean_rewards=-633]\u001b[A\n",
            "Training:  25%|██▍       | 491/2000 [04:47<18:07,  1.39iteration/s, mean_rewards=-527]\u001b[A\n",
            "Training:  25%|██▍       | 492/2000 [04:48<15:47,  1.59iteration/s, mean_rewards=-527]\u001b[A\n",
            "Training:  25%|██▍       | 492/2000 [04:48<15:47,  1.59iteration/s, mean_rewards=-1.71e+3]\u001b[A\n",
            "Training:  25%|██▍       | 493/2000 [04:49<18:43,  1.34iteration/s, mean_rewards=-1.71e+3]\u001b[A\n",
            "Training:  25%|██▍       | 493/2000 [04:49<18:43,  1.34iteration/s, mean_rewards=-557]    \u001b[A\n",
            "Training:  25%|██▍       | 494/2000 [04:49<17:44,  1.42iteration/s, mean_rewards=-557]\u001b[A\n",
            "Training:  25%|██▍       | 494/2000 [04:49<17:44,  1.42iteration/s, mean_rewards=-668]\u001b[A\n",
            "Training:  25%|██▍       | 495/2000 [04:50<16:02,  1.56iteration/s, mean_rewards=-668]\u001b[A\n",
            "Training:  25%|██▍       | 495/2000 [04:50<16:02,  1.56iteration/s, mean_rewards=-840]\u001b[A\n",
            "Training:  25%|██▍       | 496/2000 [04:50<15:51,  1.58iteration/s, mean_rewards=-840]\u001b[A\n",
            "Training:  25%|██▍       | 496/2000 [04:51<15:51,  1.58iteration/s, mean_rewards=-1.83e+3]\u001b[A\n",
            "Training:  25%|██▍       | 497/2000 [04:51<19:58,  1.25iteration/s, mean_rewards=-1.83e+3]\u001b[A\n",
            "Training:  25%|██▍       | 497/2000 [04:52<19:58,  1.25iteration/s, mean_rewards=-627]    \u001b[A\n",
            "Training:  25%|██▍       | 498/2000 [04:52<17:50,  1.40iteration/s, mean_rewards=-627]\u001b[A\n",
            "Training:  25%|██▍       | 498/2000 [04:52<17:50,  1.40iteration/s, mean_rewards=-695]\u001b[A\n",
            "Training:  25%|██▍       | 499/2000 [04:53<16:42,  1.50iteration/s, mean_rewards=-695]\u001b[A\n",
            "Training:  25%|██▍       | 499/2000 [04:53<16:42,  1.50iteration/s, mean_rewards=-1.06e+3]\u001b[A\n",
            "Training:  25%|██▌       | 500/2000 [04:53<17:51,  1.40iteration/s, mean_rewards=-1.06e+3]\u001b[A\n",
            "Training:  25%|██▌       | 500/2000 [04:54<17:51,  1.40iteration/s, mean_rewards=-485]    \u001b[A\n",
            "Training:  25%|██▌       | 501/2000 [04:54<15:57,  1.57iteration/s, mean_rewards=-485]\u001b[A\n",
            "Training:  25%|██▌       | 501/2000 [04:54<15:57,  1.57iteration/s, mean_rewards=-1.48e+3]\u001b[A\n",
            "Training:  25%|██▌       | 502/2000 [04:55<18:30,  1.35iteration/s, mean_rewards=-1.48e+3]\u001b[A\n",
            "Training:  25%|██▌       | 502/2000 [04:55<18:30,  1.35iteration/s, mean_rewards=-663]    \u001b[A\n",
            "Training:  25%|██▌       | 503/2000 [04:55<17:09,  1.45iteration/s, mean_rewards=-663]\u001b[A\n",
            "Training:  25%|██▌       | 503/2000 [04:56<17:09,  1.45iteration/s, mean_rewards=-739]\u001b[A\n",
            "Training:  25%|██▌       | 504/2000 [04:56<17:26,  1.43iteration/s, mean_rewards=-739]\u001b[A\n",
            "Training:  25%|██▌       | 504/2000 [04:57<17:26,  1.43iteration/s, mean_rewards=-786]\u001b[A\n",
            "Training:  25%|██▌       | 505/2000 [04:57<17:35,  1.42iteration/s, mean_rewards=-786]\u001b[A\n",
            "Training:  25%|██▌       | 505/2000 [04:57<17:35,  1.42iteration/s, mean_rewards=-630]\u001b[A\n",
            "Training:  25%|██▌       | 506/2000 [04:58<18:37,  1.34iteration/s, mean_rewards=-630]\u001b[A\n",
            "Training:  25%|██▌       | 506/2000 [04:59<18:37,  1.34iteration/s, mean_rewards=-3.12e+3]\u001b[A\n",
            "Training:  25%|██▌       | 507/2000 [05:00<29:39,  1.19s/iteration, mean_rewards=-3.12e+3]\u001b[A\n",
            "Training:  25%|██▌       | 507/2000 [05:00<29:39,  1.19s/iteration, mean_rewards=-674]    \u001b[A\n",
            "Training:  25%|██▌       | 508/2000 [05:01<25:37,  1.03s/iteration, mean_rewards=-674]\u001b[A\n",
            "Training:  25%|██▌       | 508/2000 [05:01<25:37,  1.03s/iteration, mean_rewards=-547]\u001b[A\n",
            "Training:  25%|██▌       | 509/2000 [05:01<20:53,  1.19iteration/s, mean_rewards=-547]\u001b[A\n",
            "Training:  25%|██▌       | 509/2000 [05:01<20:53,  1.19iteration/s, mean_rewards=-892]\u001b[A\n",
            "Training:  26%|██▌       | 510/2000 [05:02<19:25,  1.28iteration/s, mean_rewards=-892]\u001b[A\n",
            "Training:  26%|██▌       | 510/2000 [05:02<19:25,  1.28iteration/s, mean_rewards=-646]\u001b[A\n",
            "Training:  26%|██▌       | 511/2000 [05:02<17:42,  1.40iteration/s, mean_rewards=-646]\u001b[A\n",
            "Training:  26%|██▌       | 511/2000 [05:03<17:42,  1.40iteration/s, mean_rewards=-1.08e+3]\u001b[A\n",
            "Training:  26%|██▌       | 512/2000 [05:03<19:38,  1.26iteration/s, mean_rewards=-1.08e+3]\u001b[A\n",
            "Training:  26%|██▌       | 512/2000 [05:03<19:38,  1.26iteration/s, mean_rewards=-644]    \u001b[A\n",
            "Training:  26%|██▌       | 513/2000 [05:04<17:19,  1.43iteration/s, mean_rewards=-644]\u001b[A\n",
            "Training:  26%|██▌       | 513/2000 [05:04<17:19,  1.43iteration/s, mean_rewards=-733]\u001b[A\n",
            "Training:  26%|██▌       | 514/2000 [05:04<16:41,  1.48iteration/s, mean_rewards=-733]\u001b[A\n",
            "Training:  26%|██▌       | 514/2000 [05:05<16:41,  1.48iteration/s, mean_rewards=-636]\u001b[A\n",
            "Training:  26%|██▌       | 515/2000 [05:05<16:29,  1.50iteration/s, mean_rewards=-636]\u001b[A\n",
            "Training:  26%|██▌       | 515/2000 [05:05<16:29,  1.50iteration/s, mean_rewards=-613]\u001b[A\n",
            "Training:  26%|██▌       | 516/2000 [05:05<15:12,  1.63iteration/s, mean_rewards=-613]\u001b[A\n",
            "Training:  26%|██▌       | 516/2000 [05:06<15:12,  1.63iteration/s, mean_rewards=-1.54e+3]\u001b[A\n",
            "Training:  26%|██▌       | 517/2000 [05:06<18:05,  1.37iteration/s, mean_rewards=-1.54e+3]\u001b[A\n",
            "Training:  26%|██▌       | 517/2000 [05:07<18:05,  1.37iteration/s, mean_rewards=-497]    \u001b[A\n",
            "Training:  26%|██▌       | 518/2000 [05:07<16:11,  1.53iteration/s, mean_rewards=-497]\u001b[A\n",
            "Training:  26%|██▌       | 518/2000 [05:07<16:11,  1.53iteration/s, mean_rewards=-899]\u001b[A\n",
            "Training:  26%|██▌       | 519/2000 [05:08<16:37,  1.48iteration/s, mean_rewards=-899]\u001b[A\n",
            "Training:  26%|██▌       | 519/2000 [05:08<16:37,  1.48iteration/s, mean_rewards=-1.2e+3]\u001b[A\n",
            "Training:  26%|██▌       | 520/2000 [05:08<17:29,  1.41iteration/s, mean_rewards=-1.2e+3]\u001b[A\n",
            "Training:  26%|██▌       | 520/2000 [05:09<17:29,  1.41iteration/s, mean_rewards=-765]   \u001b[A\n",
            "Training:  26%|██▌       | 521/2000 [05:09<16:13,  1.52iteration/s, mean_rewards=-765]\u001b[A\n",
            "Training:  26%|██▌       | 521/2000 [05:09<16:13,  1.52iteration/s, mean_rewards=-1.06e+3]\u001b[A\n",
            "Training:  26%|██▌       | 522/2000 [05:10<16:44,  1.47iteration/s, mean_rewards=-1.06e+3]\u001b[A\n",
            "Training:  26%|██▌       | 522/2000 [05:10<16:44,  1.47iteration/s, mean_rewards=-720]    \u001b[A\n",
            "Training:  26%|██▌       | 523/2000 [05:10<16:32,  1.49iteration/s, mean_rewards=-720]\u001b[A\n",
            "Training:  26%|██▌       | 523/2000 [05:11<16:32,  1.49iteration/s, mean_rewards=-609]\u001b[A\n",
            "Training:  26%|██▌       | 524/2000 [05:11<16:26,  1.50iteration/s, mean_rewards=-609]\u001b[A\n",
            "Training:  26%|██▌       | 524/2000 [05:11<16:26,  1.50iteration/s, mean_rewards=-558]\u001b[A\n",
            "Training:  26%|██▋       | 525/2000 [05:12<16:14,  1.51iteration/s, mean_rewards=-558]\u001b[A\n",
            "Training:  26%|██▋       | 525/2000 [05:12<16:14,  1.51iteration/s, mean_rewards=-669]\u001b[A\n",
            "Training:  26%|██▋       | 526/2000 [05:12<16:46,  1.47iteration/s, mean_rewards=-669]\u001b[A\n",
            "Training:  26%|██▋       | 526/2000 [05:13<16:46,  1.47iteration/s, mean_rewards=-602]\u001b[A\n",
            "Training:  26%|██▋       | 527/2000 [05:13<15:47,  1.55iteration/s, mean_rewards=-602]\u001b[A\n",
            "Training:  26%|██▋       | 527/2000 [05:13<15:47,  1.55iteration/s, mean_rewards=-586]\u001b[A\n",
            "Training:  26%|██▋       | 528/2000 [05:13<14:27,  1.70iteration/s, mean_rewards=-586]\u001b[A\n",
            "Training:  26%|██▋       | 528/2000 [05:14<14:27,  1.70iteration/s, mean_rewards=-707]\u001b[A\n",
            "Training:  26%|██▋       | 529/2000 [05:14<14:03,  1.74iteration/s, mean_rewards=-707]\u001b[A\n",
            "Training:  26%|██▋       | 529/2000 [05:14<14:03,  1.74iteration/s, mean_rewards=-690]\u001b[A\n",
            "Training:  26%|██▋       | 530/2000 [05:14<13:43,  1.79iteration/s, mean_rewards=-690]\u001b[A\n",
            "Training:  26%|██▋       | 530/2000 [05:15<13:43,  1.79iteration/s, mean_rewards=-697]\u001b[A\n",
            "Training:  27%|██▋       | 531/2000 [05:15<13:36,  1.80iteration/s, mean_rewards=-697]\u001b[A\n",
            "Training:  27%|██▋       | 531/2000 [05:15<13:36,  1.80iteration/s, mean_rewards=-604]\u001b[A\n",
            "Training:  27%|██▋       | 532/2000 [05:15<12:30,  1.96iteration/s, mean_rewards=-604]\u001b[A\n",
            "Training:  27%|██▋       | 532/2000 [05:16<12:30,  1.96iteration/s, mean_rewards=-567]\u001b[A\n",
            "Training:  27%|██▋       | 533/2000 [05:16<12:10,  2.01iteration/s, mean_rewards=-567]\u001b[A\n",
            "Training:  27%|██▋       | 533/2000 [05:16<12:10,  2.01iteration/s, mean_rewards=-981]\u001b[A\n",
            "Training:  27%|██▋       | 534/2000 [05:16<13:39,  1.79iteration/s, mean_rewards=-981]\u001b[A\n",
            "Training:  27%|██▋       | 534/2000 [05:17<13:39,  1.79iteration/s, mean_rewards=-613]\u001b[A\n",
            "Training:  27%|██▋       | 535/2000 [05:17<13:46,  1.77iteration/s, mean_rewards=-613]\u001b[A\n",
            "Training:  27%|██▋       | 535/2000 [05:17<13:46,  1.77iteration/s, mean_rewards=-680]\u001b[A\n",
            "Training:  27%|██▋       | 536/2000 [05:18<14:14,  1.71iteration/s, mean_rewards=-680]\u001b[A\n",
            "Training:  27%|██▋       | 536/2000 [05:18<14:14,  1.71iteration/s, mean_rewards=-588]\u001b[A\n",
            "Training:  27%|██▋       | 537/2000 [05:18<13:32,  1.80iteration/s, mean_rewards=-588]\u001b[A\n",
            "Training:  27%|██▋       | 537/2000 [05:19<13:32,  1.80iteration/s, mean_rewards=-1.82e+3]\u001b[A\n",
            "Training:  27%|██▋       | 538/2000 [05:19<18:00,  1.35iteration/s, mean_rewards=-1.82e+3]\u001b[A\n",
            "Training:  27%|██▋       | 538/2000 [05:20<18:00,  1.35iteration/s, mean_rewards=-615]    \u001b[A\n",
            "Training:  27%|██▋       | 539/2000 [05:20<16:26,  1.48iteration/s, mean_rewards=-615]\u001b[A\n",
            "Training:  27%|██▋       | 539/2000 [05:20<16:26,  1.48iteration/s, mean_rewards=-535]\u001b[A\n",
            "Training:  27%|██▋       | 540/2000 [05:20<14:49,  1.64iteration/s, mean_rewards=-535]\u001b[A\n",
            "Training:  27%|██▋       | 540/2000 [05:21<14:49,  1.64iteration/s, mean_rewards=-1.7e+3]\u001b[A\n",
            "Training:  27%|██▋       | 541/2000 [05:21<18:04,  1.34iteration/s, mean_rewards=-1.7e+3]\u001b[A\n",
            "Training:  27%|██▋       | 541/2000 [05:22<18:04,  1.34iteration/s, mean_rewards=-549]   \u001b[A\n",
            "Training:  27%|██▋       | 542/2000 [05:22<15:38,  1.55iteration/s, mean_rewards=-549]\u001b[A\n",
            "Training:  27%|██▋       | 542/2000 [05:22<15:38,  1.55iteration/s, mean_rewards=-638]\u001b[A\n",
            "Training:  27%|██▋       | 543/2000 [05:22<15:21,  1.58iteration/s, mean_rewards=-638]\u001b[A\n",
            "Training:  27%|██▋       | 543/2000 [05:23<15:21,  1.58iteration/s, mean_rewards=-659]\u001b[A\n",
            "Training:  27%|██▋       | 544/2000 [05:23<14:45,  1.64iteration/s, mean_rewards=-659]\u001b[A\n",
            "Training:  27%|██▋       | 544/2000 [05:24<14:45,  1.64iteration/s, mean_rewards=-943]\u001b[A\n",
            "Training:  27%|██▋       | 545/2000 [05:24<16:57,  1.43iteration/s, mean_rewards=-943]\u001b[A\n",
            "Training:  27%|██▋       | 545/2000 [05:24<16:57,  1.43iteration/s, mean_rewards=-581]\u001b[A\n",
            "Training:  27%|██▋       | 546/2000 [05:25<16:45,  1.45iteration/s, mean_rewards=-581]\u001b[A\n",
            "Training:  27%|██▋       | 546/2000 [05:26<16:45,  1.45iteration/s, mean_rewards=-1.66e+3]\u001b[A\n",
            "Training:  27%|██▋       | 547/2000 [05:26<22:53,  1.06iteration/s, mean_rewards=-1.66e+3]\u001b[A\n",
            "Training:  27%|██▋       | 547/2000 [05:27<22:53,  1.06iteration/s, mean_rewards=-1.31e+3]\u001b[A\n",
            "Training:  27%|██▋       | 548/2000 [05:27<22:10,  1.09iteration/s, mean_rewards=-1.31e+3]\u001b[A\n",
            "Training:  27%|██▋       | 548/2000 [05:27<22:10,  1.09iteration/s, mean_rewards=-528]    \u001b[A\n",
            "Training:  27%|██▋       | 549/2000 [05:27<18:29,  1.31iteration/s, mean_rewards=-528]\u001b[A\n",
            "Training:  27%|██▋       | 549/2000 [05:28<18:29,  1.31iteration/s, mean_rewards=-1.16e+3]\u001b[A\n",
            "Training:  28%|██▊       | 550/2000 [05:28<19:21,  1.25iteration/s, mean_rewards=-1.16e+3]\u001b[A\n",
            "Training:  28%|██▊       | 550/2000 [05:29<19:21,  1.25iteration/s, mean_rewards=-558]    \u001b[A\n",
            "Training:  28%|██▊       | 551/2000 [05:29<17:36,  1.37iteration/s, mean_rewards=-558]\u001b[A\n",
            "Training:  28%|██▊       | 551/2000 [05:30<17:36,  1.37iteration/s, mean_rewards=-1.86e+3]\u001b[A\n",
            "Training:  28%|██▊       | 552/2000 [05:30<21:12,  1.14iteration/s, mean_rewards=-1.86e+3]\u001b[A\n",
            "Training:  28%|██▊       | 552/2000 [05:30<21:12,  1.14iteration/s, mean_rewards=-764]    \u001b[A\n",
            "Training:  28%|██▊       | 553/2000 [05:31<19:17,  1.25iteration/s, mean_rewards=-764]\u001b[A\n",
            "Training:  28%|██▊       | 553/2000 [05:31<19:17,  1.25iteration/s, mean_rewards=-820]\u001b[A\n",
            "Training:  28%|██▊       | 554/2000 [05:31<18:08,  1.33iteration/s, mean_rewards=-820]\u001b[A\n",
            "Training:  28%|██▊       | 554/2000 [05:32<18:08,  1.33iteration/s, mean_rewards=-637]\u001b[A\n",
            "Training:  28%|██▊       | 555/2000 [05:32<17:18,  1.39iteration/s, mean_rewards=-637]\u001b[A\n",
            "Training:  28%|██▊       | 555/2000 [05:32<17:18,  1.39iteration/s, mean_rewards=-690]\u001b[A\n",
            "Training:  28%|██▊       | 556/2000 [05:32<16:12,  1.48iteration/s, mean_rewards=-690]\u001b[A\n",
            "Training:  28%|██▊       | 556/2000 [05:33<16:12,  1.48iteration/s, mean_rewards=-560]\u001b[A\n",
            "Training:  28%|██▊       | 557/2000 [05:33<14:56,  1.61iteration/s, mean_rewards=-560]\u001b[A\n",
            "Training:  28%|██▊       | 557/2000 [05:33<14:56,  1.61iteration/s, mean_rewards=-1.01e+3]\u001b[A\n",
            "Training:  28%|██▊       | 558/2000 [05:34<15:41,  1.53iteration/s, mean_rewards=-1.01e+3]\u001b[A\n",
            "Training:  28%|██▊       | 558/2000 [05:34<15:41,  1.53iteration/s, mean_rewards=-467]    \u001b[A\n",
            "Training:  28%|██▊       | 559/2000 [05:34<13:55,  1.72iteration/s, mean_rewards=-467]\u001b[A\n",
            "Training:  28%|██▊       | 559/2000 [05:34<13:55,  1.72iteration/s, mean_rewards=-631]\u001b[A\n",
            "Training:  28%|██▊       | 560/2000 [05:35<13:33,  1.77iteration/s, mean_rewards=-631]\u001b[A\n",
            "Training:  28%|██▊       | 560/2000 [05:35<13:33,  1.77iteration/s, mean_rewards=-587]\u001b[A\n",
            "Training:  28%|██▊       | 561/2000 [05:35<12:23,  1.93iteration/s, mean_rewards=-587]\u001b[A\n",
            "Training:  28%|██▊       | 561/2000 [05:35<12:23,  1.93iteration/s, mean_rewards=-542]\u001b[A\n",
            "Training:  28%|██▊       | 562/2000 [05:36<12:16,  1.95iteration/s, mean_rewards=-542]\u001b[A\n",
            "Training:  28%|██▊       | 562/2000 [05:36<12:16,  1.95iteration/s, mean_rewards=-824]\u001b[A\n",
            "Training:  28%|██▊       | 563/2000 [05:36<14:58,  1.60iteration/s, mean_rewards=-824]\u001b[A\n",
            "Training:  28%|██▊       | 563/2000 [05:38<14:58,  1.60iteration/s, mean_rewards=-2.15e+3]\u001b[A\n",
            "Training:  28%|██▊       | 564/2000 [05:38<22:00,  1.09iteration/s, mean_rewards=-2.15e+3]\u001b[A\n",
            "Training:  28%|██▊       | 564/2000 [05:39<22:00,  1.09iteration/s, mean_rewards=-919]    \u001b[A\n",
            "Training:  28%|██▊       | 565/2000 [05:39<20:23,  1.17iteration/s, mean_rewards=-919]\u001b[A\n",
            "Training:  28%|██▊       | 565/2000 [05:39<20:23,  1.17iteration/s, mean_rewards=-973]\u001b[A\n",
            "Training:  28%|██▊       | 566/2000 [05:39<18:51,  1.27iteration/s, mean_rewards=-973]\u001b[A\n",
            "Training:  28%|██▊       | 566/2000 [05:41<18:51,  1.27iteration/s, mean_rewards=-2.55e+3]\u001b[A\n",
            "Training:  28%|██▊       | 567/2000 [05:41<24:39,  1.03s/iteration, mean_rewards=-2.55e+3]\u001b[A\n",
            "Training:  28%|██▊       | 567/2000 [05:41<24:39,  1.03s/iteration, mean_rewards=-808]    \u001b[A\n",
            "Training:  28%|██▊       | 568/2000 [05:42<21:45,  1.10iteration/s, mean_rewards=-808]\u001b[A\n",
            "Training:  28%|██▊       | 568/2000 [05:42<21:45,  1.10iteration/s, mean_rewards=-919]\u001b[A\n",
            "Training:  28%|██▊       | 569/2000 [05:42<20:29,  1.16iteration/s, mean_rewards=-919]\u001b[A\n",
            "Training:  28%|██▊       | 569/2000 [05:43<20:29,  1.16iteration/s, mean_rewards=-454]\u001b[A\n",
            "Training:  28%|██▊       | 570/2000 [05:43<17:32,  1.36iteration/s, mean_rewards=-454]\u001b[A\n",
            "Training:  28%|██▊       | 570/2000 [05:43<17:32,  1.36iteration/s, mean_rewards=-543]\u001b[A\n",
            "Training:  29%|██▊       | 571/2000 [05:43<15:15,  1.56iteration/s, mean_rewards=-543]\u001b[A\n",
            "Training:  29%|██▊       | 571/2000 [05:44<15:15,  1.56iteration/s, mean_rewards=-976]\u001b[A\n",
            "Training:  29%|██▊       | 572/2000 [05:44<15:52,  1.50iteration/s, mean_rewards=-976]\u001b[A\n",
            "Training:  29%|██▊       | 572/2000 [05:45<15:52,  1.50iteration/s, mean_rewards=-1.26e+3]\u001b[A\n",
            "Training:  29%|██▊       | 573/2000 [05:45<17:28,  1.36iteration/s, mean_rewards=-1.26e+3]\u001b[A\n",
            "Training:  29%|██▊       | 573/2000 [05:46<17:28,  1.36iteration/s, mean_rewards=-1.55e+3]\u001b[A\n",
            "Training:  29%|██▊       | 574/2000 [05:46<20:14,  1.17iteration/s, mean_rewards=-1.55e+3]\u001b[A\n",
            "Training:  29%|██▊       | 574/2000 [05:46<20:14,  1.17iteration/s, mean_rewards=-518]    \u001b[A\n",
            "Training:  29%|██▉       | 575/2000 [05:46<17:18,  1.37iteration/s, mean_rewards=-518]\u001b[A\n",
            "Training:  29%|██▉       | 575/2000 [05:47<17:18,  1.37iteration/s, mean_rewards=-727]\u001b[A\n",
            "Training:  29%|██▉       | 576/2000 [05:47<15:36,  1.52iteration/s, mean_rewards=-727]\u001b[A\n",
            "Training:  29%|██▉       | 576/2000 [05:47<15:36,  1.52iteration/s, mean_rewards=-793]\u001b[A\n",
            "Training:  29%|██▉       | 577/2000 [05:48<15:50,  1.50iteration/s, mean_rewards=-793]\u001b[A\n",
            "Training:  29%|██▉       | 577/2000 [05:48<15:50,  1.50iteration/s, mean_rewards=-1.04e+3]\u001b[A\n",
            "Training:  29%|██▉       | 578/2000 [05:49<19:14,  1.23iteration/s, mean_rewards=-1.04e+3]\u001b[A\n",
            "Training:  29%|██▉       | 578/2000 [05:49<19:14,  1.23iteration/s, mean_rewards=-597]    \u001b[A\n",
            "Training:  29%|██▉       | 579/2000 [05:49<17:47,  1.33iteration/s, mean_rewards=-597]\u001b[A\n",
            "Training:  29%|██▉       | 579/2000 [05:50<17:47,  1.33iteration/s, mean_rewards=-627]\u001b[A\n",
            "Training:  29%|██▉       | 580/2000 [05:50<18:18,  1.29iteration/s, mean_rewards=-627]\u001b[A\n",
            "Training:  29%|██▉       | 580/2000 [05:51<18:18,  1.29iteration/s, mean_rewards=-2.39e+3]\u001b[A\n",
            "Training:  29%|██▉       | 581/2000 [05:52<22:20,  1.06iteration/s, mean_rewards=-2.39e+3]\u001b[A\n",
            "Training:  29%|██▉       | 581/2000 [05:52<22:20,  1.06iteration/s, mean_rewards=-466]    \u001b[A\n",
            "Training:  29%|██▉       | 582/2000 [05:52<19:10,  1.23iteration/s, mean_rewards=-466]\u001b[A\n",
            "Training:  29%|██▉       | 582/2000 [05:53<19:10,  1.23iteration/s, mean_rewards=-909]\u001b[A\n",
            "Training:  29%|██▉       | 583/2000 [05:53<18:30,  1.28iteration/s, mean_rewards=-909]\u001b[A\n",
            "Training:  29%|██▉       | 583/2000 [05:53<18:30,  1.28iteration/s, mean_rewards=-873]\u001b[A\n",
            "Training:  29%|██▉       | 584/2000 [05:53<17:55,  1.32iteration/s, mean_rewards=-873]\u001b[A\n",
            "Training:  29%|██▉       | 584/2000 [05:54<17:55,  1.32iteration/s, mean_rewards=-737]\u001b[A\n",
            "Training:  29%|██▉       | 585/2000 [05:54<16:58,  1.39iteration/s, mean_rewards=-737]\u001b[A\n",
            "Training:  29%|██▉       | 585/2000 [05:54<16:58,  1.39iteration/s, mean_rewards=-515]\u001b[A\n",
            "Training:  29%|██▉       | 586/2000 [05:55<15:16,  1.54iteration/s, mean_rewards=-515]\u001b[A\n",
            "Training:  29%|██▉       | 586/2000 [05:55<15:16,  1.54iteration/s, mean_rewards=-667]\u001b[A\n",
            "Training:  29%|██▉       | 587/2000 [05:55<15:08,  1.56iteration/s, mean_rewards=-667]\u001b[A\n",
            "Training:  29%|██▉       | 587/2000 [05:56<15:08,  1.56iteration/s, mean_rewards=-582]\u001b[A\n",
            "Training:  29%|██▉       | 588/2000 [05:56<14:22,  1.64iteration/s, mean_rewards=-582]\u001b[A\n",
            "Training:  29%|██▉       | 588/2000 [05:56<14:22,  1.64iteration/s, mean_rewards=-450]\u001b[A\n",
            "Training:  29%|██▉       | 589/2000 [05:56<12:57,  1.82iteration/s, mean_rewards=-450]\u001b[A\n",
            "Training:  29%|██▉       | 589/2000 [05:57<12:57,  1.82iteration/s, mean_rewards=-770]\u001b[A\n",
            "Training:  30%|██▉       | 590/2000 [05:57<13:37,  1.72iteration/s, mean_rewards=-770]\u001b[A\n",
            "Training:  30%|██▉       | 590/2000 [05:57<13:37,  1.72iteration/s, mean_rewards=-1.06e+3]\u001b[A\n",
            "Training:  30%|██▉       | 591/2000 [05:58<15:11,  1.55iteration/s, mean_rewards=-1.06e+3]\u001b[A\n",
            "Training:  30%|██▉       | 591/2000 [05:58<15:11,  1.55iteration/s, mean_rewards=-784]    \u001b[A\n",
            "Training:  30%|██▉       | 592/2000 [05:58<14:45,  1.59iteration/s, mean_rewards=-784]\u001b[A\n",
            "Training:  30%|██▉       | 592/2000 [05:59<14:45,  1.59iteration/s, mean_rewards=-1.23e+3]\u001b[A\n",
            "Training:  30%|██▉       | 593/2000 [05:59<17:39,  1.33iteration/s, mean_rewards=-1.23e+3]\u001b[A\n",
            "Training:  30%|██▉       | 593/2000 [06:00<17:39,  1.33iteration/s, mean_rewards=-1.84e+3]\u001b[A\n",
            "Training:  30%|██▉       | 594/2000 [06:00<20:10,  1.16iteration/s, mean_rewards=-1.84e+3]\u001b[A\n",
            "Training:  30%|██▉       | 594/2000 [06:01<20:10,  1.16iteration/s, mean_rewards=-844]    \u001b[A\n",
            "Training:  30%|██▉       | 595/2000 [06:01<20:39,  1.13iteration/s, mean_rewards=-844]\u001b[A\n",
            "Training:  30%|██▉       | 595/2000 [06:02<20:39,  1.13iteration/s, mean_rewards=-860]\u001b[A\n",
            "Training:  30%|██▉       | 596/2000 [06:02<20:01,  1.17iteration/s, mean_rewards=-860]\u001b[A\n",
            "Training:  30%|██▉       | 596/2000 [06:03<20:01,  1.17iteration/s, mean_rewards=-869]\u001b[A\n",
            "Training:  30%|██▉       | 597/2000 [06:03<20:49,  1.12iteration/s, mean_rewards=-869]\u001b[A\n",
            "Training:  30%|██▉       | 597/2000 [06:04<20:49,  1.12iteration/s, mean_rewards=-2.23e+3]\u001b[A\n",
            "Training:  30%|██▉       | 598/2000 [06:04<24:55,  1.07s/iteration, mean_rewards=-2.23e+3]\u001b[A\n",
            "Training:  30%|██▉       | 598/2000 [06:05<24:55,  1.07s/iteration, mean_rewards=-723]    \u001b[A\n",
            "Training:  30%|██▉       | 599/2000 [06:05<21:21,  1.09iteration/s, mean_rewards=-723]\u001b[A\n",
            "Training:  30%|██▉       | 599/2000 [06:05<21:21,  1.09iteration/s, mean_rewards=-618]\u001b[A\n",
            "Training:  30%|███       | 600/2000 [06:06<18:51,  1.24iteration/s, mean_rewards=-618]\u001b[A\n",
            "Training:  30%|███       | 600/2000 [06:06<18:51,  1.24iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  30%|███       | 601/2000 [06:06<16:07,  1.45iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  30%|███       | 601/2000 [06:06<16:07,  1.45iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  30%|███       | 602/2000 [06:06<13:33,  1.72iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  30%|███       | 602/2000 [06:07<13:33,  1.72iteration/s, mean_rewards=-168]\u001b[A\n",
            "Training:  30%|███       | 603/2000 [06:07<12:32,  1.86iteration/s, mean_rewards=-168]\u001b[A\n",
            "Training:  30%|███       | 603/2000 [06:07<12:32,  1.86iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  30%|███       | 604/2000 [06:07<11:15,  2.07iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  30%|███       | 604/2000 [06:07<11:15,  2.07iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  30%|███       | 605/2000 [06:07<10:03,  2.31iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  30%|███       | 605/2000 [06:08<10:03,  2.31iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  30%|███       | 606/2000 [06:08<09:33,  2.43iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  30%|███       | 606/2000 [06:08<09:33,  2.43iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  30%|███       | 607/2000 [06:08<09:10,  2.53iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  30%|███       | 607/2000 [06:08<09:10,  2.53iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  30%|███       | 608/2000 [06:08<08:34,  2.71iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  30%|███       | 608/2000 [06:09<08:34,  2.71iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  30%|███       | 609/2000 [06:09<08:08,  2.85iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  30%|███       | 609/2000 [06:09<08:08,  2.85iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  30%|███       | 610/2000 [06:09<08:17,  2.80iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  30%|███       | 610/2000 [06:09<08:17,  2.80iteration/s, mean_rewards=-116]\u001b[A\n",
            "Training:  31%|███       | 611/2000 [06:10<08:28,  2.73iteration/s, mean_rewards=-116]\u001b[A\n",
            "Training:  31%|███       | 611/2000 [06:10<08:28,  2.73iteration/s, mean_rewards=-52.1]\u001b[A\n",
            "Training:  31%|███       | 612/2000 [06:10<08:23,  2.76iteration/s, mean_rewards=-52.1]\u001b[A\n",
            "Training:  31%|███       | 612/2000 [06:10<08:23,  2.76iteration/s, mean_rewards=-149] \u001b[A\n",
            "Training:  31%|███       | 613/2000 [06:10<08:22,  2.76iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  31%|███       | 613/2000 [06:11<08:22,  2.76iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  31%|███       | 614/2000 [06:11<08:31,  2.71iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  31%|███       | 614/2000 [06:11<08:31,  2.71iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  31%|███       | 615/2000 [06:11<08:01,  2.88iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  31%|███       | 615/2000 [06:11<08:01,  2.88iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  31%|███       | 616/2000 [06:11<07:43,  2.99iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  31%|███       | 616/2000 [06:11<07:43,  2.99iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  31%|███       | 617/2000 [06:12<07:57,  2.90iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  31%|███       | 617/2000 [06:12<07:57,  2.90iteration/s, mean_rewards=-169]\u001b[A\n",
            "Training:  31%|███       | 618/2000 [06:12<08:25,  2.73iteration/s, mean_rewards=-169]\u001b[A\n",
            "Training:  31%|███       | 618/2000 [06:12<08:25,  2.73iteration/s, mean_rewards=-79.2]\u001b[A\n",
            "Training:  31%|███       | 619/2000 [06:12<08:58,  2.57iteration/s, mean_rewards=-79.2]\u001b[A\n",
            "Training:  31%|███       | 619/2000 [06:13<08:58,  2.57iteration/s, mean_rewards=-121] \u001b[A\n",
            "Training:  31%|███       | 620/2000 [06:13<09:21,  2.46iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  31%|███       | 620/2000 [06:13<09:21,  2.46iteration/s, mean_rewards=-91.3]\u001b[A\n",
            "Training:  31%|███       | 621/2000 [06:13<08:52,  2.59iteration/s, mean_rewards=-91.3]\u001b[A\n",
            "Training:  31%|███       | 621/2000 [06:13<08:52,  2.59iteration/s, mean_rewards=-122] \u001b[A\n",
            "Training:  31%|███       | 622/2000 [06:14<08:32,  2.69iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  31%|███       | 622/2000 [06:14<08:32,  2.69iteration/s, mean_rewards=-97.7]\u001b[A\n",
            "Training:  31%|███       | 623/2000 [06:14<09:24,  2.44iteration/s, mean_rewards=-97.7]\u001b[A\n",
            "Training:  31%|███       | 623/2000 [06:14<09:24,  2.44iteration/s, mean_rewards=-139] \u001b[A\n",
            "Training:  31%|███       | 624/2000 [06:14<09:12,  2.49iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:  31%|███       | 624/2000 [06:15<09:12,  2.49iteration/s, mean_rewards=-165]\u001b[A\n",
            "Training:  31%|███▏      | 625/2000 [06:15<09:53,  2.32iteration/s, mean_rewards=-165]\u001b[A\n",
            "Training:  31%|███▏      | 625/2000 [06:15<09:53,  2.32iteration/s, mean_rewards=-87.2]\u001b[A\n",
            "Training:  31%|███▏      | 626/2000 [06:15<10:15,  2.23iteration/s, mean_rewards=-87.2]\u001b[A\n",
            "Training:  31%|███▏      | 626/2000 [06:16<10:15,  2.23iteration/s, mean_rewards=-127] \u001b[A\n",
            "Training:  31%|███▏      | 627/2000 [06:16<10:35,  2.16iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  31%|███▏      | 627/2000 [06:16<10:35,  2.16iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  31%|███▏      | 628/2000 [06:16<10:31,  2.17iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  31%|███▏      | 628/2000 [06:17<10:31,  2.17iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  31%|███▏      | 629/2000 [06:17<10:19,  2.21iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  31%|███▏      | 629/2000 [06:17<10:19,  2.21iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  32%|███▏      | 630/2000 [06:17<09:26,  2.42iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  32%|███▏      | 630/2000 [06:17<09:26,  2.42iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  32%|███▏      | 631/2000 [06:18<09:21,  2.44iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  32%|███▏      | 631/2000 [06:18<09:21,  2.44iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  32%|███▏      | 632/2000 [06:18<09:08,  2.49iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  32%|███▏      | 632/2000 [06:18<09:08,  2.49iteration/s, mean_rewards=-54] \u001b[A\n",
            "Training:  32%|███▏      | 633/2000 [06:18<09:18,  2.45iteration/s, mean_rewards=-54]\u001b[A\n",
            "Training:  32%|███▏      | 633/2000 [06:19<09:18,  2.45iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:  32%|███▏      | 634/2000 [06:19<08:57,  2.54iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:  32%|███▏      | 634/2000 [06:19<08:57,  2.54iteration/s, mean_rewards=-45.9]\u001b[A\n",
            "Training:  32%|███▏      | 635/2000 [06:19<08:56,  2.55iteration/s, mean_rewards=-45.9]\u001b[A\n",
            "Training:  32%|███▏      | 635/2000 [06:19<08:56,  2.55iteration/s, mean_rewards=-149] \u001b[A\n",
            "Training:  32%|███▏      | 636/2000 [06:20<08:53,  2.56iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  32%|███▏      | 636/2000 [06:20<08:53,  2.56iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  32%|███▏      | 637/2000 [06:20<08:45,  2.59iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  32%|███▏      | 637/2000 [06:20<08:45,  2.59iteration/s, mean_rewards=-216]\u001b[A\n",
            "Training:  32%|███▏      | 638/2000 [06:20<09:06,  2.49iteration/s, mean_rewards=-216]\u001b[A\n",
            "Training:  32%|███▏      | 638/2000 [06:21<09:06,  2.49iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  32%|███▏      | 639/2000 [06:21<08:46,  2.58iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  32%|███▏      | 639/2000 [06:21<08:46,  2.58iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  32%|███▏      | 640/2000 [06:21<09:05,  2.50iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  32%|███▏      | 640/2000 [06:21<09:05,  2.50iteration/s, mean_rewards=-73.3]\u001b[A\n",
            "Training:  32%|███▏      | 641/2000 [06:22<09:00,  2.51iteration/s, mean_rewards=-73.3]\u001b[A\n",
            "Training:  32%|███▏      | 641/2000 [06:22<09:00,  2.51iteration/s, mean_rewards=-128] \u001b[A\n",
            "Training:  32%|███▏      | 642/2000 [06:22<08:51,  2.55iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  32%|███▏      | 642/2000 [06:22<08:51,  2.55iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  32%|███▏      | 643/2000 [06:22<08:24,  2.69iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  32%|███▏      | 643/2000 [06:22<08:24,  2.69iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  32%|███▏      | 644/2000 [06:23<08:26,  2.68iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  32%|███▏      | 644/2000 [06:23<08:26,  2.68iteration/s, mean_rewards=-105]\u001b[A\n",
            "Training:  32%|███▏      | 645/2000 [06:23<08:37,  2.62iteration/s, mean_rewards=-105]\u001b[A\n",
            "Training:  32%|███▏      | 645/2000 [06:23<08:37,  2.62iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  32%|███▏      | 646/2000 [06:23<08:51,  2.55iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  32%|███▏      | 646/2000 [06:24<08:51,  2.55iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  32%|███▏      | 647/2000 [06:24<08:34,  2.63iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  32%|███▏      | 647/2000 [06:24<08:34,  2.63iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  32%|███▏      | 648/2000 [06:24<08:17,  2.72iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  32%|███▏      | 648/2000 [06:24<08:17,  2.72iteration/s, mean_rewards=-162]\u001b[A\n",
            "Training:  32%|███▏      | 649/2000 [06:24<08:10,  2.75iteration/s, mean_rewards=-162]\u001b[A\n",
            "Training:  32%|███▏      | 649/2000 [06:25<08:10,  2.75iteration/s, mean_rewards=-174]\u001b[A\n",
            "Training:  32%|███▎      | 650/2000 [06:25<08:16,  2.72iteration/s, mean_rewards=-174]\u001b[A\n",
            "Training:  32%|███▎      | 650/2000 [06:25<08:16,  2.72iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  33%|███▎      | 651/2000 [06:25<08:16,  2.72iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  33%|███▎      | 651/2000 [06:25<08:16,  2.72iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  33%|███▎      | 652/2000 [06:26<08:17,  2.71iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  33%|███▎      | 652/2000 [06:26<08:17,  2.71iteration/s, mean_rewards=-55.2]\u001b[A\n",
            "Training:  33%|███▎      | 653/2000 [06:26<08:49,  2.54iteration/s, mean_rewards=-55.2]\u001b[A\n",
            "Training:  33%|███▎      | 653/2000 [06:26<08:49,  2.54iteration/s, mean_rewards=-129] \u001b[A\n",
            "Training:  33%|███▎      | 654/2000 [06:26<09:05,  2.47iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  33%|███▎      | 654/2000 [06:27<09:05,  2.47iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  33%|███▎      | 655/2000 [06:27<09:00,  2.49iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  33%|███▎      | 655/2000 [06:27<09:00,  2.49iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  33%|███▎      | 656/2000 [06:27<08:52,  2.52iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  33%|███▎      | 656/2000 [06:28<08:52,  2.52iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  33%|███▎      | 657/2000 [06:28<09:58,  2.24iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  33%|███▎      | 657/2000 [06:28<09:58,  2.24iteration/s, mean_rewards=-165]\u001b[A\n",
            "Training:  33%|███▎      | 658/2000 [06:28<10:32,  2.12iteration/s, mean_rewards=-165]\u001b[A\n",
            "Training:  33%|███▎      | 658/2000 [06:29<10:32,  2.12iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  33%|███▎      | 659/2000 [06:29<10:57,  2.04iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  33%|███▎      | 659/2000 [06:29<10:57,  2.04iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  33%|███▎      | 660/2000 [06:29<10:28,  2.13iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  33%|███▎      | 660/2000 [06:29<10:28,  2.13iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  33%|███▎      | 661/2000 [06:30<09:26,  2.36iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  33%|███▎      | 661/2000 [06:30<09:26,  2.36iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  33%|███▎      | 662/2000 [06:30<08:57,  2.49iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  33%|███▎      | 662/2000 [06:30<08:57,  2.49iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:  33%|███▎      | 663/2000 [06:30<08:41,  2.56iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:  33%|███▎      | 663/2000 [06:31<08:41,  2.56iteration/s, mean_rewards=-119]\u001b[A\n",
            "Training:  33%|███▎      | 664/2000 [06:31<08:29,  2.62iteration/s, mean_rewards=-119]\u001b[A\n",
            "Training:  33%|███▎      | 664/2000 [06:31<08:29,  2.62iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  33%|███▎      | 665/2000 [06:31<08:31,  2.61iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  33%|███▎      | 665/2000 [06:31<08:31,  2.61iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  33%|███▎      | 666/2000 [06:31<08:03,  2.76iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  33%|███▎      | 666/2000 [06:32<08:03,  2.76iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  33%|███▎      | 667/2000 [06:32<07:39,  2.90iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  33%|███▎      | 667/2000 [06:32<07:39,  2.90iteration/s, mean_rewards=-112]\u001b[A\n",
            "Training:  33%|███▎      | 668/2000 [06:32<07:47,  2.85iteration/s, mean_rewards=-112]\u001b[A\n",
            "Training:  33%|███▎      | 668/2000 [06:32<07:47,  2.85iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  33%|███▎      | 669/2000 [06:32<07:51,  2.82iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  33%|███▎      | 669/2000 [06:33<07:51,  2.82iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  34%|███▎      | 670/2000 [06:33<07:32,  2.94iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  34%|███▎      | 670/2000 [06:33<07:32,  2.94iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  34%|███▎      | 671/2000 [06:33<07:27,  2.97iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  34%|███▎      | 671/2000 [06:33<07:27,  2.97iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  34%|███▎      | 672/2000 [06:33<07:41,  2.88iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  34%|███▎      | 672/2000 [06:34<07:41,  2.88iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  34%|███▎      | 673/2000 [06:34<07:43,  2.86iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  34%|███▎      | 673/2000 [06:34<07:43,  2.86iteration/s, mean_rewards=-182]\u001b[A\n",
            "Training:  34%|███▎      | 674/2000 [06:34<08:00,  2.76iteration/s, mean_rewards=-182]\u001b[A\n",
            "Training:  34%|███▎      | 674/2000 [06:34<08:00,  2.76iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  34%|███▍      | 675/2000 [06:34<07:46,  2.84iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  34%|███▍      | 675/2000 [06:35<07:46,  2.84iteration/s, mean_rewards=-213]\u001b[A\n",
            "Training:  34%|███▍      | 676/2000 [06:35<08:20,  2.65iteration/s, mean_rewards=-213]\u001b[A\n",
            "Training:  34%|███▍      | 676/2000 [06:35<08:20,  2.65iteration/s, mean_rewards=-173]\u001b[A\n",
            "Training:  34%|███▍      | 677/2000 [06:35<08:39,  2.55iteration/s, mean_rewards=-173]\u001b[A\n",
            "Training:  34%|███▍      | 677/2000 [06:36<08:39,  2.55iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  34%|███▍      | 678/2000 [06:36<08:09,  2.70iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  34%|███▍      | 678/2000 [06:36<08:09,  2.70iteration/s, mean_rewards=-167]\u001b[A\n",
            "Training:  34%|███▍      | 679/2000 [06:36<08:17,  2.66iteration/s, mean_rewards=-167]\u001b[A\n",
            "Training:  34%|███▍      | 679/2000 [06:36<08:17,  2.66iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  34%|███▍      | 680/2000 [06:36<08:24,  2.62iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  34%|███▍      | 680/2000 [06:37<08:24,  2.62iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  34%|███▍      | 681/2000 [06:37<08:23,  2.62iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  34%|███▍      | 681/2000 [06:37<08:23,  2.62iteration/s, mean_rewards=-157]\u001b[A\n",
            "Training:  34%|███▍      | 682/2000 [06:37<08:27,  2.60iteration/s, mean_rewards=-157]\u001b[A\n",
            "Training:  34%|███▍      | 682/2000 [06:37<08:27,  2.60iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  34%|███▍      | 683/2000 [06:38<08:15,  2.66iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  34%|███▍      | 683/2000 [06:38<08:15,  2.66iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  34%|███▍      | 684/2000 [06:38<08:06,  2.70iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  34%|███▍      | 684/2000 [06:38<08:06,  2.70iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  34%|███▍      | 685/2000 [06:38<08:11,  2.67iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  34%|███▍      | 685/2000 [06:39<08:11,  2.67iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  34%|███▍      | 686/2000 [06:39<08:04,  2.71iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  34%|███▍      | 686/2000 [06:39<08:04,  2.71iteration/s, mean_rewards=-62.2]\u001b[A\n",
            "Training:  34%|███▍      | 687/2000 [06:39<07:56,  2.76iteration/s, mean_rewards=-62.2]\u001b[A\n",
            "Training:  34%|███▍      | 687/2000 [06:39<07:56,  2.76iteration/s, mean_rewards=-138] \u001b[A\n",
            "Training:  34%|███▍      | 688/2000 [06:40<08:40,  2.52iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:  34%|███▍      | 688/2000 [06:40<08:40,  2.52iteration/s, mean_rewards=-78.8]\u001b[A\n",
            "Training:  34%|███▍      | 689/2000 [06:40<08:31,  2.56iteration/s, mean_rewards=-78.8]\u001b[A\n",
            "Training:  34%|███▍      | 689/2000 [06:40<08:31,  2.56iteration/s, mean_rewards=-146] \u001b[A\n",
            "Training:  34%|███▍      | 690/2000 [06:40<08:31,  2.56iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  34%|███▍      | 690/2000 [06:41<08:31,  2.56iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  35%|███▍      | 691/2000 [06:41<09:08,  2.39iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  35%|███▍      | 691/2000 [06:41<09:08,  2.39iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  35%|███▍      | 692/2000 [06:41<09:11,  2.37iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  35%|███▍      | 692/2000 [06:42<09:11,  2.37iteration/s, mean_rewards=-52] \u001b[A\n",
            "Training:  35%|███▍      | 693/2000 [06:42<09:36,  2.27iteration/s, mean_rewards=-52]\u001b[A\n",
            "Training:  35%|███▍      | 693/2000 [06:42<09:36,  2.27iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  35%|███▍      | 694/2000 [06:42<09:10,  2.37iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  35%|███▍      | 694/2000 [06:42<09:10,  2.37iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  35%|███▍      | 695/2000 [06:42<09:13,  2.36iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  35%|███▍      | 695/2000 [06:43<09:13,  2.36iteration/s, mean_rewards=-115]\u001b[A\n",
            "Training:  35%|███▍      | 696/2000 [06:43<08:50,  2.46iteration/s, mean_rewards=-115]\u001b[A\n",
            "Training:  35%|███▍      | 696/2000 [06:43<08:50,  2.46iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  35%|███▍      | 697/2000 [06:43<08:39,  2.51iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  35%|███▍      | 697/2000 [06:43<08:39,  2.51iteration/s, mean_rewards=-76.3]\u001b[A\n",
            "Training:  35%|███▍      | 698/2000 [06:44<08:29,  2.56iteration/s, mean_rewards=-76.3]\u001b[A\n",
            "Training:  35%|███▍      | 698/2000 [06:44<08:29,  2.56iteration/s, mean_rewards=-165] \u001b[A\n",
            "Training:  35%|███▍      | 699/2000 [06:44<08:24,  2.58iteration/s, mean_rewards=-165]\u001b[A\n",
            "Training:  35%|███▍      | 699/2000 [06:44<08:24,  2.58iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  35%|███▌      | 700/2000 [06:44<08:13,  2.64iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  35%|███▌      | 700/2000 [06:45<08:13,  2.64iteration/s, mean_rewards=-152]\u001b[A\n",
            "Training:  35%|███▌      | 701/2000 [06:45<08:05,  2.67iteration/s, mean_rewards=-152]\u001b[A\n",
            "Training:  35%|███▌      | 701/2000 [06:45<08:05,  2.67iteration/s, mean_rewards=-116]\u001b[A\n",
            "Training:  35%|███▌      | 702/2000 [06:45<07:47,  2.78iteration/s, mean_rewards=-116]\u001b[A\n",
            "Training:  35%|███▌      | 702/2000 [06:45<07:47,  2.78iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  35%|███▌      | 703/2000 [06:45<07:57,  2.72iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  35%|███▌      | 703/2000 [06:46<07:57,  2.72iteration/s, mean_rewards=-119]\u001b[A\n",
            "Training:  35%|███▌      | 704/2000 [06:46<08:07,  2.66iteration/s, mean_rewards=-119]\u001b[A\n",
            "Training:  35%|███▌      | 704/2000 [06:46<08:07,  2.66iteration/s, mean_rewards=-56.5]\u001b[A\n",
            "Training:  35%|███▌      | 705/2000 [06:46<08:03,  2.68iteration/s, mean_rewards=-56.5]\u001b[A\n",
            "Training:  35%|███▌      | 705/2000 [06:46<08:03,  2.68iteration/s, mean_rewards=-144] \u001b[A\n",
            "Training:  35%|███▌      | 706/2000 [06:47<08:12,  2.63iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  35%|███▌      | 706/2000 [06:47<08:12,  2.63iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  35%|███▌      | 707/2000 [06:47<08:08,  2.65iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  35%|███▌      | 707/2000 [06:47<08:08,  2.65iteration/s, mean_rewards=-58.7]\u001b[A\n",
            "Training:  35%|███▌      | 708/2000 [06:47<08:19,  2.58iteration/s, mean_rewards=-58.7]\u001b[A\n",
            "Training:  35%|███▌      | 708/2000 [06:48<08:19,  2.58iteration/s, mean_rewards=-150] \u001b[A\n",
            "Training:  35%|███▌      | 709/2000 [06:48<08:07,  2.65iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  35%|███▌      | 709/2000 [06:48<08:07,  2.65iteration/s, mean_rewards=-171]\u001b[A\n",
            "Training:  36%|███▌      | 710/2000 [06:48<08:24,  2.55iteration/s, mean_rewards=-171]\u001b[A\n",
            "Training:  36%|███▌      | 710/2000 [06:48<08:24,  2.55iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  36%|███▌      | 711/2000 [06:48<07:55,  2.71iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  36%|███▌      | 711/2000 [06:49<07:55,  2.71iteration/s, mean_rewards=-152]\u001b[A\n",
            "Training:  36%|███▌      | 712/2000 [06:49<07:40,  2.79iteration/s, mean_rewards=-152]\u001b[A\n",
            "Training:  36%|███▌      | 712/2000 [06:49<07:40,  2.79iteration/s, mean_rewards=-68.7]\u001b[A\n",
            "Training:  36%|███▌      | 713/2000 [06:49<08:13,  2.61iteration/s, mean_rewards=-68.7]\u001b[A\n",
            "Training:  36%|███▌      | 713/2000 [06:49<08:13,  2.61iteration/s, mean_rewards=-91.2]\u001b[A\n",
            "Training:  36%|███▌      | 714/2000 [06:50<08:05,  2.65iteration/s, mean_rewards=-91.2]\u001b[A\n",
            "Training:  36%|███▌      | 714/2000 [06:50<08:05,  2.65iteration/s, mean_rewards=-90.5]\u001b[A\n",
            "Training:  36%|███▌      | 715/2000 [06:50<08:28,  2.53iteration/s, mean_rewards=-90.5]\u001b[A\n",
            "Training:  36%|███▌      | 715/2000 [06:50<08:28,  2.53iteration/s, mean_rewards=-140] \u001b[A\n",
            "Training:  36%|███▌      | 716/2000 [06:50<08:18,  2.58iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  36%|███▌      | 716/2000 [06:51<08:18,  2.58iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  36%|███▌      | 717/2000 [06:51<08:22,  2.55iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  36%|███▌      | 717/2000 [06:51<08:22,  2.55iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  36%|███▌      | 718/2000 [06:51<08:10,  2.61iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  36%|███▌      | 718/2000 [06:51<08:10,  2.61iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  36%|███▌      | 719/2000 [06:51<07:48,  2.74iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  36%|███▌      | 719/2000 [06:52<07:48,  2.74iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  36%|███▌      | 720/2000 [06:52<08:34,  2.49iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  36%|███▌      | 720/2000 [06:52<08:34,  2.49iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  36%|███▌      | 721/2000 [06:52<08:55,  2.39iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  36%|███▌      | 721/2000 [06:53<08:55,  2.39iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  36%|███▌      | 722/2000 [06:53<08:45,  2.43iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  36%|███▌      | 722/2000 [06:53<08:45,  2.43iteration/s, mean_rewards=-106]\u001b[A\n",
            "Training:  36%|███▌      | 723/2000 [06:53<09:16,  2.30iteration/s, mean_rewards=-106]\u001b[A\n",
            "Training:  36%|███▌      | 723/2000 [06:54<09:16,  2.30iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  36%|███▌      | 724/2000 [06:54<09:05,  2.34iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  36%|███▌      | 724/2000 [06:54<09:05,  2.34iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  36%|███▋      | 725/2000 [06:54<10:01,  2.12iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  36%|███▋      | 725/2000 [06:55<10:01,  2.12iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  36%|███▋      | 726/2000 [06:55<09:31,  2.23iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  36%|███▋      | 726/2000 [06:55<09:31,  2.23iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  36%|███▋      | 727/2000 [06:55<09:25,  2.25iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  36%|███▋      | 727/2000 [06:55<09:25,  2.25iteration/s, mean_rewards=-159]\u001b[A\n",
            "Training:  36%|███▋      | 728/2000 [06:55<08:42,  2.44iteration/s, mean_rewards=-159]\u001b[A\n",
            "Training:  36%|███▋      | 728/2000 [06:56<08:42,  2.44iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:  36%|███▋      | 729/2000 [06:56<08:21,  2.54iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:  36%|███▋      | 729/2000 [06:56<08:21,  2.54iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  36%|███▋      | 730/2000 [06:56<08:20,  2.54iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  36%|███▋      | 730/2000 [06:56<08:20,  2.54iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  37%|███▋      | 731/2000 [06:57<07:46,  2.72iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  37%|███▋      | 731/2000 [06:57<07:46,  2.72iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  37%|███▋      | 732/2000 [06:57<07:49,  2.70iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  37%|███▋      | 732/2000 [06:57<07:49,  2.70iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:  37%|███▋      | 733/2000 [06:57<08:10,  2.59iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:  37%|███▋      | 733/2000 [06:58<08:10,  2.59iteration/s, mean_rewards=-63.9]\u001b[A\n",
            "Training:  37%|███▋      | 734/2000 [06:58<08:25,  2.51iteration/s, mean_rewards=-63.9]\u001b[A\n",
            "Training:  37%|███▋      | 734/2000 [06:58<08:25,  2.51iteration/s, mean_rewards=-131] \u001b[A\n",
            "Training:  37%|███▋      | 735/2000 [06:58<08:24,  2.51iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  37%|███▋      | 735/2000 [06:58<08:24,  2.51iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  37%|███▋      | 736/2000 [06:59<08:11,  2.57iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  37%|███▋      | 736/2000 [06:59<08:11,  2.57iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  37%|███▋      | 737/2000 [06:59<07:42,  2.73iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  37%|███▋      | 737/2000 [06:59<07:42,  2.73iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  37%|███▋      | 738/2000 [06:59<08:09,  2.58iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  37%|███▋      | 738/2000 [06:59<08:09,  2.58iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  37%|███▋      | 739/2000 [07:00<07:42,  2.72iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  37%|███▋      | 739/2000 [07:00<07:42,  2.72iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  37%|███▋      | 740/2000 [07:00<07:36,  2.76iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  37%|███▋      | 740/2000 [07:00<07:36,  2.76iteration/s, mean_rewards=-173]\u001b[A\n",
            "Training:  37%|███▋      | 741/2000 [07:00<07:50,  2.68iteration/s, mean_rewards=-173]\u001b[A\n",
            "Training:  37%|███▋      | 741/2000 [07:01<07:50,  2.68iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  37%|███▋      | 742/2000 [07:01<07:52,  2.66iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  37%|███▋      | 742/2000 [07:01<07:52,  2.66iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  37%|███▋      | 743/2000 [07:01<07:35,  2.76iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  37%|███▋      | 743/2000 [07:01<07:35,  2.76iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  37%|███▋      | 744/2000 [07:01<07:41,  2.72iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  37%|███▋      | 744/2000 [07:02<07:41,  2.72iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  37%|███▋      | 745/2000 [07:02<07:41,  2.72iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  37%|███▋      | 745/2000 [07:02<07:41,  2.72iteration/s, mean_rewards=-163]\u001b[A\n",
            "Training:  37%|███▋      | 746/2000 [07:02<08:07,  2.57iteration/s, mean_rewards=-163]\u001b[A\n",
            "Training:  37%|███▋      | 746/2000 [07:02<08:07,  2.57iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  37%|███▋      | 747/2000 [07:03<07:44,  2.70iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  37%|███▋      | 747/2000 [07:03<07:44,  2.70iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  37%|███▋      | 748/2000 [07:03<07:36,  2.75iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  37%|███▋      | 748/2000 [07:03<07:36,  2.75iteration/s, mean_rewards=-164]\u001b[A\n",
            "Training:  37%|███▋      | 749/2000 [07:03<07:48,  2.67iteration/s, mean_rewards=-164]\u001b[A\n",
            "Training:  37%|███▋      | 749/2000 [07:04<07:48,  2.67iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  38%|███▊      | 750/2000 [07:04<07:46,  2.68iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  38%|███▊      | 750/2000 [07:04<07:46,  2.68iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  38%|███▊      | 751/2000 [07:04<07:23,  2.81iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  38%|███▊      | 751/2000 [07:04<07:23,  2.81iteration/s, mean_rewards=-119]\u001b[A\n",
            "Training:  38%|███▊      | 752/2000 [07:04<07:35,  2.74iteration/s, mean_rewards=-119]\u001b[A\n",
            "Training:  38%|███▊      | 752/2000 [07:05<07:35,  2.74iteration/s, mean_rewards=-163]\u001b[A\n",
            "Training:  38%|███▊      | 753/2000 [07:05<07:41,  2.70iteration/s, mean_rewards=-163]\u001b[A\n",
            "Training:  38%|███▊      | 753/2000 [07:05<07:41,  2.70iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  38%|███▊      | 754/2000 [07:05<07:48,  2.66iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  38%|███▊      | 754/2000 [07:06<07:48,  2.66iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  38%|███▊      | 755/2000 [07:06<08:35,  2.41iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  38%|███▊      | 755/2000 [07:06<08:35,  2.41iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  38%|███▊      | 756/2000 [07:06<08:17,  2.50iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  38%|███▊      | 756/2000 [07:06<08:17,  2.50iteration/s, mean_rewards=-164]\u001b[A\n",
            "Training:  38%|███▊      | 757/2000 [07:07<08:53,  2.33iteration/s, mean_rewards=-164]\u001b[A\n",
            "Training:  38%|███▊      | 757/2000 [07:07<08:53,  2.33iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  38%|███▊      | 758/2000 [07:07<09:23,  2.20iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  38%|███▊      | 758/2000 [07:07<09:23,  2.20iteration/s, mean_rewards=-166]\u001b[A\n",
            "Training:  38%|███▊      | 759/2000 [07:08<09:56,  2.08iteration/s, mean_rewards=-166]\u001b[A\n",
            "Training:  38%|███▊      | 759/2000 [07:08<09:56,  2.08iteration/s, mean_rewards=-170]\u001b[A\n",
            "Training:  38%|███▊      | 760/2000 [07:08<09:46,  2.11iteration/s, mean_rewards=-170]\u001b[A\n",
            "Training:  38%|███▊      | 760/2000 [07:08<09:46,  2.11iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  38%|███▊      | 761/2000 [07:08<09:18,  2.22iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  38%|███▊      | 761/2000 [07:09<09:18,  2.22iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  38%|███▊      | 762/2000 [07:09<08:46,  2.35iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  38%|███▊      | 762/2000 [07:09<08:46,  2.35iteration/s, mean_rewards=-105]\u001b[A\n",
            "Training:  38%|███▊      | 763/2000 [07:09<08:29,  2.43iteration/s, mean_rewards=-105]\u001b[A\n",
            "Training:  38%|███▊      | 763/2000 [07:09<08:29,  2.43iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  38%|███▊      | 764/2000 [07:10<08:42,  2.37iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  38%|███▊      | 764/2000 [07:10<08:42,  2.37iteration/s, mean_rewards=-78.2]\u001b[A\n",
            "Training:  38%|███▊      | 765/2000 [07:10<08:19,  2.47iteration/s, mean_rewards=-78.2]\u001b[A\n",
            "Training:  38%|███▊      | 765/2000 [07:10<08:19,  2.47iteration/s, mean_rewards=-167] \u001b[A\n",
            "Training:  38%|███▊      | 766/2000 [07:10<08:05,  2.54iteration/s, mean_rewards=-167]\u001b[A\n",
            "Training:  38%|███▊      | 766/2000 [07:11<08:05,  2.54iteration/s, mean_rewards=-171]\u001b[A\n",
            "Training:  38%|███▊      | 767/2000 [07:11<08:02,  2.56iteration/s, mean_rewards=-171]\u001b[A\n",
            "Training:  38%|███▊      | 767/2000 [07:11<08:02,  2.56iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  38%|███▊      | 768/2000 [07:11<07:55,  2.59iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  38%|███▊      | 768/2000 [07:11<07:55,  2.59iteration/s, mean_rewards=-116]\u001b[A\n",
            "Training:  38%|███▊      | 769/2000 [07:11<07:25,  2.76iteration/s, mean_rewards=-116]\u001b[A\n",
            "Training:  38%|███▊      | 769/2000 [07:12<07:25,  2.76iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  38%|███▊      | 770/2000 [07:12<07:15,  2.83iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  38%|███▊      | 770/2000 [07:12<07:15,  2.83iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  39%|███▊      | 771/2000 [07:12<07:52,  2.60iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  39%|███▊      | 771/2000 [07:12<07:52,  2.60iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  39%|███▊      | 772/2000 [07:13<07:46,  2.63iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  39%|███▊      | 772/2000 [07:13<07:46,  2.63iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  39%|███▊      | 773/2000 [07:13<07:40,  2.66iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  39%|███▊      | 773/2000 [07:13<07:40,  2.66iteration/s, mean_rewards=-163]\u001b[A\n",
            "Training:  39%|███▊      | 774/2000 [07:13<07:41,  2.65iteration/s, mean_rewards=-163]\u001b[A\n",
            "Training:  39%|███▊      | 774/2000 [07:14<07:41,  2.65iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  39%|███▉      | 775/2000 [07:14<07:20,  2.78iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  39%|███▉      | 775/2000 [07:14<07:20,  2.78iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:  39%|███▉      | 776/2000 [07:14<07:07,  2.86iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:  39%|███▉      | 776/2000 [07:14<07:07,  2.86iteration/s, mean_rewards=-75] \u001b[A\n",
            "Training:  39%|███▉      | 777/2000 [07:14<07:38,  2.66iteration/s, mean_rewards=-75]\u001b[A\n",
            "Training:  39%|███▉      | 777/2000 [07:15<07:38,  2.66iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  39%|███▉      | 778/2000 [07:15<07:13,  2.82iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  39%|███▉      | 778/2000 [07:15<07:13,  2.82iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  39%|███▉      | 779/2000 [07:15<07:09,  2.84iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  39%|███▉      | 779/2000 [07:15<07:09,  2.84iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  39%|███▉      | 780/2000 [07:15<06:47,  2.99iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  39%|███▉      | 780/2000 [07:16<06:47,  2.99iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  39%|███▉      | 781/2000 [07:16<07:10,  2.83iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  39%|███▉      | 781/2000 [07:16<07:10,  2.83iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  39%|███▉      | 782/2000 [07:16<06:55,  2.93iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  39%|███▉      | 782/2000 [07:16<06:55,  2.93iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  39%|███▉      | 783/2000 [07:16<06:47,  2.98iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  39%|███▉      | 783/2000 [07:17<06:47,  2.98iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  39%|███▉      | 784/2000 [07:17<06:57,  2.92iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  39%|███▉      | 784/2000 [07:17<06:57,  2.92iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  39%|███▉      | 785/2000 [07:17<07:23,  2.74iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  39%|███▉      | 785/2000 [07:17<07:23,  2.74iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  39%|███▉      | 786/2000 [07:18<07:27,  2.71iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  39%|███▉      | 786/2000 [07:18<07:27,  2.71iteration/s, mean_rewards=-25.2]\u001b[A\n",
            "Training:  39%|███▉      | 787/2000 [07:18<08:43,  2.32iteration/s, mean_rewards=-25.2]\u001b[A\n",
            "Training:  39%|███▉      | 787/2000 [07:18<08:43,  2.32iteration/s, mean_rewards=-144] \u001b[A\n",
            "Training:  39%|███▉      | 788/2000 [07:19<08:44,  2.31iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  39%|███▉      | 788/2000 [07:19<08:44,  2.31iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  39%|███▉      | 789/2000 [07:19<08:19,  2.43iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  39%|███▉      | 789/2000 [07:19<08:19,  2.43iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  40%|███▉      | 790/2000 [07:19<08:27,  2.39iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  40%|███▉      | 790/2000 [07:20<08:27,  2.39iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  40%|███▉      | 791/2000 [07:20<08:21,  2.41iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  40%|███▉      | 791/2000 [07:20<08:21,  2.41iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  40%|███▉      | 792/2000 [07:20<08:51,  2.27iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  40%|███▉      | 792/2000 [07:21<08:51,  2.27iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  40%|███▉      | 793/2000 [07:21<08:30,  2.36iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  40%|███▉      | 793/2000 [07:21<08:30,  2.36iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  40%|███▉      | 794/2000 [07:21<08:08,  2.47iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  40%|███▉      | 794/2000 [07:21<08:08,  2.47iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  40%|███▉      | 795/2000 [07:21<07:32,  2.66iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  40%|███▉      | 795/2000 [07:22<07:32,  2.66iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  40%|███▉      | 796/2000 [07:22<07:40,  2.62iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  40%|███▉      | 796/2000 [07:22<07:40,  2.62iteration/s, mean_rewards=-105]\u001b[A\n",
            "Training:  40%|███▉      | 797/2000 [07:22<07:34,  2.65iteration/s, mean_rewards=-105]\u001b[A\n",
            "Training:  40%|███▉      | 797/2000 [07:22<07:34,  2.65iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  40%|███▉      | 798/2000 [07:22<07:10,  2.79iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  40%|███▉      | 798/2000 [07:23<07:10,  2.79iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  40%|███▉      | 799/2000 [07:23<06:57,  2.87iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  40%|███▉      | 799/2000 [07:23<06:57,  2.87iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  40%|████      | 800/2000 [07:23<06:56,  2.88iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  40%|████      | 800/2000 [07:23<06:56,  2.88iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  40%|████      | 801/2000 [07:23<06:59,  2.86iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  40%|████      | 801/2000 [07:24<06:59,  2.86iteration/s, mean_rewards=-58.3]\u001b[A\n",
            "Training:  40%|████      | 802/2000 [07:24<07:03,  2.83iteration/s, mean_rewards=-58.3]\u001b[A\n",
            "Training:  40%|████      | 802/2000 [07:24<07:03,  2.83iteration/s, mean_rewards=-99.6]\u001b[A\n",
            "Training:  40%|████      | 803/2000 [07:24<07:07,  2.80iteration/s, mean_rewards=-99.6]\u001b[A\n",
            "Training:  40%|████      | 803/2000 [07:24<07:07,  2.80iteration/s, mean_rewards=-120] \u001b[A\n",
            "Training:  40%|████      | 804/2000 [07:24<07:09,  2.78iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  40%|████      | 804/2000 [07:25<07:09,  2.78iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  40%|████      | 805/2000 [07:25<06:57,  2.86iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  40%|████      | 805/2000 [07:25<06:57,  2.86iteration/s, mean_rewards=-166]\u001b[A\n",
            "Training:  40%|████      | 806/2000 [07:25<07:09,  2.78iteration/s, mean_rewards=-166]\u001b[A\n",
            "Training:  40%|████      | 806/2000 [07:25<07:09,  2.78iteration/s, mean_rewards=-157]\u001b[A\n",
            "Training:  40%|████      | 807/2000 [07:26<07:29,  2.66iteration/s, mean_rewards=-157]\u001b[A\n",
            "Training:  40%|████      | 807/2000 [07:26<07:29,  2.66iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  40%|████      | 808/2000 [07:26<07:10,  2.77iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  40%|████      | 808/2000 [07:26<07:10,  2.77iteration/s, mean_rewards=-42.4]\u001b[A\n",
            "Training:  40%|████      | 809/2000 [07:26<07:09,  2.77iteration/s, mean_rewards=-42.4]\u001b[A\n",
            "Training:  40%|████      | 809/2000 [07:27<07:09,  2.77iteration/s, mean_rewards=-117] \u001b[A\n",
            "Training:  40%|████      | 810/2000 [07:27<06:52,  2.89iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  40%|████      | 810/2000 [07:27<06:52,  2.89iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  41%|████      | 811/2000 [07:27<07:08,  2.77iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  41%|████      | 811/2000 [07:27<07:08,  2.77iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:  41%|████      | 812/2000 [07:27<07:10,  2.76iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:  41%|████      | 812/2000 [07:28<07:10,  2.76iteration/s, mean_rewards=-65] \u001b[A\n",
            "Training:  41%|████      | 813/2000 [07:28<07:25,  2.67iteration/s, mean_rewards=-65]\u001b[A\n",
            "Training:  41%|████      | 813/2000 [07:28<07:25,  2.67iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  41%|████      | 814/2000 [07:28<06:54,  2.86iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  41%|████      | 814/2000 [07:28<06:54,  2.86iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  41%|████      | 815/2000 [07:28<07:02,  2.80iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  41%|████      | 815/2000 [07:29<07:02,  2.80iteration/s, mean_rewards=-223]\u001b[A\n",
            "Training:  41%|████      | 816/2000 [07:29<07:26,  2.65iteration/s, mean_rewards=-223]\u001b[A\n",
            "Training:  41%|████      | 816/2000 [07:29<07:26,  2.65iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  41%|████      | 817/2000 [07:29<07:14,  2.72iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  41%|████      | 817/2000 [07:29<07:14,  2.72iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  41%|████      | 818/2000 [07:30<06:54,  2.85iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  41%|████      | 818/2000 [07:30<06:54,  2.85iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  41%|████      | 819/2000 [07:30<07:19,  2.69iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  41%|████      | 819/2000 [07:30<07:19,  2.69iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  41%|████      | 820/2000 [07:30<07:21,  2.67iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  41%|████      | 820/2000 [07:31<07:21,  2.67iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:  41%|████      | 821/2000 [07:31<07:43,  2.54iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:  41%|████      | 821/2000 [07:31<07:43,  2.54iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  41%|████      | 822/2000 [07:31<07:50,  2.51iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  41%|████      | 822/2000 [07:31<07:50,  2.51iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  41%|████      | 823/2000 [07:32<08:06,  2.42iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  41%|████      | 823/2000 [07:32<08:06,  2.42iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  41%|████      | 824/2000 [07:32<09:13,  2.13iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  41%|████      | 824/2000 [07:33<09:13,  2.13iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  41%|████▏     | 825/2000 [07:33<09:24,  2.08iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  41%|████▏     | 825/2000 [07:33<09:24,  2.08iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  41%|████▏     | 826/2000 [07:33<09:06,  2.15iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  41%|████▏     | 826/2000 [07:33<09:06,  2.15iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  41%|████▏     | 827/2000 [07:34<08:45,  2.23iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  41%|████▏     | 827/2000 [07:34<08:45,  2.23iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  41%|████▏     | 828/2000 [07:34<08:11,  2.38iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  41%|████▏     | 828/2000 [07:34<08:11,  2.38iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:  41%|████▏     | 829/2000 [07:34<07:53,  2.47iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:  41%|████▏     | 829/2000 [07:35<07:53,  2.47iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  42%|████▏     | 830/2000 [07:35<07:36,  2.56iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  42%|████▏     | 830/2000 [07:35<07:36,  2.56iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  42%|████▏     | 831/2000 [07:35<07:10,  2.72iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  42%|████▏     | 831/2000 [07:35<07:10,  2.72iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  42%|████▏     | 832/2000 [07:35<06:45,  2.88iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  42%|████▏     | 832/2000 [07:35<06:45,  2.88iteration/s, mean_rewards=-101]\u001b[A\n",
            "Training:  42%|████▏     | 833/2000 [07:36<06:46,  2.87iteration/s, mean_rewards=-101]\u001b[A\n",
            "Training:  42%|████▏     | 833/2000 [07:36<06:46,  2.87iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  42%|████▏     | 834/2000 [07:36<07:16,  2.67iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  42%|████▏     | 834/2000 [07:36<07:16,  2.67iteration/s, mean_rewards=-106]\u001b[A\n",
            "Training:  42%|████▏     | 835/2000 [07:36<07:13,  2.69iteration/s, mean_rewards=-106]\u001b[A\n",
            "Training:  42%|████▏     | 835/2000 [07:37<07:13,  2.69iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  42%|████▏     | 836/2000 [07:37<07:04,  2.74iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  42%|████▏     | 836/2000 [07:37<07:04,  2.74iteration/s, mean_rewards=-205]\u001b[A\n",
            "Training:  42%|████▏     | 837/2000 [07:37<07:21,  2.63iteration/s, mean_rewards=-205]\u001b[A\n",
            "Training:  42%|████▏     | 837/2000 [07:37<07:21,  2.63iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  42%|████▏     | 838/2000 [07:38<07:23,  2.62iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  42%|████▏     | 838/2000 [07:38<07:23,  2.62iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  42%|████▏     | 839/2000 [07:38<07:04,  2.74iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  42%|████▏     | 839/2000 [07:38<07:04,  2.74iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  42%|████▏     | 840/2000 [07:38<07:05,  2.72iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  42%|████▏     | 840/2000 [07:38<07:05,  2.72iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  42%|████▏     | 841/2000 [07:39<06:57,  2.78iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  42%|████▏     | 841/2000 [07:39<06:57,  2.78iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  42%|████▏     | 842/2000 [07:39<06:56,  2.78iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  42%|████▏     | 842/2000 [07:39<06:56,  2.78iteration/s, mean_rewards=-58.3]\u001b[A\n",
            "Training:  42%|████▏     | 843/2000 [07:39<06:40,  2.89iteration/s, mean_rewards=-58.3]\u001b[A\n",
            "Training:  42%|████▏     | 843/2000 [07:39<06:40,  2.89iteration/s, mean_rewards=-138] \u001b[A\n",
            "Training:  42%|████▏     | 844/2000 [07:40<06:26,  2.99iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:  42%|████▏     | 844/2000 [07:40<06:26,  2.99iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  42%|████▏     | 845/2000 [07:40<06:34,  2.93iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  42%|████▏     | 845/2000 [07:40<06:34,  2.93iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:  42%|████▏     | 846/2000 [07:40<06:51,  2.80iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:  42%|████▏     | 846/2000 [07:41<06:51,  2.80iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  42%|████▏     | 847/2000 [07:41<06:54,  2.78iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  42%|████▏     | 847/2000 [07:41<06:54,  2.78iteration/s, mean_rewards=-96.6]\u001b[A\n",
            "Training:  42%|████▏     | 848/2000 [07:41<06:50,  2.81iteration/s, mean_rewards=-96.6]\u001b[A\n",
            "Training:  42%|████▏     | 848/2000 [07:41<06:50,  2.81iteration/s, mean_rewards=-63.9]\u001b[A\n",
            "Training:  42%|████▏     | 849/2000 [07:41<06:48,  2.81iteration/s, mean_rewards=-63.9]\u001b[A\n",
            "Training:  42%|████▏     | 849/2000 [07:42<06:48,  2.81iteration/s, mean_rewards=-120] \u001b[A\n",
            "Training:  42%|████▎     | 850/2000 [07:42<06:55,  2.77iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  42%|████▎     | 850/2000 [07:42<06:55,  2.77iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  43%|████▎     | 851/2000 [07:42<06:54,  2.77iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  43%|████▎     | 851/2000 [07:42<06:54,  2.77iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:  43%|████▎     | 852/2000 [07:42<06:49,  2.81iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:  43%|████▎     | 852/2000 [07:43<06:49,  2.81iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:  43%|████▎     | 853/2000 [07:43<06:29,  2.94iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:  43%|████▎     | 853/2000 [07:43<06:29,  2.94iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  43%|████▎     | 854/2000 [07:43<06:16,  3.05iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  43%|████▎     | 854/2000 [07:43<06:16,  3.05iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  43%|████▎     | 855/2000 [07:43<06:09,  3.10iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  43%|████▎     | 855/2000 [07:44<06:09,  3.10iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  43%|████▎     | 856/2000 [07:44<06:34,  2.90iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  43%|████▎     | 856/2000 [07:44<06:34,  2.90iteration/s, mean_rewards=-74.8]\u001b[A\n",
            "Training:  43%|████▎     | 857/2000 [07:44<06:49,  2.79iteration/s, mean_rewards=-74.8]\u001b[A\n",
            "Training:  43%|████▎     | 857/2000 [07:44<06:49,  2.79iteration/s, mean_rewards=-162] \u001b[A\n",
            "Training:  43%|████▎     | 858/2000 [07:45<07:15,  2.62iteration/s, mean_rewards=-162]\u001b[A\n",
            "Training:  43%|████▎     | 858/2000 [07:45<07:15,  2.62iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  43%|████▎     | 859/2000 [07:45<07:09,  2.66iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  43%|████▎     | 859/2000 [07:45<07:09,  2.66iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  43%|████▎     | 860/2000 [07:45<07:51,  2.42iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  43%|████▎     | 860/2000 [07:46<07:51,  2.42iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:  43%|████▎     | 861/2000 [07:46<08:19,  2.28iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:  43%|████▎     | 861/2000 [07:46<08:19,  2.28iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  43%|████▎     | 862/2000 [07:46<08:41,  2.18iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  43%|████▎     | 862/2000 [07:47<08:41,  2.18iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  43%|████▎     | 863/2000 [07:47<08:24,  2.26iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  43%|████▎     | 863/2000 [07:47<08:24,  2.26iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  43%|████▎     | 864/2000 [07:47<08:05,  2.34iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  43%|████▎     | 864/2000 [07:48<08:05,  2.34iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  43%|████▎     | 865/2000 [07:48<07:51,  2.41iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  43%|████▎     | 865/2000 [07:48<07:51,  2.41iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:  43%|████▎     | 866/2000 [07:48<07:17,  2.59iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:  43%|████▎     | 866/2000 [07:48<07:17,  2.59iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  43%|████▎     | 867/2000 [07:48<07:14,  2.61iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  43%|████▎     | 867/2000 [07:49<07:14,  2.61iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  43%|████▎     | 868/2000 [07:49<07:16,  2.59iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  43%|████▎     | 868/2000 [07:49<07:16,  2.59iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  43%|████▎     | 869/2000 [07:49<07:33,  2.49iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  43%|████▎     | 869/2000 [07:49<07:33,  2.49iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  44%|████▎     | 870/2000 [07:50<07:01,  2.68iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  44%|████▎     | 870/2000 [07:50<07:01,  2.68iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  44%|████▎     | 871/2000 [07:50<06:51,  2.74iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  44%|████▎     | 871/2000 [07:50<06:51,  2.74iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:  44%|████▎     | 872/2000 [07:50<06:57,  2.70iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:  44%|████▎     | 872/2000 [07:50<06:57,  2.70iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  44%|████▎     | 873/2000 [07:51<07:02,  2.67iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  44%|████▎     | 873/2000 [07:51<07:02,  2.67iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  44%|████▎     | 874/2000 [07:51<06:52,  2.73iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  44%|████▎     | 874/2000 [07:51<06:52,  2.73iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  44%|████▍     | 875/2000 [07:51<06:55,  2.71iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  44%|████▍     | 875/2000 [07:52<06:55,  2.71iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  44%|████▍     | 876/2000 [07:52<06:37,  2.82iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  44%|████▍     | 876/2000 [07:52<06:37,  2.82iteration/s, mean_rewards=-204]\u001b[A\n",
            "Training:  44%|████▍     | 877/2000 [07:52<07:11,  2.60iteration/s, mean_rewards=-204]\u001b[A\n",
            "Training:  44%|████▍     | 877/2000 [07:52<07:11,  2.60iteration/s, mean_rewards=-80.4]\u001b[A\n",
            "Training:  44%|████▍     | 878/2000 [07:52<07:05,  2.63iteration/s, mean_rewards=-80.4]\u001b[A\n",
            "Training:  44%|████▍     | 878/2000 [07:53<07:05,  2.63iteration/s, mean_rewards=-154] \u001b[A\n",
            "Training:  44%|████▍     | 879/2000 [07:53<07:07,  2.62iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  44%|████▍     | 879/2000 [07:53<07:07,  2.62iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  44%|████▍     | 880/2000 [07:53<07:23,  2.52iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  44%|████▍     | 880/2000 [07:54<07:23,  2.52iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  44%|████▍     | 881/2000 [07:54<07:06,  2.62iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  44%|████▍     | 881/2000 [07:54<07:06,  2.62iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  44%|████▍     | 882/2000 [07:54<06:41,  2.79iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  44%|████▍     | 882/2000 [07:54<06:41,  2.79iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  44%|████▍     | 883/2000 [07:54<06:41,  2.78iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  44%|████▍     | 883/2000 [07:54<06:41,  2.78iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  44%|████▍     | 884/2000 [07:55<06:17,  2.96iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  44%|████▍     | 884/2000 [07:55<06:17,  2.96iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  44%|████▍     | 885/2000 [07:55<06:34,  2.83iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  44%|████▍     | 885/2000 [07:55<06:34,  2.83iteration/s, mean_rewards=-10.7]\u001b[A\n",
            "Training:  44%|████▍     | 886/2000 [07:55<06:45,  2.75iteration/s, mean_rewards=-10.7]\u001b[A\n",
            "Training:  44%|████▍     | 886/2000 [07:56<06:45,  2.75iteration/s, mean_rewards=-168] \u001b[A\n",
            "Training:  44%|████▍     | 887/2000 [07:56<06:45,  2.74iteration/s, mean_rewards=-168]\u001b[A\n",
            "Training:  44%|████▍     | 887/2000 [07:56<06:45,  2.74iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  44%|████▍     | 888/2000 [07:56<06:50,  2.71iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  44%|████▍     | 888/2000 [07:56<06:50,  2.71iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  44%|████▍     | 889/2000 [07:56<06:43,  2.75iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  44%|████▍     | 889/2000 [07:57<06:43,  2.75iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  44%|████▍     | 890/2000 [07:57<06:49,  2.71iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  44%|████▍     | 890/2000 [07:57<06:49,  2.71iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  45%|████▍     | 891/2000 [07:57<07:27,  2.48iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  45%|████▍     | 891/2000 [07:58<07:27,  2.48iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  45%|████▍     | 892/2000 [07:58<08:22,  2.21iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  45%|████▍     | 892/2000 [07:58<08:22,  2.21iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  45%|████▍     | 893/2000 [07:58<08:02,  2.29iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  45%|████▍     | 893/2000 [07:59<08:02,  2.29iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  45%|████▍     | 894/2000 [07:59<08:13,  2.24iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  45%|████▍     | 894/2000 [07:59<08:13,  2.24iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  45%|████▍     | 895/2000 [07:59<08:19,  2.21iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  45%|████▍     | 895/2000 [08:00<08:19,  2.21iteration/s, mean_rewards=-211]\u001b[A\n",
            "Training:  45%|████▍     | 896/2000 [08:00<09:12,  2.00iteration/s, mean_rewards=-211]\u001b[A\n",
            "Training:  45%|████▍     | 896/2000 [08:00<09:12,  2.00iteration/s, mean_rewards=-119]\u001b[A\n",
            "Training:  45%|████▍     | 897/2000 [08:00<09:08,  2.01iteration/s, mean_rewards=-119]\u001b[A\n",
            "Training:  45%|████▍     | 897/2000 [08:01<09:08,  2.01iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  45%|████▍     | 898/2000 [08:01<08:01,  2.29iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  45%|████▍     | 898/2000 [08:01<08:01,  2.29iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:  45%|████▍     | 899/2000 [08:01<07:40,  2.39iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:  45%|████▍     | 899/2000 [08:01<07:40,  2.39iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  45%|████▌     | 900/2000 [08:01<07:20,  2.50iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  45%|████▌     | 900/2000 [08:02<07:20,  2.50iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  45%|████▌     | 901/2000 [08:02<07:32,  2.43iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  45%|████▌     | 901/2000 [08:02<07:32,  2.43iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  45%|████▌     | 902/2000 [08:02<07:23,  2.47iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  45%|████▌     | 902/2000 [08:02<07:23,  2.47iteration/s, mean_rewards=-168]\u001b[A\n",
            "Training:  45%|████▌     | 903/2000 [08:03<07:29,  2.44iteration/s, mean_rewards=-168]\u001b[A\n",
            "Training:  45%|████▌     | 903/2000 [08:03<07:29,  2.44iteration/s, mean_rewards=-60.5]\u001b[A\n",
            "Training:  45%|████▌     | 904/2000 [08:03<07:16,  2.51iteration/s, mean_rewards=-60.5]\u001b[A\n",
            "Training:  45%|████▌     | 904/2000 [08:03<07:16,  2.51iteration/s, mean_rewards=-111] \u001b[A\n",
            "Training:  45%|████▌     | 905/2000 [08:03<06:38,  2.75iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  45%|████▌     | 905/2000 [08:03<06:38,  2.75iteration/s, mean_rewards=-72.6]\u001b[A\n",
            "Training:  45%|████▌     | 906/2000 [08:04<06:22,  2.86iteration/s, mean_rewards=-72.6]\u001b[A\n",
            "Training:  45%|████▌     | 906/2000 [08:04<06:22,  2.86iteration/s, mean_rewards=-150] \u001b[A\n",
            "Training:  45%|████▌     | 907/2000 [08:04<06:23,  2.85iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  45%|████▌     | 907/2000 [08:04<06:23,  2.85iteration/s, mean_rewards=-102]\u001b[A\n",
            "Training:  45%|████▌     | 908/2000 [08:04<06:05,  2.99iteration/s, mean_rewards=-102]\u001b[A\n",
            "Training:  45%|████▌     | 908/2000 [08:04<06:05,  2.99iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:  45%|████▌     | 909/2000 [08:05<06:19,  2.87iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:  45%|████▌     | 909/2000 [08:05<06:19,  2.87iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  46%|████▌     | 910/2000 [08:05<06:19,  2.87iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  46%|████▌     | 910/2000 [08:05<06:19,  2.87iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  46%|████▌     | 911/2000 [08:05<06:24,  2.83iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  46%|████▌     | 911/2000 [08:06<06:24,  2.83iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  46%|████▌     | 912/2000 [08:06<06:07,  2.96iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  46%|████▌     | 912/2000 [08:06<06:07,  2.96iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  46%|████▌     | 913/2000 [08:06<06:21,  2.85iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  46%|████▌     | 913/2000 [08:06<06:21,  2.85iteration/s, mean_rewards=-152]\u001b[A\n",
            "Training:  46%|████▌     | 914/2000 [08:06<06:20,  2.85iteration/s, mean_rewards=-152]\u001b[A\n",
            "Training:  46%|████▌     | 914/2000 [08:07<06:20,  2.85iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  46%|████▌     | 915/2000 [08:07<06:01,  3.00iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  46%|████▌     | 915/2000 [08:07<06:01,  3.00iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  46%|████▌     | 916/2000 [08:07<06:14,  2.89iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  46%|████▌     | 916/2000 [08:07<06:14,  2.89iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  46%|████▌     | 917/2000 [08:07<06:03,  2.98iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  46%|████▌     | 917/2000 [08:08<06:03,  2.98iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  46%|████▌     | 918/2000 [08:08<05:58,  3.02iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  46%|████▌     | 918/2000 [08:08<05:58,  3.02iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  46%|████▌     | 919/2000 [08:08<05:55,  3.04iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  46%|████▌     | 919/2000 [08:08<05:55,  3.04iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  46%|████▌     | 920/2000 [08:08<06:06,  2.95iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  46%|████▌     | 920/2000 [08:09<06:06,  2.95iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  46%|████▌     | 921/2000 [08:09<06:06,  2.94iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  46%|████▌     | 921/2000 [08:09<06:06,  2.94iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  46%|████▌     | 922/2000 [08:09<06:30,  2.76iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  46%|████▌     | 922/2000 [08:09<06:30,  2.76iteration/s, mean_rewards=-5.75]\u001b[A\n",
            "Training:  46%|████▌     | 923/2000 [08:10<06:48,  2.64iteration/s, mean_rewards=-5.75]\u001b[A\n",
            "Training:  46%|████▌     | 923/2000 [08:10<06:48,  2.64iteration/s, mean_rewards=-155] \u001b[A\n",
            "Training:  46%|████▌     | 924/2000 [08:10<06:56,  2.58iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  46%|████▌     | 924/2000 [08:10<06:56,  2.58iteration/s, mean_rewards=-63.1]\u001b[A\n",
            "Training:  46%|████▋     | 925/2000 [08:11<07:54,  2.27iteration/s, mean_rewards=-63.1]\u001b[A\n",
            "Training:  46%|████▋     | 925/2000 [08:11<07:54,  2.27iteration/s, mean_rewards=-126] \u001b[A\n",
            "Training:  46%|████▋     | 926/2000 [08:11<08:07,  2.21iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  46%|████▋     | 926/2000 [08:11<08:07,  2.21iteration/s, mean_rewards=-163]\u001b[A\n",
            "Training:  46%|████▋     | 927/2000 [08:11<08:25,  2.12iteration/s, mean_rewards=-163]\u001b[A\n",
            "Training:  46%|████▋     | 927/2000 [08:12<08:25,  2.12iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  46%|████▋     | 928/2000 [08:12<08:11,  2.18iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  46%|████▋     | 928/2000 [08:12<08:11,  2.18iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:  46%|████▋     | 929/2000 [08:13<08:51,  2.02iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:  46%|████▋     | 929/2000 [08:13<08:51,  2.02iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  46%|████▋     | 930/2000 [08:13<08:22,  2.13iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  46%|████▋     | 930/2000 [08:13<08:22,  2.13iteration/s, mean_rewards=-173]\u001b[A\n",
            "Training:  47%|████▋     | 931/2000 [08:13<08:28,  2.10iteration/s, mean_rewards=-173]\u001b[A\n",
            "Training:  47%|████▋     | 931/2000 [08:14<08:28,  2.10iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  47%|████▋     | 932/2000 [08:14<08:07,  2.19iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  47%|████▋     | 932/2000 [08:14<08:07,  2.19iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  47%|████▋     | 933/2000 [08:14<07:40,  2.32iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  47%|████▋     | 933/2000 [08:14<07:40,  2.32iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  47%|████▋     | 934/2000 [08:15<07:00,  2.53iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  47%|████▋     | 934/2000 [08:15<07:00,  2.53iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  47%|████▋     | 935/2000 [08:15<06:48,  2.61iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  47%|████▋     | 935/2000 [08:15<06:48,  2.61iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  47%|████▋     | 936/2000 [08:15<06:19,  2.80iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  47%|████▋     | 936/2000 [08:15<06:19,  2.80iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  47%|████▋     | 937/2000 [08:16<06:29,  2.73iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  47%|████▋     | 937/2000 [08:16<06:29,  2.73iteration/s, mean_rewards=-168]\u001b[A\n",
            "Training:  47%|████▋     | 938/2000 [08:16<06:31,  2.71iteration/s, mean_rewards=-168]\u001b[A\n",
            "Training:  47%|████▋     | 938/2000 [08:16<06:31,  2.71iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  47%|████▋     | 939/2000 [08:16<06:14,  2.83iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  47%|████▋     | 939/2000 [08:16<06:14,  2.83iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  47%|████▋     | 940/2000 [08:17<06:14,  2.83iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  47%|████▋     | 940/2000 [08:17<06:14,  2.83iteration/s, mean_rewards=-112]\u001b[A\n",
            "Training:  47%|████▋     | 941/2000 [08:17<06:39,  2.65iteration/s, mean_rewards=-112]\u001b[A\n",
            "Training:  47%|████▋     | 941/2000 [08:17<06:39,  2.65iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  47%|████▋     | 942/2000 [08:17<06:45,  2.61iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  47%|████▋     | 942/2000 [08:18<06:45,  2.61iteration/s, mean_rewards=-63.6]\u001b[A\n",
            "Training:  47%|████▋     | 943/2000 [08:18<06:52,  2.56iteration/s, mean_rewards=-63.6]\u001b[A\n",
            "Training:  47%|████▋     | 943/2000 [08:18<06:52,  2.56iteration/s, mean_rewards=-153] \u001b[A\n",
            "Training:  47%|████▋     | 944/2000 [08:18<06:49,  2.58iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  47%|████▋     | 944/2000 [08:18<06:49,  2.58iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  47%|████▋     | 945/2000 [08:19<06:39,  2.64iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  47%|████▋     | 945/2000 [08:19<06:39,  2.64iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  47%|████▋     | 946/2000 [08:19<06:34,  2.67iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  47%|████▋     | 946/2000 [08:19<06:34,  2.67iteration/s, mean_rewards=-119]\u001b[A\n",
            "Training:  47%|████▋     | 947/2000 [08:19<06:40,  2.63iteration/s, mean_rewards=-119]\u001b[A\n",
            "Training:  47%|████▋     | 947/2000 [08:20<06:40,  2.63iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  47%|████▋     | 948/2000 [08:20<06:18,  2.78iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  47%|████▋     | 948/2000 [08:20<06:18,  2.78iteration/s, mean_rewards=-116]\u001b[A\n",
            "Training:  47%|████▋     | 949/2000 [08:20<05:52,  2.98iteration/s, mean_rewards=-116]\u001b[A\n",
            "Training:  47%|████▋     | 949/2000 [08:20<05:52,  2.98iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  48%|████▊     | 950/2000 [08:20<05:57,  2.94iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  48%|████▊     | 950/2000 [08:21<05:57,  2.94iteration/s, mean_rewards=-60.1]\u001b[A\n",
            "Training:  48%|████▊     | 951/2000 [08:21<06:25,  2.72iteration/s, mean_rewards=-60.1]\u001b[A\n",
            "Training:  48%|████▊     | 951/2000 [08:21<06:25,  2.72iteration/s, mean_rewards=-161] \u001b[A\n",
            "Training:  48%|████▊     | 952/2000 [08:21<06:27,  2.70iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:  48%|████▊     | 952/2000 [08:21<06:27,  2.70iteration/s, mean_rewards=-214]\u001b[A\n",
            "Training:  48%|████▊     | 953/2000 [08:21<06:36,  2.64iteration/s, mean_rewards=-214]\u001b[A\n",
            "Training:  48%|████▊     | 953/2000 [08:22<06:36,  2.64iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  48%|████▊     | 954/2000 [08:22<06:52,  2.54iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  48%|████▊     | 954/2000 [08:22<06:52,  2.54iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  48%|████▊     | 955/2000 [08:22<06:39,  2.61iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  48%|████▊     | 955/2000 [08:22<06:39,  2.61iteration/s, mean_rewards=-106]\u001b[A\n",
            "Training:  48%|████▊     | 956/2000 [08:23<06:29,  2.68iteration/s, mean_rewards=-106]\u001b[A\n",
            "Training:  48%|████▊     | 956/2000 [08:23<06:29,  2.68iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  48%|████▊     | 957/2000 [08:23<06:43,  2.59iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  48%|████▊     | 957/2000 [08:23<06:43,  2.59iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  48%|████▊     | 958/2000 [08:23<06:48,  2.55iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  48%|████▊     | 958/2000 [08:24<06:48,  2.55iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  48%|████▊     | 959/2000 [08:24<07:08,  2.43iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  48%|████▊     | 959/2000 [08:24<07:08,  2.43iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  48%|████▊     | 960/2000 [08:24<06:59,  2.48iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  48%|████▊     | 960/2000 [08:25<06:59,  2.48iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  48%|████▊     | 961/2000 [08:25<07:37,  2.27iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  48%|████▊     | 961/2000 [08:25<07:37,  2.27iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  48%|████▊     | 962/2000 [08:25<07:59,  2.16iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  48%|████▊     | 962/2000 [08:26<07:59,  2.16iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:  48%|████▊     | 963/2000 [08:26<08:01,  2.15iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:  48%|████▊     | 963/2000 [08:26<08:01,  2.15iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  48%|████▊     | 964/2000 [08:26<08:33,  2.02iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  48%|████▊     | 964/2000 [08:27<08:33,  2.02iteration/s, mean_rewards=-91.4]\u001b[A\n",
            "Training:  48%|████▊     | 965/2000 [08:27<07:31,  2.29iteration/s, mean_rewards=-91.4]\u001b[A\n",
            "Training:  48%|████▊     | 965/2000 [08:27<07:31,  2.29iteration/s, mean_rewards=-129] \u001b[A\n",
            "Training:  48%|████▊     | 966/2000 [08:27<07:08,  2.41iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  48%|████▊     | 966/2000 [08:27<07:08,  2.41iteration/s, mean_rewards=-81] \u001b[A\n",
            "Training:  48%|████▊     | 967/2000 [08:27<06:49,  2.52iteration/s, mean_rewards=-81]\u001b[A\n",
            "Training:  48%|████▊     | 967/2000 [08:28<06:49,  2.52iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  48%|████▊     | 968/2000 [08:28<07:01,  2.45iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  48%|████▊     | 968/2000 [08:28<07:01,  2.45iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  48%|████▊     | 969/2000 [08:28<06:54,  2.49iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  48%|████▊     | 969/2000 [08:28<06:54,  2.49iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  48%|████▊     | 970/2000 [08:29<06:56,  2.47iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  48%|████▊     | 970/2000 [08:29<06:56,  2.47iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:  49%|████▊     | 971/2000 [08:29<06:46,  2.53iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:  49%|████▊     | 971/2000 [08:29<06:46,  2.53iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  49%|████▊     | 972/2000 [08:29<06:35,  2.60iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  49%|████▊     | 972/2000 [08:30<06:35,  2.60iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  49%|████▊     | 973/2000 [08:30<06:08,  2.79iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  49%|████▊     | 973/2000 [08:30<06:08,  2.79iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  49%|████▊     | 974/2000 [08:30<05:49,  2.94iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  49%|████▊     | 974/2000 [08:30<05:49,  2.94iteration/s, mean_rewards=-228]\u001b[A\n",
            "Training:  49%|████▉     | 975/2000 [08:30<06:02,  2.83iteration/s, mean_rewards=-228]\u001b[A\n",
            "Training:  49%|████▉     | 975/2000 [08:31<06:02,  2.83iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  49%|████▉     | 976/2000 [08:31<05:59,  2.85iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  49%|████▉     | 976/2000 [08:31<05:59,  2.85iteration/s, mean_rewards=-116]\u001b[A\n",
            "Training:  49%|████▉     | 977/2000 [08:31<06:02,  2.82iteration/s, mean_rewards=-116]\u001b[A\n",
            "Training:  49%|████▉     | 977/2000 [08:31<06:02,  2.82iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  49%|████▉     | 978/2000 [08:31<06:09,  2.77iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  49%|████▉     | 978/2000 [08:32<06:09,  2.77iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  49%|████▉     | 979/2000 [08:32<06:10,  2.76iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  49%|████▉     | 979/2000 [08:32<06:10,  2.76iteration/s, mean_rewards=-66.4]\u001b[A\n",
            "Training:  49%|████▉     | 980/2000 [08:32<06:07,  2.78iteration/s, mean_rewards=-66.4]\u001b[A\n",
            "Training:  49%|████▉     | 980/2000 [08:32<06:07,  2.78iteration/s, mean_rewards=-113] \u001b[A\n",
            "Training:  49%|████▉     | 981/2000 [08:33<06:16,  2.71iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  49%|████▉     | 981/2000 [08:33<06:16,  2.71iteration/s, mean_rewards=-58.6]\u001b[A\n",
            "Training:  49%|████▉     | 982/2000 [08:33<06:21,  2.67iteration/s, mean_rewards=-58.6]\u001b[A\n",
            "Training:  49%|████▉     | 982/2000 [08:33<06:21,  2.67iteration/s, mean_rewards=-109] \u001b[A\n",
            "Training:  49%|████▉     | 983/2000 [08:33<06:18,  2.69iteration/s, mean_rewards=-109]\u001b[A\n",
            "Training:  49%|████▉     | 983/2000 [08:33<06:18,  2.69iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  49%|████▉     | 984/2000 [08:34<05:56,  2.85iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  49%|████▉     | 984/2000 [08:34<05:56,  2.85iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  49%|████▉     | 985/2000 [08:34<05:44,  2.94iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  49%|████▉     | 985/2000 [08:34<05:44,  2.94iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:  49%|████▉     | 986/2000 [08:34<05:40,  2.98iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:  49%|████▉     | 986/2000 [08:34<05:40,  2.98iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:  49%|████▉     | 987/2000 [08:35<06:00,  2.81iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:  49%|████▉     | 987/2000 [08:35<06:00,  2.81iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  49%|████▉     | 988/2000 [08:35<05:46,  2.92iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  49%|████▉     | 988/2000 [08:35<05:46,  2.92iteration/s, mean_rewards=-43.5]\u001b[A\n",
            "Training:  49%|████▉     | 989/2000 [08:35<05:53,  2.86iteration/s, mean_rewards=-43.5]\u001b[A\n",
            "Training:  49%|████▉     | 989/2000 [08:36<05:53,  2.86iteration/s, mean_rewards=-154] \u001b[A\n",
            "Training:  50%|████▉     | 990/2000 [08:36<06:01,  2.79iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  50%|████▉     | 990/2000 [08:36<06:01,  2.79iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  50%|████▉     | 991/2000 [08:36<06:07,  2.74iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  50%|████▉     | 991/2000 [08:36<06:07,  2.74iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:  50%|████▉     | 992/2000 [08:36<06:24,  2.62iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:  50%|████▉     | 992/2000 [08:37<06:24,  2.62iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  50%|████▉     | 993/2000 [08:37<06:52,  2.44iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  50%|████▉     | 993/2000 [08:37<06:52,  2.44iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  50%|████▉     | 994/2000 [08:37<07:14,  2.32iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  50%|████▉     | 994/2000 [08:38<07:14,  2.32iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  50%|████▉     | 995/2000 [08:38<07:06,  2.36iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  50%|████▉     | 995/2000 [08:38<07:06,  2.36iteration/s, mean_rewards=-168]\u001b[A\n",
            "Training:  50%|████▉     | 996/2000 [08:38<07:35,  2.20iteration/s, mean_rewards=-168]\u001b[A\n",
            "Training:  50%|████▉     | 996/2000 [08:39<07:35,  2.20iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  50%|████▉     | 997/2000 [08:39<08:03,  2.08iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  50%|████▉     | 997/2000 [08:39<08:03,  2.08iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  50%|████▉     | 998/2000 [08:39<07:25,  2.25iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  50%|████▉     | 998/2000 [08:39<07:25,  2.25iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  50%|████▉     | 999/2000 [08:40<07:02,  2.37iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  50%|████▉     | 999/2000 [08:40<07:02,  2.37iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  50%|█████     | 1000/2000 [08:40<06:48,  2.45iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  50%|█████     | 1000/2000 [08:40<06:48,  2.45iteration/s, mean_rewards=-535]\u001b[A\n",
            "Training:  50%|█████     | 1001/2000 [08:41<07:25,  2.24iteration/s, mean_rewards=-535]\u001b[A\n",
            "Training:  50%|█████     | 1001/2000 [08:41<07:25,  2.24iteration/s, mean_rewards=-557]\u001b[A\n",
            "Training:  50%|█████     | 1002/2000 [08:41<07:40,  2.17iteration/s, mean_rewards=-557]\u001b[A\n",
            "Training:  50%|█████     | 1002/2000 [08:42<07:40,  2.17iteration/s, mean_rewards=-996]\u001b[A\n",
            "Training:  50%|█████     | 1003/2000 [08:42<08:59,  1.85iteration/s, mean_rewards=-996]\u001b[A\n",
            "Training:  50%|█████     | 1003/2000 [08:42<08:59,  1.85iteration/s, mean_rewards=-756]\u001b[A\n",
            "Training:  50%|█████     | 1004/2000 [08:42<09:08,  1.82iteration/s, mean_rewards=-756]\u001b[A\n",
            "Training:  50%|█████     | 1004/2000 [08:43<09:08,  1.82iteration/s, mean_rewards=-652]\u001b[A\n",
            "Training:  50%|█████     | 1005/2000 [08:43<08:49,  1.88iteration/s, mean_rewards=-652]\u001b[A\n",
            "Training:  50%|█████     | 1005/2000 [08:43<08:49,  1.88iteration/s, mean_rewards=-593]\u001b[A\n",
            "Training:  50%|█████     | 1006/2000 [08:43<08:27,  1.96iteration/s, mean_rewards=-593]\u001b[A\n",
            "Training:  50%|█████     | 1006/2000 [08:44<08:27,  1.96iteration/s, mean_rewards=-679]\u001b[A\n",
            "Training:  50%|█████     | 1007/2000 [08:44<08:52,  1.86iteration/s, mean_rewards=-679]\u001b[A\n",
            "Training:  50%|█████     | 1007/2000 [08:44<08:52,  1.86iteration/s, mean_rewards=-945]\u001b[A\n",
            "Training:  50%|█████     | 1008/2000 [08:45<10:05,  1.64iteration/s, mean_rewards=-945]\u001b[A\n",
            "Training:  50%|█████     | 1008/2000 [08:45<10:05,  1.64iteration/s, mean_rewards=-519]\u001b[A\n",
            "Training:  50%|█████     | 1009/2000 [08:45<09:18,  1.78iteration/s, mean_rewards=-519]\u001b[A\n",
            "Training:  50%|█████     | 1009/2000 [08:46<09:18,  1.78iteration/s, mean_rewards=-677]\u001b[A\n",
            "Training:  50%|█████     | 1010/2000 [08:46<09:33,  1.73iteration/s, mean_rewards=-677]\u001b[A\n",
            "Training:  50%|█████     | 1010/2000 [08:46<09:33,  1.73iteration/s, mean_rewards=-892]\u001b[A\n",
            "Training:  51%|█████     | 1011/2000 [08:46<09:51,  1.67iteration/s, mean_rewards=-892]\u001b[A\n",
            "Training:  51%|█████     | 1011/2000 [08:47<09:51,  1.67iteration/s, mean_rewards=-1.02e+3]\u001b[A\n",
            "Training:  51%|█████     | 1012/2000 [08:47<10:21,  1.59iteration/s, mean_rewards=-1.02e+3]\u001b[A\n",
            "Training:  51%|█████     | 1012/2000 [08:48<10:21,  1.59iteration/s, mean_rewards=-585]    \u001b[A\n",
            "Training:  51%|█████     | 1013/2000 [08:48<10:24,  1.58iteration/s, mean_rewards=-585]\u001b[A\n",
            "Training:  51%|█████     | 1013/2000 [08:48<10:24,  1.58iteration/s, mean_rewards=-768]\u001b[A\n",
            "Training:  51%|█████     | 1014/2000 [08:48<10:31,  1.56iteration/s, mean_rewards=-768]\u001b[A\n",
            "Training:  51%|█████     | 1014/2000 [08:49<10:31,  1.56iteration/s, mean_rewards=-554]\u001b[A\n",
            "Training:  51%|█████     | 1015/2000 [08:49<09:31,  1.72iteration/s, mean_rewards=-554]\u001b[A\n",
            "Training:  51%|█████     | 1015/2000 [08:50<09:31,  1.72iteration/s, mean_rewards=-1.41e+3]\u001b[A\n",
            "Training:  51%|█████     | 1016/2000 [08:50<12:24,  1.32iteration/s, mean_rewards=-1.41e+3]\u001b[A\n",
            "Training:  51%|█████     | 1016/2000 [08:51<12:24,  1.32iteration/s, mean_rewards=-943]    \u001b[A\n",
            "Training:  51%|█████     | 1017/2000 [08:51<13:21,  1.23iteration/s, mean_rewards=-943]\u001b[A\n",
            "Training:  51%|█████     | 1017/2000 [08:51<13:21,  1.23iteration/s, mean_rewards=-617]\u001b[A\n",
            "Training:  51%|█████     | 1018/2000 [08:52<12:22,  1.32iteration/s, mean_rewards=-617]\u001b[A\n",
            "Training:  51%|█████     | 1018/2000 [08:52<12:22,  1.32iteration/s, mean_rewards=-614]\u001b[A\n",
            "Training:  51%|█████     | 1019/2000 [08:52<11:36,  1.41iteration/s, mean_rewards=-614]\u001b[A\n",
            "Training:  51%|█████     | 1019/2000 [08:53<11:36,  1.41iteration/s, mean_rewards=-613]\u001b[A\n",
            "Training:  51%|█████     | 1020/2000 [08:53<11:09,  1.46iteration/s, mean_rewards=-613]\u001b[A\n",
            "Training:  51%|█████     | 1020/2000 [08:53<11:09,  1.46iteration/s, mean_rewards=-1.01e+3]\u001b[A\n",
            "Training:  51%|█████     | 1021/2000 [08:54<11:45,  1.39iteration/s, mean_rewards=-1.01e+3]\u001b[A\n",
            "Training:  51%|█████     | 1021/2000 [08:54<11:45,  1.39iteration/s, mean_rewards=-929]    \u001b[A\n",
            "Training:  51%|█████     | 1022/2000 [08:54<11:44,  1.39iteration/s, mean_rewards=-929]\u001b[A\n",
            "Training:  51%|█████     | 1022/2000 [08:55<11:44,  1.39iteration/s, mean_rewards=-593]\u001b[A\n",
            "Training:  51%|█████     | 1023/2000 [08:55<11:11,  1.46iteration/s, mean_rewards=-593]\u001b[A\n",
            "Training:  51%|█████     | 1023/2000 [08:56<11:11,  1.46iteration/s, mean_rewards=-1.3e+3]\u001b[A\n",
            "Training:  51%|█████     | 1024/2000 [08:56<12:01,  1.35iteration/s, mean_rewards=-1.3e+3]\u001b[A\n",
            "Training:  51%|█████     | 1024/2000 [08:56<12:01,  1.35iteration/s, mean_rewards=-563]   \u001b[A\n",
            "Training:  51%|█████▏    | 1025/2000 [08:56<10:23,  1.56iteration/s, mean_rewards=-563]\u001b[A\n",
            "Training:  51%|█████▏    | 1025/2000 [08:57<10:23,  1.56iteration/s, mean_rewards=-783]\u001b[A\n",
            "Training:  51%|█████▏    | 1026/2000 [08:57<10:33,  1.54iteration/s, mean_rewards=-783]\u001b[A\n",
            "Training:  51%|█████▏    | 1026/2000 [08:57<10:33,  1.54iteration/s, mean_rewards=-1.3e+3]\u001b[A\n",
            "Training:  51%|█████▏    | 1027/2000 [08:58<11:46,  1.38iteration/s, mean_rewards=-1.3e+3]\u001b[A\n",
            "Training:  51%|█████▏    | 1027/2000 [08:58<11:46,  1.38iteration/s, mean_rewards=-717]   \u001b[A\n",
            "Training:  51%|█████▏    | 1028/2000 [08:58<10:56,  1.48iteration/s, mean_rewards=-717]\u001b[A\n",
            "Training:  51%|█████▏    | 1028/2000 [08:59<10:56,  1.48iteration/s, mean_rewards=-690]\u001b[A\n",
            "Training:  51%|█████▏    | 1029/2000 [08:59<10:58,  1.47iteration/s, mean_rewards=-690]\u001b[A\n",
            "Training:  51%|█████▏    | 1029/2000 [08:59<10:58,  1.47iteration/s, mean_rewards=-474]\u001b[A\n",
            "Training:  52%|█████▏    | 1030/2000 [08:59<09:56,  1.63iteration/s, mean_rewards=-474]\u001b[A\n",
            "Training:  52%|█████▏    | 1030/2000 [09:00<09:56,  1.63iteration/s, mean_rewards=-796]\u001b[A\n",
            "Training:  52%|█████▏    | 1031/2000 [09:00<09:53,  1.63iteration/s, mean_rewards=-796]\u001b[A\n",
            "Training:  52%|█████▏    | 1031/2000 [09:01<09:53,  1.63iteration/s, mean_rewards=-958]\u001b[A\n",
            "Training:  52%|█████▏    | 1032/2000 [09:01<10:47,  1.49iteration/s, mean_rewards=-958]\u001b[A\n",
            "Training:  52%|█████▏    | 1032/2000 [09:01<10:47,  1.49iteration/s, mean_rewards=-1.03e+3]\u001b[A\n",
            "Training:  52%|█████▏    | 1033/2000 [09:02<11:22,  1.42iteration/s, mean_rewards=-1.03e+3]\u001b[A\n",
            "Training:  52%|█████▏    | 1033/2000 [09:02<11:22,  1.42iteration/s, mean_rewards=-515]    \u001b[A\n",
            "Training:  52%|█████▏    | 1034/2000 [09:02<10:51,  1.48iteration/s, mean_rewards=-515]\u001b[A\n",
            "Training:  52%|█████▏    | 1034/2000 [09:03<10:51,  1.48iteration/s, mean_rewards=-594]\u001b[A\n",
            "Training:  52%|█████▏    | 1035/2000 [09:03<10:56,  1.47iteration/s, mean_rewards=-594]\u001b[A\n",
            "Training:  52%|█████▏    | 1035/2000 [09:04<10:56,  1.47iteration/s, mean_rewards=-664]\u001b[A\n",
            "Training:  52%|█████▏    | 1036/2000 [09:04<11:44,  1.37iteration/s, mean_rewards=-664]\u001b[A\n",
            "Training:  52%|█████▏    | 1036/2000 [09:04<11:44,  1.37iteration/s, mean_rewards=-627]\u001b[A\n",
            "Training:  52%|█████▏    | 1037/2000 [09:05<11:40,  1.38iteration/s, mean_rewards=-627]\u001b[A\n",
            "Training:  52%|█████▏    | 1037/2000 [09:05<11:40,  1.38iteration/s, mean_rewards=-618]\u001b[A\n",
            "Training:  52%|█████▏    | 1038/2000 [09:05<10:33,  1.52iteration/s, mean_rewards=-618]\u001b[A\n",
            "Training:  52%|█████▏    | 1038/2000 [09:06<10:33,  1.52iteration/s, mean_rewards=-928]\u001b[A\n",
            "Training:  52%|█████▏    | 1039/2000 [09:06<10:46,  1.49iteration/s, mean_rewards=-928]\u001b[A\n",
            "Training:  52%|█████▏    | 1039/2000 [09:06<10:46,  1.49iteration/s, mean_rewards=-508]\u001b[A\n",
            "Training:  52%|█████▏    | 1040/2000 [09:06<09:45,  1.64iteration/s, mean_rewards=-508]\u001b[A\n",
            "Training:  52%|█████▏    | 1040/2000 [09:07<09:45,  1.64iteration/s, mean_rewards=-537]\u001b[A\n",
            "Training:  52%|█████▏    | 1041/2000 [09:07<09:26,  1.69iteration/s, mean_rewards=-537]\u001b[A\n",
            "Training:  52%|█████▏    | 1041/2000 [09:07<09:26,  1.69iteration/s, mean_rewards=-662]\u001b[A\n",
            "Training:  52%|█████▏    | 1042/2000 [09:07<08:48,  1.81iteration/s, mean_rewards=-662]\u001b[A\n",
            "Training:  52%|█████▏    | 1042/2000 [09:07<08:48,  1.81iteration/s, mean_rewards=-569]\u001b[A\n",
            "Training:  52%|█████▏    | 1043/2000 [09:08<08:17,  1.93iteration/s, mean_rewards=-569]\u001b[A\n",
            "Training:  52%|█████▏    | 1043/2000 [09:08<08:17,  1.93iteration/s, mean_rewards=-534]\u001b[A\n",
            "Training:  52%|█████▏    | 1044/2000 [09:08<08:10,  1.95iteration/s, mean_rewards=-534]\u001b[A\n",
            "Training:  52%|█████▏    | 1044/2000 [09:08<08:10,  1.95iteration/s, mean_rewards=-595]\u001b[A\n",
            "Training:  52%|█████▏    | 1045/2000 [09:09<07:58,  2.00iteration/s, mean_rewards=-595]\u001b[A\n",
            "Training:  52%|█████▏    | 1045/2000 [09:09<07:58,  2.00iteration/s, mean_rewards=-530]\u001b[A\n",
            "Training:  52%|█████▏    | 1046/2000 [09:09<07:33,  2.10iteration/s, mean_rewards=-530]\u001b[A\n",
            "Training:  52%|█████▏    | 1046/2000 [09:09<07:33,  2.10iteration/s, mean_rewards=-735]\u001b[A\n",
            "Training:  52%|█████▏    | 1047/2000 [09:10<08:05,  1.96iteration/s, mean_rewards=-735]\u001b[A\n",
            "Training:  52%|█████▏    | 1047/2000 [09:10<08:05,  1.96iteration/s, mean_rewards=-602]\u001b[A\n",
            "Training:  52%|█████▏    | 1048/2000 [09:10<08:13,  1.93iteration/s, mean_rewards=-602]\u001b[A\n",
            "Training:  52%|█████▏    | 1048/2000 [09:11<08:13,  1.93iteration/s, mean_rewards=-671]\u001b[A\n",
            "Training:  52%|█████▏    | 1049/2000 [09:11<08:19,  1.91iteration/s, mean_rewards=-671]\u001b[A\n",
            "Training:  52%|█████▏    | 1049/2000 [09:11<08:19,  1.91iteration/s, mean_rewards=-666]\u001b[A\n",
            "Training:  52%|█████▎    | 1050/2000 [09:11<08:47,  1.80iteration/s, mean_rewards=-666]\u001b[A\n",
            "Training:  52%|█████▎    | 1050/2000 [09:12<08:47,  1.80iteration/s, mean_rewards=-2.21e+3]\u001b[A\n",
            "Training:  53%|█████▎    | 1051/2000 [09:13<12:15,  1.29iteration/s, mean_rewards=-2.21e+3]\u001b[A\n",
            "Training:  53%|█████▎    | 1051/2000 [09:13<12:15,  1.29iteration/s, mean_rewards=-947]    \u001b[A\n",
            "Training:  53%|█████▎    | 1052/2000 [09:13<12:18,  1.28iteration/s, mean_rewards=-947]\u001b[A\n",
            "Training:  53%|█████▎    | 1052/2000 [09:14<12:18,  1.28iteration/s, mean_rewards=-850]\u001b[A\n",
            "Training:  53%|█████▎    | 1053/2000 [09:14<11:50,  1.33iteration/s, mean_rewards=-850]\u001b[A\n",
            "Training:  53%|█████▎    | 1053/2000 [09:14<11:50,  1.33iteration/s, mean_rewards=-687]\u001b[A\n",
            "Training:  53%|█████▎    | 1054/2000 [09:15<11:08,  1.41iteration/s, mean_rewards=-687]\u001b[A\n",
            "Training:  53%|█████▎    | 1054/2000 [09:15<11:08,  1.41iteration/s, mean_rewards=-589]\u001b[A\n",
            "Training:  53%|█████▎    | 1055/2000 [09:15<10:40,  1.48iteration/s, mean_rewards=-589]\u001b[A\n",
            "Training:  53%|█████▎    | 1055/2000 [09:16<10:40,  1.48iteration/s, mean_rewards=-489]\u001b[A\n",
            "Training:  53%|█████▎    | 1056/2000 [09:16<10:28,  1.50iteration/s, mean_rewards=-489]\u001b[A\n",
            "Training:  53%|█████▎    | 1056/2000 [09:16<10:28,  1.50iteration/s, mean_rewards=-644]\u001b[A\n",
            "Training:  53%|█████▎    | 1057/2000 [09:17<10:36,  1.48iteration/s, mean_rewards=-644]\u001b[A\n",
            "Training:  53%|█████▎    | 1057/2000 [09:17<10:36,  1.48iteration/s, mean_rewards=-1.1e+3]\u001b[A\n",
            "Training:  53%|█████▎    | 1058/2000 [09:18<12:08,  1.29iteration/s, mean_rewards=-1.1e+3]\u001b[A\n",
            "Training:  53%|█████▎    | 1058/2000 [09:18<12:08,  1.29iteration/s, mean_rewards=-674]   \u001b[A\n",
            "Training:  53%|█████▎    | 1059/2000 [09:18<11:27,  1.37iteration/s, mean_rewards=-674]\u001b[A\n",
            "Training:  53%|█████▎    | 1059/2000 [09:19<11:27,  1.37iteration/s, mean_rewards=-511]\u001b[A\n",
            "Training:  53%|█████▎    | 1060/2000 [09:19<10:12,  1.53iteration/s, mean_rewards=-511]\u001b[A\n",
            "Training:  53%|█████▎    | 1060/2000 [09:19<10:12,  1.53iteration/s, mean_rewards=-780]\u001b[A\n",
            "Training:  53%|█████▎    | 1061/2000 [09:19<09:45,  1.60iteration/s, mean_rewards=-780]\u001b[A\n",
            "Training:  53%|█████▎    | 1061/2000 [09:20<09:45,  1.60iteration/s, mean_rewards=-705]\u001b[A\n",
            "Training:  53%|█████▎    | 1062/2000 [09:20<09:09,  1.71iteration/s, mean_rewards=-705]\u001b[A\n",
            "Training:  53%|█████▎    | 1062/2000 [09:20<09:09,  1.71iteration/s, mean_rewards=-634]\u001b[A\n",
            "Training:  53%|█████▎    | 1063/2000 [09:20<09:22,  1.67iteration/s, mean_rewards=-634]\u001b[A\n",
            "Training:  53%|█████▎    | 1063/2000 [09:21<09:22,  1.67iteration/s, mean_rewards=-641]\u001b[A\n",
            "Training:  53%|█████▎    | 1064/2000 [09:21<08:45,  1.78iteration/s, mean_rewards=-641]\u001b[A\n",
            "Training:  53%|█████▎    | 1064/2000 [09:21<08:45,  1.78iteration/s, mean_rewards=-598]\u001b[A\n",
            "Training:  53%|█████▎    | 1065/2000 [09:21<08:39,  1.80iteration/s, mean_rewards=-598]\u001b[A\n",
            "Training:  53%|█████▎    | 1065/2000 [09:22<08:39,  1.80iteration/s, mean_rewards=-554]\u001b[A\n",
            "Training:  53%|█████▎    | 1066/2000 [09:22<08:19,  1.87iteration/s, mean_rewards=-554]\u001b[A\n",
            "Training:  53%|█████▎    | 1066/2000 [09:22<08:19,  1.87iteration/s, mean_rewards=-822]\u001b[A\n",
            "Training:  53%|█████▎    | 1067/2000 [09:23<08:56,  1.74iteration/s, mean_rewards=-822]\u001b[A\n",
            "Training:  53%|█████▎    | 1067/2000 [09:23<08:56,  1.74iteration/s, mean_rewards=-673]\u001b[A\n",
            "Training:  53%|█████▎    | 1068/2000 [09:23<09:05,  1.71iteration/s, mean_rewards=-673]\u001b[A\n",
            "Training:  53%|█████▎    | 1068/2000 [09:24<09:05,  1.71iteration/s, mean_rewards=-800]\u001b[A\n",
            "Training:  53%|█████▎    | 1069/2000 [09:24<09:18,  1.67iteration/s, mean_rewards=-800]\u001b[A\n",
            "Training:  53%|█████▎    | 1069/2000 [09:24<09:18,  1.67iteration/s, mean_rewards=-960]\u001b[A\n",
            "Training:  54%|█████▎    | 1070/2000 [09:24<09:32,  1.62iteration/s, mean_rewards=-960]\u001b[A\n",
            "Training:  54%|█████▎    | 1070/2000 [09:25<09:32,  1.62iteration/s, mean_rewards=-1.04e+3]\u001b[A\n",
            "Training:  54%|█████▎    | 1071/2000 [09:25<10:23,  1.49iteration/s, mean_rewards=-1.04e+3]\u001b[A\n",
            "Training:  54%|█████▎    | 1071/2000 [09:26<10:23,  1.49iteration/s, mean_rewards=-1.21e+3]\u001b[A\n",
            "Training:  54%|█████▎    | 1072/2000 [09:26<10:57,  1.41iteration/s, mean_rewards=-1.21e+3]\u001b[A\n",
            "Training:  54%|█████▎    | 1072/2000 [09:27<10:57,  1.41iteration/s, mean_rewards=-531]    \u001b[A\n",
            "Training:  54%|█████▎    | 1073/2000 [09:27<10:23,  1.49iteration/s, mean_rewards=-531]\u001b[A\n",
            "Training:  54%|█████▎    | 1073/2000 [09:27<10:23,  1.49iteration/s, mean_rewards=-1.04e+3]\u001b[A\n",
            "Training:  54%|█████▎    | 1074/2000 [09:27<10:57,  1.41iteration/s, mean_rewards=-1.04e+3]\u001b[A\n",
            "Training:  54%|█████▎    | 1074/2000 [09:29<10:57,  1.41iteration/s, mean_rewards=-1.87e+3]\u001b[A\n",
            "Training:  54%|█████▍    | 1075/2000 [09:29<15:25,  1.00s/iteration, mean_rewards=-1.87e+3]\u001b[A\n",
            "Training:  54%|█████▍    | 1075/2000 [09:30<15:25,  1.00s/iteration, mean_rewards=-483]    \u001b[A\n",
            "Training:  54%|█████▍    | 1076/2000 [09:30<13:58,  1.10iteration/s, mean_rewards=-483]\u001b[A\n",
            "Training:  54%|█████▍    | 1076/2000 [09:30<13:58,  1.10iteration/s, mean_rewards=-812]\u001b[A\n",
            "Training:  54%|█████▍    | 1077/2000 [09:31<13:29,  1.14iteration/s, mean_rewards=-812]\u001b[A\n",
            "Training:  54%|█████▍    | 1077/2000 [09:31<13:29,  1.14iteration/s, mean_rewards=-540]\u001b[A\n",
            "Training:  54%|█████▍    | 1078/2000 [09:31<11:25,  1.34iteration/s, mean_rewards=-540]\u001b[A\n",
            "Training:  54%|█████▍    | 1078/2000 [09:32<11:25,  1.34iteration/s, mean_rewards=-1.04e+3]\u001b[A\n",
            "Training:  54%|█████▍    | 1079/2000 [09:32<12:47,  1.20iteration/s, mean_rewards=-1.04e+3]\u001b[A\n",
            "Training:  54%|█████▍    | 1079/2000 [09:33<12:47,  1.20iteration/s, mean_rewards=-763]    \u001b[A\n",
            "Training:  54%|█████▍    | 1080/2000 [09:33<12:05,  1.27iteration/s, mean_rewards=-763]\u001b[A\n",
            "Training:  54%|█████▍    | 1080/2000 [09:33<12:05,  1.27iteration/s, mean_rewards=-869]\u001b[A\n",
            "Training:  54%|█████▍    | 1081/2000 [09:33<11:35,  1.32iteration/s, mean_rewards=-869]\u001b[A\n",
            "Training:  54%|█████▍    | 1081/2000 [09:34<11:35,  1.32iteration/s, mean_rewards=-999]\u001b[A\n",
            "Training:  54%|█████▍    | 1082/2000 [09:34<11:28,  1.33iteration/s, mean_rewards=-999]\u001b[A\n",
            "Training:  54%|█████▍    | 1082/2000 [09:35<11:28,  1.33iteration/s, mean_rewards=-649]\u001b[A\n",
            "Training:  54%|█████▍    | 1083/2000 [09:35<10:41,  1.43iteration/s, mean_rewards=-649]\u001b[A\n",
            "Training:  54%|█████▍    | 1083/2000 [09:35<10:41,  1.43iteration/s, mean_rewards=-639]\u001b[A\n",
            "Training:  54%|█████▍    | 1084/2000 [09:35<09:21,  1.63iteration/s, mean_rewards=-639]\u001b[A\n",
            "Training:  54%|█████▍    | 1084/2000 [09:36<09:21,  1.63iteration/s, mean_rewards=-1.56e+3]\u001b[A\n",
            "Training:  54%|█████▍    | 1085/2000 [09:36<10:46,  1.42iteration/s, mean_rewards=-1.56e+3]\u001b[A\n",
            "Training:  54%|█████▍    | 1085/2000 [09:37<10:46,  1.42iteration/s, mean_rewards=-842]    \u001b[A\n",
            "Training:  54%|█████▍    | 1086/2000 [09:37<10:24,  1.46iteration/s, mean_rewards=-842]\u001b[A\n",
            "Training:  54%|█████▍    | 1086/2000 [09:37<10:24,  1.46iteration/s, mean_rewards=-835]\u001b[A\n",
            "Training:  54%|█████▍    | 1087/2000 [09:37<10:21,  1.47iteration/s, mean_rewards=-835]\u001b[A\n",
            "Training:  54%|█████▍    | 1087/2000 [09:38<10:21,  1.47iteration/s, mean_rewards=-908]\u001b[A\n",
            "Training:  54%|█████▍    | 1088/2000 [09:38<10:44,  1.41iteration/s, mean_rewards=-908]\u001b[A\n",
            "Training:  54%|█████▍    | 1088/2000 [09:39<10:44,  1.41iteration/s, mean_rewards=-681]\u001b[A\n",
            "Training:  54%|█████▍    | 1089/2000 [09:39<10:09,  1.49iteration/s, mean_rewards=-681]\u001b[A\n",
            "Training:  54%|█████▍    | 1089/2000 [09:39<10:09,  1.49iteration/s, mean_rewards=-1.19e+3]\u001b[A\n",
            "Training:  55%|█████▍    | 1090/2000 [09:40<10:43,  1.41iteration/s, mean_rewards=-1.19e+3]\u001b[A\n",
            "Training:  55%|█████▍    | 1090/2000 [09:40<10:43,  1.41iteration/s, mean_rewards=-970]    \u001b[A\n",
            "Training:  55%|█████▍    | 1091/2000 [09:40<11:03,  1.37iteration/s, mean_rewards=-970]\u001b[A\n",
            "Training:  55%|█████▍    | 1091/2000 [09:41<11:03,  1.37iteration/s, mean_rewards=-561]\u001b[A\n",
            "Training:  55%|█████▍    | 1092/2000 [09:41<11:18,  1.34iteration/s, mean_rewards=-561]\u001b[A\n",
            "Training:  55%|█████▍    | 1092/2000 [09:42<11:18,  1.34iteration/s, mean_rewards=-998]\u001b[A\n",
            "Training:  55%|█████▍    | 1093/2000 [09:42<12:22,  1.22iteration/s, mean_rewards=-998]\u001b[A\n",
            "Training:  55%|█████▍    | 1093/2000 [09:43<12:22,  1.22iteration/s, mean_rewards=-660]\u001b[A\n",
            "Training:  55%|█████▍    | 1094/2000 [09:43<12:12,  1.24iteration/s, mean_rewards=-660]\u001b[A\n",
            "Training:  55%|█████▍    | 1094/2000 [09:44<12:12,  1.24iteration/s, mean_rewards=-907]\u001b[A\n",
            "Training:  55%|█████▍    | 1095/2000 [09:44<12:08,  1.24iteration/s, mean_rewards=-907]\u001b[A\n",
            "Training:  55%|█████▍    | 1095/2000 [09:44<12:08,  1.24iteration/s, mean_rewards=-823]\u001b[A\n",
            "Training:  55%|█████▍    | 1096/2000 [09:44<11:06,  1.36iteration/s, mean_rewards=-823]\u001b[A\n",
            "Training:  55%|█████▍    | 1096/2000 [09:45<11:06,  1.36iteration/s, mean_rewards=-769]\u001b[A\n",
            "Training:  55%|█████▍    | 1097/2000 [09:45<10:23,  1.45iteration/s, mean_rewards=-769]\u001b[A\n",
            "Training:  55%|█████▍    | 1097/2000 [09:45<10:23,  1.45iteration/s, mean_rewards=-594]\u001b[A\n",
            "Training:  55%|█████▍    | 1098/2000 [09:45<09:34,  1.57iteration/s, mean_rewards=-594]\u001b[A\n",
            "Training:  55%|█████▍    | 1098/2000 [09:46<09:34,  1.57iteration/s, mean_rewards=-608]\u001b[A\n",
            "Training:  55%|█████▍    | 1099/2000 [09:46<09:05,  1.65iteration/s, mean_rewards=-608]\u001b[A\n",
            "Training:  55%|█████▍    | 1099/2000 [09:47<09:05,  1.65iteration/s, mean_rewards=-1.62e+3]\u001b[A\n",
            "Training:  55%|█████▌    | 1100/2000 [09:47<11:22,  1.32iteration/s, mean_rewards=-1.62e+3]\u001b[A\n",
            "Training:  55%|█████▌    | 1100/2000 [09:48<11:22,  1.32iteration/s, mean_rewards=-839]    \u001b[A\n",
            "Training:  55%|█████▌    | 1101/2000 [09:48<10:54,  1.37iteration/s, mean_rewards=-839]\u001b[A\n",
            "Training:  55%|█████▌    | 1101/2000 [09:48<10:54,  1.37iteration/s, mean_rewards=-854]\u001b[A\n",
            "Training:  55%|█████▌    | 1102/2000 [09:48<10:49,  1.38iteration/s, mean_rewards=-854]\u001b[A\n",
            "Training:  55%|█████▌    | 1102/2000 [09:49<10:49,  1.38iteration/s, mean_rewards=-681]\u001b[A\n",
            "Training:  55%|█████▌    | 1103/2000 [09:49<09:41,  1.54iteration/s, mean_rewards=-681]\u001b[A\n",
            "Training:  55%|█████▌    | 1103/2000 [09:49<09:41,  1.54iteration/s, mean_rewards=-517]\u001b[A\n",
            "Training:  55%|█████▌    | 1104/2000 [09:49<08:36,  1.74iteration/s, mean_rewards=-517]\u001b[A\n",
            "Training:  55%|█████▌    | 1104/2000 [09:50<08:36,  1.74iteration/s, mean_rewards=-540]\u001b[A\n",
            "Training:  55%|█████▌    | 1105/2000 [09:50<08:30,  1.75iteration/s, mean_rewards=-540]\u001b[A\n",
            "Training:  55%|█████▌    | 1105/2000 [09:51<08:30,  1.75iteration/s, mean_rewards=-2.08e+3]\u001b[A\n",
            "Training:  55%|█████▌    | 1106/2000 [09:51<11:34,  1.29iteration/s, mean_rewards=-2.08e+3]\u001b[A\n",
            "Training:  55%|█████▌    | 1106/2000 [09:51<11:34,  1.29iteration/s, mean_rewards=-621]    \u001b[A\n",
            "Training:  55%|█████▌    | 1107/2000 [09:52<10:09,  1.47iteration/s, mean_rewards=-621]\u001b[A\n",
            "Training:  55%|█████▌    | 1107/2000 [09:52<10:09,  1.47iteration/s, mean_rewards=-484]\u001b[A\n",
            "Training:  55%|█████▌    | 1108/2000 [09:52<08:59,  1.65iteration/s, mean_rewards=-484]\u001b[A\n",
            "Training:  55%|█████▌    | 1108/2000 [09:52<08:59,  1.65iteration/s, mean_rewards=-801]\u001b[A\n",
            "Training:  55%|█████▌    | 1109/2000 [09:53<08:55,  1.66iteration/s, mean_rewards=-801]\u001b[A\n",
            "Training:  55%|█████▌    | 1109/2000 [09:53<08:55,  1.66iteration/s, mean_rewards=-1.21e+3]\u001b[A\n",
            "Training:  56%|█████▌    | 1110/2000 [09:54<11:03,  1.34iteration/s, mean_rewards=-1.21e+3]\u001b[A\n",
            "Training:  56%|█████▌    | 1110/2000 [09:54<11:03,  1.34iteration/s, mean_rewards=-732]    \u001b[A\n",
            "Training:  56%|█████▌    | 1111/2000 [09:54<10:51,  1.36iteration/s, mean_rewards=-732]\u001b[A\n",
            "Training:  56%|█████▌    | 1111/2000 [09:55<10:51,  1.36iteration/s, mean_rewards=-806]\u001b[A\n",
            "Training:  56%|█████▌    | 1112/2000 [09:55<11:58,  1.24iteration/s, mean_rewards=-806]\u001b[A\n",
            "Training:  56%|█████▌    | 1112/2000 [09:56<11:58,  1.24iteration/s, mean_rewards=-787]\u001b[A\n",
            "Training:  56%|█████▌    | 1113/2000 [09:56<12:55,  1.14iteration/s, mean_rewards=-787]\u001b[A\n",
            "Training:  56%|█████▌    | 1113/2000 [09:57<12:55,  1.14iteration/s, mean_rewards=-723]\u001b[A\n",
            "Training:  56%|█████▌    | 1114/2000 [09:57<11:46,  1.25iteration/s, mean_rewards=-723]\u001b[A\n",
            "Training:  56%|█████▌    | 1114/2000 [09:58<11:46,  1.25iteration/s, mean_rewards=-990]\u001b[A\n",
            "Training:  56%|█████▌    | 1115/2000 [09:58<11:55,  1.24iteration/s, mean_rewards=-990]\u001b[A\n",
            "Training:  56%|█████▌    | 1115/2000 [09:58<11:55,  1.24iteration/s, mean_rewards=-631]\u001b[A\n",
            "Training:  56%|█████▌    | 1116/2000 [09:58<10:18,  1.43iteration/s, mean_rewards=-631]\u001b[A\n",
            "Training:  56%|█████▌    | 1116/2000 [09:59<10:18,  1.43iteration/s, mean_rewards=-971]\u001b[A\n",
            "Training:  56%|█████▌    | 1117/2000 [09:59<10:43,  1.37iteration/s, mean_rewards=-971]\u001b[A\n",
            "Training:  56%|█████▌    | 1117/2000 [09:59<10:43,  1.37iteration/s, mean_rewards=-636]\u001b[A\n",
            "Training:  56%|█████▌    | 1118/2000 [10:00<09:56,  1.48iteration/s, mean_rewards=-636]\u001b[A\n",
            "Training:  56%|█████▌    | 1118/2000 [10:00<09:56,  1.48iteration/s, mean_rewards=-443]\u001b[A\n",
            "Training:  56%|█████▌    | 1119/2000 [10:00<09:04,  1.62iteration/s, mean_rewards=-443]\u001b[A\n",
            "Training:  56%|█████▌    | 1119/2000 [10:01<09:04,  1.62iteration/s, mean_rewards=-786]\u001b[A\n",
            "Training:  56%|█████▌    | 1120/2000 [10:01<09:28,  1.55iteration/s, mean_rewards=-786]\u001b[A\n",
            "Training:  56%|█████▌    | 1120/2000 [10:01<09:28,  1.55iteration/s, mean_rewards=-625]\u001b[A\n",
            "Training:  56%|█████▌    | 1121/2000 [10:01<08:45,  1.67iteration/s, mean_rewards=-625]\u001b[A\n",
            "Training:  56%|█████▌    | 1121/2000 [10:02<08:45,  1.67iteration/s, mean_rewards=-1.63e+3]\u001b[A\n",
            "Training:  56%|█████▌    | 1122/2000 [10:02<11:02,  1.32iteration/s, mean_rewards=-1.63e+3]\u001b[A\n",
            "Training:  56%|█████▌    | 1122/2000 [10:03<11:02,  1.32iteration/s, mean_rewards=-1.51e+3]\u001b[A\n",
            "Training:  56%|█████▌    | 1123/2000 [10:04<12:56,  1.13iteration/s, mean_rewards=-1.51e+3]\u001b[A\n",
            "Training:  56%|█████▌    | 1123/2000 [10:04<12:56,  1.13iteration/s, mean_rewards=-1.09e+3]\u001b[A\n",
            "Training:  56%|█████▌    | 1124/2000 [10:04<12:43,  1.15iteration/s, mean_rewards=-1.09e+3]\u001b[A\n",
            "Training:  56%|█████▌    | 1124/2000 [10:05<12:43,  1.15iteration/s, mean_rewards=-580]    \u001b[A\n",
            "Training:  56%|█████▋    | 1125/2000 [10:05<10:54,  1.34iteration/s, mean_rewards=-580]\u001b[A\n",
            "Training:  56%|█████▋    | 1125/2000 [10:05<10:54,  1.34iteration/s, mean_rewards=-1.11e+3]\u001b[A\n",
            "Training:  56%|█████▋    | 1126/2000 [10:06<10:55,  1.33iteration/s, mean_rewards=-1.11e+3]\u001b[A\n",
            "Training:  56%|█████▋    | 1126/2000 [10:06<10:55,  1.33iteration/s, mean_rewards=-853]    \u001b[A\n",
            "Training:  56%|█████▋    | 1127/2000 [10:06<10:39,  1.36iteration/s, mean_rewards=-853]\u001b[A\n",
            "Training:  56%|█████▋    | 1127/2000 [10:07<10:39,  1.36iteration/s, mean_rewards=-648]\u001b[A\n",
            "Training:  56%|█████▋    | 1128/2000 [10:07<11:00,  1.32iteration/s, mean_rewards=-648]\u001b[A\n",
            "Training:  56%|█████▋    | 1128/2000 [10:08<11:00,  1.32iteration/s, mean_rewards=-601]\u001b[A\n",
            "Training:  56%|█████▋    | 1129/2000 [10:08<10:44,  1.35iteration/s, mean_rewards=-601]\u001b[A\n",
            "Training:  56%|█████▋    | 1129/2000 [10:09<10:44,  1.35iteration/s, mean_rewards=-1.51e+3]\u001b[A\n",
            "Training:  56%|█████▋    | 1130/2000 [10:09<13:17,  1.09iteration/s, mean_rewards=-1.51e+3]\u001b[A\n",
            "Training:  56%|█████▋    | 1130/2000 [10:10<13:17,  1.09iteration/s, mean_rewards=-592]    \u001b[A\n",
            "Training:  57%|█████▋    | 1131/2000 [10:10<11:40,  1.24iteration/s, mean_rewards=-592]\u001b[A\n",
            "Training:  57%|█████▋    | 1131/2000 [10:10<11:40,  1.24iteration/s, mean_rewards=-699]\u001b[A\n",
            "Training:  57%|█████▋    | 1132/2000 [10:10<10:19,  1.40iteration/s, mean_rewards=-699]\u001b[A\n",
            "Training:  57%|█████▋    | 1132/2000 [10:11<10:19,  1.40iteration/s, mean_rewards=-999]\u001b[A\n",
            "Training:  57%|█████▋    | 1133/2000 [10:11<10:38,  1.36iteration/s, mean_rewards=-999]\u001b[A\n",
            "Training:  57%|█████▋    | 1133/2000 [10:11<10:38,  1.36iteration/s, mean_rewards=-588]\u001b[A\n",
            "Training:  57%|█████▋    | 1134/2000 [10:12<09:42,  1.49iteration/s, mean_rewards=-588]\u001b[A\n",
            "Training:  57%|█████▋    | 1134/2000 [10:12<09:42,  1.49iteration/s, mean_rewards=-777]\u001b[A\n",
            "Training:  57%|█████▋    | 1135/2000 [10:12<09:37,  1.50iteration/s, mean_rewards=-777]\u001b[A\n",
            "Training:  57%|█████▋    | 1135/2000 [10:13<09:37,  1.50iteration/s, mean_rewards=-566]\u001b[A\n",
            "Training:  57%|█████▋    | 1136/2000 [10:13<08:49,  1.63iteration/s, mean_rewards=-566]\u001b[A\n",
            "Training:  57%|█████▋    | 1136/2000 [10:13<08:49,  1.63iteration/s, mean_rewards=-515]\u001b[A\n",
            "Training:  57%|█████▋    | 1137/2000 [10:13<08:29,  1.69iteration/s, mean_rewards=-515]\u001b[A\n",
            "Training:  57%|█████▋    | 1137/2000 [10:14<08:29,  1.69iteration/s, mean_rewards=-664]\u001b[A\n",
            "Training:  57%|█████▋    | 1138/2000 [10:14<08:21,  1.72iteration/s, mean_rewards=-664]\u001b[A\n",
            "Training:  57%|█████▋    | 1138/2000 [10:14<08:21,  1.72iteration/s, mean_rewards=-562]\u001b[A\n",
            "Training:  57%|█████▋    | 1139/2000 [10:14<07:52,  1.82iteration/s, mean_rewards=-562]\u001b[A\n",
            "Training:  57%|█████▋    | 1139/2000 [10:15<07:52,  1.82iteration/s, mean_rewards=-890]\u001b[A\n",
            "Training:  57%|█████▋    | 1140/2000 [10:15<08:16,  1.73iteration/s, mean_rewards=-890]\u001b[A\n",
            "Training:  57%|█████▋    | 1140/2000 [10:15<08:16,  1.73iteration/s, mean_rewards=-549]\u001b[A\n",
            "Training:  57%|█████▋    | 1141/2000 [10:15<07:47,  1.84iteration/s, mean_rewards=-549]\u001b[A\n",
            "Training:  57%|█████▋    | 1141/2000 [10:16<07:47,  1.84iteration/s, mean_rewards=-488]\u001b[A\n",
            "Training:  57%|█████▋    | 1142/2000 [10:16<07:32,  1.90iteration/s, mean_rewards=-488]\u001b[A\n",
            "Training:  57%|█████▋    | 1142/2000 [10:16<07:32,  1.90iteration/s, mean_rewards=-490]\u001b[A\n",
            "Training:  57%|█████▋    | 1143/2000 [10:16<07:18,  1.96iteration/s, mean_rewards=-490]\u001b[A\n",
            "Training:  57%|█████▋    | 1143/2000 [10:17<07:18,  1.96iteration/s, mean_rewards=-537]\u001b[A\n",
            "Training:  57%|█████▋    | 1144/2000 [10:17<07:03,  2.02iteration/s, mean_rewards=-537]\u001b[A\n",
            "Training:  57%|█████▋    | 1144/2000 [10:17<07:03,  2.02iteration/s, mean_rewards=-600]\u001b[A\n",
            "Training:  57%|█████▋    | 1145/2000 [10:17<07:06,  2.01iteration/s, mean_rewards=-600]\u001b[A\n",
            "Training:  57%|█████▋    | 1145/2000 [10:18<07:06,  2.01iteration/s, mean_rewards=-826]\u001b[A\n",
            "Training:  57%|█████▋    | 1146/2000 [10:18<07:29,  1.90iteration/s, mean_rewards=-826]\u001b[A\n",
            "Training:  57%|█████▋    | 1146/2000 [10:18<07:29,  1.90iteration/s, mean_rewards=-727]\u001b[A\n",
            "Training:  57%|█████▋    | 1147/2000 [10:19<08:06,  1.75iteration/s, mean_rewards=-727]\u001b[A\n",
            "Training:  57%|█████▋    | 1147/2000 [10:19<08:06,  1.75iteration/s, mean_rewards=-828]\u001b[A\n",
            "Training:  57%|█████▋    | 1148/2000 [10:19<09:11,  1.55iteration/s, mean_rewards=-828]\u001b[A\n",
            "Training:  57%|█████▋    | 1148/2000 [10:20<09:11,  1.55iteration/s, mean_rewards=-625]\u001b[A\n",
            "Training:  57%|█████▋    | 1149/2000 [10:20<09:04,  1.56iteration/s, mean_rewards=-625]\u001b[A\n",
            "Training:  57%|█████▋    | 1149/2000 [10:21<09:04,  1.56iteration/s, mean_rewards=-587]\u001b[A\n",
            "Training:  57%|█████▊    | 1150/2000 [10:21<09:22,  1.51iteration/s, mean_rewards=-587]\u001b[A\n",
            "Training:  57%|█████▊    | 1150/2000 [10:21<09:22,  1.51iteration/s, mean_rewards=-906]\u001b[A\n",
            "Training:  58%|█████▊    | 1151/2000 [10:22<10:22,  1.36iteration/s, mean_rewards=-906]\u001b[A\n",
            "Training:  58%|█████▊    | 1151/2000 [10:22<10:22,  1.36iteration/s, mean_rewards=-491]\u001b[A\n",
            "Training:  58%|█████▊    | 1152/2000 [10:22<09:17,  1.52iteration/s, mean_rewards=-491]\u001b[A\n",
            "Training:  58%|█████▊    | 1152/2000 [10:23<09:17,  1.52iteration/s, mean_rewards=-2.32e+3]\u001b[A\n",
            "Training:  58%|█████▊    | 1153/2000 [10:24<12:52,  1.10iteration/s, mean_rewards=-2.32e+3]\u001b[A\n",
            "Training:  58%|█████▊    | 1153/2000 [10:24<12:52,  1.10iteration/s, mean_rewards=-713]    \u001b[A\n",
            "Training:  58%|█████▊    | 1154/2000 [10:24<11:57,  1.18iteration/s, mean_rewards=-713]\u001b[A\n",
            "Training:  58%|█████▊    | 1154/2000 [10:25<11:57,  1.18iteration/s, mean_rewards=-472]\u001b[A\n",
            "Training:  58%|█████▊    | 1155/2000 [10:25<10:05,  1.40iteration/s, mean_rewards=-472]\u001b[A\n",
            "Training:  58%|█████▊    | 1155/2000 [10:25<10:05,  1.40iteration/s, mean_rewards=-701]\u001b[A\n",
            "Training:  58%|█████▊    | 1156/2000 [10:25<10:02,  1.40iteration/s, mean_rewards=-701]\u001b[A\n",
            "Training:  58%|█████▊    | 1156/2000 [10:26<10:02,  1.40iteration/s, mean_rewards=-592]\u001b[A\n",
            "Training:  58%|█████▊    | 1157/2000 [10:26<09:03,  1.55iteration/s, mean_rewards=-592]\u001b[A\n",
            "Training:  58%|█████▊    | 1157/2000 [10:26<09:03,  1.55iteration/s, mean_rewards=-609]\u001b[A\n",
            "Training:  58%|█████▊    | 1158/2000 [10:26<08:18,  1.69iteration/s, mean_rewards=-609]\u001b[A\n",
            "Training:  58%|█████▊    | 1158/2000 [10:27<08:18,  1.69iteration/s, mean_rewards=-522]\u001b[A\n",
            "Training:  58%|█████▊    | 1159/2000 [10:27<08:10,  1.71iteration/s, mean_rewards=-522]\u001b[A\n",
            "Training:  58%|█████▊    | 1159/2000 [10:27<08:10,  1.71iteration/s, mean_rewards=-578]\u001b[A\n",
            "Training:  58%|█████▊    | 1160/2000 [10:28<07:59,  1.75iteration/s, mean_rewards=-578]\u001b[A\n",
            "Training:  58%|█████▊    | 1160/2000 [10:28<07:59,  1.75iteration/s, mean_rewards=-1.05e+3]\u001b[A\n",
            "Training:  58%|█████▊    | 1161/2000 [10:28<08:37,  1.62iteration/s, mean_rewards=-1.05e+3]\u001b[A\n",
            "Training:  58%|█████▊    | 1161/2000 [10:29<08:37,  1.62iteration/s, mean_rewards=-979]    \u001b[A\n",
            "Training:  58%|█████▊    | 1162/2000 [10:29<09:00,  1.55iteration/s, mean_rewards=-979]\u001b[A\n",
            "Training:  58%|█████▊    | 1162/2000 [10:29<09:00,  1.55iteration/s, mean_rewards=-625]\u001b[A\n",
            "Training:  58%|█████▊    | 1163/2000 [10:29<08:19,  1.68iteration/s, mean_rewards=-625]\u001b[A\n",
            "Training:  58%|█████▊    | 1163/2000 [10:30<08:19,  1.68iteration/s, mean_rewards=-511]\u001b[A\n",
            "Training:  58%|█████▊    | 1164/2000 [10:30<08:12,  1.70iteration/s, mean_rewards=-511]\u001b[A\n",
            "Training:  58%|█████▊    | 1164/2000 [10:31<08:12,  1.70iteration/s, mean_rewards=-1.71e+3]\u001b[A\n",
            "Training:  58%|█████▊    | 1165/2000 [10:31<10:00,  1.39iteration/s, mean_rewards=-1.71e+3]\u001b[A\n",
            "Training:  58%|█████▊    | 1165/2000 [10:31<10:00,  1.39iteration/s, mean_rewards=-593]    \u001b[A\n",
            "Training:  58%|█████▊    | 1166/2000 [10:32<09:12,  1.51iteration/s, mean_rewards=-593]\u001b[A\n",
            "Training:  58%|█████▊    | 1166/2000 [10:32<09:12,  1.51iteration/s, mean_rewards=-559]\u001b[A\n",
            "Training:  58%|█████▊    | 1167/2000 [10:32<08:27,  1.64iteration/s, mean_rewards=-559]\u001b[A\n",
            "Training:  58%|█████▊    | 1167/2000 [10:33<08:27,  1.64iteration/s, mean_rewards=-656]\u001b[A\n",
            "Training:  58%|█████▊    | 1168/2000 [10:33<08:52,  1.56iteration/s, mean_rewards=-656]\u001b[A\n",
            "Training:  58%|█████▊    | 1168/2000 [10:33<08:52,  1.56iteration/s, mean_rewards=-677]\u001b[A\n",
            "Training:  58%|█████▊    | 1169/2000 [10:33<08:59,  1.54iteration/s, mean_rewards=-677]\u001b[A\n",
            "Training:  58%|█████▊    | 1169/2000 [10:34<08:59,  1.54iteration/s, mean_rewards=-634]\u001b[A\n",
            "Training:  58%|█████▊    | 1170/2000 [10:34<09:22,  1.48iteration/s, mean_rewards=-634]\u001b[A\n",
            "Training:  58%|█████▊    | 1170/2000 [10:35<09:22,  1.48iteration/s, mean_rewards=-510]\u001b[A\n",
            "Training:  59%|█████▊    | 1171/2000 [10:35<09:02,  1.53iteration/s, mean_rewards=-510]\u001b[A\n",
            "Training:  59%|█████▊    | 1171/2000 [10:35<09:02,  1.53iteration/s, mean_rewards=-579]\u001b[A\n",
            "Training:  59%|█████▊    | 1172/2000 [10:35<08:31,  1.62iteration/s, mean_rewards=-579]\u001b[A\n",
            "Training:  59%|█████▊    | 1172/2000 [10:36<08:31,  1.62iteration/s, mean_rewards=-748]\u001b[A\n",
            "Training:  59%|█████▊    | 1173/2000 [10:36<08:36,  1.60iteration/s, mean_rewards=-748]\u001b[A\n",
            "Training:  59%|█████▊    | 1173/2000 [10:36<08:36,  1.60iteration/s, mean_rewards=-901]\u001b[A\n",
            "Training:  59%|█████▊    | 1174/2000 [10:37<09:01,  1.53iteration/s, mean_rewards=-901]\u001b[A\n",
            "Training:  59%|█████▊    | 1174/2000 [10:37<09:01,  1.53iteration/s, mean_rewards=-921]\u001b[A\n",
            "Training:  59%|█████▉    | 1175/2000 [10:37<09:05,  1.51iteration/s, mean_rewards=-921]\u001b[A\n",
            "Training:  59%|█████▉    | 1175/2000 [10:38<09:05,  1.51iteration/s, mean_rewards=-940]\u001b[A\n",
            "Training:  59%|█████▉    | 1176/2000 [10:38<09:33,  1.44iteration/s, mean_rewards=-940]\u001b[A\n",
            "Training:  59%|█████▉    | 1176/2000 [10:39<09:33,  1.44iteration/s, mean_rewards=-1.45e+3]\u001b[A\n",
            "Training:  59%|█████▉    | 1177/2000 [10:39<10:48,  1.27iteration/s, mean_rewards=-1.45e+3]\u001b[A\n",
            "Training:  59%|█████▉    | 1177/2000 [10:39<10:48,  1.27iteration/s, mean_rewards=-482]    \u001b[A\n",
            "Training:  59%|█████▉    | 1178/2000 [10:40<09:30,  1.44iteration/s, mean_rewards=-482]\u001b[A\n",
            "Training:  59%|█████▉    | 1178/2000 [10:40<09:30,  1.44iteration/s, mean_rewards=-651]\u001b[A\n",
            "Training:  59%|█████▉    | 1179/2000 [10:40<08:31,  1.60iteration/s, mean_rewards=-651]\u001b[A\n",
            "Training:  59%|█████▉    | 1179/2000 [10:40<08:31,  1.60iteration/s, mean_rewards=-564]\u001b[A\n",
            "Training:  59%|█████▉    | 1180/2000 [10:41<07:49,  1.75iteration/s, mean_rewards=-564]\u001b[A\n",
            "Training:  59%|█████▉    | 1180/2000 [10:41<07:49,  1.75iteration/s, mean_rewards=-976]\u001b[A\n",
            "Training:  59%|█████▉    | 1181/2000 [10:41<09:05,  1.50iteration/s, mean_rewards=-976]\u001b[A\n",
            "Training:  59%|█████▉    | 1181/2000 [10:42<09:05,  1.50iteration/s, mean_rewards=-741]\u001b[A\n",
            "Training:  59%|█████▉    | 1182/2000 [10:42<08:38,  1.58iteration/s, mean_rewards=-741]\u001b[A\n",
            "Training:  59%|█████▉    | 1182/2000 [10:42<08:38,  1.58iteration/s, mean_rewards=-538]\u001b[A\n",
            "Training:  59%|█████▉    | 1183/2000 [10:42<07:57,  1.71iteration/s, mean_rewards=-538]\u001b[A\n",
            "Training:  59%|█████▉    | 1183/2000 [10:43<07:57,  1.71iteration/s, mean_rewards=-412]\u001b[A\n",
            "Training:  59%|█████▉    | 1184/2000 [10:43<07:51,  1.73iteration/s, mean_rewards=-412]\u001b[A\n",
            "Training:  59%|█████▉    | 1184/2000 [10:43<07:51,  1.73iteration/s, mean_rewards=-634]\u001b[A\n",
            "Training:  59%|█████▉    | 1185/2000 [10:44<07:59,  1.70iteration/s, mean_rewards=-634]\u001b[A\n",
            "Training:  59%|█████▉    | 1185/2000 [10:44<07:59,  1.70iteration/s, mean_rewards=-685]\u001b[A\n",
            "Training:  59%|█████▉    | 1186/2000 [10:44<08:10,  1.66iteration/s, mean_rewards=-685]\u001b[A\n",
            "Training:  59%|█████▉    | 1186/2000 [10:45<08:10,  1.66iteration/s, mean_rewards=-551]\u001b[A\n",
            "Training:  59%|█████▉    | 1187/2000 [10:45<07:52,  1.72iteration/s, mean_rewards=-551]\u001b[A\n",
            "Training:  59%|█████▉    | 1187/2000 [10:46<07:52,  1.72iteration/s, mean_rewards=-1.89e+3]\u001b[A\n",
            "Training:  59%|█████▉    | 1188/2000 [10:46<12:10,  1.11iteration/s, mean_rewards=-1.89e+3]\u001b[A\n",
            "Training:  59%|█████▉    | 1188/2000 [10:47<12:10,  1.11iteration/s, mean_rewards=-582]    \u001b[A\n",
            "Training:  59%|█████▉    | 1189/2000 [10:47<11:10,  1.21iteration/s, mean_rewards=-582]\u001b[A\n",
            "Training:  59%|█████▉    | 1189/2000 [10:47<11:10,  1.21iteration/s, mean_rewards=-562]\u001b[A\n",
            "Training:  60%|█████▉    | 1190/2000 [10:48<09:54,  1.36iteration/s, mean_rewards=-562]\u001b[A\n",
            "Training:  60%|█████▉    | 1190/2000 [10:48<09:54,  1.36iteration/s, mean_rewards=-656]\u001b[A\n",
            "Training:  60%|█████▉    | 1191/2000 [10:48<09:03,  1.49iteration/s, mean_rewards=-656]\u001b[A\n",
            "Training:  60%|█████▉    | 1191/2000 [10:48<09:03,  1.49iteration/s, mean_rewards=-451]\u001b[A\n",
            "Training:  60%|█████▉    | 1192/2000 [10:49<08:17,  1.62iteration/s, mean_rewards=-451]\u001b[A\n",
            "Training:  60%|█████▉    | 1192/2000 [10:49<08:17,  1.62iteration/s, mean_rewards=-596]\u001b[A\n",
            "Training:  60%|█████▉    | 1193/2000 [10:49<07:42,  1.75iteration/s, mean_rewards=-596]\u001b[A\n",
            "Training:  60%|█████▉    | 1193/2000 [10:49<07:42,  1.75iteration/s, mean_rewards=-558]\u001b[A\n",
            "Training:  60%|█████▉    | 1194/2000 [10:50<07:46,  1.73iteration/s, mean_rewards=-558]\u001b[A\n",
            "Training:  60%|█████▉    | 1194/2000 [10:50<07:46,  1.73iteration/s, mean_rewards=-1.25e+3]\u001b[A\n",
            "Training:  60%|█████▉    | 1195/2000 [10:51<09:05,  1.47iteration/s, mean_rewards=-1.25e+3]\u001b[A\n",
            "Training:  60%|█████▉    | 1195/2000 [10:51<09:05,  1.47iteration/s, mean_rewards=-565]    \u001b[A\n",
            "Training:  60%|█████▉    | 1196/2000 [10:51<08:53,  1.51iteration/s, mean_rewards=-565]\u001b[A\n",
            "Training:  60%|█████▉    | 1196/2000 [10:52<08:53,  1.51iteration/s, mean_rewards=-1.75e+3]\u001b[A\n",
            "Training:  60%|█████▉    | 1197/2000 [10:52<10:46,  1.24iteration/s, mean_rewards=-1.75e+3]\u001b[A\n",
            "Training:  60%|█████▉    | 1197/2000 [10:53<10:46,  1.24iteration/s, mean_rewards=-755]    \u001b[A\n",
            "Training:  60%|█████▉    | 1198/2000 [10:53<10:03,  1.33iteration/s, mean_rewards=-755]\u001b[A\n",
            "Training:  60%|█████▉    | 1198/2000 [10:54<10:03,  1.33iteration/s, mean_rewards=-1.61e+3]\u001b[A\n",
            "Training:  60%|█████▉    | 1199/2000 [10:54<11:20,  1.18iteration/s, mean_rewards=-1.61e+3]\u001b[A\n",
            "Training:  60%|█████▉    | 1199/2000 [10:54<11:20,  1.18iteration/s, mean_rewards=-691]    \u001b[A\n",
            "Training:  60%|██████    | 1200/2000 [10:55<10:08,  1.31iteration/s, mean_rewards=-691]\u001b[A\n",
            "Training:  60%|██████    | 1200/2000 [10:55<10:08,  1.31iteration/s, mean_rewards=-397]\u001b[A\n",
            "Training:  60%|██████    | 1201/2000 [10:55<08:54,  1.50iteration/s, mean_rewards=-397]\u001b[A\n",
            "Training:  60%|██████    | 1201/2000 [10:55<08:54,  1.50iteration/s, mean_rewards=-732]\u001b[A\n",
            "Training:  60%|██████    | 1202/2000 [10:56<08:26,  1.58iteration/s, mean_rewards=-732]\u001b[A\n",
            "Training:  60%|██████    | 1202/2000 [10:56<08:26,  1.58iteration/s, mean_rewards=-99.3]\u001b[A\n",
            "Training:  60%|██████    | 1203/2000 [10:56<07:06,  1.87iteration/s, mean_rewards=-99.3]\u001b[A\n",
            "Training:  60%|██████    | 1203/2000 [10:56<07:06,  1.87iteration/s, mean_rewards=-639] \u001b[A\n",
            "Training:  60%|██████    | 1204/2000 [10:56<07:04,  1.87iteration/s, mean_rewards=-639]\u001b[A\n",
            "Training:  60%|██████    | 1204/2000 [10:57<07:04,  1.87iteration/s, mean_rewards=-356]\u001b[A\n",
            "Training:  60%|██████    | 1205/2000 [10:57<06:25,  2.06iteration/s, mean_rewards=-356]\u001b[A\n",
            "Training:  60%|██████    | 1205/2000 [10:57<06:25,  2.06iteration/s, mean_rewards=-788]\u001b[A\n",
            "Training:  60%|██████    | 1206/2000 [10:57<06:47,  1.95iteration/s, mean_rewards=-788]\u001b[A\n",
            "Training:  60%|██████    | 1206/2000 [10:58<06:47,  1.95iteration/s, mean_rewards=-512]\u001b[A\n",
            "Training:  60%|██████    | 1207/2000 [10:58<07:17,  1.81iteration/s, mean_rewards=-512]\u001b[A\n",
            "Training:  60%|██████    | 1207/2000 [10:59<07:17,  1.81iteration/s, mean_rewards=-577]\u001b[A\n",
            "Training:  60%|██████    | 1208/2000 [10:59<07:56,  1.66iteration/s, mean_rewards=-577]\u001b[A\n",
            "Training:  60%|██████    | 1208/2000 [11:00<07:56,  1.66iteration/s, mean_rewards=-1.25e+3]\u001b[A\n",
            "Training:  60%|██████    | 1209/2000 [11:00<09:52,  1.34iteration/s, mean_rewards=-1.25e+3]\u001b[A\n",
            "Training:  60%|██████    | 1209/2000 [11:01<09:52,  1.34iteration/s, mean_rewards=-891]    \u001b[A\n",
            "Training:  60%|██████    | 1210/2000 [11:01<10:45,  1.22iteration/s, mean_rewards=-891]\u001b[A\n",
            "Training:  60%|██████    | 1210/2000 [11:01<10:45,  1.22iteration/s, mean_rewards=-904]\u001b[A\n",
            "Training:  61%|██████    | 1211/2000 [11:02<10:26,  1.26iteration/s, mean_rewards=-904]\u001b[A\n",
            "Training:  61%|██████    | 1211/2000 [11:02<10:26,  1.26iteration/s, mean_rewards=-753]\u001b[A\n",
            "Training:  61%|██████    | 1212/2000 [11:02<09:27,  1.39iteration/s, mean_rewards=-753]\u001b[A\n",
            "Training:  61%|██████    | 1212/2000 [11:03<09:27,  1.39iteration/s, mean_rewards=-728]\u001b[A\n",
            "Training:  61%|██████    | 1213/2000 [11:03<08:57,  1.46iteration/s, mean_rewards=-728]\u001b[A\n",
            "Training:  61%|██████    | 1213/2000 [11:03<08:57,  1.46iteration/s, mean_rewards=-1.69e+3]\u001b[A\n",
            "Training:  61%|██████    | 1214/2000 [11:04<10:16,  1.28iteration/s, mean_rewards=-1.69e+3]\u001b[A\n",
            "Training:  61%|██████    | 1214/2000 [11:04<10:16,  1.28iteration/s, mean_rewards=-789]    \u001b[A\n",
            "Training:  61%|██████    | 1215/2000 [11:04<09:55,  1.32iteration/s, mean_rewards=-789]\u001b[A\n",
            "Training:  61%|██████    | 1215/2000 [11:05<09:55,  1.32iteration/s, mean_rewards=-1.08e+3]\u001b[A\n",
            "Training:  61%|██████    | 1216/2000 [11:05<10:15,  1.27iteration/s, mean_rewards=-1.08e+3]\u001b[A\n",
            "Training:  61%|██████    | 1216/2000 [11:06<10:15,  1.27iteration/s, mean_rewards=-1.25e+3]\u001b[A\n",
            "Training:  61%|██████    | 1217/2000 [11:06<10:26,  1.25iteration/s, mean_rewards=-1.25e+3]\u001b[A\n",
            "Training:  61%|██████    | 1217/2000 [11:06<10:26,  1.25iteration/s, mean_rewards=-89.4]   \u001b[A\n",
            "Training:  61%|██████    | 1218/2000 [11:06<08:35,  1.52iteration/s, mean_rewards=-89.4]\u001b[A\n",
            "Training:  61%|██████    | 1218/2000 [11:07<08:35,  1.52iteration/s, mean_rewards=-432] \u001b[A\n",
            "Training:  61%|██████    | 1219/2000 [11:07<07:45,  1.68iteration/s, mean_rewards=-432]\u001b[A\n",
            "Training:  61%|██████    | 1219/2000 [11:07<07:45,  1.68iteration/s, mean_rewards=-605]\u001b[A\n",
            "Training:  61%|██████    | 1220/2000 [11:07<07:17,  1.78iteration/s, mean_rewards=-605]\u001b[A\n",
            "Training:  61%|██████    | 1220/2000 [11:08<07:17,  1.78iteration/s, mean_rewards=-541]\u001b[A\n",
            "Training:  61%|██████    | 1221/2000 [11:08<06:58,  1.86iteration/s, mean_rewards=-541]\u001b[A\n",
            "Training:  61%|██████    | 1221/2000 [11:08<06:58,  1.86iteration/s, mean_rewards=-1.32e+3]\u001b[A\n",
            "Training:  61%|██████    | 1222/2000 [11:09<08:25,  1.54iteration/s, mean_rewards=-1.32e+3]\u001b[A\n",
            "Training:  61%|██████    | 1222/2000 [11:09<08:25,  1.54iteration/s, mean_rewards=-576]    \u001b[A\n",
            "Training:  61%|██████    | 1223/2000 [11:09<07:31,  1.72iteration/s, mean_rewards=-576]\u001b[A\n",
            "Training:  61%|██████    | 1223/2000 [11:10<07:31,  1.72iteration/s, mean_rewards=-673]\u001b[A\n",
            "Training:  61%|██████    | 1224/2000 [11:10<07:26,  1.74iteration/s, mean_rewards=-673]\u001b[A\n",
            "Training:  61%|██████    | 1224/2000 [11:11<07:26,  1.74iteration/s, mean_rewards=-1.35e+3]\u001b[A\n",
            "Training:  61%|██████▏   | 1225/2000 [11:11<09:42,  1.33iteration/s, mean_rewards=-1.35e+3]\u001b[A\n",
            "Training:  61%|██████▏   | 1225/2000 [11:11<09:42,  1.33iteration/s, mean_rewards=-541]    \u001b[A\n",
            "Training:  61%|██████▏   | 1226/2000 [11:12<09:31,  1.35iteration/s, mean_rewards=-541]\u001b[A\n",
            "Training:  61%|██████▏   | 1226/2000 [11:12<09:31,  1.35iteration/s, mean_rewards=-314]\u001b[A\n",
            "Training:  61%|██████▏   | 1227/2000 [11:12<09:22,  1.38iteration/s, mean_rewards=-314]\u001b[A\n",
            "Training:  61%|██████▏   | 1227/2000 [11:13<09:22,  1.38iteration/s, mean_rewards=-591]\u001b[A\n",
            "Training:  61%|██████▏   | 1228/2000 [11:13<09:07,  1.41iteration/s, mean_rewards=-591]\u001b[A\n",
            "Training:  61%|██████▏   | 1228/2000 [11:13<09:07,  1.41iteration/s, mean_rewards=-269]\u001b[A\n",
            "Training:  61%|██████▏   | 1229/2000 [11:13<08:06,  1.59iteration/s, mean_rewards=-269]\u001b[A\n",
            "Training:  61%|██████▏   | 1229/2000 [11:14<08:06,  1.59iteration/s, mean_rewards=-528]\u001b[A\n",
            "Training:  62%|██████▏   | 1230/2000 [11:14<07:43,  1.66iteration/s, mean_rewards=-528]\u001b[A\n",
            "Training:  62%|██████▏   | 1230/2000 [11:14<07:43,  1.66iteration/s, mean_rewards=-725]\u001b[A\n",
            "Training:  62%|██████▏   | 1231/2000 [11:15<07:29,  1.71iteration/s, mean_rewards=-725]\u001b[A\n",
            "Training:  62%|██████▏   | 1231/2000 [11:15<07:29,  1.71iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  62%|██████▏   | 1232/2000 [11:15<06:26,  1.99iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  62%|██████▏   | 1232/2000 [11:15<06:26,  1.99iteration/s, mean_rewards=-765]\u001b[A\n",
            "Training:  62%|██████▏   | 1233/2000 [11:15<06:49,  1.87iteration/s, mean_rewards=-765]\u001b[A\n",
            "Training:  62%|██████▏   | 1233/2000 [11:16<06:49,  1.87iteration/s, mean_rewards=-549]\u001b[A\n",
            "Training:  62%|██████▏   | 1234/2000 [11:16<06:35,  1.94iteration/s, mean_rewards=-549]\u001b[A\n",
            "Training:  62%|██████▏   | 1234/2000 [11:16<06:35,  1.94iteration/s, mean_rewards=-349]\u001b[A\n",
            "Training:  62%|██████▏   | 1235/2000 [11:16<06:19,  2.01iteration/s, mean_rewards=-349]\u001b[A\n",
            "Training:  62%|██████▏   | 1235/2000 [11:17<06:19,  2.01iteration/s, mean_rewards=-753]\u001b[A\n",
            "Training:  62%|██████▏   | 1236/2000 [11:17<06:50,  1.86iteration/s, mean_rewards=-753]\u001b[A\n",
            "Training:  62%|██████▏   | 1236/2000 [11:17<06:50,  1.86iteration/s, mean_rewards=-591]\u001b[A\n",
            "Training:  62%|██████▏   | 1237/2000 [11:18<06:47,  1.87iteration/s, mean_rewards=-591]\u001b[A\n",
            "Training:  62%|██████▏   | 1237/2000 [11:18<06:47,  1.87iteration/s, mean_rewards=-744]\u001b[A\n",
            "Training:  62%|██████▏   | 1238/2000 [11:18<07:02,  1.80iteration/s, mean_rewards=-744]\u001b[A\n",
            "Training:  62%|██████▏   | 1238/2000 [11:18<07:02,  1.80iteration/s, mean_rewards=-637]\u001b[A\n",
            "Training:  62%|██████▏   | 1239/2000 [11:19<06:50,  1.85iteration/s, mean_rewards=-637]\u001b[A\n",
            "Training:  62%|██████▏   | 1239/2000 [11:19<06:50,  1.85iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  62%|██████▏   | 1240/2000 [11:19<06:01,  2.10iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  62%|██████▏   | 1240/2000 [11:19<06:01,  2.10iteration/s, mean_rewards=-567]\u001b[A\n",
            "Training:  62%|██████▏   | 1241/2000 [11:19<06:00,  2.11iteration/s, mean_rewards=-567]\u001b[A\n",
            "Training:  62%|██████▏   | 1241/2000 [11:20<06:00,  2.11iteration/s, mean_rewards=-666]\u001b[A\n",
            "Training:  62%|██████▏   | 1242/2000 [11:20<06:02,  2.09iteration/s, mean_rewards=-666]\u001b[A\n",
            "Training:  62%|██████▏   | 1242/2000 [11:20<06:02,  2.09iteration/s, mean_rewards=-759]\u001b[A\n",
            "Training:  62%|██████▏   | 1243/2000 [11:21<06:39,  1.90iteration/s, mean_rewards=-759]\u001b[A\n",
            "Training:  62%|██████▏   | 1243/2000 [11:21<06:39,  1.90iteration/s, mean_rewards=-297]\u001b[A\n",
            "Training:  62%|██████▏   | 1244/2000 [11:21<06:02,  2.09iteration/s, mean_rewards=-297]\u001b[A\n",
            "Training:  62%|██████▏   | 1244/2000 [11:21<06:02,  2.09iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  62%|██████▏   | 1245/2000 [11:21<05:23,  2.33iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  62%|██████▏   | 1245/2000 [11:21<05:23,  2.33iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:  62%|██████▏   | 1246/2000 [11:22<05:07,  2.46iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:  62%|██████▏   | 1246/2000 [11:22<05:07,  2.46iteration/s, mean_rewards=-693]\u001b[A\n",
            "Training:  62%|██████▏   | 1247/2000 [11:22<05:35,  2.24iteration/s, mean_rewards=-693]\u001b[A\n",
            "Training:  62%|██████▏   | 1247/2000 [11:23<05:35,  2.24iteration/s, mean_rewards=-811]\u001b[A\n",
            "Training:  62%|██████▏   | 1248/2000 [11:23<06:20,  1.98iteration/s, mean_rewards=-811]\u001b[A\n",
            "Training:  62%|██████▏   | 1248/2000 [11:23<06:20,  1.98iteration/s, mean_rewards=-554]\u001b[A\n",
            "Training:  62%|██████▏   | 1249/2000 [11:23<06:38,  1.88iteration/s, mean_rewards=-554]\u001b[A\n",
            "Training:  62%|██████▏   | 1249/2000 [11:24<06:38,  1.88iteration/s, mean_rewards=-389]\u001b[A\n",
            "Training:  62%|██████▎   | 1250/2000 [11:24<06:53,  1.81iteration/s, mean_rewards=-389]\u001b[A\n",
            "Training:  62%|██████▎   | 1250/2000 [11:26<06:53,  1.81iteration/s, mean_rewards=-2.89e+3]\u001b[A\n",
            "Training:  63%|██████▎   | 1251/2000 [11:26<12:56,  1.04s/iteration, mean_rewards=-2.89e+3]\u001b[A\n",
            "Training:  63%|██████▎   | 1251/2000 [11:26<12:56,  1.04s/iteration, mean_rewards=-703]    \u001b[A\n",
            "Training:  63%|██████▎   | 1252/2000 [11:27<11:03,  1.13iteration/s, mean_rewards=-703]\u001b[A\n",
            "Training:  63%|██████▎   | 1252/2000 [11:27<11:03,  1.13iteration/s, mean_rewards=-429]\u001b[A\n",
            "Training:  63%|██████▎   | 1253/2000 [11:27<09:45,  1.28iteration/s, mean_rewards=-429]\u001b[A\n",
            "Training:  63%|██████▎   | 1253/2000 [11:27<09:45,  1.28iteration/s, mean_rewards=-382]\u001b[A\n",
            "Training:  63%|██████▎   | 1254/2000 [11:28<08:17,  1.50iteration/s, mean_rewards=-382]\u001b[A\n",
            "Training:  63%|██████▎   | 1254/2000 [11:28<08:17,  1.50iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  63%|██████▎   | 1255/2000 [11:28<06:58,  1.78iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  63%|██████▎   | 1255/2000 [11:28<06:58,  1.78iteration/s, mean_rewards=-797]\u001b[A\n",
            "Training:  63%|██████▎   | 1256/2000 [11:29<07:17,  1.70iteration/s, mean_rewards=-797]\u001b[A\n",
            "Training:  63%|██████▎   | 1256/2000 [11:29<07:17,  1.70iteration/s, mean_rewards=-521]\u001b[A\n",
            "Training:  63%|██████▎   | 1257/2000 [11:29<06:49,  1.82iteration/s, mean_rewards=-521]\u001b[A\n",
            "Training:  63%|██████▎   | 1257/2000 [11:29<06:49,  1.82iteration/s, mean_rewards=-317]\u001b[A\n",
            "Training:  63%|██████▎   | 1258/2000 [11:29<06:10,  2.00iteration/s, mean_rewards=-317]\u001b[A\n",
            "Training:  63%|██████▎   | 1258/2000 [11:30<06:10,  2.00iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  63%|██████▎   | 1259/2000 [11:30<05:27,  2.26iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  63%|██████▎   | 1259/2000 [11:30<05:27,  2.26iteration/s, mean_rewards=-483]\u001b[A\n",
            "Training:  63%|██████▎   | 1260/2000 [11:30<05:43,  2.15iteration/s, mean_rewards=-483]\u001b[A\n",
            "Training:  63%|██████▎   | 1260/2000 [11:31<05:43,  2.15iteration/s, mean_rewards=-707]\u001b[A\n",
            "Training:  63%|██████▎   | 1261/2000 [11:31<06:04,  2.03iteration/s, mean_rewards=-707]\u001b[A\n",
            "Training:  63%|██████▎   | 1261/2000 [11:31<06:04,  2.03iteration/s, mean_rewards=-455]\u001b[A\n",
            "Training:  63%|██████▎   | 1262/2000 [11:31<05:47,  2.12iteration/s, mean_rewards=-455]\u001b[A\n",
            "Training:  63%|██████▎   | 1262/2000 [11:32<05:47,  2.12iteration/s, mean_rewards=-1.06e+3]\u001b[A\n",
            "Training:  63%|██████▎   | 1263/2000 [11:32<06:56,  1.77iteration/s, mean_rewards=-1.06e+3]\u001b[A\n",
            "Training:  63%|██████▎   | 1263/2000 [11:32<06:56,  1.77iteration/s, mean_rewards=-283]    \u001b[A\n",
            "Training:  63%|██████▎   | 1264/2000 [11:32<06:18,  1.94iteration/s, mean_rewards=-283]\u001b[A\n",
            "Training:  63%|██████▎   | 1264/2000 [11:33<06:18,  1.94iteration/s, mean_rewards=-361]\u001b[A\n",
            "Training:  63%|██████▎   | 1265/2000 [11:33<05:48,  2.11iteration/s, mean_rewards=-361]\u001b[A\n",
            "Training:  63%|██████▎   | 1265/2000 [11:33<05:48,  2.11iteration/s, mean_rewards=-1.16e+3]\u001b[A\n",
            "Training:  63%|██████▎   | 1266/2000 [11:34<07:09,  1.71iteration/s, mean_rewards=-1.16e+3]\u001b[A\n",
            "Training:  63%|██████▎   | 1266/2000 [11:34<07:09,  1.71iteration/s, mean_rewards=-617]    \u001b[A\n",
            "Training:  63%|██████▎   | 1267/2000 [11:34<06:32,  1.87iteration/s, mean_rewards=-617]\u001b[A\n",
            "Training:  63%|██████▎   | 1267/2000 [11:34<06:32,  1.87iteration/s, mean_rewards=-624]\u001b[A\n",
            "Training:  63%|██████▎   | 1268/2000 [11:35<06:34,  1.86iteration/s, mean_rewards=-624]\u001b[A\n",
            "Training:  63%|██████▎   | 1268/2000 [11:35<06:34,  1.86iteration/s, mean_rewards=-41.8]\u001b[A\n",
            "Training:  63%|██████▎   | 1269/2000 [11:35<05:43,  2.13iteration/s, mean_rewards=-41.8]\u001b[A\n",
            "Training:  63%|██████▎   | 1269/2000 [11:35<05:43,  2.13iteration/s, mean_rewards=-637] \u001b[A\n",
            "Training:  64%|██████▎   | 1270/2000 [11:35<05:47,  2.10iteration/s, mean_rewards=-637]\u001b[A\n",
            "Training:  64%|██████▎   | 1270/2000 [11:36<05:47,  2.10iteration/s, mean_rewards=-774]\u001b[A\n",
            "Training:  64%|██████▎   | 1271/2000 [11:36<05:57,  2.04iteration/s, mean_rewards=-774]\u001b[A\n",
            "Training:  64%|██████▎   | 1271/2000 [11:36<05:57,  2.04iteration/s, mean_rewards=-648]\u001b[A\n",
            "Training:  64%|██████▎   | 1272/2000 [11:37<06:45,  1.80iteration/s, mean_rewards=-648]\u001b[A\n",
            "Training:  64%|██████▎   | 1272/2000 [11:37<06:45,  1.80iteration/s, mean_rewards=-429]\u001b[A\n",
            "Training:  64%|██████▎   | 1273/2000 [11:37<06:35,  1.84iteration/s, mean_rewards=-429]\u001b[A\n",
            "Training:  64%|██████▎   | 1273/2000 [11:38<06:35,  1.84iteration/s, mean_rewards=-822]\u001b[A\n",
            "Training:  64%|██████▎   | 1274/2000 [11:38<07:23,  1.64iteration/s, mean_rewards=-822]\u001b[A\n",
            "Training:  64%|██████▎   | 1274/2000 [11:38<07:23,  1.64iteration/s, mean_rewards=-498]\u001b[A\n",
            "Training:  64%|██████▍   | 1275/2000 [11:39<07:47,  1.55iteration/s, mean_rewards=-498]\u001b[A\n",
            "Training:  64%|██████▍   | 1275/2000 [11:39<07:47,  1.55iteration/s, mean_rewards=-1.01e+3]\u001b[A\n",
            "Training:  64%|██████▍   | 1276/2000 [11:39<08:26,  1.43iteration/s, mean_rewards=-1.01e+3]\u001b[A\n",
            "Training:  64%|██████▍   | 1276/2000 [11:40<08:26,  1.43iteration/s, mean_rewards=-308]    \u001b[A\n",
            "Training:  64%|██████▍   | 1277/2000 [11:40<07:20,  1.64iteration/s, mean_rewards=-308]\u001b[A\n",
            "Training:  64%|██████▍   | 1277/2000 [11:40<07:20,  1.64iteration/s, mean_rewards=-89] \u001b[A\n",
            "Training:  64%|██████▍   | 1278/2000 [11:40<06:11,  1.94iteration/s, mean_rewards=-89]\u001b[A\n",
            "Training:  64%|██████▍   | 1278/2000 [11:40<06:11,  1.94iteration/s, mean_rewards=-356]\u001b[A\n",
            "Training:  64%|██████▍   | 1279/2000 [11:41<05:46,  2.08iteration/s, mean_rewards=-356]\u001b[A\n",
            "Training:  64%|██████▍   | 1279/2000 [11:41<05:46,  2.08iteration/s, mean_rewards=-693]\u001b[A\n",
            "Training:  64%|██████▍   | 1280/2000 [11:41<05:47,  2.07iteration/s, mean_rewards=-693]\u001b[A\n",
            "Training:  64%|██████▍   | 1280/2000 [11:42<05:47,  2.07iteration/s, mean_rewards=-1.38e+3]\u001b[A\n",
            "Training:  64%|██████▍   | 1281/2000 [11:42<07:40,  1.56iteration/s, mean_rewards=-1.38e+3]\u001b[A\n",
            "Training:  64%|██████▍   | 1281/2000 [11:43<07:40,  1.56iteration/s, mean_rewards=-2.82e+3]\u001b[A\n",
            "Training:  64%|██████▍   | 1282/2000 [11:44<11:07,  1.08iteration/s, mean_rewards=-2.82e+3]\u001b[A\n",
            "Training:  64%|██████▍   | 1282/2000 [11:44<11:07,  1.08iteration/s, mean_rewards=-826]    \u001b[A\n",
            "Training:  64%|██████▍   | 1283/2000 [11:44<10:09,  1.18iteration/s, mean_rewards=-826]\u001b[A\n",
            "Training:  64%|██████▍   | 1283/2000 [11:45<10:09,  1.18iteration/s, mean_rewards=-453]\u001b[A\n",
            "Training:  64%|██████▍   | 1284/2000 [11:45<08:44,  1.36iteration/s, mean_rewards=-453]\u001b[A\n",
            "Training:  64%|██████▍   | 1284/2000 [11:45<08:44,  1.36iteration/s, mean_rewards=-498]\u001b[A\n",
            "Training:  64%|██████▍   | 1285/2000 [11:45<07:55,  1.50iteration/s, mean_rewards=-498]\u001b[A\n",
            "Training:  64%|██████▍   | 1285/2000 [11:46<07:55,  1.50iteration/s, mean_rewards=-557]\u001b[A\n",
            "Training:  64%|██████▍   | 1286/2000 [11:46<07:19,  1.62iteration/s, mean_rewards=-557]\u001b[A\n",
            "Training:  64%|██████▍   | 1286/2000 [11:46<07:19,  1.62iteration/s, mean_rewards=-349]\u001b[A\n",
            "Training:  64%|██████▍   | 1287/2000 [11:46<06:52,  1.73iteration/s, mean_rewards=-349]\u001b[A\n",
            "Training:  64%|██████▍   | 1287/2000 [11:46<06:52,  1.73iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  64%|██████▍   | 1288/2000 [11:47<05:59,  1.98iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  64%|██████▍   | 1288/2000 [11:47<05:59,  1.98iteration/s, mean_rewards=-644]\u001b[A\n",
            "Training:  64%|██████▍   | 1289/2000 [11:47<06:12,  1.91iteration/s, mean_rewards=-644]\u001b[A\n",
            "Training:  64%|██████▍   | 1289/2000 [11:48<06:12,  1.91iteration/s, mean_rewards=-542]\u001b[A\n",
            "Training:  64%|██████▍   | 1290/2000 [11:48<06:20,  1.87iteration/s, mean_rewards=-542]\u001b[A\n",
            "Training:  64%|██████▍   | 1290/2000 [11:48<06:20,  1.87iteration/s, mean_rewards=-306]\u001b[A\n",
            "Training:  65%|██████▍   | 1291/2000 [11:48<05:54,  2.00iteration/s, mean_rewards=-306]\u001b[A\n",
            "Training:  65%|██████▍   | 1291/2000 [11:48<05:54,  2.00iteration/s, mean_rewards=-340]\u001b[A\n",
            "Training:  65%|██████▍   | 1292/2000 [11:49<05:30,  2.14iteration/s, mean_rewards=-340]\u001b[A\n",
            "Training:  65%|██████▍   | 1292/2000 [11:50<05:30,  2.14iteration/s, mean_rewards=-1.51e+3]\u001b[A\n",
            "Training:  65%|██████▍   | 1293/2000 [11:50<08:50,  1.33iteration/s, mean_rewards=-1.51e+3]\u001b[A\n",
            "Training:  65%|██████▍   | 1293/2000 [11:51<08:50,  1.33iteration/s, mean_rewards=-931]    \u001b[A\n",
            "Training:  65%|██████▍   | 1294/2000 [11:51<09:52,  1.19iteration/s, mean_rewards=-931]\u001b[A\n",
            "Training:  65%|██████▍   | 1294/2000 [11:52<09:52,  1.19iteration/s, mean_rewards=-1.51e+3]\u001b[A\n",
            "Training:  65%|██████▍   | 1295/2000 [11:52<10:50,  1.08iteration/s, mean_rewards=-1.51e+3]\u001b[A\n",
            "Training:  65%|██████▍   | 1295/2000 [11:52<10:50,  1.08iteration/s, mean_rewards=-596]    \u001b[A\n",
            "Training:  65%|██████▍   | 1296/2000 [11:53<09:09,  1.28iteration/s, mean_rewards=-596]\u001b[A\n",
            "Training:  65%|██████▍   | 1296/2000 [11:53<09:09,  1.28iteration/s, mean_rewards=-400]\u001b[A\n",
            "Training:  65%|██████▍   | 1297/2000 [11:53<07:49,  1.50iteration/s, mean_rewards=-400]\u001b[A\n",
            "Training:  65%|██████▍   | 1297/2000 [11:53<07:49,  1.50iteration/s, mean_rewards=-300]\u001b[A\n",
            "Training:  65%|██████▍   | 1298/2000 [11:53<06:52,  1.70iteration/s, mean_rewards=-300]\u001b[A\n",
            "Training:  65%|██████▍   | 1298/2000 [11:54<06:52,  1.70iteration/s, mean_rewards=-667]\u001b[A\n",
            "Training:  65%|██████▍   | 1299/2000 [11:54<07:02,  1.66iteration/s, mean_rewards=-667]\u001b[A\n",
            "Training:  65%|██████▍   | 1299/2000 [11:55<07:02,  1.66iteration/s, mean_rewards=-848]\u001b[A\n",
            "Training:  65%|██████▌   | 1300/2000 [11:55<07:43,  1.51iteration/s, mean_rewards=-848]\u001b[A\n",
            "Training:  65%|██████▌   | 1300/2000 [11:55<07:43,  1.51iteration/s, mean_rewards=-393]\u001b[A\n",
            "Training:  65%|██████▌   | 1301/2000 [11:55<06:51,  1.70iteration/s, mean_rewards=-393]\u001b[A\n",
            "Training:  65%|██████▌   | 1301/2000 [11:55<06:51,  1.70iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  65%|██████▌   | 1302/2000 [11:56<05:53,  1.98iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  65%|██████▌   | 1302/2000 [11:56<05:53,  1.98iteration/s, mean_rewards=-472]\u001b[A\n",
            "Training:  65%|██████▌   | 1303/2000 [11:56<05:40,  2.05iteration/s, mean_rewards=-472]\u001b[A\n",
            "Training:  65%|██████▌   | 1303/2000 [11:56<05:40,  2.05iteration/s, mean_rewards=-326]\u001b[A\n",
            "Training:  65%|██████▌   | 1304/2000 [11:56<05:33,  2.09iteration/s, mean_rewards=-326]\u001b[A\n",
            "Training:  65%|██████▌   | 1304/2000 [11:57<05:33,  2.09iteration/s, mean_rewards=-444]\u001b[A\n",
            "Training:  65%|██████▌   | 1305/2000 [11:57<05:27,  2.12iteration/s, mean_rewards=-444]\u001b[A\n",
            "Training:  65%|██████▌   | 1305/2000 [11:57<05:27,  2.12iteration/s, mean_rewards=-419]\u001b[A\n",
            "Training:  65%|██████▌   | 1306/2000 [11:57<05:34,  2.07iteration/s, mean_rewards=-419]\u001b[A\n",
            "Training:  65%|██████▌   | 1306/2000 [11:58<05:34,  2.07iteration/s, mean_rewards=-640]\u001b[A\n",
            "Training:  65%|██████▌   | 1307/2000 [11:58<05:58,  1.93iteration/s, mean_rewards=-640]\u001b[A\n",
            "Training:  65%|██████▌   | 1307/2000 [11:58<05:58,  1.93iteration/s, mean_rewards=-99.2]\u001b[A\n",
            "Training:  65%|██████▌   | 1308/2000 [11:58<05:15,  2.19iteration/s, mean_rewards=-99.2]\u001b[A\n",
            "Training:  65%|██████▌   | 1308/2000 [11:59<05:15,  2.19iteration/s, mean_rewards=-287] \u001b[A\n",
            "Training:  65%|██████▌   | 1309/2000 [11:59<05:00,  2.30iteration/s, mean_rewards=-287]\u001b[A\n",
            "Training:  65%|██████▌   | 1309/2000 [11:59<05:00,  2.30iteration/s, mean_rewards=-730]\u001b[A\n",
            "Training:  66%|██████▌   | 1310/2000 [11:59<05:23,  2.13iteration/s, mean_rewards=-730]\u001b[A\n",
            "Training:  66%|██████▌   | 1310/2000 [11:59<05:23,  2.13iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  66%|██████▌   | 1311/2000 [12:00<05:06,  2.25iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  66%|██████▌   | 1311/2000 [12:00<05:06,  2.25iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  66%|██████▌   | 1312/2000 [12:00<04:54,  2.34iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  66%|██████▌   | 1312/2000 [12:00<04:54,  2.34iteration/s, mean_rewards=-490]\u001b[A\n",
            "Training:  66%|██████▌   | 1313/2000 [12:01<05:27,  2.10iteration/s, mean_rewards=-490]\u001b[A\n",
            "Training:  66%|██████▌   | 1313/2000 [12:01<05:27,  2.10iteration/s, mean_rewards=-390]\u001b[A\n",
            "Training:  66%|██████▌   | 1314/2000 [12:01<05:30,  2.07iteration/s, mean_rewards=-390]\u001b[A\n",
            "Training:  66%|██████▌   | 1314/2000 [12:02<05:30,  2.07iteration/s, mean_rewards=-542]\u001b[A\n",
            "Training:  66%|██████▌   | 1315/2000 [12:02<06:24,  1.78iteration/s, mean_rewards=-542]\u001b[A\n",
            "Training:  66%|██████▌   | 1315/2000 [12:03<06:24,  1.78iteration/s, mean_rewards=-924]\u001b[A\n",
            "Training:  66%|██████▌   | 1316/2000 [12:03<08:03,  1.42iteration/s, mean_rewards=-924]\u001b[A\n",
            "Training:  66%|██████▌   | 1316/2000 [12:03<08:03,  1.42iteration/s, mean_rewards=-340]\u001b[A\n",
            "Training:  66%|██████▌   | 1317/2000 [12:03<07:24,  1.54iteration/s, mean_rewards=-340]\u001b[A\n",
            "Training:  66%|██████▌   | 1317/2000 [12:04<07:24,  1.54iteration/s, mean_rewards=-331]\u001b[A\n",
            "Training:  66%|██████▌   | 1318/2000 [12:04<06:54,  1.65iteration/s, mean_rewards=-331]\u001b[A\n",
            "Training:  66%|██████▌   | 1318/2000 [12:04<06:54,  1.65iteration/s, mean_rewards=-349]\u001b[A\n",
            "Training:  66%|██████▌   | 1319/2000 [12:04<06:40,  1.70iteration/s, mean_rewards=-349]\u001b[A\n",
            "Training:  66%|██████▌   | 1319/2000 [12:05<06:40,  1.70iteration/s, mean_rewards=-1.08e+3]\u001b[A\n",
            "Training:  66%|██████▌   | 1320/2000 [12:05<07:08,  1.59iteration/s, mean_rewards=-1.08e+3]\u001b[A\n",
            "Training:  66%|██████▌   | 1320/2000 [12:06<07:08,  1.59iteration/s, mean_rewards=-673]    \u001b[A\n",
            "Training:  66%|██████▌   | 1321/2000 [12:06<06:51,  1.65iteration/s, mean_rewards=-673]\u001b[A\n",
            "Training:  66%|██████▌   | 1321/2000 [12:06<06:51,  1.65iteration/s, mean_rewards=-605]\u001b[A\n",
            "Training:  66%|██████▌   | 1322/2000 [12:06<06:29,  1.74iteration/s, mean_rewards=-605]\u001b[A\n",
            "Training:  66%|██████▌   | 1322/2000 [12:07<06:29,  1.74iteration/s, mean_rewards=-1.12e+3]\u001b[A\n",
            "Training:  66%|██████▌   | 1323/2000 [12:07<07:08,  1.58iteration/s, mean_rewards=-1.12e+3]\u001b[A\n",
            "Training:  66%|██████▌   | 1323/2000 [12:07<07:08,  1.58iteration/s, mean_rewards=-120]    \u001b[A\n",
            "Training:  66%|██████▌   | 1324/2000 [12:07<06:00,  1.87iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  66%|██████▌   | 1324/2000 [12:08<06:00,  1.87iteration/s, mean_rewards=-342]\u001b[A\n",
            "Training:  66%|██████▋   | 1325/2000 [12:08<05:32,  2.03iteration/s, mean_rewards=-342]\u001b[A\n",
            "Training:  66%|██████▋   | 1325/2000 [12:08<05:32,  2.03iteration/s, mean_rewards=-589]\u001b[A\n",
            "Training:  66%|██████▋   | 1326/2000 [12:08<05:40,  1.98iteration/s, mean_rewards=-589]\u001b[A\n",
            "Training:  66%|██████▋   | 1326/2000 [12:09<05:40,  1.98iteration/s, mean_rewards=-331]\u001b[A\n",
            "Training:  66%|██████▋   | 1327/2000 [12:09<05:19,  2.10iteration/s, mean_rewards=-331]\u001b[A\n",
            "Training:  66%|██████▋   | 1327/2000 [12:09<05:19,  2.10iteration/s, mean_rewards=-1.1e+3]\u001b[A\n",
            "Training:  66%|██████▋   | 1328/2000 [12:09<06:27,  1.73iteration/s, mean_rewards=-1.1e+3]\u001b[A\n",
            "Training:  66%|██████▋   | 1328/2000 [12:10<06:27,  1.73iteration/s, mean_rewards=-376]   \u001b[A\n",
            "Training:  66%|██████▋   | 1329/2000 [12:10<06:02,  1.85iteration/s, mean_rewards=-376]\u001b[A\n",
            "Training:  66%|██████▋   | 1329/2000 [12:10<06:02,  1.85iteration/s, mean_rewards=-322]\u001b[A\n",
            "Training:  66%|██████▋   | 1330/2000 [12:10<05:32,  2.01iteration/s, mean_rewards=-322]\u001b[A\n",
            "Training:  66%|██████▋   | 1330/2000 [12:11<05:32,  2.01iteration/s, mean_rewards=-699]\u001b[A\n",
            "Training:  67%|██████▋   | 1331/2000 [12:11<05:52,  1.90iteration/s, mean_rewards=-699]\u001b[A\n",
            "Training:  67%|██████▋   | 1331/2000 [12:12<05:52,  1.90iteration/s, mean_rewards=-1.18e+3]\u001b[A\n",
            "Training:  67%|██████▋   | 1332/2000 [12:12<07:02,  1.58iteration/s, mean_rewards=-1.18e+3]\u001b[A\n",
            "Training:  67%|██████▋   | 1332/2000 [12:12<07:02,  1.58iteration/s, mean_rewards=-675]    \u001b[A\n",
            "Training:  67%|██████▋   | 1333/2000 [12:12<07:08,  1.56iteration/s, mean_rewards=-675]\u001b[A\n",
            "Training:  67%|██████▋   | 1333/2000 [12:13<07:08,  1.56iteration/s, mean_rewards=-557]\u001b[A\n",
            "Training:  67%|██████▋   | 1334/2000 [12:13<06:52,  1.61iteration/s, mean_rewards=-557]\u001b[A\n",
            "Training:  67%|██████▋   | 1334/2000 [12:13<06:52,  1.61iteration/s, mean_rewards=-619]\u001b[A\n",
            "Training:  67%|██████▋   | 1335/2000 [12:14<06:36,  1.68iteration/s, mean_rewards=-619]\u001b[A\n",
            "Training:  67%|██████▋   | 1335/2000 [12:14<06:36,  1.68iteration/s, mean_rewards=-1.34e+3]\u001b[A\n",
            "Training:  67%|██████▋   | 1336/2000 [12:14<07:33,  1.46iteration/s, mean_rewards=-1.34e+3]\u001b[A\n",
            "Training:  67%|██████▋   | 1336/2000 [12:15<07:33,  1.46iteration/s, mean_rewards=-342]    \u001b[A\n",
            "Training:  67%|██████▋   | 1337/2000 [12:15<06:58,  1.58iteration/s, mean_rewards=-342]\u001b[A\n",
            "Training:  67%|██████▋   | 1337/2000 [12:15<06:58,  1.58iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  67%|██████▋   | 1338/2000 [12:15<06:19,  1.74iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  67%|██████▋   | 1338/2000 [12:16<06:19,  1.74iteration/s, mean_rewards=-595]\u001b[A\n",
            "Training:  67%|██████▋   | 1339/2000 [12:16<06:19,  1.74iteration/s, mean_rewards=-595]\u001b[A\n",
            "Training:  67%|██████▋   | 1339/2000 [12:16<06:19,  1.74iteration/s, mean_rewards=-381]\u001b[A\n",
            "Training:  67%|██████▋   | 1340/2000 [12:17<06:45,  1.63iteration/s, mean_rewards=-381]\u001b[A\n",
            "Training:  67%|██████▋   | 1340/2000 [12:17<06:45,  1.63iteration/s, mean_rewards=-553]\u001b[A\n",
            "Training:  67%|██████▋   | 1341/2000 [12:17<06:55,  1.59iteration/s, mean_rewards=-553]\u001b[A\n",
            "Training:  67%|██████▋   | 1341/2000 [12:18<06:55,  1.59iteration/s, mean_rewards=-507]\u001b[A\n",
            "Training:  67%|██████▋   | 1342/2000 [12:18<06:13,  1.76iteration/s, mean_rewards=-507]\u001b[A\n",
            "Training:  67%|██████▋   | 1342/2000 [12:18<06:13,  1.76iteration/s, mean_rewards=-542]\u001b[A\n",
            "Training:  67%|██████▋   | 1343/2000 [12:18<06:07,  1.79iteration/s, mean_rewards=-542]\u001b[A\n",
            "Training:  67%|██████▋   | 1343/2000 [12:19<06:07,  1.79iteration/s, mean_rewards=-425]\u001b[A\n",
            "Training:  67%|██████▋   | 1344/2000 [12:19<05:38,  1.94iteration/s, mean_rewards=-425]\u001b[A\n",
            "Training:  67%|██████▋   | 1344/2000 [12:19<05:38,  1.94iteration/s, mean_rewards=-1.1e+3]\u001b[A\n",
            "Training:  67%|██████▋   | 1345/2000 [12:20<06:38,  1.64iteration/s, mean_rewards=-1.1e+3]\u001b[A\n",
            "Training:  67%|██████▋   | 1345/2000 [12:20<06:38,  1.64iteration/s, mean_rewards=-716]   \u001b[A\n",
            "Training:  67%|██████▋   | 1346/2000 [12:20<06:44,  1.62iteration/s, mean_rewards=-716]\u001b[A\n",
            "Training:  67%|██████▋   | 1346/2000 [12:21<06:44,  1.62iteration/s, mean_rewards=-549]\u001b[A\n",
            "Training:  67%|██████▋   | 1347/2000 [12:21<06:57,  1.57iteration/s, mean_rewards=-549]\u001b[A\n",
            "Training:  67%|██████▋   | 1347/2000 [12:21<06:57,  1.57iteration/s, mean_rewards=-885]\u001b[A\n",
            "Training:  67%|██████▋   | 1348/2000 [12:22<07:00,  1.55iteration/s, mean_rewards=-885]\u001b[A\n",
            "Training:  67%|██████▋   | 1348/2000 [12:22<07:00,  1.55iteration/s, mean_rewards=-385]\u001b[A\n",
            "Training:  67%|██████▋   | 1349/2000 [12:22<06:19,  1.72iteration/s, mean_rewards=-385]\u001b[A\n",
            "Training:  67%|██████▋   | 1349/2000 [12:22<06:19,  1.72iteration/s, mean_rewards=-336]\u001b[A\n",
            "Training:  68%|██████▊   | 1350/2000 [12:22<05:42,  1.90iteration/s, mean_rewards=-336]\u001b[A\n",
            "Training:  68%|██████▊   | 1350/2000 [12:23<05:42,  1.90iteration/s, mean_rewards=-457]\u001b[A\n",
            "Training:  68%|██████▊   | 1351/2000 [12:23<05:28,  1.98iteration/s, mean_rewards=-457]\u001b[A\n",
            "Training:  68%|██████▊   | 1351/2000 [12:23<05:28,  1.98iteration/s, mean_rewards=-711]\u001b[A\n",
            "Training:  68%|██████▊   | 1352/2000 [12:24<06:04,  1.78iteration/s, mean_rewards=-711]\u001b[A\n",
            "Training:  68%|██████▊   | 1352/2000 [12:24<06:04,  1.78iteration/s, mean_rewards=-633]\u001b[A\n",
            "Training:  68%|██████▊   | 1353/2000 [12:24<06:09,  1.75iteration/s, mean_rewards=-633]\u001b[A\n",
            "Training:  68%|██████▊   | 1353/2000 [12:25<06:09,  1.75iteration/s, mean_rewards=-742]\u001b[A\n",
            "Training:  68%|██████▊   | 1354/2000 [12:25<06:19,  1.70iteration/s, mean_rewards=-742]\u001b[A\n",
            "Training:  68%|██████▊   | 1354/2000 [12:25<06:19,  1.70iteration/s, mean_rewards=-465]\u001b[A\n",
            "Training:  68%|██████▊   | 1355/2000 [12:25<06:11,  1.73iteration/s, mean_rewards=-465]\u001b[A\n",
            "Training:  68%|██████▊   | 1355/2000 [12:26<06:11,  1.73iteration/s, mean_rewards=-477]\u001b[A\n",
            "Training:  68%|██████▊   | 1356/2000 [12:26<05:52,  1.83iteration/s, mean_rewards=-477]\u001b[A\n",
            "Training:  68%|██████▊   | 1356/2000 [12:26<05:52,  1.83iteration/s, mean_rewards=-748]\u001b[A\n",
            "Training:  68%|██████▊   | 1357/2000 [12:27<06:28,  1.66iteration/s, mean_rewards=-748]\u001b[A\n",
            "Training:  68%|██████▊   | 1357/2000 [12:27<06:28,  1.66iteration/s, mean_rewards=-416]\u001b[A\n",
            "Training:  68%|██████▊   | 1358/2000 [12:27<05:58,  1.79iteration/s, mean_rewards=-416]\u001b[A\n",
            "Training:  68%|██████▊   | 1358/2000 [12:27<05:58,  1.79iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  68%|██████▊   | 1359/2000 [12:27<05:12,  2.05iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  68%|██████▊   | 1359/2000 [12:28<05:12,  2.05iteration/s, mean_rewards=-320]\u001b[A\n",
            "Training:  68%|██████▊   | 1360/2000 [12:28<05:15,  2.03iteration/s, mean_rewards=-320]\u001b[A\n",
            "Training:  68%|██████▊   | 1360/2000 [12:28<05:15,  2.03iteration/s, mean_rewards=-604]\u001b[A\n",
            "Training:  68%|██████▊   | 1361/2000 [12:28<05:28,  1.94iteration/s, mean_rewards=-604]\u001b[A\n",
            "Training:  68%|██████▊   | 1361/2000 [12:29<05:28,  1.94iteration/s, mean_rewards=-732]\u001b[A\n",
            "Training:  68%|██████▊   | 1362/2000 [12:29<06:31,  1.63iteration/s, mean_rewards=-732]\u001b[A\n",
            "Training:  68%|██████▊   | 1362/2000 [12:30<06:31,  1.63iteration/s, mean_rewards=-523]\u001b[A\n",
            "Training:  68%|██████▊   | 1363/2000 [12:30<06:48,  1.56iteration/s, mean_rewards=-523]\u001b[A\n",
            "Training:  68%|██████▊   | 1363/2000 [12:30<06:48,  1.56iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  68%|██████▊   | 1364/2000 [12:30<05:51,  1.81iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  68%|██████▊   | 1364/2000 [12:31<05:51,  1.81iteration/s, mean_rewards=-334]\u001b[A\n",
            "Training:  68%|██████▊   | 1365/2000 [12:31<05:30,  1.92iteration/s, mean_rewards=-334]\u001b[A\n",
            "Training:  68%|██████▊   | 1365/2000 [12:31<05:30,  1.92iteration/s, mean_rewards=-377]\u001b[A\n",
            "Training:  68%|██████▊   | 1366/2000 [12:31<05:11,  2.04iteration/s, mean_rewards=-377]\u001b[A\n",
            "Training:  68%|██████▊   | 1366/2000 [12:32<05:11,  2.04iteration/s, mean_rewards=-2e+3]\u001b[A\n",
            "Training:  68%|██████▊   | 1367/2000 [12:32<07:50,  1.35iteration/s, mean_rewards=-2e+3]\u001b[A\n",
            "Training:  68%|██████▊   | 1367/2000 [12:33<07:50,  1.35iteration/s, mean_rewards=-981] \u001b[A\n",
            "Training:  68%|██████▊   | 1368/2000 [12:33<08:13,  1.28iteration/s, mean_rewards=-981]\u001b[A\n",
            "Training:  68%|██████▊   | 1368/2000 [12:34<08:13,  1.28iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  68%|██████▊   | 1369/2000 [12:34<07:08,  1.47iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  68%|██████▊   | 1369/2000 [12:34<07:08,  1.47iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  68%|██████▊   | 1370/2000 [12:34<06:00,  1.75iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  68%|██████▊   | 1370/2000 [12:34<06:00,  1.75iteration/s, mean_rewards=-81.1]\u001b[A\n",
            "Training:  69%|██████▊   | 1371/2000 [12:34<05:24,  1.94iteration/s, mean_rewards=-81.1]\u001b[A\n",
            "Training:  69%|██████▊   | 1371/2000 [12:35<05:24,  1.94iteration/s, mean_rewards=-162] \u001b[A\n",
            "Training:  69%|██████▊   | 1372/2000 [12:35<04:54,  2.13iteration/s, mean_rewards=-162]\u001b[A\n",
            "Training:  69%|██████▊   | 1372/2000 [12:35<04:54,  2.13iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  69%|██████▊   | 1373/2000 [12:35<04:36,  2.27iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  69%|██████▊   | 1373/2000 [12:35<04:36,  2.27iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  69%|██████▊   | 1374/2000 [12:36<04:33,  2.29iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  69%|██████▊   | 1374/2000 [12:36<04:33,  2.29iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  69%|██████▉   | 1375/2000 [12:36<04:27,  2.34iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  69%|██████▉   | 1375/2000 [12:36<04:27,  2.34iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  69%|██████▉   | 1376/2000 [12:36<04:20,  2.39iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  69%|██████▉   | 1376/2000 [12:37<04:20,  2.39iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  69%|██████▉   | 1377/2000 [12:37<04:11,  2.48iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  69%|██████▉   | 1377/2000 [12:37<04:11,  2.48iteration/s, mean_rewards=-100]\u001b[A\n",
            "Training:  69%|██████▉   | 1378/2000 [12:37<03:55,  2.65iteration/s, mean_rewards=-100]\u001b[A\n",
            "Training:  69%|██████▉   | 1378/2000 [12:37<03:55,  2.65iteration/s, mean_rewards=-218]\u001b[A\n",
            "Training:  69%|██████▉   | 1379/2000 [12:38<04:07,  2.51iteration/s, mean_rewards=-218]\u001b[A\n",
            "Training:  69%|██████▉   | 1379/2000 [12:38<04:07,  2.51iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  69%|██████▉   | 1380/2000 [12:38<03:50,  2.68iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  69%|██████▉   | 1380/2000 [12:38<03:50,  2.68iteration/s, mean_rewards=-188]\u001b[A\n",
            "Training:  69%|██████▉   | 1381/2000 [12:38<03:55,  2.63iteration/s, mean_rewards=-188]\u001b[A\n",
            "Training:  69%|██████▉   | 1381/2000 [12:39<03:55,  2.63iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  69%|██████▉   | 1382/2000 [12:39<03:57,  2.60iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  69%|██████▉   | 1382/2000 [12:39<03:57,  2.60iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  69%|██████▉   | 1383/2000 [12:39<03:51,  2.66iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  69%|██████▉   | 1383/2000 [12:39<03:51,  2.66iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  69%|██████▉   | 1384/2000 [12:39<03:40,  2.80iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  69%|██████▉   | 1384/2000 [12:40<03:40,  2.80iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  69%|██████▉   | 1385/2000 [12:40<03:33,  2.89iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  69%|██████▉   | 1385/2000 [12:40<03:33,  2.89iteration/s, mean_rewards=-79.8]\u001b[A\n",
            "Training:  69%|██████▉   | 1386/2000 [12:40<04:00,  2.55iteration/s, mean_rewards=-79.8]\u001b[A\n",
            "Training:  69%|██████▉   | 1386/2000 [12:40<04:00,  2.55iteration/s, mean_rewards=-149] \u001b[A\n",
            "Training:  69%|██████▉   | 1387/2000 [12:41<04:08,  2.46iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  69%|██████▉   | 1387/2000 [12:41<04:08,  2.46iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  69%|██████▉   | 1388/2000 [12:41<04:23,  2.32iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  69%|██████▉   | 1388/2000 [12:41<04:23,  2.32iteration/s, mean_rewards=-162]\u001b[A\n",
            "Training:  69%|██████▉   | 1389/2000 [12:42<04:35,  2.22iteration/s, mean_rewards=-162]\u001b[A\n",
            "Training:  69%|██████▉   | 1389/2000 [12:42<04:35,  2.22iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  70%|██████▉   | 1390/2000 [12:42<04:34,  2.22iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  70%|██████▉   | 1390/2000 [12:42<04:34,  2.22iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  70%|██████▉   | 1391/2000 [12:42<04:29,  2.26iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  70%|██████▉   | 1391/2000 [12:43<04:29,  2.26iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  70%|██████▉   | 1392/2000 [12:43<04:26,  2.28iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  70%|██████▉   | 1392/2000 [12:43<04:26,  2.28iteration/s, mean_rewards=-105]\u001b[A\n",
            "Training:  70%|██████▉   | 1393/2000 [12:43<04:17,  2.35iteration/s, mean_rewards=-105]\u001b[A\n",
            "Training:  70%|██████▉   | 1393/2000 [12:44<04:17,  2.35iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  70%|██████▉   | 1394/2000 [12:44<04:09,  2.42iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  70%|██████▉   | 1394/2000 [12:44<04:09,  2.42iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  70%|██████▉   | 1395/2000 [12:44<03:58,  2.53iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  70%|██████▉   | 1395/2000 [12:44<03:58,  2.53iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  70%|██████▉   | 1396/2000 [12:44<03:44,  2.69iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  70%|██████▉   | 1396/2000 [12:45<03:44,  2.69iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:  70%|██████▉   | 1397/2000 [12:45<03:48,  2.64iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:  70%|██████▉   | 1397/2000 [12:45<03:48,  2.64iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  70%|██████▉   | 1398/2000 [12:45<03:36,  2.78iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  70%|██████▉   | 1398/2000 [12:45<03:36,  2.78iteration/s, mean_rewards=-184]\u001b[A\n",
            "Training:  70%|██████▉   | 1399/2000 [12:45<03:39,  2.74iteration/s, mean_rewards=-184]\u001b[A\n",
            "Training:  70%|██████▉   | 1399/2000 [12:46<03:39,  2.74iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  70%|███████   | 1400/2000 [12:46<03:40,  2.73iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  70%|███████   | 1400/2000 [12:46<03:40,  2.73iteration/s, mean_rewards=-218]\u001b[A\n",
            "Training:  70%|███████   | 1401/2000 [12:47<05:11,  1.92iteration/s, mean_rewards=-218]\u001b[A\n",
            "Training:  70%|███████   | 1401/2000 [12:47<05:11,  1.92iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  70%|███████   | 1402/2000 [12:47<04:49,  2.06iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  70%|███████   | 1402/2000 [12:47<04:49,  2.06iteration/s, mean_rewards=-314]\u001b[A\n",
            "Training:  70%|███████   | 1403/2000 [12:48<04:46,  2.08iteration/s, mean_rewards=-314]\u001b[A\n",
            "Training:  70%|███████   | 1403/2000 [12:48<04:46,  2.08iteration/s, mean_rewards=-87.3]\u001b[A\n",
            "Training:  70%|███████   | 1404/2000 [12:48<04:19,  2.30iteration/s, mean_rewards=-87.3]\u001b[A\n",
            "Training:  70%|███████   | 1404/2000 [12:48<04:19,  2.30iteration/s, mean_rewards=-109] \u001b[A\n",
            "Training:  70%|███████   | 1405/2000 [12:48<04:14,  2.34iteration/s, mean_rewards=-109]\u001b[A\n",
            "Training:  70%|███████   | 1405/2000 [12:49<04:14,  2.34iteration/s, mean_rewards=-340]\u001b[A\n",
            "Training:  70%|███████   | 1406/2000 [12:49<04:59,  1.99iteration/s, mean_rewards=-340]\u001b[A\n",
            "Training:  70%|███████   | 1406/2000 [12:49<04:59,  1.99iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  70%|███████   | 1407/2000 [12:49<04:36,  2.15iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  70%|███████   | 1407/2000 [12:50<04:36,  2.15iteration/s, mean_rewards=-254]\u001b[A\n",
            "Training:  70%|███████   | 1408/2000 [12:50<04:26,  2.22iteration/s, mean_rewards=-254]\u001b[A\n",
            "Training:  70%|███████   | 1408/2000 [12:50<04:26,  2.22iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  70%|███████   | 1409/2000 [12:50<04:23,  2.24iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  70%|███████   | 1409/2000 [12:50<04:23,  2.24iteration/s, mean_rewards=-251]\u001b[A\n",
            "Training:  70%|███████   | 1410/2000 [12:51<04:23,  2.24iteration/s, mean_rewards=-251]\u001b[A\n",
            "Training:  70%|███████   | 1410/2000 [12:51<04:23,  2.24iteration/s, mean_rewards=-308]\u001b[A\n",
            "Training:  71%|███████   | 1411/2000 [12:51<05:06,  1.92iteration/s, mean_rewards=-308]\u001b[A\n",
            "Training:  71%|███████   | 1411/2000 [12:52<05:06,  1.92iteration/s, mean_rewards=-225]\u001b[A\n",
            "Training:  71%|███████   | 1412/2000 [12:52<04:54,  2.00iteration/s, mean_rewards=-225]\u001b[A\n",
            "Training:  71%|███████   | 1412/2000 [12:52<04:54,  2.00iteration/s, mean_rewards=-188]\u001b[A\n",
            "Training:  71%|███████   | 1413/2000 [12:52<04:46,  2.05iteration/s, mean_rewards=-188]\u001b[A\n",
            "Training:  71%|███████   | 1413/2000 [12:53<04:46,  2.05iteration/s, mean_rewards=-283]\u001b[A\n",
            "Training:  71%|███████   | 1414/2000 [12:53<05:22,  1.82iteration/s, mean_rewards=-283]\u001b[A\n",
            "Training:  71%|███████   | 1414/2000 [12:53<05:22,  1.82iteration/s, mean_rewards=-160]\u001b[A\n",
            "Training:  71%|███████   | 1415/2000 [12:53<05:03,  1.93iteration/s, mean_rewards=-160]\u001b[A\n",
            "Training:  71%|███████   | 1415/2000 [12:54<05:03,  1.93iteration/s, mean_rewards=-367]\u001b[A\n",
            "Training:  71%|███████   | 1416/2000 [12:54<05:19,  1.83iteration/s, mean_rewards=-367]\u001b[A\n",
            "Training:  71%|███████   | 1416/2000 [12:54<05:19,  1.83iteration/s, mean_rewards=-166]\u001b[A\n",
            "Training:  71%|███████   | 1417/2000 [12:55<05:26,  1.79iteration/s, mean_rewards=-166]\u001b[A\n",
            "Training:  71%|███████   | 1417/2000 [12:55<05:26,  1.79iteration/s, mean_rewards=-290]\u001b[A\n",
            "Training:  71%|███████   | 1418/2000 [12:55<05:47,  1.67iteration/s, mean_rewards=-290]\u001b[A\n",
            "Training:  71%|███████   | 1418/2000 [12:56<05:47,  1.67iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  71%|███████   | 1419/2000 [12:56<05:26,  1.78iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  71%|███████   | 1419/2000 [12:56<05:26,  1.78iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  71%|███████   | 1420/2000 [12:56<04:44,  2.04iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  71%|███████   | 1420/2000 [12:56<04:44,  2.04iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  71%|███████   | 1421/2000 [12:56<04:12,  2.29iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  71%|███████   | 1421/2000 [12:57<04:12,  2.29iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  71%|███████   | 1422/2000 [12:57<03:52,  2.49iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  71%|███████   | 1422/2000 [12:57<03:52,  2.49iteration/s, mean_rewards=-71.8]\u001b[A\n",
            "Training:  71%|███████   | 1423/2000 [12:57<03:50,  2.51iteration/s, mean_rewards=-71.8]\u001b[A\n",
            "Training:  71%|███████   | 1423/2000 [12:57<03:50,  2.51iteration/s, mean_rewards=-134] \u001b[A\n",
            "Training:  71%|███████   | 1424/2000 [12:57<03:41,  2.59iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  71%|███████   | 1424/2000 [12:58<03:41,  2.59iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  71%|███████▏  | 1425/2000 [12:58<03:38,  2.63iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  71%|███████▏  | 1425/2000 [12:58<03:38,  2.63iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  71%|███████▏  | 1426/2000 [12:58<03:36,  2.65iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  71%|███████▏  | 1426/2000 [12:58<03:36,  2.65iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  71%|███████▏  | 1427/2000 [12:59<03:34,  2.68iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  71%|███████▏  | 1427/2000 [12:59<03:34,  2.68iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  71%|███████▏  | 1428/2000 [12:59<03:44,  2.55iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  71%|███████▏  | 1428/2000 [12:59<03:44,  2.55iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  71%|███████▏  | 1429/2000 [12:59<03:30,  2.71iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  71%|███████▏  | 1429/2000 [13:00<03:30,  2.71iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  72%|███████▏  | 1430/2000 [13:00<03:20,  2.85iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  72%|███████▏  | 1430/2000 [13:00<03:20,  2.85iteration/s, mean_rewards=-194]\u001b[A\n",
            "Training:  72%|███████▏  | 1431/2000 [13:00<03:26,  2.76iteration/s, mean_rewards=-194]\u001b[A\n",
            "Training:  72%|███████▏  | 1431/2000 [13:00<03:26,  2.76iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  72%|███████▏  | 1432/2000 [13:00<03:24,  2.77iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  72%|███████▏  | 1432/2000 [13:01<03:24,  2.77iteration/s, mean_rewards=-115]\u001b[A\n",
            "Training:  72%|███████▏  | 1433/2000 [13:01<03:24,  2.77iteration/s, mean_rewards=-115]\u001b[A\n",
            "Training:  72%|███████▏  | 1433/2000 [13:01<03:24,  2.77iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:  72%|███████▏  | 1434/2000 [13:01<03:18,  2.85iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:  72%|███████▏  | 1434/2000 [13:01<03:18,  2.85iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  72%|███████▏  | 1435/2000 [13:01<03:13,  2.92iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  72%|███████▏  | 1435/2000 [13:02<03:13,  2.92iteration/s, mean_rewards=-179]\u001b[A\n",
            "Training:  72%|███████▏  | 1436/2000 [13:02<03:20,  2.81iteration/s, mean_rewards=-179]\u001b[A\n",
            "Training:  72%|███████▏  | 1436/2000 [13:02<03:20,  2.81iteration/s, mean_rewards=-52.4]\u001b[A\n",
            "Training:  72%|███████▏  | 1437/2000 [13:02<03:28,  2.70iteration/s, mean_rewards=-52.4]\u001b[A\n",
            "Training:  72%|███████▏  | 1437/2000 [13:02<03:28,  2.70iteration/s, mean_rewards=-123] \u001b[A\n",
            "Training:  72%|███████▏  | 1438/2000 [13:03<03:26,  2.72iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  72%|███████▏  | 1438/2000 [13:03<03:26,  2.72iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  72%|███████▏  | 1439/2000 [13:03<03:33,  2.63iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  72%|███████▏  | 1439/2000 [13:03<03:33,  2.63iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  72%|███████▏  | 1440/2000 [13:03<03:21,  2.79iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  72%|███████▏  | 1440/2000 [13:03<03:21,  2.79iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:  72%|███████▏  | 1441/2000 [13:04<03:14,  2.88iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:  72%|███████▏  | 1441/2000 [13:04<03:14,  2.88iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  72%|███████▏  | 1442/2000 [13:04<03:19,  2.79iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  72%|███████▏  | 1442/2000 [13:04<03:19,  2.79iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:  72%|███████▏  | 1443/2000 [13:04<03:22,  2.75iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:  72%|███████▏  | 1443/2000 [13:05<03:22,  2.75iteration/s, mean_rewards=-71.1]\u001b[A\n",
            "Training:  72%|███████▏  | 1444/2000 [13:05<03:33,  2.60iteration/s, mean_rewards=-71.1]\u001b[A\n",
            "Training:  72%|███████▏  | 1444/2000 [13:05<03:33,  2.60iteration/s, mean_rewards=-154] \u001b[A\n",
            "Training:  72%|███████▏  | 1445/2000 [13:05<03:42,  2.50iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  72%|███████▏  | 1445/2000 [13:05<03:42,  2.50iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  72%|███████▏  | 1446/2000 [13:06<03:28,  2.65iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  72%|███████▏  | 1446/2000 [13:06<03:28,  2.65iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  72%|███████▏  | 1447/2000 [13:06<03:24,  2.70iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  72%|███████▏  | 1447/2000 [13:06<03:24,  2.70iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  72%|███████▏  | 1448/2000 [13:06<03:45,  2.44iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  72%|███████▏  | 1448/2000 [13:07<03:45,  2.44iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  72%|███████▏  | 1449/2000 [13:07<03:44,  2.46iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  72%|███████▏  | 1449/2000 [13:07<03:44,  2.46iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  72%|███████▎  | 1450/2000 [13:07<04:03,  2.26iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  72%|███████▎  | 1450/2000 [13:08<04:03,  2.26iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  73%|███████▎  | 1451/2000 [13:08<04:13,  2.17iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  73%|███████▎  | 1451/2000 [13:08<04:13,  2.17iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  73%|███████▎  | 1452/2000 [13:08<04:22,  2.09iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  73%|███████▎  | 1452/2000 [13:09<04:22,  2.09iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:  73%|███████▎  | 1453/2000 [13:09<04:25,  2.06iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:  73%|███████▎  | 1453/2000 [13:09<04:25,  2.06iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  73%|███████▎  | 1454/2000 [13:09<03:57,  2.30iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  73%|███████▎  | 1454/2000 [13:09<03:57,  2.30iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  73%|███████▎  | 1455/2000 [13:09<03:36,  2.52iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  73%|███████▎  | 1455/2000 [13:10<03:36,  2.52iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  73%|███████▎  | 1456/2000 [13:10<03:31,  2.57iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  73%|███████▎  | 1456/2000 [13:10<03:31,  2.57iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  73%|███████▎  | 1457/2000 [13:10<03:26,  2.63iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  73%|███████▎  | 1457/2000 [13:10<03:26,  2.63iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  73%|███████▎  | 1458/2000 [13:11<03:26,  2.62iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  73%|███████▎  | 1458/2000 [13:11<03:26,  2.62iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  73%|███████▎  | 1459/2000 [13:11<03:28,  2.60iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  73%|███████▎  | 1459/2000 [13:11<03:28,  2.60iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  73%|███████▎  | 1460/2000 [13:11<03:34,  2.51iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  73%|███████▎  | 1460/2000 [13:12<03:34,  2.51iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  73%|███████▎  | 1461/2000 [13:12<03:19,  2.70iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  73%|███████▎  | 1461/2000 [13:12<03:19,  2.70iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  73%|███████▎  | 1462/2000 [13:12<03:18,  2.71iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  73%|███████▎  | 1462/2000 [13:12<03:18,  2.71iteration/s, mean_rewards=-214]\u001b[A\n",
            "Training:  73%|███████▎  | 1463/2000 [13:12<03:22,  2.65iteration/s, mean_rewards=-214]\u001b[A\n",
            "Training:  73%|███████▎  | 1463/2000 [13:13<03:22,  2.65iteration/s, mean_rewards=-105]\u001b[A\n",
            "Training:  73%|███████▎  | 1464/2000 [13:13<03:10,  2.81iteration/s, mean_rewards=-105]\u001b[A\n",
            "Training:  73%|███████▎  | 1464/2000 [13:13<03:10,  2.81iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  73%|███████▎  | 1465/2000 [13:13<03:09,  2.83iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  73%|███████▎  | 1465/2000 [13:13<03:09,  2.83iteration/s, mean_rewards=-64.8]\u001b[A\n",
            "Training:  73%|███████▎  | 1466/2000 [13:14<03:28,  2.57iteration/s, mean_rewards=-64.8]\u001b[A\n",
            "Training:  73%|███████▎  | 1466/2000 [13:14<03:28,  2.57iteration/s, mean_rewards=-137] \u001b[A\n",
            "Training:  73%|███████▎  | 1467/2000 [13:14<03:27,  2.57iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  73%|███████▎  | 1467/2000 [13:14<03:27,  2.57iteration/s, mean_rewards=-162]\u001b[A\n",
            "Training:  73%|███████▎  | 1468/2000 [13:14<03:29,  2.54iteration/s, mean_rewards=-162]\u001b[A\n",
            "Training:  73%|███████▎  | 1468/2000 [13:15<03:29,  2.54iteration/s, mean_rewards=-88.8]\u001b[A\n",
            "Training:  73%|███████▎  | 1469/2000 [13:15<03:39,  2.42iteration/s, mean_rewards=-88.8]\u001b[A\n",
            "Training:  73%|███████▎  | 1469/2000 [13:15<03:39,  2.42iteration/s, mean_rewards=-115] \u001b[A\n",
            "Training:  74%|███████▎  | 1470/2000 [13:15<03:44,  2.36iteration/s, mean_rewards=-115]\u001b[A\n",
            "Training:  74%|███████▎  | 1470/2000 [13:16<03:44,  2.36iteration/s, mean_rewards=-172]\u001b[A\n",
            "Training:  74%|███████▎  | 1471/2000 [13:16<03:46,  2.33iteration/s, mean_rewards=-172]\u001b[A\n",
            "Training:  74%|███████▎  | 1471/2000 [13:16<03:46,  2.33iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  74%|███████▎  | 1472/2000 [13:16<03:28,  2.53iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  74%|███████▎  | 1472/2000 [13:16<03:28,  2.53iteration/s, mean_rewards=-159]\u001b[A\n",
            "Training:  74%|███████▎  | 1473/2000 [13:16<03:20,  2.63iteration/s, mean_rewards=-159]\u001b[A\n",
            "Training:  74%|███████▎  | 1473/2000 [13:17<03:20,  2.63iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  74%|███████▎  | 1474/2000 [13:17<03:18,  2.65iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  74%|███████▎  | 1474/2000 [13:17<03:18,  2.65iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  74%|███████▍  | 1475/2000 [13:17<03:09,  2.77iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  74%|███████▍  | 1475/2000 [13:17<03:09,  2.77iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  74%|███████▍  | 1476/2000 [13:17<03:02,  2.87iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  74%|███████▍  | 1476/2000 [13:18<03:02,  2.87iteration/s, mean_rewards=-109]\u001b[A\n",
            "Training:  74%|███████▍  | 1477/2000 [13:18<03:07,  2.78iteration/s, mean_rewards=-109]\u001b[A\n",
            "Training:  74%|███████▍  | 1477/2000 [13:18<03:07,  2.78iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  74%|███████▍  | 1478/2000 [13:18<03:06,  2.79iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  74%|███████▍  | 1478/2000 [13:18<03:06,  2.79iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  74%|███████▍  | 1479/2000 [13:19<03:13,  2.69iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  74%|███████▍  | 1479/2000 [13:19<03:13,  2.69iteration/s, mean_rewards=-240]\u001b[A\n",
            "Training:  74%|███████▍  | 1480/2000 [13:19<03:33,  2.44iteration/s, mean_rewards=-240]\u001b[A\n",
            "Training:  74%|███████▍  | 1480/2000 [13:19<03:33,  2.44iteration/s, mean_rewards=-91.4]\u001b[A\n",
            "Training:  74%|███████▍  | 1481/2000 [13:20<03:55,  2.20iteration/s, mean_rewards=-91.4]\u001b[A\n",
            "Training:  74%|███████▍  | 1481/2000 [13:20<03:55,  2.20iteration/s, mean_rewards=-128] \u001b[A\n",
            "Training:  74%|███████▍  | 1482/2000 [13:20<03:55,  2.20iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  74%|███████▍  | 1482/2000 [13:20<03:55,  2.20iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  74%|███████▍  | 1483/2000 [13:21<04:02,  2.13iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  74%|███████▍  | 1483/2000 [13:21<04:02,  2.13iteration/s, mean_rewards=-99.2]\u001b[A\n",
            "Training:  74%|███████▍  | 1484/2000 [13:21<03:55,  2.19iteration/s, mean_rewards=-99.2]\u001b[A\n",
            "Training:  74%|███████▍  | 1484/2000 [13:21<03:55,  2.19iteration/s, mean_rewards=-118] \u001b[A\n",
            "Training:  74%|███████▍  | 1485/2000 [13:22<04:08,  2.07iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  74%|███████▍  | 1485/2000 [13:22<04:08,  2.07iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  74%|███████▍  | 1486/2000 [13:22<04:07,  2.08iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  74%|███████▍  | 1486/2000 [13:22<04:07,  2.08iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  74%|███████▍  | 1487/2000 [13:22<03:49,  2.24iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  74%|███████▍  | 1487/2000 [13:23<03:49,  2.24iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  74%|███████▍  | 1488/2000 [13:23<03:42,  2.30iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  74%|███████▍  | 1488/2000 [13:23<03:42,  2.30iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  74%|███████▍  | 1489/2000 [13:23<03:24,  2.50iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  74%|███████▍  | 1489/2000 [13:23<03:24,  2.50iteration/s, mean_rewards=-62] \u001b[A\n",
            "Training:  74%|███████▍  | 1490/2000 [13:23<03:12,  2.65iteration/s, mean_rewards=-62]\u001b[A\n",
            "Training:  74%|███████▍  | 1490/2000 [13:24<03:12,  2.65iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  75%|███████▍  | 1491/2000 [13:24<03:04,  2.76iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  75%|███████▍  | 1491/2000 [13:24<03:04,  2.76iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  75%|███████▍  | 1492/2000 [13:24<03:06,  2.72iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  75%|███████▍  | 1492/2000 [13:24<03:06,  2.72iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  75%|███████▍  | 1493/2000 [13:25<03:11,  2.65iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  75%|███████▍  | 1493/2000 [13:25<03:11,  2.65iteration/s, mean_rewards=-170]\u001b[A\n",
            "Training:  75%|███████▍  | 1494/2000 [13:25<03:15,  2.59iteration/s, mean_rewards=-170]\u001b[A\n",
            "Training:  75%|███████▍  | 1494/2000 [13:25<03:15,  2.59iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:  75%|███████▍  | 1495/2000 [13:25<03:06,  2.70iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:  75%|███████▍  | 1495/2000 [13:25<03:06,  2.70iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  75%|███████▍  | 1496/2000 [13:26<02:58,  2.83iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  75%|███████▍  | 1496/2000 [13:26<02:58,  2.83iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  75%|███████▍  | 1497/2000 [13:26<03:00,  2.78iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  75%|███████▍  | 1497/2000 [13:26<03:00,  2.78iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  75%|███████▍  | 1498/2000 [13:26<03:04,  2.73iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  75%|███████▍  | 1498/2000 [13:27<03:04,  2.73iteration/s, mean_rewards=-65.5]\u001b[A\n",
            "Training:  75%|███████▍  | 1499/2000 [13:27<03:03,  2.73iteration/s, mean_rewards=-65.5]\u001b[A\n",
            "Training:  75%|███████▍  | 1499/2000 [13:27<03:03,  2.73iteration/s, mean_rewards=-127] \u001b[A\n",
            "Training:  75%|███████▌  | 1500/2000 [13:27<03:02,  2.74iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  75%|███████▌  | 1500/2000 [13:27<03:02,  2.74iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  75%|███████▌  | 1501/2000 [13:27<02:53,  2.88iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  75%|███████▌  | 1501/2000 [13:28<02:53,  2.88iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:  75%|███████▌  | 1502/2000 [13:28<02:50,  2.93iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:  75%|███████▌  | 1502/2000 [13:28<02:50,  2.93iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  75%|███████▌  | 1503/2000 [13:28<02:48,  2.95iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  75%|███████▌  | 1503/2000 [13:28<02:48,  2.95iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  75%|███████▌  | 1504/2000 [13:28<02:45,  3.00iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  75%|███████▌  | 1504/2000 [13:29<02:45,  3.00iteration/s, mean_rewards=-116]\u001b[A\n",
            "Training:  75%|███████▌  | 1505/2000 [13:29<02:52,  2.87iteration/s, mean_rewards=-116]\u001b[A\n",
            "Training:  75%|███████▌  | 1505/2000 [13:29<02:52,  2.87iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  75%|███████▌  | 1506/2000 [13:29<03:07,  2.63iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  75%|███████▌  | 1506/2000 [13:29<03:07,  2.63iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  75%|███████▌  | 1507/2000 [13:30<03:07,  2.63iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  75%|███████▌  | 1507/2000 [13:30<03:07,  2.63iteration/s, mean_rewards=-168]\u001b[A\n",
            "Training:  75%|███████▌  | 1508/2000 [13:30<03:10,  2.58iteration/s, mean_rewards=-168]\u001b[A\n",
            "Training:  75%|███████▌  | 1508/2000 [13:30<03:10,  2.58iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  75%|███████▌  | 1509/2000 [13:30<03:06,  2.63iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  75%|███████▌  | 1509/2000 [13:31<03:06,  2.63iteration/s, mean_rewards=-68.2]\u001b[A\n",
            "Training:  76%|███████▌  | 1510/2000 [13:31<03:05,  2.64iteration/s, mean_rewards=-68.2]\u001b[A\n",
            "Training:  76%|███████▌  | 1510/2000 [13:31<03:05,  2.64iteration/s, mean_rewards=-144] \u001b[A\n",
            "Training:  76%|███████▌  | 1511/2000 [13:31<03:10,  2.57iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  76%|███████▌  | 1511/2000 [13:31<03:10,  2.57iteration/s, mean_rewards=-94.1]\u001b[A\n",
            "Training:  76%|███████▌  | 1512/2000 [13:31<02:56,  2.76iteration/s, mean_rewards=-94.1]\u001b[A\n",
            "Training:  76%|███████▌  | 1512/2000 [13:32<02:56,  2.76iteration/s, mean_rewards=-134] \u001b[A\n",
            "Training:  76%|███████▌  | 1513/2000 [13:32<03:02,  2.66iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  76%|███████▌  | 1513/2000 [13:32<03:02,  2.66iteration/s, mean_rewards=-119]\u001b[A\n",
            "Training:  76%|███████▌  | 1514/2000 [13:32<03:30,  2.31iteration/s, mean_rewards=-119]\u001b[A\n",
            "Training:  76%|███████▌  | 1514/2000 [13:33<03:30,  2.31iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  76%|███████▌  | 1515/2000 [13:33<03:22,  2.40iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  76%|███████▌  | 1515/2000 [13:33<03:22,  2.40iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  76%|███████▌  | 1516/2000 [13:33<03:31,  2.29iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  76%|███████▌  | 1516/2000 [13:34<03:31,  2.29iteration/s, mean_rewards=-152]\u001b[A\n",
            "Training:  76%|███████▌  | 1517/2000 [13:34<03:40,  2.19iteration/s, mean_rewards=-152]\u001b[A\n",
            "Training:  76%|███████▌  | 1517/2000 [13:34<03:40,  2.19iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  76%|███████▌  | 1518/2000 [13:34<03:44,  2.14iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  76%|███████▌  | 1518/2000 [13:35<03:44,  2.14iteration/s, mean_rewards=-116]\u001b[A\n",
            "Training:  76%|███████▌  | 1519/2000 [13:35<03:55,  2.05iteration/s, mean_rewards=-116]\u001b[A\n",
            "Training:  76%|███████▌  | 1519/2000 [13:35<03:55,  2.05iteration/s, mean_rewards=-157]\u001b[A\n",
            "Training:  76%|███████▌  | 1520/2000 [13:35<03:40,  2.17iteration/s, mean_rewards=-157]\u001b[A\n",
            "Training:  76%|███████▌  | 1520/2000 [13:35<03:40,  2.17iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  76%|███████▌  | 1521/2000 [13:36<03:26,  2.32iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  76%|███████▌  | 1521/2000 [13:36<03:26,  2.32iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  76%|███████▌  | 1522/2000 [13:36<03:07,  2.55iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  76%|███████▌  | 1522/2000 [13:36<03:07,  2.55iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  76%|███████▌  | 1523/2000 [13:36<03:08,  2.52iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  76%|███████▌  | 1523/2000 [13:37<03:08,  2.52iteration/s, mean_rewards=-92.3]\u001b[A\n",
            "Training:  76%|███████▌  | 1524/2000 [13:37<03:07,  2.53iteration/s, mean_rewards=-92.3]\u001b[A\n",
            "Training:  76%|███████▌  | 1524/2000 [13:37<03:07,  2.53iteration/s, mean_rewards=-137] \u001b[A\n",
            "Training:  76%|███████▋  | 1525/2000 [13:37<03:14,  2.44iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  76%|███████▋  | 1525/2000 [13:37<03:14,  2.44iteration/s, mean_rewards=-184]\u001b[A\n",
            "Training:  76%|███████▋  | 1526/2000 [13:38<03:13,  2.45iteration/s, mean_rewards=-184]\u001b[A\n",
            "Training:  76%|███████▋  | 1526/2000 [13:38<03:13,  2.45iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  76%|███████▋  | 1527/2000 [13:38<02:58,  2.65iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  76%|███████▋  | 1527/2000 [13:38<02:58,  2.65iteration/s, mean_rewards=-115]\u001b[A\n",
            "Training:  76%|███████▋  | 1528/2000 [13:38<02:58,  2.64iteration/s, mean_rewards=-115]\u001b[A\n",
            "Training:  76%|███████▋  | 1528/2000 [13:38<02:58,  2.64iteration/s, mean_rewards=-104]\u001b[A\n",
            "Training:  76%|███████▋  | 1529/2000 [13:39<02:49,  2.78iteration/s, mean_rewards=-104]\u001b[A\n",
            "Training:  76%|███████▋  | 1529/2000 [13:39<02:49,  2.78iteration/s, mean_rewards=-75.2]\u001b[A\n",
            "Training:  76%|███████▋  | 1530/2000 [13:39<02:41,  2.91iteration/s, mean_rewards=-75.2]\u001b[A\n",
            "Training:  76%|███████▋  | 1530/2000 [13:39<02:41,  2.91iteration/s, mean_rewards=-139] \u001b[A\n",
            "Training:  77%|███████▋  | 1531/2000 [13:39<02:45,  2.84iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:  77%|███████▋  | 1531/2000 [13:39<02:45,  2.84iteration/s, mean_rewards=-104]\u001b[A\n",
            "Training:  77%|███████▋  | 1532/2000 [13:40<02:41,  2.90iteration/s, mean_rewards=-104]\u001b[A\n",
            "Training:  77%|███████▋  | 1532/2000 [13:40<02:41,  2.90iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  77%|███████▋  | 1533/2000 [13:40<02:36,  2.99iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  77%|███████▋  | 1533/2000 [13:40<02:36,  2.99iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  77%|███████▋  | 1534/2000 [13:40<02:38,  2.93iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  77%|███████▋  | 1534/2000 [13:40<02:38,  2.93iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  77%|███████▋  | 1535/2000 [13:41<02:47,  2.78iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  77%|███████▋  | 1535/2000 [13:41<02:47,  2.78iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  77%|███████▋  | 1536/2000 [13:41<02:47,  2.77iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  77%|███████▋  | 1536/2000 [13:41<02:47,  2.77iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  77%|███████▋  | 1537/2000 [13:41<02:59,  2.58iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  77%|███████▋  | 1537/2000 [13:42<02:59,  2.58iteration/s, mean_rewards=-164]\u001b[A\n",
            "Training:  77%|███████▋  | 1538/2000 [13:42<03:05,  2.49iteration/s, mean_rewards=-164]\u001b[A\n",
            "Training:  77%|███████▋  | 1538/2000 [13:42<03:05,  2.49iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  77%|███████▋  | 1539/2000 [13:42<03:03,  2.51iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  77%|███████▋  | 1539/2000 [13:42<03:03,  2.51iteration/s, mean_rewards=-119]\u001b[A\n",
            "Training:  77%|███████▋  | 1540/2000 [13:43<03:02,  2.52iteration/s, mean_rewards=-119]\u001b[A\n",
            "Training:  77%|███████▋  | 1540/2000 [13:43<03:02,  2.52iteration/s, mean_rewards=-109]\u001b[A\n",
            "Training:  77%|███████▋  | 1541/2000 [13:43<03:02,  2.51iteration/s, mean_rewards=-109]\u001b[A\n",
            "Training:  77%|███████▋  | 1541/2000 [13:43<03:02,  2.51iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:  77%|███████▋  | 1542/2000 [13:43<02:50,  2.69iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:  77%|███████▋  | 1542/2000 [13:44<02:50,  2.69iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  77%|███████▋  | 1543/2000 [13:44<02:51,  2.66iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  77%|███████▋  | 1543/2000 [13:44<02:51,  2.66iteration/s, mean_rewards=-168]\u001b[A\n",
            "Training:  77%|███████▋  | 1544/2000 [13:44<02:58,  2.55iteration/s, mean_rewards=-168]\u001b[A\n",
            "Training:  77%|███████▋  | 1544/2000 [13:44<02:58,  2.55iteration/s, mean_rewards=-207]\u001b[A\n",
            "Training:  77%|███████▋  | 1545/2000 [13:45<03:07,  2.43iteration/s, mean_rewards=-207]\u001b[A\n",
            "Training:  77%|███████▋  | 1545/2000 [13:45<03:07,  2.43iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  77%|███████▋  | 1546/2000 [13:45<03:04,  2.46iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  77%|███████▋  | 1546/2000 [13:45<03:04,  2.46iteration/s, mean_rewards=-35.1]\u001b[A\n",
            "Training:  77%|███████▋  | 1547/2000 [13:45<03:07,  2.42iteration/s, mean_rewards=-35.1]\u001b[A\n",
            "Training:  77%|███████▋  | 1547/2000 [13:46<03:07,  2.42iteration/s, mean_rewards=-132] \u001b[A\n",
            "Training:  77%|███████▋  | 1548/2000 [13:46<03:15,  2.31iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  77%|███████▋  | 1548/2000 [13:46<03:15,  2.31iteration/s, mean_rewards=-162]\u001b[A\n",
            "Training:  77%|███████▋  | 1549/2000 [13:46<03:17,  2.28iteration/s, mean_rewards=-162]\u001b[A\n",
            "Training:  77%|███████▋  | 1549/2000 [13:47<03:17,  2.28iteration/s, mean_rewards=-192]\u001b[A\n",
            "Training:  78%|███████▊  | 1550/2000 [13:47<03:31,  2.13iteration/s, mean_rewards=-192]\u001b[A\n",
            "Training:  78%|███████▊  | 1550/2000 [13:47<03:31,  2.13iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  78%|███████▊  | 1551/2000 [13:47<03:31,  2.12iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  78%|███████▊  | 1551/2000 [13:48<03:31,  2.12iteration/s, mean_rewards=-163]\u001b[A\n",
            "Training:  78%|███████▊  | 1552/2000 [13:48<03:47,  1.97iteration/s, mean_rewards=-163]\u001b[A\n",
            "Training:  78%|███████▊  | 1552/2000 [13:48<03:47,  1.97iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  78%|███████▊  | 1553/2000 [13:48<03:25,  2.18iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  78%|███████▊  | 1553/2000 [13:49<03:25,  2.18iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  78%|███████▊  | 1554/2000 [13:49<03:15,  2.28iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  78%|███████▊  | 1554/2000 [13:49<03:15,  2.28iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  78%|███████▊  | 1555/2000 [13:49<03:06,  2.39iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  78%|███████▊  | 1555/2000 [13:49<03:06,  2.39iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  78%|███████▊  | 1556/2000 [13:49<02:54,  2.54iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  78%|███████▊  | 1556/2000 [13:50<02:54,  2.54iteration/s, mean_rewards=-84.1]\u001b[A\n",
            "Training:  78%|███████▊  | 1557/2000 [13:50<02:48,  2.64iteration/s, mean_rewards=-84.1]\u001b[A\n",
            "Training:  78%|███████▊  | 1557/2000 [13:50<02:48,  2.64iteration/s, mean_rewards=-180] \u001b[A\n",
            "Training:  78%|███████▊  | 1558/2000 [13:50<02:49,  2.60iteration/s, mean_rewards=-180]\u001b[A\n",
            "Training:  78%|███████▊  | 1558/2000 [13:50<02:49,  2.60iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  78%|███████▊  | 1559/2000 [13:51<02:49,  2.60iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  78%|███████▊  | 1559/2000 [13:51<02:49,  2.60iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  78%|███████▊  | 1560/2000 [13:51<02:42,  2.70iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  78%|███████▊  | 1560/2000 [13:51<02:42,  2.70iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  78%|███████▊  | 1561/2000 [13:51<02:43,  2.69iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  78%|███████▊  | 1561/2000 [13:51<02:43,  2.69iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  78%|███████▊  | 1562/2000 [13:52<02:37,  2.77iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  78%|███████▊  | 1562/2000 [13:52<02:37,  2.77iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  78%|███████▊  | 1563/2000 [13:52<02:50,  2.57iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  78%|███████▊  | 1563/2000 [13:52<02:50,  2.57iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  78%|███████▊  | 1564/2000 [13:52<02:46,  2.61iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  78%|███████▊  | 1564/2000 [13:53<02:46,  2.61iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  78%|███████▊  | 1565/2000 [13:53<02:38,  2.75iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  78%|███████▊  | 1565/2000 [13:53<02:38,  2.75iteration/s, mean_rewards=-165]\u001b[A\n",
            "Training:  78%|███████▊  | 1566/2000 [13:53<02:34,  2.81iteration/s, mean_rewards=-165]\u001b[A\n",
            "Training:  78%|███████▊  | 1566/2000 [13:53<02:34,  2.81iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  78%|███████▊  | 1567/2000 [13:53<02:35,  2.78iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  78%|███████▊  | 1567/2000 [13:54<02:35,  2.78iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  78%|███████▊  | 1568/2000 [13:54<02:33,  2.82iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  78%|███████▊  | 1568/2000 [13:54<02:33,  2.82iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  78%|███████▊  | 1569/2000 [13:54<02:28,  2.90iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  78%|███████▊  | 1569/2000 [13:54<02:28,  2.90iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  78%|███████▊  | 1570/2000 [13:54<02:32,  2.82iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  78%|███████▊  | 1570/2000 [13:55<02:32,  2.82iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  79%|███████▊  | 1571/2000 [13:55<02:38,  2.71iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  79%|███████▊  | 1571/2000 [13:55<02:38,  2.71iteration/s, mean_rewards=-189]\u001b[A\n",
            "Training:  79%|███████▊  | 1572/2000 [13:55<02:47,  2.56iteration/s, mean_rewards=-189]\u001b[A\n",
            "Training:  79%|███████▊  | 1572/2000 [13:56<02:47,  2.56iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  79%|███████▊  | 1573/2000 [13:56<02:49,  2.53iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  79%|███████▊  | 1573/2000 [13:56<02:49,  2.53iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  79%|███████▊  | 1574/2000 [13:56<02:47,  2.54iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  79%|███████▊  | 1574/2000 [13:56<02:47,  2.54iteration/s, mean_rewards=-157]\u001b[A\n",
            "Training:  79%|███████▉  | 1575/2000 [13:57<02:46,  2.55iteration/s, mean_rewards=-157]\u001b[A\n",
            "Training:  79%|███████▉  | 1575/2000 [13:57<02:46,  2.55iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:  79%|███████▉  | 1576/2000 [13:57<02:39,  2.65iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:  79%|███████▉  | 1576/2000 [13:57<02:39,  2.65iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  79%|███████▉  | 1577/2000 [13:57<02:38,  2.66iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  79%|███████▉  | 1577/2000 [13:57<02:38,  2.66iteration/s, mean_rewards=-105]\u001b[A\n",
            "Training:  79%|███████▉  | 1578/2000 [13:58<02:38,  2.67iteration/s, mean_rewards=-105]\u001b[A\n",
            "Training:  79%|███████▉  | 1578/2000 [13:58<02:38,  2.67iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  79%|███████▉  | 1579/2000 [13:58<02:39,  2.65iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  79%|███████▉  | 1579/2000 [13:58<02:39,  2.65iteration/s, mean_rewards=-112]\u001b[A\n",
            "Training:  79%|███████▉  | 1580/2000 [13:58<02:43,  2.57iteration/s, mean_rewards=-112]\u001b[A\n",
            "Training:  79%|███████▉  | 1580/2000 [13:59<02:43,  2.57iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:  79%|███████▉  | 1581/2000 [13:59<02:55,  2.38iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:  79%|███████▉  | 1581/2000 [13:59<02:55,  2.38iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  79%|███████▉  | 1582/2000 [13:59<02:51,  2.43iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  79%|███████▉  | 1582/2000 [14:00<02:51,  2.43iteration/s, mean_rewards=-170]\u001b[A\n",
            "Training:  79%|███████▉  | 1583/2000 [14:00<03:06,  2.23iteration/s, mean_rewards=-170]\u001b[A\n",
            "Training:  79%|███████▉  | 1583/2000 [14:00<03:06,  2.23iteration/s, mean_rewards=-78.3]\u001b[A\n",
            "Training:  79%|███████▉  | 1584/2000 [14:00<03:16,  2.12iteration/s, mean_rewards=-78.3]\u001b[A\n",
            "Training:  79%|███████▉  | 1584/2000 [14:01<03:16,  2.12iteration/s, mean_rewards=-127] \u001b[A\n",
            "Training:  79%|███████▉  | 1585/2000 [14:01<03:13,  2.14iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  79%|███████▉  | 1585/2000 [14:01<03:13,  2.14iteration/s, mean_rewards=-100]\u001b[A\n",
            "Training:  79%|███████▉  | 1586/2000 [14:01<03:04,  2.25iteration/s, mean_rewards=-100]\u001b[A\n",
            "Training:  79%|███████▉  | 1586/2000 [14:01<03:04,  2.25iteration/s, mean_rewards=-210]\u001b[A\n",
            "Training:  79%|███████▉  | 1587/2000 [14:02<02:58,  2.32iteration/s, mean_rewards=-210]\u001b[A\n",
            "Training:  79%|███████▉  | 1587/2000 [14:02<02:58,  2.32iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  79%|███████▉  | 1588/2000 [14:02<02:57,  2.32iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  79%|███████▉  | 1588/2000 [14:02<02:57,  2.32iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  79%|███████▉  | 1589/2000 [14:02<02:51,  2.40iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  79%|███████▉  | 1589/2000 [14:03<02:51,  2.40iteration/s, mean_rewards=-171]\u001b[A\n",
            "Training:  80%|███████▉  | 1590/2000 [14:03<02:50,  2.40iteration/s, mean_rewards=-171]\u001b[A\n",
            "Training:  80%|███████▉  | 1590/2000 [14:03<02:50,  2.40iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  80%|███████▉  | 1591/2000 [14:03<02:41,  2.54iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  80%|███████▉  | 1591/2000 [14:03<02:41,  2.54iteration/s, mean_rewards=-157]\u001b[A\n",
            "Training:  80%|███████▉  | 1592/2000 [14:04<02:37,  2.60iteration/s, mean_rewards=-157]\u001b[A\n",
            "Training:  80%|███████▉  | 1592/2000 [14:04<02:37,  2.60iteration/s, mean_rewards=-115]\u001b[A\n",
            "Training:  80%|███████▉  | 1593/2000 [14:04<02:29,  2.72iteration/s, mean_rewards=-115]\u001b[A\n",
            "Training:  80%|███████▉  | 1593/2000 [14:04<02:29,  2.72iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  80%|███████▉  | 1594/2000 [14:04<02:29,  2.72iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  80%|███████▉  | 1594/2000 [14:04<02:29,  2.72iteration/s, mean_rewards=-101]\u001b[A\n",
            "Training:  80%|███████▉  | 1595/2000 [14:05<02:21,  2.85iteration/s, mean_rewards=-101]\u001b[A\n",
            "Training:  80%|███████▉  | 1595/2000 [14:05<02:21,  2.85iteration/s, mean_rewards=-167]\u001b[A\n",
            "Training:  80%|███████▉  | 1596/2000 [14:05<02:25,  2.78iteration/s, mean_rewards=-167]\u001b[A\n",
            "Training:  80%|███████▉  | 1596/2000 [14:05<02:25,  2.78iteration/s, mean_rewards=-167]\u001b[A\n",
            "Training:  80%|███████▉  | 1597/2000 [14:05<02:27,  2.73iteration/s, mean_rewards=-167]\u001b[A\n",
            "Training:  80%|███████▉  | 1597/2000 [14:06<02:27,  2.73iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  80%|███████▉  | 1598/2000 [14:06<02:27,  2.72iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  80%|███████▉  | 1598/2000 [14:06<02:27,  2.72iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  80%|███████▉  | 1599/2000 [14:06<02:30,  2.67iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  80%|███████▉  | 1599/2000 [14:06<02:30,  2.67iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  80%|████████  | 1600/2000 [14:06<02:26,  2.74iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  80%|████████  | 1600/2000 [14:07<02:26,  2.74iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:  80%|████████  | 1601/2000 [14:07<02:20,  2.83iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:  80%|████████  | 1601/2000 [14:07<02:20,  2.83iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  80%|████████  | 1602/2000 [14:07<02:16,  2.92iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  80%|████████  | 1602/2000 [14:07<02:16,  2.92iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  80%|████████  | 1603/2000 [14:07<02:28,  2.68iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  80%|████████  | 1603/2000 [14:08<02:28,  2.68iteration/s, mean_rewards=-119]\u001b[A\n",
            "Training:  80%|████████  | 1604/2000 [14:08<02:26,  2.71iteration/s, mean_rewards=-119]\u001b[A\n",
            "Training:  80%|████████  | 1604/2000 [14:08<02:26,  2.71iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  80%|████████  | 1605/2000 [14:08<02:19,  2.83iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  80%|████████  | 1605/2000 [14:08<02:19,  2.83iteration/s, mean_rewards=-191]\u001b[A\n",
            "Training:  80%|████████  | 1606/2000 [14:09<02:20,  2.81iteration/s, mean_rewards=-191]\u001b[A\n",
            "Training:  80%|████████  | 1606/2000 [14:09<02:20,  2.81iteration/s, mean_rewards=-157]\u001b[A\n",
            "Training:  80%|████████  | 1607/2000 [14:09<02:19,  2.81iteration/s, mean_rewards=-157]\u001b[A\n",
            "Training:  80%|████████  | 1607/2000 [14:09<02:19,  2.81iteration/s, mean_rewards=-181]\u001b[A\n",
            "Training:  80%|████████  | 1608/2000 [14:09<02:23,  2.74iteration/s, mean_rewards=-181]\u001b[A\n",
            "Training:  80%|████████  | 1608/2000 [14:09<02:23,  2.74iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  80%|████████  | 1609/2000 [14:10<02:17,  2.84iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  80%|████████  | 1609/2000 [14:10<02:17,  2.84iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  80%|████████  | 1610/2000 [14:10<02:11,  2.97iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  80%|████████  | 1610/2000 [14:10<02:11,  2.97iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  81%|████████  | 1611/2000 [14:10<02:18,  2.82iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  81%|████████  | 1611/2000 [14:11<02:18,  2.82iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  81%|████████  | 1612/2000 [14:11<02:21,  2.74iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  81%|████████  | 1612/2000 [14:11<02:21,  2.74iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:  81%|████████  | 1613/2000 [14:11<02:35,  2.48iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:  81%|████████  | 1613/2000 [14:12<02:35,  2.48iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  81%|████████  | 1614/2000 [14:12<02:44,  2.34iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  81%|████████  | 1614/2000 [14:12<02:44,  2.34iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  81%|████████  | 1615/2000 [14:12<02:39,  2.41iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  81%|████████  | 1615/2000 [14:12<02:39,  2.41iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  81%|████████  | 1616/2000 [14:12<02:39,  2.41iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  81%|████████  | 1616/2000 [14:13<02:39,  2.41iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  81%|████████  | 1617/2000 [14:13<02:40,  2.39iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  81%|████████  | 1617/2000 [14:13<02:40,  2.39iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  81%|████████  | 1618/2000 [14:13<02:43,  2.33iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  81%|████████  | 1618/2000 [14:14<02:43,  2.33iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  81%|████████  | 1619/2000 [14:14<02:52,  2.20iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  81%|████████  | 1619/2000 [14:14<02:52,  2.20iteration/s, mean_rewards=-93.2]\u001b[A\n",
            "Training:  81%|████████  | 1620/2000 [14:14<02:43,  2.33iteration/s, mean_rewards=-93.2]\u001b[A\n",
            "Training:  81%|████████  | 1620/2000 [14:15<02:43,  2.33iteration/s, mean_rewards=-163] \u001b[A\n",
            "Training:  81%|████████  | 1621/2000 [14:15<02:47,  2.27iteration/s, mean_rewards=-163]\u001b[A\n",
            "Training:  81%|████████  | 1621/2000 [14:15<02:47,  2.27iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  81%|████████  | 1622/2000 [14:15<02:38,  2.39iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  81%|████████  | 1622/2000 [14:15<02:38,  2.39iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  81%|████████  | 1623/2000 [14:15<02:31,  2.49iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  81%|████████  | 1623/2000 [14:16<02:31,  2.49iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  81%|████████  | 1624/2000 [14:16<02:28,  2.53iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  81%|████████  | 1624/2000 [14:16<02:28,  2.53iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  81%|████████▏ | 1625/2000 [14:16<02:26,  2.56iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  81%|████████▏ | 1625/2000 [14:16<02:26,  2.56iteration/s, mean_rewards=-169]\u001b[A\n",
            "Training:  81%|████████▏ | 1626/2000 [14:17<02:24,  2.58iteration/s, mean_rewards=-169]\u001b[A\n",
            "Training:  81%|████████▏ | 1626/2000 [14:17<02:24,  2.58iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  81%|████████▏ | 1627/2000 [14:17<02:14,  2.77iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  81%|████████▏ | 1627/2000 [14:17<02:14,  2.77iteration/s, mean_rewards=-115]\u001b[A\n",
            "Training:  81%|████████▏ | 1628/2000 [14:17<02:10,  2.84iteration/s, mean_rewards=-115]\u001b[A\n",
            "Training:  81%|████████▏ | 1628/2000 [14:17<02:10,  2.84iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  81%|████████▏ | 1629/2000 [14:17<02:04,  2.99iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  81%|████████▏ | 1629/2000 [14:18<02:04,  2.99iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  82%|████████▏ | 1630/2000 [14:18<02:09,  2.86iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  82%|████████▏ | 1630/2000 [14:18<02:09,  2.86iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  82%|████████▏ | 1631/2000 [14:18<02:05,  2.93iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  82%|████████▏ | 1631/2000 [14:18<02:05,  2.93iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  82%|████████▏ | 1632/2000 [14:19<02:10,  2.81iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  82%|████████▏ | 1632/2000 [14:19<02:10,  2.81iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  82%|████████▏ | 1633/2000 [14:19<02:04,  2.94iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  82%|████████▏ | 1633/2000 [14:19<02:04,  2.94iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  82%|████████▏ | 1634/2000 [14:19<02:08,  2.84iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  82%|████████▏ | 1634/2000 [14:20<02:08,  2.84iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  82%|████████▏ | 1635/2000 [14:20<02:15,  2.69iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  82%|████████▏ | 1635/2000 [14:20<02:15,  2.69iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  82%|████████▏ | 1636/2000 [14:20<02:15,  2.69iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  82%|████████▏ | 1636/2000 [14:20<02:15,  2.69iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  82%|████████▏ | 1637/2000 [14:20<02:15,  2.67iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  82%|████████▏ | 1637/2000 [14:21<02:15,  2.67iteration/s, mean_rewards=-172]\u001b[A\n",
            "Training:  82%|████████▏ | 1638/2000 [14:21<02:17,  2.64iteration/s, mean_rewards=-172]\u001b[A\n",
            "Training:  82%|████████▏ | 1638/2000 [14:21<02:17,  2.64iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  82%|████████▏ | 1639/2000 [14:21<02:18,  2.61iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  82%|████████▏ | 1639/2000 [14:21<02:18,  2.61iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  82%|████████▏ | 1640/2000 [14:22<02:17,  2.61iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  82%|████████▏ | 1640/2000 [14:22<02:17,  2.61iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  82%|████████▏ | 1641/2000 [14:22<02:10,  2.75iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  82%|████████▏ | 1641/2000 [14:22<02:10,  2.75iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  82%|████████▏ | 1642/2000 [14:22<02:13,  2.69iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  82%|████████▏ | 1642/2000 [14:23<02:13,  2.69iteration/s, mean_rewards=-187]\u001b[A\n",
            "Training:  82%|████████▏ | 1643/2000 [14:23<02:22,  2.51iteration/s, mean_rewards=-187]\u001b[A\n",
            "Training:  82%|████████▏ | 1643/2000 [14:23<02:22,  2.51iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  82%|████████▏ | 1644/2000 [14:23<02:14,  2.65iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  82%|████████▏ | 1644/2000 [14:23<02:14,  2.65iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  82%|████████▏ | 1645/2000 [14:23<02:12,  2.67iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  82%|████████▏ | 1645/2000 [14:24<02:12,  2.67iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  82%|████████▏ | 1646/2000 [14:24<02:12,  2.68iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  82%|████████▏ | 1646/2000 [14:24<02:12,  2.68iteration/s, mean_rewards=-112]\u001b[A\n",
            "Training:  82%|████████▏ | 1647/2000 [14:24<02:14,  2.62iteration/s, mean_rewards=-112]\u001b[A\n",
            "Training:  82%|████████▏ | 1647/2000 [14:24<02:14,  2.62iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  82%|████████▏ | 1648/2000 [14:25<02:16,  2.59iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  82%|████████▏ | 1648/2000 [14:25<02:16,  2.59iteration/s, mean_rewards=-112]\u001b[A\n",
            "Training:  82%|████████▏ | 1649/2000 [14:25<02:17,  2.56iteration/s, mean_rewards=-112]\u001b[A\n",
            "Training:  82%|████████▏ | 1649/2000 [14:25<02:17,  2.56iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  82%|████████▎ | 1650/2000 [14:25<02:24,  2.42iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  82%|████████▎ | 1650/2000 [14:26<02:24,  2.42iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  83%|████████▎ | 1651/2000 [14:26<02:30,  2.32iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  83%|████████▎ | 1651/2000 [14:26<02:30,  2.32iteration/s, mean_rewards=-170]\u001b[A\n",
            "Training:  83%|████████▎ | 1652/2000 [14:27<02:41,  2.15iteration/s, mean_rewards=-170]\u001b[A\n",
            "Training:  83%|████████▎ | 1652/2000 [14:27<02:41,  2.15iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  83%|████████▎ | 1653/2000 [14:27<02:37,  2.21iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  83%|████████▎ | 1653/2000 [14:27<02:37,  2.21iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  83%|████████▎ | 1654/2000 [14:27<02:24,  2.40iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  83%|████████▎ | 1654/2000 [14:27<02:24,  2.40iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  83%|████████▎ | 1655/2000 [14:28<02:14,  2.56iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  83%|████████▎ | 1655/2000 [14:28<02:14,  2.56iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  83%|████████▎ | 1656/2000 [14:28<02:16,  2.52iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  83%|████████▎ | 1656/2000 [14:28<02:16,  2.52iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  83%|████████▎ | 1657/2000 [14:28<02:06,  2.71iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  83%|████████▎ | 1657/2000 [14:29<02:06,  2.71iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  83%|████████▎ | 1658/2000 [14:29<02:13,  2.57iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  83%|████████▎ | 1658/2000 [14:29<02:13,  2.57iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  83%|████████▎ | 1659/2000 [14:29<02:10,  2.61iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  83%|████████▎ | 1659/2000 [14:29<02:10,  2.61iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  83%|████████▎ | 1660/2000 [14:29<02:07,  2.66iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  83%|████████▎ | 1660/2000 [14:30<02:07,  2.66iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  83%|████████▎ | 1661/2000 [14:30<02:13,  2.54iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  83%|████████▎ | 1661/2000 [14:30<02:13,  2.54iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  83%|████████▎ | 1662/2000 [14:30<02:12,  2.55iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  83%|████████▎ | 1662/2000 [14:31<02:12,  2.55iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  83%|████████▎ | 1663/2000 [14:31<02:12,  2.54iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  83%|████████▎ | 1663/2000 [14:31<02:12,  2.54iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  83%|████████▎ | 1664/2000 [14:31<02:11,  2.56iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  83%|████████▎ | 1664/2000 [14:31<02:11,  2.56iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  83%|████████▎ | 1665/2000 [14:31<02:04,  2.69iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  83%|████████▎ | 1665/2000 [14:32<02:04,  2.69iteration/s, mean_rewards=-152]\u001b[A\n",
            "Training:  83%|████████▎ | 1666/2000 [14:32<02:06,  2.64iteration/s, mean_rewards=-152]\u001b[A\n",
            "Training:  83%|████████▎ | 1666/2000 [14:32<02:06,  2.64iteration/s, mean_rewards=-94.5]\u001b[A\n",
            "Training:  83%|████████▎ | 1667/2000 [14:32<02:12,  2.51iteration/s, mean_rewards=-94.5]\u001b[A\n",
            "Training:  83%|████████▎ | 1667/2000 [14:32<02:12,  2.51iteration/s, mean_rewards=-124] \u001b[A\n",
            "Training:  83%|████████▎ | 1668/2000 [14:33<02:04,  2.67iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  83%|████████▎ | 1668/2000 [14:33<02:04,  2.67iteration/s, mean_rewards=-60.5]\u001b[A\n",
            "Training:  83%|████████▎ | 1669/2000 [14:33<02:05,  2.64iteration/s, mean_rewards=-60.5]\u001b[A\n",
            "Training:  83%|████████▎ | 1669/2000 [14:33<02:05,  2.64iteration/s, mean_rewards=-150] \u001b[A\n",
            "Training:  84%|████████▎ | 1670/2000 [14:33<02:14,  2.45iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  84%|████████▎ | 1670/2000 [14:34<02:14,  2.45iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  84%|████████▎ | 1671/2000 [14:34<02:12,  2.49iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  84%|████████▎ | 1671/2000 [14:34<02:12,  2.49iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  84%|████████▎ | 1672/2000 [14:34<02:16,  2.40iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  84%|████████▎ | 1672/2000 [14:35<02:16,  2.40iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  84%|████████▎ | 1673/2000 [14:35<02:12,  2.47iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  84%|████████▎ | 1673/2000 [14:35<02:12,  2.47iteration/s, mean_rewards=-166]\u001b[A\n",
            "Training:  84%|████████▎ | 1674/2000 [14:35<02:14,  2.42iteration/s, mean_rewards=-166]\u001b[A\n",
            "Training:  84%|████████▎ | 1674/2000 [14:35<02:14,  2.42iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  84%|████████▍ | 1675/2000 [14:35<02:08,  2.54iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  84%|████████▍ | 1675/2000 [14:36<02:08,  2.54iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  84%|████████▍ | 1676/2000 [14:36<02:11,  2.46iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  84%|████████▍ | 1676/2000 [14:36<02:11,  2.46iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  84%|████████▍ | 1677/2000 [14:36<02:12,  2.43iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  84%|████████▍ | 1677/2000 [14:37<02:12,  2.43iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  84%|████████▍ | 1678/2000 [14:37<02:14,  2.39iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  84%|████████▍ | 1678/2000 [14:37<02:14,  2.39iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  84%|████████▍ | 1679/2000 [14:37<02:14,  2.38iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  84%|████████▍ | 1679/2000 [14:38<02:14,  2.38iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  84%|████████▍ | 1680/2000 [14:38<02:25,  2.21iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  84%|████████▍ | 1680/2000 [14:38<02:25,  2.21iteration/s, mean_rewards=-72.5]\u001b[A\n",
            "Training:  84%|████████▍ | 1681/2000 [14:38<02:29,  2.14iteration/s, mean_rewards=-72.5]\u001b[A\n",
            "Training:  84%|████████▍ | 1681/2000 [14:39<02:29,  2.14iteration/s, mean_rewards=-149] \u001b[A\n",
            "Training:  84%|████████▍ | 1682/2000 [14:39<02:28,  2.14iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  84%|████████▍ | 1682/2000 [14:39<02:28,  2.14iteration/s, mean_rewards=-176]\u001b[A\n",
            "Training:  84%|████████▍ | 1683/2000 [14:39<02:35,  2.03iteration/s, mean_rewards=-176]\u001b[A\n",
            "Training:  84%|████████▍ | 1683/2000 [14:39<02:35,  2.03iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  84%|████████▍ | 1684/2000 [14:40<02:26,  2.16iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  84%|████████▍ | 1684/2000 [14:40<02:26,  2.16iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  84%|████████▍ | 1685/2000 [14:40<02:16,  2.30iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  84%|████████▍ | 1685/2000 [14:40<02:16,  2.30iteration/s, mean_rewards=-36.4]\u001b[A\n",
            "Training:  84%|████████▍ | 1686/2000 [14:40<02:04,  2.52iteration/s, mean_rewards=-36.4]\u001b[A\n",
            "Training:  84%|████████▍ | 1686/2000 [14:41<02:04,  2.52iteration/s, mean_rewards=-164] \u001b[A\n",
            "Training:  84%|████████▍ | 1687/2000 [14:41<02:03,  2.53iteration/s, mean_rewards=-164]\u001b[A\n",
            "Training:  84%|████████▍ | 1687/2000 [14:41<02:03,  2.53iteration/s, mean_rewards=-61.6]\u001b[A\n",
            "Training:  84%|████████▍ | 1688/2000 [14:41<02:01,  2.58iteration/s, mean_rewards=-61.6]\u001b[A\n",
            "Training:  84%|████████▍ | 1688/2000 [14:41<02:01,  2.58iteration/s, mean_rewards=-148] \u001b[A\n",
            "Training:  84%|████████▍ | 1689/2000 [14:41<01:58,  2.61iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  84%|████████▍ | 1689/2000 [14:42<01:58,  2.61iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  84%|████████▍ | 1690/2000 [14:42<01:52,  2.75iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  84%|████████▍ | 1690/2000 [14:42<01:52,  2.75iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:  85%|████████▍ | 1691/2000 [14:42<01:55,  2.68iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:  85%|████████▍ | 1691/2000 [14:42<01:55,  2.68iteration/s, mean_rewards=-96] \u001b[A\n",
            "Training:  85%|████████▍ | 1692/2000 [14:43<01:57,  2.61iteration/s, mean_rewards=-96]\u001b[A\n",
            "Training:  85%|████████▍ | 1692/2000 [14:43<01:57,  2.61iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  85%|████████▍ | 1693/2000 [14:43<01:57,  2.62iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  85%|████████▍ | 1693/2000 [14:43<01:57,  2.62iteration/s, mean_rewards=-152]\u001b[A\n",
            "Training:  85%|████████▍ | 1694/2000 [14:43<01:55,  2.65iteration/s, mean_rewards=-152]\u001b[A\n",
            "Training:  85%|████████▍ | 1694/2000 [14:44<01:55,  2.65iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  85%|████████▍ | 1695/2000 [14:44<01:56,  2.62iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  85%|████████▍ | 1695/2000 [14:44<01:56,  2.62iteration/s, mean_rewards=-105]\u001b[A\n",
            "Training:  85%|████████▍ | 1696/2000 [14:44<01:55,  2.63iteration/s, mean_rewards=-105]\u001b[A\n",
            "Training:  85%|████████▍ | 1696/2000 [14:44<01:55,  2.63iteration/s, mean_rewards=-89] \u001b[A\n",
            "Training:  85%|████████▍ | 1697/2000 [14:44<01:56,  2.60iteration/s, mean_rewards=-89]\u001b[A\n",
            "Training:  85%|████████▍ | 1697/2000 [14:45<01:56,  2.60iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  85%|████████▍ | 1698/2000 [14:45<02:00,  2.51iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  85%|████████▍ | 1698/2000 [14:45<02:00,  2.51iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  85%|████████▍ | 1699/2000 [14:45<01:59,  2.52iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  85%|████████▍ | 1699/2000 [14:46<01:59,  2.52iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  85%|████████▌ | 1700/2000 [14:46<02:03,  2.43iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  85%|████████▌ | 1700/2000 [14:46<02:03,  2.43iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  85%|████████▌ | 1701/2000 [14:46<01:58,  2.52iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  85%|████████▌ | 1701/2000 [14:46<01:58,  2.52iteration/s, mean_rewards=-116]\u001b[A\n",
            "Training:  85%|████████▌ | 1702/2000 [14:46<01:54,  2.60iteration/s, mean_rewards=-116]\u001b[A\n",
            "Training:  85%|████████▌ | 1702/2000 [14:47<01:54,  2.60iteration/s, mean_rewards=-51.1]\u001b[A\n",
            "Training:  85%|████████▌ | 1703/2000 [14:47<01:53,  2.61iteration/s, mean_rewards=-51.1]\u001b[A\n",
            "Training:  85%|████████▌ | 1703/2000 [14:47<01:53,  2.61iteration/s, mean_rewards=-163] \u001b[A\n",
            "Training:  85%|████████▌ | 1704/2000 [14:47<01:53,  2.62iteration/s, mean_rewards=-163]\u001b[A\n",
            "Training:  85%|████████▌ | 1704/2000 [14:47<01:53,  2.62iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:  85%|████████▌ | 1705/2000 [14:47<01:47,  2.75iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:  85%|████████▌ | 1705/2000 [14:48<01:47,  2.75iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:  85%|████████▌ | 1706/2000 [14:48<01:48,  2.72iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:  85%|████████▌ | 1706/2000 [14:48<01:48,  2.72iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  85%|████████▌ | 1707/2000 [14:48<01:46,  2.74iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  85%|████████▌ | 1707/2000 [14:48<01:46,  2.74iteration/s, mean_rewards=-105]\u001b[A\n",
            "Training:  85%|████████▌ | 1708/2000 [14:49<01:40,  2.91iteration/s, mean_rewards=-105]\u001b[A\n",
            "Training:  85%|████████▌ | 1708/2000 [14:49<01:40,  2.91iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  85%|████████▌ | 1709/2000 [14:49<01:37,  2.97iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  85%|████████▌ | 1709/2000 [14:49<01:37,  2.97iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  86%|████████▌ | 1710/2000 [14:49<01:36,  3.00iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  86%|████████▌ | 1710/2000 [14:49<01:36,  3.00iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  86%|████████▌ | 1711/2000 [14:50<01:44,  2.77iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  86%|████████▌ | 1711/2000 [14:50<01:44,  2.77iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  86%|████████▌ | 1712/2000 [14:50<01:48,  2.65iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  86%|████████▌ | 1712/2000 [14:50<01:48,  2.65iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  86%|████████▌ | 1713/2000 [14:50<01:52,  2.56iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  86%|████████▌ | 1713/2000 [14:51<01:52,  2.56iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  86%|████████▌ | 1714/2000 [14:51<02:08,  2.22iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  86%|████████▌ | 1714/2000 [14:51<02:08,  2.22iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  86%|████████▌ | 1715/2000 [14:52<02:14,  2.13iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  86%|████████▌ | 1715/2000 [14:52<02:14,  2.13iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  86%|████████▌ | 1716/2000 [14:52<02:18,  2.05iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  86%|████████▌ | 1716/2000 [14:52<02:18,  2.05iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  86%|████████▌ | 1717/2000 [14:53<02:20,  2.01iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  86%|████████▌ | 1717/2000 [14:53<02:20,  2.01iteration/s, mean_rewards=-104]\u001b[A\n",
            "Training:  86%|████████▌ | 1718/2000 [14:53<02:08,  2.19iteration/s, mean_rewards=-104]\u001b[A\n",
            "Training:  86%|████████▌ | 1718/2000 [14:53<02:08,  2.19iteration/s, mean_rewards=-230]\u001b[A\n",
            "Training:  86%|████████▌ | 1719/2000 [14:53<02:03,  2.27iteration/s, mean_rewards=-230]\u001b[A\n",
            "Training:  86%|████████▌ | 1719/2000 [14:54<02:03,  2.27iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  86%|████████▌ | 1720/2000 [14:54<01:59,  2.35iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  86%|████████▌ | 1720/2000 [14:54<01:59,  2.35iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  86%|████████▌ | 1721/2000 [14:54<01:57,  2.37iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  86%|████████▌ | 1721/2000 [14:54<01:57,  2.37iteration/s, mean_rewards=-193]\u001b[A\n",
            "Training:  86%|████████▌ | 1722/2000 [14:55<01:58,  2.35iteration/s, mean_rewards=-193]\u001b[A\n",
            "Training:  86%|████████▌ | 1722/2000 [14:55<01:58,  2.35iteration/s, mean_rewards=-185]\u001b[A\n",
            "Training:  86%|████████▌ | 1723/2000 [14:55<01:58,  2.35iteration/s, mean_rewards=-185]\u001b[A\n",
            "Training:  86%|████████▌ | 1723/2000 [14:55<01:58,  2.35iteration/s, mean_rewards=-171]\u001b[A\n",
            "Training:  86%|████████▌ | 1724/2000 [14:55<01:54,  2.40iteration/s, mean_rewards=-171]\u001b[A\n",
            "Training:  86%|████████▌ | 1724/2000 [14:56<01:54,  2.40iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  86%|████████▋ | 1725/2000 [14:56<01:58,  2.33iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  86%|████████▋ | 1725/2000 [14:56<01:58,  2.33iteration/s, mean_rewards=-106]\u001b[A\n",
            "Training:  86%|████████▋ | 1726/2000 [14:56<01:52,  2.43iteration/s, mean_rewards=-106]\u001b[A\n",
            "Training:  86%|████████▋ | 1726/2000 [14:57<01:52,  2.43iteration/s, mean_rewards=-159]\u001b[A\n",
            "Training:  86%|████████▋ | 1727/2000 [14:57<01:54,  2.39iteration/s, mean_rewards=-159]\u001b[A\n",
            "Training:  86%|████████▋ | 1727/2000 [14:57<01:54,  2.39iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  86%|████████▋ | 1728/2000 [14:57<01:49,  2.47iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  86%|████████▋ | 1728/2000 [14:57<01:49,  2.47iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  86%|████████▋ | 1729/2000 [14:57<01:46,  2.54iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  86%|████████▋ | 1729/2000 [14:58<01:46,  2.54iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  86%|████████▋ | 1730/2000 [14:58<01:48,  2.49iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  86%|████████▋ | 1730/2000 [14:58<01:48,  2.49iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  87%|████████▋ | 1731/2000 [14:58<01:45,  2.54iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  87%|████████▋ | 1731/2000 [14:58<01:45,  2.54iteration/s, mean_rewards=-85.2]\u001b[A\n",
            "Training:  87%|████████▋ | 1732/2000 [14:59<01:45,  2.54iteration/s, mean_rewards=-85.2]\u001b[A\n",
            "Training:  87%|████████▋ | 1732/2000 [14:59<01:45,  2.54iteration/s, mean_rewards=-116] \u001b[A\n",
            "Training:  87%|████████▋ | 1733/2000 [14:59<01:42,  2.59iteration/s, mean_rewards=-116]\u001b[A\n",
            "Training:  87%|████████▋ | 1733/2000 [14:59<01:42,  2.59iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  87%|████████▋ | 1734/2000 [14:59<01:38,  2.70iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  87%|████████▋ | 1734/2000 [15:00<01:38,  2.70iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  87%|████████▋ | 1735/2000 [15:00<01:38,  2.70iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  87%|████████▋ | 1735/2000 [15:00<01:38,  2.70iteration/s, mean_rewards=-92.4]\u001b[A\n",
            "Training:  87%|████████▋ | 1736/2000 [15:00<01:43,  2.56iteration/s, mean_rewards=-92.4]\u001b[A\n",
            "Training:  87%|████████▋ | 1736/2000 [15:00<01:43,  2.56iteration/s, mean_rewards=-125] \u001b[A\n",
            "Training:  87%|████████▋ | 1737/2000 [15:00<01:37,  2.70iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  87%|████████▋ | 1737/2000 [15:01<01:37,  2.70iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  87%|████████▋ | 1738/2000 [15:01<01:39,  2.62iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  87%|████████▋ | 1738/2000 [15:01<01:39,  2.62iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  87%|████████▋ | 1739/2000 [15:01<01:41,  2.58iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  87%|████████▋ | 1739/2000 [15:01<01:41,  2.58iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  87%|████████▋ | 1740/2000 [15:02<01:34,  2.75iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  87%|████████▋ | 1740/2000 [15:02<01:34,  2.75iteration/s, mean_rewards=-79.2]\u001b[A\n",
            "Training:  87%|████████▋ | 1741/2000 [15:02<01:36,  2.68iteration/s, mean_rewards=-79.2]\u001b[A\n",
            "Training:  87%|████████▋ | 1741/2000 [15:02<01:36,  2.68iteration/s, mean_rewards=-139] \u001b[A\n",
            "Training:  87%|████████▋ | 1742/2000 [15:02<01:36,  2.68iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:  87%|████████▋ | 1742/2000 [15:03<01:36,  2.68iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  87%|████████▋ | 1743/2000 [15:03<01:38,  2.62iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  87%|████████▋ | 1743/2000 [15:03<01:38,  2.62iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  87%|████████▋ | 1744/2000 [15:03<01:45,  2.43iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  87%|████████▋ | 1744/2000 [15:04<01:45,  2.43iteration/s, mean_rewards=-159]\u001b[A\n",
            "Training:  87%|████████▋ | 1745/2000 [15:04<01:55,  2.22iteration/s, mean_rewards=-159]\u001b[A\n",
            "Training:  87%|████████▋ | 1745/2000 [15:04<01:55,  2.22iteration/s, mean_rewards=-109]\u001b[A\n",
            "Training:  87%|████████▋ | 1746/2000 [15:04<01:59,  2.13iteration/s, mean_rewards=-109]\u001b[A\n",
            "Training:  87%|████████▋ | 1746/2000 [15:05<01:59,  2.13iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  87%|████████▋ | 1747/2000 [15:05<01:54,  2.22iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  87%|████████▋ | 1747/2000 [15:05<01:54,  2.22iteration/s, mean_rewards=-52.2]\u001b[A\n",
            "Training:  87%|████████▋ | 1748/2000 [15:05<01:52,  2.24iteration/s, mean_rewards=-52.2]\u001b[A\n",
            "Training:  87%|████████▋ | 1748/2000 [15:06<01:52,  2.24iteration/s, mean_rewards=-116] \u001b[A\n",
            "Training:  87%|████████▋ | 1749/2000 [15:06<02:02,  2.05iteration/s, mean_rewards=-116]\u001b[A\n",
            "Training:  87%|████████▋ | 1749/2000 [15:06<02:02,  2.05iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  88%|████████▊ | 1750/2000 [15:06<01:53,  2.20iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  88%|████████▊ | 1750/2000 [15:06<01:53,  2.20iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  88%|████████▊ | 1751/2000 [15:06<01:48,  2.30iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  88%|████████▊ | 1751/2000 [15:07<01:48,  2.30iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  88%|████████▊ | 1752/2000 [15:07<01:39,  2.49iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  88%|████████▊ | 1752/2000 [15:07<01:39,  2.49iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  88%|████████▊ | 1753/2000 [15:07<01:37,  2.52iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  88%|████████▊ | 1753/2000 [15:07<01:37,  2.52iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  88%|████████▊ | 1754/2000 [15:08<01:37,  2.52iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  88%|████████▊ | 1754/2000 [15:08<01:37,  2.52iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  88%|████████▊ | 1755/2000 [15:08<01:30,  2.71iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  88%|████████▊ | 1755/2000 [15:08<01:30,  2.71iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  88%|████████▊ | 1756/2000 [15:08<01:30,  2.68iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  88%|████████▊ | 1756/2000 [15:09<01:30,  2.68iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  88%|████████▊ | 1757/2000 [15:09<01:35,  2.55iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  88%|████████▊ | 1757/2000 [15:09<01:35,  2.55iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  88%|████████▊ | 1758/2000 [15:09<01:33,  2.59iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  88%|████████▊ | 1758/2000 [15:09<01:33,  2.59iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  88%|████████▊ | 1759/2000 [15:09<01:35,  2.51iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  88%|████████▊ | 1759/2000 [15:10<01:35,  2.51iteration/s, mean_rewards=-253]\u001b[A\n",
            "Training:  88%|████████▊ | 1760/2000 [15:10<01:43,  2.32iteration/s, mean_rewards=-253]\u001b[A\n",
            "Training:  88%|████████▊ | 1760/2000 [15:10<01:43,  2.32iteration/s, mean_rewards=-119]\u001b[A\n",
            "Training:  88%|████████▊ | 1761/2000 [15:10<01:45,  2.27iteration/s, mean_rewards=-119]\u001b[A\n",
            "Training:  88%|████████▊ | 1761/2000 [15:11<01:45,  2.27iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  88%|████████▊ | 1762/2000 [15:11<01:36,  2.46iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  88%|████████▊ | 1762/2000 [15:11<01:36,  2.46iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  88%|████████▊ | 1763/2000 [15:11<01:33,  2.55iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  88%|████████▊ | 1763/2000 [15:11<01:33,  2.55iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  88%|████████▊ | 1764/2000 [15:12<01:32,  2.56iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  88%|████████▊ | 1764/2000 [15:12<01:32,  2.56iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  88%|████████▊ | 1765/2000 [15:12<01:27,  2.68iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  88%|████████▊ | 1765/2000 [15:12<01:27,  2.68iteration/s, mean_rewards=-187]\u001b[A\n",
            "Training:  88%|████████▊ | 1766/2000 [15:12<01:34,  2.49iteration/s, mean_rewards=-187]\u001b[A\n",
            "Training:  88%|████████▊ | 1766/2000 [15:13<01:34,  2.49iteration/s, mean_rewards=-36.8]\u001b[A\n",
            "Training:  88%|████████▊ | 1767/2000 [15:13<01:32,  2.51iteration/s, mean_rewards=-36.8]\u001b[A\n",
            "Training:  88%|████████▊ | 1767/2000 [15:13<01:32,  2.51iteration/s, mean_rewards=-112] \u001b[A\n",
            "Training:  88%|████████▊ | 1768/2000 [15:13<01:24,  2.74iteration/s, mean_rewards=-112]\u001b[A\n",
            "Training:  88%|████████▊ | 1768/2000 [15:13<01:24,  2.74iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  88%|████████▊ | 1769/2000 [15:13<01:20,  2.86iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  88%|████████▊ | 1769/2000 [15:14<01:20,  2.86iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  88%|████████▊ | 1770/2000 [15:14<01:26,  2.65iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  88%|████████▊ | 1770/2000 [15:14<01:26,  2.65iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  89%|████████▊ | 1771/2000 [15:14<01:23,  2.75iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  89%|████████▊ | 1771/2000 [15:14<01:23,  2.75iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  89%|████████▊ | 1772/2000 [15:14<01:24,  2.71iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  89%|████████▊ | 1772/2000 [15:15<01:24,  2.71iteration/s, mean_rewards=-187]\u001b[A\n",
            "Training:  89%|████████▊ | 1773/2000 [15:15<01:27,  2.59iteration/s, mean_rewards=-187]\u001b[A\n",
            "Training:  89%|████████▊ | 1773/2000 [15:15<01:27,  2.59iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  89%|████████▊ | 1774/2000 [15:15<01:29,  2.53iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  89%|████████▊ | 1774/2000 [15:16<01:29,  2.53iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  89%|████████▉ | 1775/2000 [15:16<01:27,  2.58iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  89%|████████▉ | 1775/2000 [15:16<01:27,  2.58iteration/s, mean_rewards=-101]\u001b[A\n",
            "Training:  89%|████████▉ | 1776/2000 [15:16<01:27,  2.56iteration/s, mean_rewards=-101]\u001b[A\n",
            "Training:  89%|████████▉ | 1776/2000 [15:16<01:27,  2.56iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  89%|████████▉ | 1777/2000 [15:17<01:34,  2.37iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  89%|████████▉ | 1777/2000 [15:17<01:34,  2.37iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  89%|████████▉ | 1778/2000 [15:17<01:34,  2.34iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  89%|████████▉ | 1778/2000 [15:17<01:34,  2.34iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  89%|████████▉ | 1779/2000 [15:17<01:38,  2.25iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  89%|████████▉ | 1779/2000 [15:18<01:38,  2.25iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  89%|████████▉ | 1780/2000 [15:18<01:34,  2.34iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  89%|████████▉ | 1780/2000 [15:18<01:34,  2.34iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  89%|████████▉ | 1781/2000 [15:18<01:41,  2.15iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  89%|████████▉ | 1781/2000 [15:19<01:41,  2.15iteration/s, mean_rewards=-172]\u001b[A\n",
            "Training:  89%|████████▉ | 1782/2000 [15:19<01:42,  2.13iteration/s, mean_rewards=-172]\u001b[A\n",
            "Training:  89%|████████▉ | 1782/2000 [15:19<01:42,  2.13iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  89%|████████▉ | 1783/2000 [15:19<01:40,  2.15iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  89%|████████▉ | 1783/2000 [15:20<01:40,  2.15iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  89%|████████▉ | 1784/2000 [15:20<01:39,  2.18iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  89%|████████▉ | 1784/2000 [15:20<01:39,  2.18iteration/s, mean_rewards=-203]\u001b[A\n",
            "Training:  89%|████████▉ | 1785/2000 [15:20<01:34,  2.27iteration/s, mean_rewards=-203]\u001b[A\n",
            "Training:  89%|████████▉ | 1785/2000 [15:20<01:34,  2.27iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  89%|████████▉ | 1786/2000 [15:21<01:26,  2.46iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  89%|████████▉ | 1786/2000 [15:21<01:26,  2.46iteration/s, mean_rewards=-40.2]\u001b[A\n",
            "Training:  89%|████████▉ | 1787/2000 [15:21<01:25,  2.49iteration/s, mean_rewards=-40.2]\u001b[A\n",
            "Training:  89%|████████▉ | 1787/2000 [15:21<01:25,  2.49iteration/s, mean_rewards=-123] \u001b[A\n",
            "Training:  89%|████████▉ | 1788/2000 [15:21<01:23,  2.55iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  89%|████████▉ | 1788/2000 [15:22<01:23,  2.55iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  89%|████████▉ | 1789/2000 [15:22<01:20,  2.63iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  89%|████████▉ | 1789/2000 [15:22<01:20,  2.63iteration/s, mean_rewards=-92.1]\u001b[A\n",
            "Training:  90%|████████▉ | 1790/2000 [15:22<01:20,  2.61iteration/s, mean_rewards=-92.1]\u001b[A\n",
            "Training:  90%|████████▉ | 1790/2000 [15:22<01:20,  2.61iteration/s, mean_rewards=-147] \u001b[A\n",
            "Training:  90%|████████▉ | 1791/2000 [15:22<01:15,  2.76iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:  90%|████████▉ | 1791/2000 [15:23<01:15,  2.76iteration/s, mean_rewards=-220]\u001b[A\n",
            "Training:  90%|████████▉ | 1792/2000 [15:23<01:20,  2.57iteration/s, mean_rewards=-220]\u001b[A\n",
            "Training:  90%|████████▉ | 1792/2000 [15:23<01:20,  2.57iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:  90%|████████▉ | 1793/2000 [15:23<01:19,  2.61iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:  90%|████████▉ | 1793/2000 [15:23<01:19,  2.61iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  90%|████████▉ | 1794/2000 [15:24<01:19,  2.59iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  90%|████████▉ | 1794/2000 [15:24<01:19,  2.59iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  90%|████████▉ | 1795/2000 [15:24<01:21,  2.50iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  90%|████████▉ | 1795/2000 [15:24<01:21,  2.50iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  90%|████████▉ | 1796/2000 [15:24<01:20,  2.54iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  90%|████████▉ | 1796/2000 [15:25<01:20,  2.54iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  90%|████████▉ | 1797/2000 [15:25<01:15,  2.68iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  90%|████████▉ | 1797/2000 [15:25<01:15,  2.68iteration/s, mean_rewards=-159]\u001b[A\n",
            "Training:  90%|████████▉ | 1798/2000 [15:25<01:14,  2.71iteration/s, mean_rewards=-159]\u001b[A\n",
            "Training:  90%|████████▉ | 1798/2000 [15:25<01:14,  2.71iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  90%|████████▉ | 1799/2000 [15:26<01:18,  2.55iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  90%|████████▉ | 1799/2000 [15:26<01:18,  2.55iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  90%|█████████ | 1800/2000 [15:26<01:17,  2.60iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  90%|█████████ | 1800/2000 [15:26<01:17,  2.60iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  90%|█████████ | 1801/2000 [15:26<01:16,  2.59iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  90%|█████████ | 1801/2000 [15:26<01:16,  2.59iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  90%|█████████ | 1802/2000 [15:27<01:13,  2.71iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  90%|█████████ | 1802/2000 [15:27<01:13,  2.71iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  90%|█████████ | 1803/2000 [15:27<01:12,  2.70iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  90%|█████████ | 1803/2000 [15:27<01:12,  2.70iteration/s, mean_rewards=-92.6]\u001b[A\n",
            "Training:  90%|█████████ | 1804/2000 [15:27<01:12,  2.69iteration/s, mean_rewards=-92.6]\u001b[A\n",
            "Training:  90%|█████████ | 1804/2000 [15:28<01:12,  2.69iteration/s, mean_rewards=-183] \u001b[A\n",
            "Training:  90%|█████████ | 1805/2000 [15:28<01:12,  2.67iteration/s, mean_rewards=-183]\u001b[A\n",
            "Training:  90%|█████████ | 1805/2000 [15:28<01:12,  2.67iteration/s, mean_rewards=-95.8]\u001b[A\n",
            "Training:  90%|█████████ | 1806/2000 [15:28<01:08,  2.84iteration/s, mean_rewards=-95.8]\u001b[A\n",
            "Training:  90%|█████████ | 1806/2000 [15:28<01:08,  2.84iteration/s, mean_rewards=-69.2]\u001b[A\n",
            "Training:  90%|█████████ | 1807/2000 [15:28<01:06,  2.90iteration/s, mean_rewards=-69.2]\u001b[A\n",
            "Training:  90%|█████████ | 1807/2000 [15:29<01:06,  2.90iteration/s, mean_rewards=-153] \u001b[A\n",
            "Training:  90%|█████████ | 1808/2000 [15:29<01:08,  2.81iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  90%|█████████ | 1808/2000 [15:29<01:08,  2.81iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  90%|█████████ | 1809/2000 [15:29<01:06,  2.85iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  90%|█████████ | 1809/2000 [15:29<01:06,  2.85iteration/s, mean_rewards=-105]\u001b[A\n",
            "Training:  90%|█████████ | 1810/2000 [15:30<01:15,  2.52iteration/s, mean_rewards=-105]\u001b[A\n",
            "Training:  90%|█████████ | 1810/2000 [15:30<01:15,  2.52iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  91%|█████████ | 1811/2000 [15:30<01:19,  2.36iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  91%|█████████ | 1811/2000 [15:30<01:19,  2.36iteration/s, mean_rewards=-178]\u001b[A\n",
            "Training:  91%|█████████ | 1812/2000 [15:31<01:25,  2.20iteration/s, mean_rewards=-178]\u001b[A\n",
            "Training:  91%|█████████ | 1812/2000 [15:31<01:25,  2.20iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  91%|█████████ | 1813/2000 [15:31<01:33,  2.00iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  91%|█████████ | 1813/2000 [15:31<01:33,  2.00iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  91%|█████████ | 1814/2000 [15:32<01:27,  2.13iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  91%|█████████ | 1814/2000 [15:32<01:27,  2.13iteration/s, mean_rewards=-106]\u001b[A\n",
            "Training:  91%|█████████ | 1815/2000 [15:32<01:22,  2.23iteration/s, mean_rewards=-106]\u001b[A\n",
            "Training:  91%|█████████ | 1815/2000 [15:32<01:22,  2.23iteration/s, mean_rewards=-53.1]\u001b[A\n",
            "Training:  91%|█████████ | 1816/2000 [15:32<01:25,  2.14iteration/s, mean_rewards=-53.1]\u001b[A\n",
            "Training:  91%|█████████ | 1816/2000 [15:33<01:25,  2.14iteration/s, mean_rewards=-140] \u001b[A\n",
            "Training:  91%|█████████ | 1817/2000 [15:33<01:21,  2.25iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  91%|█████████ | 1817/2000 [15:33<01:21,  2.25iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  91%|█████████ | 1818/2000 [15:33<01:21,  2.24iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  91%|█████████ | 1818/2000 [15:34<01:21,  2.24iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  91%|█████████ | 1819/2000 [15:34<01:14,  2.42iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  91%|█████████ | 1819/2000 [15:34<01:14,  2.42iteration/s, mean_rewards=-119]\u001b[A\n",
            "Training:  91%|█████████ | 1820/2000 [15:34<01:11,  2.52iteration/s, mean_rewards=-119]\u001b[A\n",
            "Training:  91%|█████████ | 1820/2000 [15:34<01:11,  2.52iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:  91%|█████████ | 1821/2000 [15:34<01:08,  2.63iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:  91%|█████████ | 1821/2000 [15:35<01:08,  2.63iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  91%|█████████ | 1822/2000 [15:35<01:08,  2.62iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  91%|█████████ | 1822/2000 [15:35<01:08,  2.62iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:  91%|█████████ | 1823/2000 [15:35<01:04,  2.73iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:  91%|█████████ | 1823/2000 [15:35<01:04,  2.73iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  91%|█████████ | 1824/2000 [15:36<01:07,  2.62iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  91%|█████████ | 1824/2000 [15:36<01:07,  2.62iteration/s, mean_rewards=-116]\u001b[A\n",
            "Training:  91%|█████████▏| 1825/2000 [15:36<01:06,  2.64iteration/s, mean_rewards=-116]\u001b[A\n",
            "Training:  91%|█████████▏| 1825/2000 [15:36<01:06,  2.64iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  91%|█████████▏| 1826/2000 [15:36<01:07,  2.56iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  91%|█████████▏| 1826/2000 [15:36<01:07,  2.56iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  91%|█████████▏| 1827/2000 [15:37<01:03,  2.73iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  91%|█████████▏| 1827/2000 [15:37<01:03,  2.73iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  91%|█████████▏| 1828/2000 [15:37<01:03,  2.73iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  91%|█████████▏| 1828/2000 [15:37<01:03,  2.73iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  91%|█████████▏| 1829/2000 [15:37<01:01,  2.80iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  91%|█████████▏| 1829/2000 [15:38<01:01,  2.80iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  92%|█████████▏| 1830/2000 [15:38<01:04,  2.62iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  92%|█████████▏| 1830/2000 [15:38<01:04,  2.62iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  92%|█████████▏| 1831/2000 [15:38<01:07,  2.49iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  92%|█████████▏| 1831/2000 [15:38<01:07,  2.49iteration/s, mean_rewards=-89.1]\u001b[A\n",
            "Training:  92%|█████████▏| 1832/2000 [15:39<01:10,  2.38iteration/s, mean_rewards=-89.1]\u001b[A\n",
            "Training:  92%|█████████▏| 1832/2000 [15:39<01:10,  2.38iteration/s, mean_rewards=-110] \u001b[A\n",
            "Training:  92%|█████████▏| 1833/2000 [15:39<01:05,  2.53iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  92%|█████████▏| 1833/2000 [15:39<01:05,  2.53iteration/s, mean_rewards=-198]\u001b[A\n",
            "Training:  92%|█████████▏| 1834/2000 [15:39<01:04,  2.56iteration/s, mean_rewards=-198]\u001b[A\n",
            "Training:  92%|█████████▏| 1834/2000 [15:40<01:04,  2.56iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  92%|█████████▏| 1835/2000 [15:40<01:05,  2.53iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  92%|█████████▏| 1835/2000 [15:40<01:05,  2.53iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  92%|█████████▏| 1836/2000 [15:40<01:00,  2.72iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  92%|█████████▏| 1836/2000 [15:40<01:00,  2.72iteration/s, mean_rewards=-67] \u001b[A\n",
            "Training:  92%|█████████▏| 1837/2000 [15:41<01:05,  2.49iteration/s, mean_rewards=-67]\u001b[A\n",
            "Training:  92%|█████████▏| 1837/2000 [15:41<01:05,  2.49iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  92%|█████████▏| 1838/2000 [15:41<01:00,  2.68iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  92%|█████████▏| 1838/2000 [15:41<01:00,  2.68iteration/s, mean_rewards=-157]\u001b[A\n",
            "Training:  92%|█████████▏| 1839/2000 [15:41<01:01,  2.63iteration/s, mean_rewards=-157]\u001b[A\n",
            "Training:  92%|█████████▏| 1839/2000 [15:42<01:01,  2.63iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  92%|█████████▏| 1840/2000 [15:42<01:01,  2.61iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  92%|█████████▏| 1840/2000 [15:42<01:01,  2.61iteration/s, mean_rewards=-68.4]\u001b[A\n",
            "Training:  92%|█████████▏| 1841/2000 [15:42<01:02,  2.56iteration/s, mean_rewards=-68.4]\u001b[A\n",
            "Training:  92%|█████████▏| 1841/2000 [15:42<01:02,  2.56iteration/s, mean_rewards=-140] \u001b[A\n",
            "Training:  92%|█████████▏| 1842/2000 [15:43<01:04,  2.47iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  92%|█████████▏| 1842/2000 [15:43<01:04,  2.47iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  92%|█████████▏| 1843/2000 [15:43<01:06,  2.37iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  92%|█████████▏| 1843/2000 [15:43<01:06,  2.37iteration/s, mean_rewards=-115]\u001b[A\n",
            "Training:  92%|█████████▏| 1844/2000 [15:43<01:06,  2.33iteration/s, mean_rewards=-115]\u001b[A\n",
            "Training:  92%|█████████▏| 1844/2000 [15:44<01:06,  2.33iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  92%|█████████▏| 1845/2000 [15:44<01:10,  2.20iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  92%|█████████▏| 1845/2000 [15:44<01:10,  2.20iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  92%|█████████▏| 1846/2000 [15:44<01:09,  2.23iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  92%|█████████▏| 1846/2000 [15:45<01:09,  2.23iteration/s, mean_rewards=-75.1]\u001b[A\n",
            "Training:  92%|█████████▏| 1847/2000 [15:45<01:09,  2.20iteration/s, mean_rewards=-75.1]\u001b[A\n",
            "Training:  92%|█████████▏| 1847/2000 [15:45<01:09,  2.20iteration/s, mean_rewards=-107] \u001b[A\n",
            "Training:  92%|█████████▏| 1848/2000 [15:45<01:09,  2.18iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  92%|█████████▏| 1848/2000 [15:46<01:09,  2.18iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  92%|█████████▏| 1849/2000 [15:46<01:08,  2.21iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  92%|█████████▏| 1849/2000 [15:46<01:08,  2.21iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  92%|█████████▎| 1850/2000 [15:46<01:04,  2.33iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  92%|█████████▎| 1850/2000 [15:46<01:04,  2.33iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  93%|█████████▎| 1851/2000 [15:47<01:04,  2.29iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  93%|█████████▎| 1851/2000 [15:47<01:04,  2.29iteration/s, mean_rewards=-72.3]\u001b[A\n",
            "Training:  93%|█████████▎| 1852/2000 [15:47<01:04,  2.28iteration/s, mean_rewards=-72.3]\u001b[A\n",
            "Training:  93%|█████████▎| 1852/2000 [15:47<01:04,  2.28iteration/s, mean_rewards=-96.5]\u001b[A\n",
            "Training:  93%|█████████▎| 1853/2000 [15:47<01:01,  2.37iteration/s, mean_rewards=-96.5]\u001b[A\n",
            "Training:  93%|█████████▎| 1853/2000 [15:48<01:01,  2.37iteration/s, mean_rewards=-84.3]\u001b[A\n",
            "Training:  93%|█████████▎| 1854/2000 [15:48<01:03,  2.30iteration/s, mean_rewards=-84.3]\u001b[A\n",
            "Training:  93%|█████████▎| 1854/2000 [15:48<01:03,  2.30iteration/s, mean_rewards=-115] \u001b[A\n",
            "Training:  93%|█████████▎| 1855/2000 [15:48<00:59,  2.42iteration/s, mean_rewards=-115]\u001b[A\n",
            "Training:  93%|█████████▎| 1855/2000 [15:49<00:59,  2.42iteration/s, mean_rewards=-116]\u001b[A\n",
            "Training:  93%|█████████▎| 1856/2000 [15:49<01:00,  2.36iteration/s, mean_rewards=-116]\u001b[A\n",
            "Training:  93%|█████████▎| 1856/2000 [15:49<01:00,  2.36iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  93%|█████████▎| 1857/2000 [15:49<00:58,  2.44iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  93%|█████████▎| 1857/2000 [15:49<00:58,  2.44iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  93%|█████████▎| 1858/2000 [15:49<00:55,  2.54iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  93%|█████████▎| 1858/2000 [15:50<00:55,  2.54iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  93%|█████████▎| 1859/2000 [15:50<00:52,  2.70iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  93%|█████████▎| 1859/2000 [15:50<00:52,  2.70iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  93%|█████████▎| 1860/2000 [15:50<00:49,  2.81iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  93%|█████████▎| 1860/2000 [15:50<00:49,  2.81iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  93%|█████████▎| 1861/2000 [15:50<00:50,  2.73iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  93%|█████████▎| 1861/2000 [15:51<00:50,  2.73iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  93%|█████████▎| 1862/2000 [15:51<00:54,  2.52iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  93%|█████████▎| 1862/2000 [15:51<00:54,  2.52iteration/s, mean_rewards=-80.8]\u001b[A\n",
            "Training:  93%|█████████▎| 1863/2000 [15:51<00:59,  2.32iteration/s, mean_rewards=-80.8]\u001b[A\n",
            "Training:  93%|█████████▎| 1863/2000 [15:52<00:59,  2.32iteration/s, mean_rewards=-116] \u001b[A\n",
            "Training:  93%|█████████▎| 1864/2000 [15:52<00:52,  2.57iteration/s, mean_rewards=-116]\u001b[A\n",
            "Training:  93%|█████████▎| 1864/2000 [15:52<00:52,  2.57iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  93%|█████████▎| 1865/2000 [15:52<00:50,  2.65iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  93%|█████████▎| 1865/2000 [15:52<00:50,  2.65iteration/s, mean_rewards=-199]\u001b[A\n",
            "Training:  93%|█████████▎| 1866/2000 [15:52<00:52,  2.57iteration/s, mean_rewards=-199]\u001b[A\n",
            "Training:  93%|█████████▎| 1866/2000 [15:53<00:52,  2.57iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  93%|█████████▎| 1867/2000 [15:53<00:48,  2.72iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  93%|█████████▎| 1867/2000 [15:53<00:48,  2.72iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  93%|█████████▎| 1868/2000 [15:53<00:47,  2.78iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  93%|█████████▎| 1868/2000 [15:53<00:47,  2.78iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  93%|█████████▎| 1869/2000 [15:54<00:47,  2.76iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  93%|█████████▎| 1869/2000 [15:54<00:47,  2.76iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  94%|█████████▎| 1870/2000 [15:54<00:47,  2.72iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  94%|█████████▎| 1870/2000 [15:54<00:47,  2.72iteration/s, mean_rewards=-88.6]\u001b[A\n",
            "Training:  94%|█████████▎| 1871/2000 [15:54<00:49,  2.60iteration/s, mean_rewards=-88.6]\u001b[A\n",
            "Training:  94%|█████████▎| 1871/2000 [15:55<00:49,  2.60iteration/s, mean_rewards=-39.1]\u001b[A\n",
            "Training:  94%|█████████▎| 1872/2000 [15:55<00:49,  2.57iteration/s, mean_rewards=-39.1]\u001b[A\n",
            "Training:  94%|█████████▎| 1872/2000 [15:55<00:49,  2.57iteration/s, mean_rewards=-122] \u001b[A\n",
            "Training:  94%|█████████▎| 1873/2000 [15:55<00:48,  2.60iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  94%|█████████▎| 1873/2000 [15:55<00:48,  2.60iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  94%|█████████▎| 1874/2000 [15:56<00:56,  2.24iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  94%|█████████▎| 1874/2000 [15:56<00:56,  2.24iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  94%|█████████▍| 1875/2000 [15:56<00:56,  2.20iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  94%|█████████▍| 1875/2000 [15:56<00:56,  2.20iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  94%|█████████▍| 1876/2000 [15:57<00:55,  2.24iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  94%|█████████▍| 1876/2000 [15:57<00:55,  2.24iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:  94%|█████████▍| 1877/2000 [15:57<00:56,  2.18iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:  94%|█████████▍| 1877/2000 [15:57<00:56,  2.18iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  94%|█████████▍| 1878/2000 [15:58<00:59,  2.05iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  94%|█████████▍| 1878/2000 [15:58<00:59,  2.05iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  94%|█████████▍| 1879/2000 [15:58<00:57,  2.09iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  94%|█████████▍| 1879/2000 [15:58<00:57,  2.09iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  94%|█████████▍| 1880/2000 [15:58<00:52,  2.28iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  94%|█████████▍| 1880/2000 [15:59<00:52,  2.28iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  94%|█████████▍| 1881/2000 [15:59<00:52,  2.28iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  94%|█████████▍| 1881/2000 [15:59<00:52,  2.28iteration/s, mean_rewards=-165]\u001b[A\n",
            "Training:  94%|█████████▍| 1882/2000 [15:59<00:49,  2.37iteration/s, mean_rewards=-165]\u001b[A\n",
            "Training:  94%|█████████▍| 1882/2000 [15:59<00:49,  2.37iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  94%|█████████▍| 1883/2000 [16:00<00:47,  2.47iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  94%|█████████▍| 1883/2000 [16:00<00:47,  2.47iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  94%|█████████▍| 1884/2000 [16:00<00:45,  2.54iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  94%|█████████▍| 1884/2000 [16:00<00:45,  2.54iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  94%|█████████▍| 1885/2000 [16:00<00:45,  2.53iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  94%|█████████▍| 1885/2000 [16:01<00:45,  2.53iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  94%|█████████▍| 1886/2000 [16:01<00:44,  2.59iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  94%|█████████▍| 1886/2000 [16:01<00:44,  2.59iteration/s, mean_rewards=-162]\u001b[A\n",
            "Training:  94%|█████████▍| 1887/2000 [16:01<00:43,  2.58iteration/s, mean_rewards=-162]\u001b[A\n",
            "Training:  94%|█████████▍| 1887/2000 [16:01<00:43,  2.58iteration/s, mean_rewards=-250]\u001b[A\n",
            "Training:  94%|█████████▍| 1888/2000 [16:02<00:45,  2.44iteration/s, mean_rewards=-250]\u001b[A\n",
            "Training:  94%|█████████▍| 1888/2000 [16:02<00:45,  2.44iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:  94%|█████████▍| 1889/2000 [16:02<00:44,  2.48iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:  94%|█████████▍| 1889/2000 [16:02<00:44,  2.48iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  94%|█████████▍| 1890/2000 [16:02<00:44,  2.48iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  94%|█████████▍| 1890/2000 [16:03<00:44,  2.48iteration/s, mean_rewards=-175]\u001b[A\n",
            "Training:  95%|█████████▍| 1891/2000 [16:03<00:45,  2.40iteration/s, mean_rewards=-175]\u001b[A\n",
            "Training:  95%|█████████▍| 1891/2000 [16:03<00:45,  2.40iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:  95%|█████████▍| 1892/2000 [16:03<00:46,  2.34iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:  95%|█████████▍| 1892/2000 [16:04<00:46,  2.34iteration/s, mean_rewards=-80.6]\u001b[A\n",
            "Training:  95%|█████████▍| 1893/2000 [16:04<00:44,  2.41iteration/s, mean_rewards=-80.6]\u001b[A\n",
            "Training:  95%|█████████▍| 1893/2000 [16:04<00:44,  2.41iteration/s, mean_rewards=-108] \u001b[A\n",
            "Training:  95%|█████████▍| 1894/2000 [16:04<00:42,  2.49iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:  95%|█████████▍| 1894/2000 [16:04<00:42,  2.49iteration/s, mean_rewards=-112]\u001b[A\n",
            "Training:  95%|█████████▍| 1895/2000 [16:04<00:43,  2.44iteration/s, mean_rewards=-112]\u001b[A\n",
            "Training:  95%|█████████▍| 1895/2000 [16:05<00:43,  2.44iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  95%|█████████▍| 1896/2000 [16:05<00:41,  2.50iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  95%|█████████▍| 1896/2000 [16:05<00:41,  2.50iteration/s, mean_rewards=-231]\u001b[A\n",
            "Training:  95%|█████████▍| 1897/2000 [16:05<00:40,  2.53iteration/s, mean_rewards=-231]\u001b[A\n",
            "Training:  95%|█████████▍| 1897/2000 [16:05<00:40,  2.53iteration/s, mean_rewards=-179]\u001b[A\n",
            "Training:  95%|█████████▍| 1898/2000 [16:06<00:40,  2.51iteration/s, mean_rewards=-179]\u001b[A\n",
            "Training:  95%|█████████▍| 1898/2000 [16:06<00:40,  2.51iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  95%|█████████▍| 1899/2000 [16:06<00:41,  2.45iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  95%|█████████▍| 1899/2000 [16:06<00:41,  2.45iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  95%|█████████▌| 1900/2000 [16:07<00:42,  2.36iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  95%|█████████▌| 1900/2000 [16:07<00:42,  2.36iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:  95%|█████████▌| 1901/2000 [16:07<00:40,  2.45iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:  95%|█████████▌| 1901/2000 [16:07<00:40,  2.45iteration/s, mean_rewards=-57.5]\u001b[A\n",
            "Training:  95%|█████████▌| 1902/2000 [16:07<00:37,  2.60iteration/s, mean_rewards=-57.5]\u001b[A\n",
            "Training:  95%|█████████▌| 1902/2000 [16:07<00:37,  2.60iteration/s, mean_rewards=-56.1]\u001b[A\n",
            "Training:  95%|█████████▌| 1903/2000 [16:08<00:36,  2.64iteration/s, mean_rewards=-56.1]\u001b[A\n",
            "Training:  95%|█████████▌| 1903/2000 [16:08<00:36,  2.64iteration/s, mean_rewards=-168] \u001b[A\n",
            "Training:  95%|█████████▌| 1904/2000 [16:08<00:37,  2.54iteration/s, mean_rewards=-168]\u001b[A\n",
            "Training:  95%|█████████▌| 1904/2000 [16:08<00:37,  2.54iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  95%|█████████▌| 1905/2000 [16:09<00:40,  2.37iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  95%|█████████▌| 1905/2000 [16:09<00:40,  2.37iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  95%|█████████▌| 1906/2000 [16:09<00:41,  2.27iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  95%|█████████▌| 1906/2000 [16:09<00:41,  2.27iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  95%|█████████▌| 1907/2000 [16:09<00:39,  2.35iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  95%|█████████▌| 1907/2000 [16:10<00:39,  2.35iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  95%|█████████▌| 1908/2000 [16:10<00:38,  2.37iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  95%|█████████▌| 1908/2000 [16:10<00:38,  2.37iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  95%|█████████▌| 1909/2000 [16:10<00:42,  2.12iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  95%|█████████▌| 1909/2000 [16:11<00:42,  2.12iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:  96%|█████████▌| 1910/2000 [16:11<00:46,  1.95iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:  96%|█████████▌| 1910/2000 [16:11<00:46,  1.95iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:  96%|█████████▌| 1911/2000 [16:11<00:43,  2.03iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:  96%|█████████▌| 1911/2000 [16:12<00:43,  2.03iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:  96%|█████████▌| 1912/2000 [16:12<00:41,  2.15iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:  96%|█████████▌| 1912/2000 [16:12<00:41,  2.15iteration/s, mean_rewards=-188]\u001b[A\n",
            "Training:  96%|█████████▌| 1913/2000 [16:12<00:39,  2.19iteration/s, mean_rewards=-188]\u001b[A\n",
            "Training:  96%|█████████▌| 1913/2000 [16:12<00:39,  2.19iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  96%|█████████▌| 1914/2000 [16:13<00:36,  2.38iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  96%|█████████▌| 1914/2000 [16:13<00:36,  2.38iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  96%|█████████▌| 1915/2000 [16:13<00:34,  2.48iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  96%|█████████▌| 1915/2000 [16:13<00:34,  2.48iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  96%|█████████▌| 1916/2000 [16:13<00:33,  2.51iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  96%|█████████▌| 1916/2000 [16:14<00:33,  2.51iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  96%|█████████▌| 1917/2000 [16:14<00:32,  2.57iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  96%|█████████▌| 1917/2000 [16:14<00:32,  2.57iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  96%|█████████▌| 1918/2000 [16:14<00:31,  2.57iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  96%|█████████▌| 1918/2000 [16:14<00:31,  2.57iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:  96%|█████████▌| 1919/2000 [16:15<00:31,  2.57iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:  96%|█████████▌| 1919/2000 [16:15<00:31,  2.57iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  96%|█████████▌| 1920/2000 [16:15<00:31,  2.55iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  96%|█████████▌| 1920/2000 [16:15<00:31,  2.55iteration/s, mean_rewards=-71.5]\u001b[A\n",
            "Training:  96%|█████████▌| 1921/2000 [16:15<00:31,  2.54iteration/s, mean_rewards=-71.5]\u001b[A\n",
            "Training:  96%|█████████▌| 1921/2000 [16:16<00:31,  2.54iteration/s, mean_rewards=-104] \u001b[A\n",
            "Training:  96%|█████████▌| 1922/2000 [16:16<00:28,  2.71iteration/s, mean_rewards=-104]\u001b[A\n",
            "Training:  96%|█████████▌| 1922/2000 [16:16<00:28,  2.71iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  96%|█████████▌| 1923/2000 [16:16<00:29,  2.60iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  96%|█████████▌| 1923/2000 [16:16<00:29,  2.60iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  96%|█████████▌| 1924/2000 [16:16<00:29,  2.59iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  96%|█████████▌| 1924/2000 [16:17<00:29,  2.59iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  96%|█████████▋| 1925/2000 [16:17<00:29,  2.53iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  96%|█████████▋| 1925/2000 [16:17<00:29,  2.53iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  96%|█████████▋| 1926/2000 [16:17<00:28,  2.56iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  96%|█████████▋| 1926/2000 [16:17<00:28,  2.56iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  96%|█████████▋| 1927/2000 [16:18<00:27,  2.62iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  96%|█████████▋| 1927/2000 [16:18<00:27,  2.62iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  96%|█████████▋| 1928/2000 [16:18<00:26,  2.76iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  96%|█████████▋| 1928/2000 [16:18<00:26,  2.76iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  96%|█████████▋| 1929/2000 [16:18<00:26,  2.72iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  96%|█████████▋| 1929/2000 [16:18<00:26,  2.72iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  96%|█████████▋| 1930/2000 [16:19<00:25,  2.80iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  96%|█████████▋| 1930/2000 [16:19<00:25,  2.80iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  97%|█████████▋| 1931/2000 [16:19<00:25,  2.67iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  97%|█████████▋| 1931/2000 [16:19<00:25,  2.67iteration/s, mean_rewards=-90.7]\u001b[A\n",
            "Training:  97%|█████████▋| 1932/2000 [16:19<00:26,  2.61iteration/s, mean_rewards=-90.7]\u001b[A\n",
            "Training:  97%|█████████▋| 1932/2000 [16:20<00:26,  2.61iteration/s, mean_rewards=-133] \u001b[A\n",
            "Training:  97%|█████████▋| 1933/2000 [16:20<00:25,  2.62iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  97%|█████████▋| 1933/2000 [16:20<00:25,  2.62iteration/s, mean_rewards=-179]\u001b[A\n",
            "Training:  97%|█████████▋| 1934/2000 [16:20<00:25,  2.61iteration/s, mean_rewards=-179]\u001b[A\n",
            "Training:  97%|█████████▋| 1934/2000 [16:20<00:25,  2.61iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  97%|█████████▋| 1935/2000 [16:21<00:25,  2.57iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  97%|█████████▋| 1935/2000 [16:21<00:25,  2.57iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  97%|█████████▋| 1936/2000 [16:21<00:24,  2.59iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  97%|█████████▋| 1936/2000 [16:21<00:24,  2.59iteration/s, mean_rewards=-162]\u001b[A\n",
            "Training:  97%|█████████▋| 1937/2000 [16:21<00:24,  2.52iteration/s, mean_rewards=-162]\u001b[A\n",
            "Training:  97%|█████████▋| 1937/2000 [16:22<00:24,  2.52iteration/s, mean_rewards=-165]\u001b[A\n",
            "Training:  97%|█████████▋| 1938/2000 [16:22<00:27,  2.28iteration/s, mean_rewards=-165]\u001b[A\n",
            "Training:  97%|█████████▋| 1938/2000 [16:22<00:27,  2.28iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  97%|█████████▋| 1939/2000 [16:22<00:26,  2.34iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  97%|█████████▋| 1939/2000 [16:23<00:26,  2.34iteration/s, mean_rewards=-93.7]\u001b[A\n",
            "Training:  97%|█████████▋| 1940/2000 [16:23<00:28,  2.10iteration/s, mean_rewards=-93.7]\u001b[A\n",
            "Training:  97%|█████████▋| 1940/2000 [16:23<00:28,  2.10iteration/s, mean_rewards=-126] \u001b[A\n",
            "Training:  97%|█████████▋| 1941/2000 [16:23<00:28,  2.06iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  97%|█████████▋| 1941/2000 [16:24<00:28,  2.06iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  97%|█████████▋| 1942/2000 [16:24<00:27,  2.08iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  97%|█████████▋| 1942/2000 [16:24<00:27,  2.08iteration/s, mean_rewards=-106]\u001b[A\n",
            "Training:  97%|█████████▋| 1943/2000 [16:24<00:26,  2.15iteration/s, mean_rewards=-106]\u001b[A\n",
            "Training:  97%|█████████▋| 1943/2000 [16:25<00:26,  2.15iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  97%|█████████▋| 1944/2000 [16:25<00:26,  2.08iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  97%|█████████▋| 1944/2000 [16:25<00:26,  2.08iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  97%|█████████▋| 1945/2000 [16:25<00:24,  2.21iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  97%|█████████▋| 1945/2000 [16:25<00:24,  2.21iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  97%|█████████▋| 1946/2000 [16:26<00:22,  2.41iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  97%|█████████▋| 1946/2000 [16:26<00:22,  2.41iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:  97%|█████████▋| 1947/2000 [16:26<00:21,  2.52iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:  97%|█████████▋| 1947/2000 [16:26<00:21,  2.52iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  97%|█████████▋| 1948/2000 [16:26<00:19,  2.66iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  97%|█████████▋| 1948/2000 [16:26<00:19,  2.66iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  97%|█████████▋| 1949/2000 [16:27<00:18,  2.77iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  97%|█████████▋| 1949/2000 [16:27<00:18,  2.77iteration/s, mean_rewards=-212]\u001b[A\n",
            "Training:  98%|█████████▊| 1950/2000 [16:27<00:19,  2.62iteration/s, mean_rewards=-212]\u001b[A\n",
            "Training:  98%|█████████▊| 1950/2000 [16:27<00:19,  2.62iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:  98%|█████████▊| 1951/2000 [16:27<00:18,  2.61iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:  98%|█████████▊| 1951/2000 [16:28<00:18,  2.61iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  98%|█████████▊| 1952/2000 [16:28<00:17,  2.71iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  98%|█████████▊| 1952/2000 [16:28<00:17,  2.71iteration/s, mean_rewards=-157]\u001b[A\n",
            "Training:  98%|█████████▊| 1953/2000 [16:28<00:17,  2.69iteration/s, mean_rewards=-157]\u001b[A\n",
            "Training:  98%|█████████▊| 1953/2000 [16:28<00:17,  2.69iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  98%|█████████▊| 1954/2000 [16:28<00:17,  2.65iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  98%|█████████▊| 1954/2000 [16:29<00:17,  2.65iteration/s, mean_rewards=-197]\u001b[A\n",
            "Training:  98%|█████████▊| 1955/2000 [16:29<00:18,  2.49iteration/s, mean_rewards=-197]\u001b[A\n",
            "Training:  98%|█████████▊| 1955/2000 [16:29<00:18,  2.49iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  98%|█████████▊| 1956/2000 [16:29<00:17,  2.47iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  98%|█████████▊| 1956/2000 [16:30<00:17,  2.47iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  98%|█████████▊| 1957/2000 [16:30<00:16,  2.57iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  98%|█████████▊| 1957/2000 [16:30<00:16,  2.57iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  98%|█████████▊| 1958/2000 [16:30<00:16,  2.57iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  98%|█████████▊| 1958/2000 [16:30<00:16,  2.57iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  98%|█████████▊| 1959/2000 [16:30<00:15,  2.70iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  98%|█████████▊| 1959/2000 [16:31<00:15,  2.70iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  98%|█████████▊| 1960/2000 [16:31<00:14,  2.69iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  98%|█████████▊| 1960/2000 [16:31<00:14,  2.69iteration/s, mean_rewards=-109]\u001b[A\n",
            "Training:  98%|█████████▊| 1961/2000 [16:31<00:13,  2.83iteration/s, mean_rewards=-109]\u001b[A\n",
            "Training:  98%|█████████▊| 1961/2000 [16:31<00:13,  2.83iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  98%|█████████▊| 1962/2000 [16:32<00:14,  2.68iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  98%|█████████▊| 1962/2000 [16:32<00:14,  2.68iteration/s, mean_rewards=-81.4]\u001b[A\n",
            "Training:  98%|█████████▊| 1963/2000 [16:32<00:13,  2.70iteration/s, mean_rewards=-81.4]\u001b[A\n",
            "Training:  98%|█████████▊| 1963/2000 [16:32<00:13,  2.70iteration/s, mean_rewards=-114] \u001b[A\n",
            "Training:  98%|█████████▊| 1964/2000 [16:32<00:13,  2.65iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  98%|█████████▊| 1964/2000 [16:33<00:13,  2.65iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  98%|█████████▊| 1965/2000 [16:33<00:13,  2.67iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  98%|█████████▊| 1965/2000 [16:33<00:13,  2.67iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  98%|█████████▊| 1966/2000 [16:33<00:11,  2.84iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  98%|█████████▊| 1966/2000 [16:33<00:11,  2.84iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  98%|█████████▊| 1967/2000 [16:33<00:11,  2.76iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  98%|█████████▊| 1967/2000 [16:34<00:11,  2.76iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  98%|█████████▊| 1968/2000 [16:34<00:11,  2.73iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  98%|█████████▊| 1968/2000 [16:34<00:11,  2.73iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  98%|█████████▊| 1969/2000 [16:34<00:11,  2.72iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  98%|█████████▊| 1969/2000 [16:34<00:11,  2.72iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:  98%|█████████▊| 1970/2000 [16:35<00:11,  2.62iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:  98%|█████████▊| 1970/2000 [16:35<00:11,  2.62iteration/s, mean_rewards=-97.8]\u001b[A\n",
            "Training:  99%|█████████▊| 1971/2000 [16:35<00:10,  2.75iteration/s, mean_rewards=-97.8]\u001b[A\n",
            "Training:  99%|█████████▊| 1971/2000 [16:35<00:10,  2.75iteration/s, mean_rewards=-143] \u001b[A\n",
            "Training:  99%|█████████▊| 1972/2000 [16:35<00:11,  2.51iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  99%|█████████▊| 1972/2000 [16:36<00:11,  2.51iteration/s, mean_rewards=-176]\u001b[A\n",
            "Training:  99%|█████████▊| 1973/2000 [16:36<00:11,  2.37iteration/s, mean_rewards=-176]\u001b[A\n",
            "Training:  99%|█████████▊| 1973/2000 [16:36<00:11,  2.37iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:  99%|█████████▊| 1974/2000 [16:36<00:11,  2.35iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:  99%|█████████▊| 1974/2000 [16:37<00:11,  2.35iteration/s, mean_rewards=-103]\u001b[A\n",
            "Training:  99%|█████████▉| 1975/2000 [16:37<00:11,  2.19iteration/s, mean_rewards=-103]\u001b[A\n",
            "Training:  99%|█████████▉| 1975/2000 [16:37<00:11,  2.19iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  99%|█████████▉| 1976/2000 [16:37<00:11,  2.02iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  99%|█████████▉| 1976/2000 [16:38<00:11,  2.02iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  99%|█████████▉| 1977/2000 [16:38<00:11,  1.96iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  99%|█████████▉| 1977/2000 [16:38<00:11,  1.96iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  99%|█████████▉| 1978/2000 [16:38<00:10,  2.05iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  99%|█████████▉| 1978/2000 [16:39<00:10,  2.05iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  99%|█████████▉| 1979/2000 [16:39<00:09,  2.20iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  99%|█████████▉| 1979/2000 [16:39<00:09,  2.20iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  99%|█████████▉| 1980/2000 [16:39<00:08,  2.34iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  99%|█████████▉| 1980/2000 [16:39<00:08,  2.34iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  99%|█████████▉| 1981/2000 [16:39<00:08,  2.35iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  99%|█████████▉| 1981/2000 [16:40<00:08,  2.35iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  99%|█████████▉| 1982/2000 [16:40<00:07,  2.42iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  99%|█████████▉| 1982/2000 [16:40<00:07,  2.42iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  99%|█████████▉| 1983/2000 [16:40<00:06,  2.58iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  99%|█████████▉| 1983/2000 [16:40<00:06,  2.58iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  99%|█████████▉| 1984/2000 [16:41<00:05,  2.72iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  99%|█████████▉| 1984/2000 [16:41<00:05,  2.72iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  99%|█████████▉| 1985/2000 [16:41<00:05,  2.62iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  99%|█████████▉| 1985/2000 [16:41<00:05,  2.62iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  99%|█████████▉| 1986/2000 [16:41<00:05,  2.68iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  99%|█████████▉| 1986/2000 [16:42<00:05,  2.68iteration/s, mean_rewards=-226]\u001b[A\n",
            "Training:  99%|█████████▉| 1987/2000 [16:42<00:05,  2.53iteration/s, mean_rewards=-226]\u001b[A\n",
            "Training:  99%|█████████▉| 1987/2000 [16:42<00:05,  2.53iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  99%|█████████▉| 1988/2000 [16:42<00:04,  2.69iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  99%|█████████▉| 1988/2000 [16:42<00:04,  2.69iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  99%|█████████▉| 1989/2000 [16:42<00:04,  2.66iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  99%|█████████▉| 1989/2000 [16:43<00:04,  2.66iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training: 100%|█████████▉| 1990/2000 [16:43<00:03,  2.65iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training: 100%|█████████▉| 1990/2000 [16:43<00:03,  2.65iteration/s, mean_rewards=-81.8]\u001b[A\n",
            "Training: 100%|█████████▉| 1991/2000 [16:43<00:03,  2.64iteration/s, mean_rewards=-81.8]\u001b[A\n",
            "Training: 100%|█████████▉| 1991/2000 [16:43<00:03,  2.64iteration/s, mean_rewards=-148] \u001b[A\n",
            "Training: 100%|█████████▉| 1992/2000 [16:44<00:02,  2.76iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training: 100%|█████████▉| 1992/2000 [16:44<00:02,  2.76iteration/s, mean_rewards=-102]\u001b[A\n",
            "Training: 100%|█████████▉| 1993/2000 [16:44<00:02,  2.88iteration/s, mean_rewards=-102]\u001b[A\n",
            "Training: 100%|█████████▉| 1993/2000 [16:44<00:02,  2.88iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training: 100%|█████████▉| 1994/2000 [16:44<00:02,  2.93iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training: 100%|█████████▉| 1994/2000 [16:44<00:02,  2.93iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training: 100%|█████████▉| 1995/2000 [16:44<00:01,  3.00iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training: 100%|█████████▉| 1995/2000 [16:45<00:01,  3.00iteration/s, mean_rewards=-116]\u001b[A\n",
            "Training: 100%|█████████▉| 1996/2000 [16:45<00:01,  3.01iteration/s, mean_rewards=-116]\u001b[A\n",
            "Training: 100%|█████████▉| 1996/2000 [16:45<00:01,  3.01iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training: 100%|█████████▉| 1997/2000 [16:45<00:01,  2.84iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training: 100%|█████████▉| 1997/2000 [16:45<00:01,  2.84iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training: 100%|█████████▉| 1998/2000 [16:46<00:00,  2.94iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training: 100%|█████████▉| 1998/2000 [16:46<00:00,  2.94iteration/s, mean_rewards=-178]\u001b[A\n",
            "Training: 100%|█████████▉| 1999/2000 [16:46<00:00,  2.78iteration/s, mean_rewards=-178]\u001b[A\n",
            "Training: 100%|█████████▉| 1999/2000 [16:46<00:00,  2.78iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training: 100%|██████████| 2000/2000 [16:46<00:00,  1.99iteration/s, mean_rewards=-120]\n"
          ]
        }
      ],
      "source": [
        "env = \"LunarLander-v2\"\n",
        "peturbations = get_peturbations(env, seed)\n",
        "print(\"Online Peturbations are\")\n",
        "print(peturbations)\n",
        "opt = \"base\"\n",
        "train(env, opt, peturbations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mphqlL159LQ3"
      },
      "source": [
        "## Train PACE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5nkoWbY83Sx",
        "outputId": "b2c32609-668c-4e3a-b9ed-37ba9d2746d5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:   0%|          | 0/2000 [00:00<?, ?iteration/s]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "USING PACE.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:   0%|          | 0/2000 [00:00<?, ?iteration/s, mean_rewards=-78.6]\u001b[A\n",
            "Training:   0%|          | 1/2000 [00:02<1:10:02,  2.10s/iteration, mean_rewards=-78.6]\u001b[A\n",
            "Training:   0%|          | 1/2000 [00:02<1:10:02,  2.10s/iteration, mean_rewards=-228] \u001b[A\n",
            "Training:   0%|          | 2/2000 [00:03<48:33,  1.46s/iteration, mean_rewards=-228]  \u001b[A\n",
            "Training:   0%|          | 2/2000 [00:03<48:33,  1.46s/iteration, mean_rewards=-278]\u001b[A\n",
            "Training:   0%|          | 3/2000 [00:04<46:20,  1.39s/iteration, mean_rewards=-278]\u001b[A\n",
            "Training:   0%|          | 3/2000 [00:04<46:20,  1.39s/iteration, mean_rewards=-318]\u001b[A\n",
            "Training:   0%|          | 4/2000 [00:05<39:40,  1.19s/iteration, mean_rewards=-318]\u001b[A\n",
            "Training:   0%|          | 4/2000 [00:05<39:40,  1.19s/iteration, mean_rewards=-106]\u001b[A\n",
            "Training:   0%|          | 5/2000 [00:06<34:27,  1.04s/iteration, mean_rewards=-106]\u001b[A\n",
            "Training:   0%|          | 5/2000 [00:06<34:27,  1.04s/iteration, mean_rewards=-177]\u001b[A\n",
            "Training:   0%|          | 6/2000 [00:06<31:56,  1.04iteration/s, mean_rewards=-177]\u001b[A\n",
            "Training:   0%|          | 6/2000 [00:07<31:56,  1.04iteration/s, mean_rewards=-266]\u001b[A\n",
            "Training:   0%|          | 7/2000 [00:07<30:28,  1.09iteration/s, mean_rewards=-266]\u001b[A\n",
            "Training:   0%|          | 7/2000 [00:08<30:28,  1.09iteration/s, mean_rewards=-103]\u001b[A\n",
            "Training:   0%|          | 8/2000 [00:08<29:03,  1.14iteration/s, mean_rewards=-103]\u001b[A\n",
            "Training:   0%|          | 8/2000 [00:08<29:03,  1.14iteration/s, mean_rewards=-177]\u001b[A\n",
            "Training:   0%|          | 9/2000 [00:09<29:07,  1.14iteration/s, mean_rewards=-177]\u001b[A\n",
            "Training:   0%|          | 9/2000 [00:09<29:07,  1.14iteration/s, mean_rewards=-292]\u001b[A\n",
            "Training:   0%|          | 10/2000 [00:10<28:33,  1.16iteration/s, mean_rewards=-292]\u001b[A\n",
            "Training:   0%|          | 10/2000 [00:10<28:33,  1.16iteration/s, mean_rewards=-192]\u001b[A\n",
            "Training:   1%|          | 11/2000 [00:11<31:52,  1.04iteration/s, mean_rewards=-192]\u001b[A\n",
            "Training:   1%|          | 11/2000 [00:11<31:52,  1.04iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:   1%|          | 12/2000 [00:12<31:07,  1.06iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:   1%|          | 12/2000 [00:12<31:07,  1.06iteration/s, mean_rewards=-162]\u001b[A\n",
            "Training:   1%|          | 13/2000 [00:13<29:58,  1.10iteration/s, mean_rewards=-162]\u001b[A\n",
            "Training:   1%|          | 13/2000 [00:13<29:58,  1.10iteration/s, mean_rewards=-191]\u001b[A\n",
            "Training:   1%|          | 14/2000 [00:14<32:53,  1.01iteration/s, mean_rewards=-191]\u001b[A\n",
            "Training:   1%|          | 14/2000 [00:14<32:53,  1.01iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:   1%|          | 15/2000 [00:15<32:48,  1.01iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:   1%|          | 15/2000 [00:15<32:48,  1.01iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:   1%|          | 16/2000 [00:16<36:19,  1.10s/iteration, mean_rewards=-161]\u001b[A\n",
            "Training:   1%|          | 16/2000 [00:17<36:19,  1.10s/iteration, mean_rewards=-312]\u001b[A\n",
            "Training:   1%|          | 17/2000 [00:17<36:29,  1.10s/iteration, mean_rewards=-312]\u001b[A\n",
            "Training:   1%|          | 17/2000 [00:18<36:29,  1.10s/iteration, mean_rewards=-46.3]\u001b[A\n",
            "Training:   1%|          | 18/2000 [00:18<36:28,  1.10s/iteration, mean_rewards=-46.3]\u001b[A\n",
            "Training:   1%|          | 18/2000 [00:19<36:28,  1.10s/iteration, mean_rewards=-51.3]\u001b[A\n",
            "Training:   1%|          | 19/2000 [00:19<33:34,  1.02s/iteration, mean_rewards=-51.3]\u001b[A\n",
            "Training:   1%|          | 19/2000 [00:19<33:34,  1.02s/iteration, mean_rewards=-146] \u001b[A\n",
            "Training:   1%|          | 20/2000 [00:20<31:04,  1.06iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:   1%|          | 20/2000 [00:20<31:04,  1.06iteration/s, mean_rewards=-270]\u001b[A\n",
            "Training:   1%|          | 21/2000 [00:21<32:00,  1.03iteration/s, mean_rewards=-270]\u001b[A\n",
            "Training:   1%|          | 21/2000 [00:21<32:00,  1.03iteration/s, mean_rewards=-231]\u001b[A\n",
            "Training:   1%|          | 22/2000 [00:22<31:29,  1.05iteration/s, mean_rewards=-231]\u001b[A\n",
            "Training:   1%|          | 22/2000 [00:22<31:29,  1.05iteration/s, mean_rewards=-216]\u001b[A\n",
            "Training:   1%|          | 23/2000 [00:23<32:13,  1.02iteration/s, mean_rewards=-216]\u001b[A\n",
            "Training:   1%|          | 23/2000 [00:23<32:13,  1.02iteration/s, mean_rewards=-62.1]\u001b[A\n",
            "Training:   1%|          | 24/2000 [00:24<29:22,  1.12iteration/s, mean_rewards=-62.1]\u001b[A\n",
            "Training:   1%|          | 24/2000 [00:24<29:22,  1.12iteration/s, mean_rewards=-183] \u001b[A\n",
            "Training:   1%|▏         | 25/2000 [00:25<30:54,  1.07iteration/s, mean_rewards=-183]\u001b[A\n",
            "Training:   1%|▏         | 25/2000 [00:25<30:54,  1.07iteration/s, mean_rewards=-70.6]\u001b[A\n",
            "Training:   1%|▏         | 26/2000 [00:26<30:44,  1.07iteration/s, mean_rewards=-70.6]\u001b[A\n",
            "Training:   1%|▏         | 26/2000 [00:26<30:44,  1.07iteration/s, mean_rewards=-176] \u001b[A\n",
            "Training:   1%|▏         | 27/2000 [00:27<31:03,  1.06iteration/s, mean_rewards=-176]\u001b[A\n",
            "Training:   1%|▏         | 27/2000 [00:27<31:03,  1.06iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:   1%|▏         | 28/2000 [00:28<33:39,  1.02s/iteration, mean_rewards=-147]\u001b[A\n",
            "Training:   1%|▏         | 28/2000 [00:28<33:39,  1.02s/iteration, mean_rewards=-150]\u001b[A\n",
            "Training:   1%|▏         | 29/2000 [00:29<37:33,  1.14s/iteration, mean_rewards=-150]\u001b[A\n",
            "Training:   1%|▏         | 29/2000 [00:30<37:33,  1.14s/iteration, mean_rewards=-171]\u001b[A\n",
            "Training:   2%|▏         | 30/2000 [00:30<36:02,  1.10s/iteration, mean_rewards=-171]\u001b[A\n",
            "Training:   2%|▏         | 30/2000 [00:31<36:02,  1.10s/iteration, mean_rewards=-146]\u001b[A\n",
            "Training:   2%|▏         | 31/2000 [00:31<35:46,  1.09s/iteration, mean_rewards=-146]\u001b[A\n",
            "Training:   2%|▏         | 31/2000 [00:32<35:46,  1.09s/iteration, mean_rewards=-109]\u001b[A\n",
            "Training:   2%|▏         | 32/2000 [00:32<34:18,  1.05s/iteration, mean_rewards=-109]\u001b[A\n",
            "Training:   2%|▏         | 32/2000 [00:33<34:18,  1.05s/iteration, mean_rewards=-114]\u001b[A\n",
            "Training:   2%|▏         | 33/2000 [00:34<39:28,  1.20s/iteration, mean_rewards=-114]\u001b[A\n",
            "Training:   2%|▏         | 33/2000 [00:34<39:28,  1.20s/iteration, mean_rewards=-94] \u001b[A\n",
            "Training:   2%|▏         | 34/2000 [00:35<36:19,  1.11s/iteration, mean_rewards=-94]\u001b[A\n",
            "Training:   2%|▏         | 34/2000 [00:35<36:19,  1.11s/iteration, mean_rewards=-132]\u001b[A\n",
            "Training:   2%|▏         | 35/2000 [00:36<35:13,  1.08s/iteration, mean_rewards=-132]\u001b[A\n",
            "Training:   2%|▏         | 35/2000 [00:36<35:13,  1.08s/iteration, mean_rewards=-125]\u001b[A\n",
            "Training:   2%|▏         | 36/2000 [00:37<37:32,  1.15s/iteration, mean_rewards=-125]\u001b[A\n",
            "Training:   2%|▏         | 36/2000 [00:38<37:32,  1.15s/iteration, mean_rewards=-52] \u001b[A\n",
            "Training:   2%|▏         | 37/2000 [00:39<48:09,  1.47s/iteration, mean_rewards=-52]\u001b[A\n",
            "Training:   2%|▏         | 37/2000 [00:40<48:09,  1.47s/iteration, mean_rewards=-68.9]\u001b[A\n",
            "Training:   2%|▏         | 38/2000 [00:41<51:39,  1.58s/iteration, mean_rewards=-68.9]\u001b[A\n",
            "Training:   2%|▏         | 38/2000 [00:42<51:39,  1.58s/iteration, mean_rewards=-32.3]\u001b[A\n",
            "Training:   2%|▏         | 39/2000 [00:43<54:50,  1.68s/iteration, mean_rewards=-32.3]\u001b[A\n",
            "Training:   2%|▏         | 39/2000 [00:44<54:50,  1.68s/iteration, mean_rewards=-15.7]\u001b[A\n",
            "Training:   2%|▏         | 40/2000 [00:46<1:08:35,  2.10s/iteration, mean_rewards=-15.7]\u001b[A\n",
            "Training:   2%|▏         | 40/2000 [00:47<1:08:35,  2.10s/iteration, mean_rewards=-112] \u001b[A\n",
            "Training:   2%|▏         | 41/2000 [00:49<1:16:31,  2.34s/iteration, mean_rewards=-112]\u001b[A\n",
            "Training:   2%|▏         | 41/2000 [00:50<1:16:31,  2.34s/iteration, mean_rewards=-21.1]\u001b[A\n",
            "Training:   2%|▏         | 42/2000 [00:52<1:22:05,  2.52s/iteration, mean_rewards=-21.1]\u001b[A\n",
            "Training:   2%|▏         | 42/2000 [00:54<1:22:05,  2.52s/iteration, mean_rewards=42.3] \u001b[A\n",
            "Training:   2%|▏         | 43/2000 [00:56<1:37:26,  2.99s/iteration, mean_rewards=42.3]\u001b[A\n",
            "Training:   2%|▏         | 43/2000 [00:58<1:37:26,  2.99s/iteration, mean_rewards=56.7]\u001b[A\n",
            "Training:   2%|▏         | 44/2000 [00:59<1:42:42,  3.15s/iteration, mean_rewards=56.7]\u001b[A\n",
            "Training:   2%|▏         | 44/2000 [01:01<1:42:42,  3.15s/iteration, mean_rewards=28.5]\u001b[A\n",
            "Training:   2%|▏         | 45/2000 [01:03<1:46:23,  3.27s/iteration, mean_rewards=28.5]\u001b[A\n",
            "Training:   2%|▏         | 45/2000 [01:05<1:46:23,  3.27s/iteration, mean_rewards=88.3]\u001b[A\n",
            "Training:   2%|▏         | 46/2000 [01:07<1:58:16,  3.63s/iteration, mean_rewards=88.3]\u001b[A\n",
            "Training:   2%|▏         | 46/2000 [01:09<1:58:16,  3.63s/iteration, mean_rewards=-18.1]\u001b[A\n",
            "Training:   2%|▏         | 47/2000 [01:11<1:52:46,  3.46s/iteration, mean_rewards=-18.1]\u001b[A\n",
            "Training:   2%|▏         | 47/2000 [01:12<1:52:46,  3.46s/iteration, mean_rewards=73.3] \u001b[A\n",
            "Training:   2%|▏         | 48/2000 [01:14<1:54:21,  3.51s/iteration, mean_rewards=73.3]\u001b[A\n",
            "Training:   2%|▏         | 48/2000 [01:16<1:54:21,  3.51s/iteration, mean_rewards=65.6]\u001b[A\n",
            "Training:   2%|▏         | 49/2000 [01:18<1:57:48,  3.62s/iteration, mean_rewards=65.6]\u001b[A\n",
            "Training:   2%|▏         | 49/2000 [01:20<1:57:48,  3.62s/iteration, mean_rewards=2.33]\u001b[A\n",
            "Training:   2%|▎         | 50/2000 [01:22<1:56:55,  3.60s/iteration, mean_rewards=2.33]\u001b[A\n",
            "Training:   2%|▎         | 50/2000 [01:23<1:56:55,  3.60s/iteration, mean_rewards=-39] \u001b[A\n",
            "Training:   3%|▎         | 51/2000 [01:25<1:51:25,  3.43s/iteration, mean_rewards=-39]\u001b[A\n",
            "Training:   3%|▎         | 51/2000 [01:26<1:51:25,  3.43s/iteration, mean_rewards=75.2]\u001b[A\n",
            "Training:   3%|▎         | 52/2000 [01:28<1:52:35,  3.47s/iteration, mean_rewards=75.2]\u001b[A\n",
            "Training:   3%|▎         | 52/2000 [01:29<1:52:35,  3.47s/iteration, mean_rewards=-15.8]\u001b[A\n",
            "Training:   3%|▎         | 53/2000 [01:31<1:49:31,  3.38s/iteration, mean_rewards=-15.8]\u001b[A\n",
            "Training:   3%|▎         | 53/2000 [01:33<1:49:31,  3.38s/iteration, mean_rewards=0.515]\u001b[A\n",
            "Training:   3%|▎         | 54/2000 [01:35<1:50:08,  3.40s/iteration, mean_rewards=0.515]\u001b[A\n",
            "Training:   3%|▎         | 54/2000 [01:36<1:50:08,  3.40s/iteration, mean_rewards=-63]  \u001b[A\n",
            "Training:   3%|▎         | 55/2000 [01:38<1:47:11,  3.31s/iteration, mean_rewards=-63]\u001b[A\n",
            "Training:   3%|▎         | 55/2000 [01:39<1:47:11,  3.31s/iteration, mean_rewards=-97.2]\u001b[A\n",
            "Training:   3%|▎         | 56/2000 [01:41<1:45:14,  3.25s/iteration, mean_rewards=-97.2]\u001b[A\n",
            "Training:   3%|▎         | 56/2000 [01:42<1:45:14,  3.25s/iteration, mean_rewards=22.5] \u001b[A\n",
            "Training:   3%|▎         | 57/2000 [01:45<1:49:23,  3.38s/iteration, mean_rewards=22.5]\u001b[A\n",
            "Training:   3%|▎         | 57/2000 [01:47<1:49:23,  3.38s/iteration, mean_rewards=44]  \u001b[A\n",
            "Training:   3%|▎         | 58/2000 [01:49<1:53:37,  3.51s/iteration, mean_rewards=44]\u001b[A\n",
            "Training:   3%|▎         | 58/2000 [01:50<1:53:37,  3.51s/iteration, mean_rewards=0.417]\u001b[A\n",
            "Training:   3%|▎         | 59/2000 [01:52<1:51:22,  3.44s/iteration, mean_rewards=0.417]\u001b[A\n",
            "Training:   3%|▎         | 59/2000 [01:53<1:51:22,  3.44s/iteration, mean_rewards=85.5] \u001b[A\n",
            "Training:   3%|▎         | 60/2000 [01:55<1:51:18,  3.44s/iteration, mean_rewards=85.5]\u001b[A\n",
            "Training:   3%|▎         | 60/2000 [01:57<1:51:18,  3.44s/iteration, mean_rewards=65.2]\u001b[A\n",
            "Training:   3%|▎         | 61/2000 [02:00<2:00:47,  3.74s/iteration, mean_rewards=65.2]\u001b[A\n",
            "Training:   3%|▎         | 61/2000 [02:01<2:00:47,  3.74s/iteration, mean_rewards=56.8]\u001b[A\n",
            "Training:   3%|▎         | 62/2000 [02:03<1:59:28,  3.70s/iteration, mean_rewards=56.8]\u001b[A\n",
            "Training:   3%|▎         | 62/2000 [02:05<1:59:28,  3.70s/iteration, mean_rewards=83.9]\u001b[A\n",
            "Training:   3%|▎         | 63/2000 [02:07<1:58:16,  3.66s/iteration, mean_rewards=83.9]\u001b[A\n",
            "Training:   3%|▎         | 63/2000 [02:09<1:58:16,  3.66s/iteration, mean_rewards=62.5]\u001b[A\n",
            "Training:   3%|▎         | 64/2000 [02:11<2:04:45,  3.87s/iteration, mean_rewards=62.5]\u001b[A\n",
            "Training:   3%|▎         | 64/2000 [02:13<2:04:45,  3.87s/iteration, mean_rewards=57.6]\u001b[A\n",
            "Training:   3%|▎         | 65/2000 [02:15<2:02:33,  3.80s/iteration, mean_rewards=57.6]\u001b[A\n",
            "Training:   3%|▎         | 65/2000 [02:17<2:02:33,  3.80s/iteration, mean_rewards=73.8]\u001b[A\n",
            "Training:   3%|▎         | 66/2000 [02:19<2:01:32,  3.77s/iteration, mean_rewards=73.8]\u001b[A\n",
            "Training:   3%|▎         | 66/2000 [02:20<2:01:32,  3.77s/iteration, mean_rewards=-15.8]\u001b[A\n",
            "Training:   3%|▎         | 67/2000 [02:22<1:56:20,  3.61s/iteration, mean_rewards=-15.8]\u001b[A\n",
            "Training:   3%|▎         | 67/2000 [02:24<1:56:20,  3.61s/iteration, mean_rewards=39.6] \u001b[A\n",
            "Training:   3%|▎         | 68/2000 [02:26<2:01:00,  3.76s/iteration, mean_rewards=39.6]\u001b[A\n",
            "Training:   3%|▎         | 68/2000 [02:28<2:01:00,  3.76s/iteration, mean_rewards=41.5]\u001b[A\n",
            "Training:   3%|▎         | 69/2000 [02:29<1:59:09,  3.70s/iteration, mean_rewards=41.5]\u001b[A\n",
            "Training:   3%|▎         | 69/2000 [02:31<1:59:09,  3.70s/iteration, mean_rewards=58.6]\u001b[A\n",
            "Training:   4%|▎         | 70/2000 [02:33<1:58:04,  3.67s/iteration, mean_rewards=58.6]\u001b[A\n",
            "Training:   4%|▎         | 70/2000 [02:35<1:58:04,  3.67s/iteration, mean_rewards=40.5]\u001b[A\n",
            "Training:   4%|▎         | 71/2000 [02:37<2:03:52,  3.85s/iteration, mean_rewards=40.5]\u001b[A\n",
            "Training:   4%|▎         | 71/2000 [02:39<2:03:52,  3.85s/iteration, mean_rewards=58.2]\u001b[A\n",
            "Training:   4%|▎         | 72/2000 [02:41<2:01:28,  3.78s/iteration, mean_rewards=58.2]\u001b[A\n",
            "Training:   4%|▎         | 72/2000 [02:43<2:01:28,  3.78s/iteration, mean_rewards=59]  \u001b[A\n",
            "Training:   4%|▎         | 73/2000 [02:45<1:59:24,  3.72s/iteration, mean_rewards=59]\u001b[A\n",
            "Training:   4%|▎         | 73/2000 [02:46<1:59:24,  3.72s/iteration, mean_rewards=33]\u001b[A\n",
            "Training:   4%|▎         | 74/2000 [02:49<2:06:26,  3.94s/iteration, mean_rewards=33]\u001b[A\n",
            "Training:   4%|▎         | 74/2000 [02:51<2:06:26,  3.94s/iteration, mean_rewards=58.1]\u001b[A\n",
            "Training:   4%|▍         | 75/2000 [02:53<2:03:53,  3.86s/iteration, mean_rewards=58.1]\u001b[A\n",
            "Training:   4%|▍         | 75/2000 [02:54<2:03:53,  3.86s/iteration, mean_rewards=29.8]\u001b[A\n",
            "Training:   4%|▍         | 76/2000 [02:56<2:01:09,  3.78s/iteration, mean_rewards=29.8]\u001b[A\n",
            "Training:   4%|▍         | 76/2000 [02:58<2:01:09,  3.78s/iteration, mean_rewards=33.3]\u001b[A\n",
            "Training:   4%|▍         | 77/2000 [03:00<2:01:05,  3.78s/iteration, mean_rewards=33.3]\u001b[A\n",
            "Training:   4%|▍         | 77/2000 [03:02<2:01:05,  3.78s/iteration, mean_rewards=-91] \u001b[A\n",
            "Training:   4%|▍         | 78/2000 [03:03<1:53:35,  3.55s/iteration, mean_rewards=-91]\u001b[A\n",
            "Training:   4%|▍         | 78/2000 [03:05<1:53:35,  3.55s/iteration, mean_rewards=-36.2]\u001b[A\n",
            "Training:   4%|▍         | 79/2000 [03:07<1:54:59,  3.59s/iteration, mean_rewards=-36.2]\u001b[A\n",
            "Training:   4%|▍         | 79/2000 [03:08<1:54:59,  3.59s/iteration, mean_rewards=40.3] \u001b[A\n",
            "Training:   4%|▍         | 80/2000 [03:10<1:55:04,  3.60s/iteration, mean_rewards=40.3]\u001b[A\n",
            "Training:   4%|▍         | 80/2000 [03:12<1:55:04,  3.60s/iteration, mean_rewards=32.7]\u001b[A\n",
            "Training:   4%|▍         | 81/2000 [03:15<2:02:39,  3.84s/iteration, mean_rewards=32.7]\u001b[A\n",
            "Training:   4%|▍         | 81/2000 [03:16<2:02:39,  3.84s/iteration, mean_rewards=30.5]\u001b[A\n",
            "Training:   4%|▍         | 82/2000 [03:18<1:59:30,  3.74s/iteration, mean_rewards=30.5]\u001b[A\n",
            "Training:   4%|▍         | 82/2000 [03:20<1:59:30,  3.74s/iteration, mean_rewards=39.8]\u001b[A\n",
            "Training:   4%|▍         | 83/2000 [03:22<1:58:31,  3.71s/iteration, mean_rewards=39.8]\u001b[A\n",
            "Training:   4%|▍         | 83/2000 [03:24<1:58:31,  3.71s/iteration, mean_rewards=36.6]\u001b[A\n",
            "Training:   4%|▍         | 84/2000 [03:26<2:00:16,  3.77s/iteration, mean_rewards=36.6]\u001b[A\n",
            "Training:   4%|▍         | 84/2000 [03:28<2:00:16,  3.77s/iteration, mean_rewards=8.89]\u001b[A\n",
            "Training:   4%|▍         | 85/2000 [03:30<2:04:12,  3.89s/iteration, mean_rewards=8.89]\u001b[A\n",
            "Training:   4%|▍         | 85/2000 [03:31<2:04:12,  3.89s/iteration, mean_rewards=-26.7]\u001b[A\n",
            "Training:   4%|▍         | 86/2000 [03:33<1:57:38,  3.69s/iteration, mean_rewards=-26.7]\u001b[A\n",
            "Training:   4%|▍         | 86/2000 [03:34<1:57:38,  3.69s/iteration, mean_rewards=-8.06]\u001b[A\n",
            "Training:   4%|▍         | 87/2000 [03:36<1:48:31,  3.40s/iteration, mean_rewards=-8.06]\u001b[A\n",
            "Training:   4%|▍         | 87/2000 [03:38<1:48:31,  3.40s/iteration, mean_rewards=13.4] \u001b[A\n",
            "Training:   4%|▍         | 88/2000 [03:40<1:56:25,  3.65s/iteration, mean_rewards=13.4]\u001b[A\n",
            "Training:   4%|▍         | 88/2000 [03:42<1:56:25,  3.65s/iteration, mean_rewards=-44.2]\u001b[A\n",
            "Training:   4%|▍         | 89/2000 [03:44<1:54:30,  3.60s/iteration, mean_rewards=-44.2]\u001b[A\n",
            "Training:   4%|▍         | 89/2000 [03:45<1:54:30,  3.60s/iteration, mean_rewards=30.8] \u001b[A\n",
            "Training:   4%|▍         | 90/2000 [03:47<1:55:31,  3.63s/iteration, mean_rewards=30.8]\u001b[A\n",
            "Training:   4%|▍         | 90/2000 [03:49<1:55:31,  3.63s/iteration, mean_rewards=13.6]\u001b[A\n",
            "Training:   5%|▍         | 91/2000 [03:51<1:58:41,  3.73s/iteration, mean_rewards=13.6]\u001b[A\n",
            "Training:   5%|▍         | 91/2000 [03:53<1:58:41,  3.73s/iteration, mean_rewards=26.4]\u001b[A\n",
            "Training:   5%|▍         | 92/2000 [03:55<2:01:37,  3.82s/iteration, mean_rewards=26.4]\u001b[A\n",
            "Training:   5%|▍         | 92/2000 [03:56<2:01:37,  3.82s/iteration, mean_rewards=-104]\u001b[A\n",
            "Training:   5%|▍         | 93/2000 [03:57<1:39:19,  3.13s/iteration, mean_rewards=-104]\u001b[A\n",
            "Training:   5%|▍         | 93/2000 [03:58<1:39:19,  3.13s/iteration, mean_rewards=-103]\u001b[A\n",
            "Training:   5%|▍         | 94/2000 [03:59<1:29:54,  2.83s/iteration, mean_rewards=-103]\u001b[A\n",
            "Training:   5%|▍         | 94/2000 [04:01<1:29:54,  2.83s/iteration, mean_rewards=-41.4]\u001b[A\n",
            "Training:   5%|▍         | 95/2000 [04:02<1:35:43,  3.01s/iteration, mean_rewards=-41.4]\u001b[A\n",
            "Training:   5%|▍         | 95/2000 [04:04<1:35:43,  3.01s/iteration, mean_rewards=-64.8]\u001b[A\n",
            "Training:   5%|▍         | 96/2000 [04:06<1:43:13,  3.25s/iteration, mean_rewards=-64.8]\u001b[A\n",
            "Training:   5%|▍         | 96/2000 [04:07<1:43:13,  3.25s/iteration, mean_rewards=-30.6]\u001b[A\n",
            "Training:   5%|▍         | 97/2000 [04:09<1:38:40,  3.11s/iteration, mean_rewards=-30.6]\u001b[A\n",
            "Training:   5%|▍         | 97/2000 [04:11<1:38:40,  3.11s/iteration, mean_rewards=36.6] \u001b[A\n",
            "Training:   5%|▍         | 98/2000 [04:13<1:42:57,  3.25s/iteration, mean_rewards=36.6]\u001b[A\n",
            "Training:   5%|▍         | 98/2000 [04:14<1:42:57,  3.25s/iteration, mean_rewards=34.7]\u001b[A\n",
            "Training:   5%|▍         | 99/2000 [04:16<1:47:09,  3.38s/iteration, mean_rewards=34.7]\u001b[A\n",
            "Training:   5%|▍         | 99/2000 [04:18<1:47:09,  3.38s/iteration, mean_rewards=-12.7]\u001b[A\n",
            "Training:   5%|▌         | 100/2000 [04:20<1:47:58,  3.41s/iteration, mean_rewards=-12.7]\u001b[A\n",
            "Training:   5%|▌         | 100/2000 [04:21<1:47:58,  3.41s/iteration, mean_rewards=16.4] \u001b[A\n",
            "Training:   5%|▌         | 101/2000 [04:23<1:50:08,  3.48s/iteration, mean_rewards=16.4]\u001b[A\n",
            "Training:   5%|▌         | 101/2000 [04:25<1:50:08,  3.48s/iteration, mean_rewards=-31.2]\u001b[A\n",
            "Training:   5%|▌         | 102/2000 [04:27<1:50:31,  3.49s/iteration, mean_rewards=-31.2]\u001b[A\n",
            "Training:   5%|▌         | 102/2000 [04:29<1:50:31,  3.49s/iteration, mean_rewards=-24.2]\u001b[A\n",
            "Training:   5%|▌         | 103/2000 [04:31<1:59:55,  3.79s/iteration, mean_rewards=-24.2]\u001b[A\n",
            "Training:   5%|▌         | 103/2000 [04:32<1:59:55,  3.79s/iteration, mean_rewards=-103] \u001b[A\n",
            "Training:   5%|▌         | 104/2000 [04:34<1:46:28,  3.37s/iteration, mean_rewards=-103]\u001b[A\n",
            "Training:   5%|▌         | 104/2000 [04:35<1:46:28,  3.37s/iteration, mean_rewards=1.99]\u001b[A\n",
            "Training:   5%|▌         | 105/2000 [04:37<1:47:54,  3.42s/iteration, mean_rewards=1.99]\u001b[A\n",
            "Training:   5%|▌         | 105/2000 [04:38<1:47:54,  3.42s/iteration, mean_rewards=-36.8]\u001b[A\n",
            "Training:   5%|▌         | 106/2000 [04:40<1:39:01,  3.14s/iteration, mean_rewards=-36.8]\u001b[A\n",
            "Training:   5%|▌         | 106/2000 [04:41<1:39:01,  3.14s/iteration, mean_rewards=-104] \u001b[A\n",
            "Training:   5%|▌         | 107/2000 [04:42<1:31:35,  2.90s/iteration, mean_rewards=-104]\u001b[A\n",
            "Training:   5%|▌         | 107/2000 [04:44<1:31:35,  2.90s/iteration, mean_rewards=-78] \u001b[A\n",
            "Training:   5%|▌         | 108/2000 [04:46<1:38:06,  3.11s/iteration, mean_rewards=-78]\u001b[A\n",
            "Training:   5%|▌         | 108/2000 [04:47<1:38:06,  3.11s/iteration, mean_rewards=-95.3]\u001b[A\n",
            "Training:   5%|▌         | 109/2000 [04:48<1:31:44,  2.91s/iteration, mean_rewards=-95.3]\u001b[A\n",
            "Training:   5%|▌         | 109/2000 [04:50<1:31:44,  2.91s/iteration, mean_rewards=-52.7]\u001b[A\n",
            "Training:   6%|▌         | 110/2000 [04:52<1:36:17,  3.06s/iteration, mean_rewards=-52.7]\u001b[A\n",
            "Training:   6%|▌         | 110/2000 [04:53<1:36:17,  3.06s/iteration, mean_rewards=-33.8]\u001b[A\n",
            "Training:   6%|▌         | 111/2000 [04:54<1:31:35,  2.91s/iteration, mean_rewards=-33.8]\u001b[A\n",
            "Training:   6%|▌         | 111/2000 [04:55<1:31:35,  2.91s/iteration, mean_rewards=-91.4]\u001b[A\n",
            "Training:   6%|▌         | 112/2000 [04:57<1:28:35,  2.82s/iteration, mean_rewards=-91.4]\u001b[A\n",
            "Training:   6%|▌         | 112/2000 [04:58<1:28:35,  2.82s/iteration, mean_rewards=-55.2]\u001b[A\n",
            "Training:   6%|▌         | 113/2000 [05:00<1:28:44,  2.82s/iteration, mean_rewards=-55.2]\u001b[A\n",
            "Training:   6%|▌         | 113/2000 [05:01<1:28:44,  2.82s/iteration, mean_rewards=6.31] \u001b[A\n",
            "Training:   6%|▌         | 114/2000 [05:03<1:36:04,  3.06s/iteration, mean_rewards=6.31]\u001b[A\n",
            "Training:   6%|▌         | 114/2000 [05:04<1:36:04,  3.06s/iteration, mean_rewards=-106]\u001b[A\n",
            "Training:   6%|▌         | 115/2000 [05:05<1:27:41,  2.79s/iteration, mean_rewards=-106]\u001b[A\n",
            "Training:   6%|▌         | 115/2000 [05:07<1:27:41,  2.79s/iteration, mean_rewards=-35.7]\u001b[A\n",
            "Training:   6%|▌         | 116/2000 [05:09<1:32:25,  2.94s/iteration, mean_rewards=-35.7]\u001b[A\n",
            "Training:   6%|▌         | 116/2000 [05:10<1:32:25,  2.94s/iteration, mean_rewards=-49.5]\u001b[A\n",
            "Training:   6%|▌         | 117/2000 [05:12<1:31:38,  2.92s/iteration, mean_rewards=-49.5]\u001b[A\n",
            "Training:   6%|▌         | 117/2000 [05:13<1:31:38,  2.92s/iteration, mean_rewards=14.7] \u001b[A\n",
            "Training:   6%|▌         | 118/2000 [05:15<1:37:26,  3.11s/iteration, mean_rewards=14.7]\u001b[A\n",
            "Training:   6%|▌         | 118/2000 [05:17<1:37:26,  3.11s/iteration, mean_rewards=-29.9]\u001b[A\n",
            "Training:   6%|▌         | 119/2000 [05:18<1:39:32,  3.18s/iteration, mean_rewards=-29.9]\u001b[A\n",
            "Training:   6%|▌         | 119/2000 [05:20<1:39:32,  3.18s/iteration, mean_rewards=-33.7]\u001b[A\n",
            "Training:   6%|▌         | 120/2000 [05:22<1:42:06,  3.26s/iteration, mean_rewards=-33.7]\u001b[A\n",
            "Training:   6%|▌         | 120/2000 [05:23<1:42:06,  3.26s/iteration, mean_rewards=-104] \u001b[A\n",
            "Training:   6%|▌         | 121/2000 [05:24<1:35:50,  3.06s/iteration, mean_rewards=-104]\u001b[A\n",
            "Training:   6%|▌         | 121/2000 [05:26<1:35:50,  3.06s/iteration, mean_rewards=-48.1]\u001b[A\n",
            "Training:   6%|▌         | 122/2000 [05:27<1:30:36,  2.89s/iteration, mean_rewards=-48.1]\u001b[A\n",
            "Training:   6%|▌         | 122/2000 [05:28<1:30:36,  2.89s/iteration, mean_rewards=-73.8]\u001b[A\n",
            "Training:   6%|▌         | 123/2000 [05:28<1:17:35,  2.48s/iteration, mean_rewards=-73.8]\u001b[A\n",
            "Training:   6%|▌         | 123/2000 [05:30<1:17:35,  2.48s/iteration, mean_rewards=7.62] \u001b[A\n",
            "Training:   6%|▌         | 124/2000 [05:32<1:26:54,  2.78s/iteration, mean_rewards=7.62]\u001b[A\n",
            "Training:   6%|▌         | 124/2000 [05:33<1:26:54,  2.78s/iteration, mean_rewards=-20] \u001b[A\n",
            "Training:   6%|▋         | 125/2000 [05:35<1:33:52,  3.00s/iteration, mean_rewards=-20]\u001b[A\n",
            "Training:   6%|▋         | 125/2000 [05:37<1:33:52,  3.00s/iteration, mean_rewards=22.1]\u001b[A\n",
            "Training:   6%|▋         | 126/2000 [05:39<1:39:34,  3.19s/iteration, mean_rewards=22.1]\u001b[A\n",
            "Training:   6%|▋         | 126/2000 [05:41<1:39:34,  3.19s/iteration, mean_rewards=23.2]\u001b[A\n",
            "Training:   6%|▋         | 127/2000 [05:43<1:43:06,  3.30s/iteration, mean_rewards=23.2]\u001b[A\n",
            "Training:   6%|▋         | 127/2000 [05:44<1:43:06,  3.30s/iteration, mean_rewards=14.9]\u001b[A\n",
            "Training:   6%|▋         | 128/2000 [05:47<1:48:16,  3.47s/iteration, mean_rewards=14.9]\u001b[A\n",
            "Training:   6%|▋         | 128/2000 [05:49<1:48:16,  3.47s/iteration, mean_rewards=30.2]\u001b[A\n",
            "Training:   6%|▋         | 129/2000 [05:51<1:55:20,  3.70s/iteration, mean_rewards=30.2]\u001b[A\n",
            "Training:   6%|▋         | 129/2000 [05:53<1:55:20,  3.70s/iteration, mean_rewards=22.8]\u001b[A\n",
            "Training:   6%|▋         | 130/2000 [05:54<1:55:20,  3.70s/iteration, mean_rewards=22.8]\u001b[A\n",
            "Training:   6%|▋         | 130/2000 [05:56<1:55:20,  3.70s/iteration, mean_rewards=37.8]\u001b[A\n",
            "Training:   7%|▋         | 131/2000 [05:58<1:54:10,  3.67s/iteration, mean_rewards=37.8]\u001b[A\n",
            "Training:   7%|▋         | 131/2000 [06:00<1:54:10,  3.67s/iteration, mean_rewards=-4.28]\u001b[A\n",
            "Training:   7%|▋         | 132/2000 [06:02<1:59:52,  3.85s/iteration, mean_rewards=-4.28]\u001b[A\n",
            "Training:   7%|▋         | 132/2000 [06:04<1:59:52,  3.85s/iteration, mean_rewards=-21]  \u001b[A\n",
            "Training:   7%|▋         | 133/2000 [06:05<1:51:53,  3.60s/iteration, mean_rewards=-21]\u001b[A\n",
            "Training:   7%|▋         | 133/2000 [06:07<1:51:53,  3.60s/iteration, mean_rewards=36.3]\u001b[A\n",
            "Training:   7%|▋         | 134/2000 [06:09<1:51:57,  3.60s/iteration, mean_rewards=36.3]\u001b[A\n",
            "Training:   7%|▋         | 134/2000 [06:11<1:51:57,  3.60s/iteration, mean_rewards=16.5]\u001b[A\n",
            "Training:   7%|▋         | 135/2000 [06:13<1:57:26,  3.78s/iteration, mean_rewards=16.5]\u001b[A\n",
            "Training:   7%|▋         | 135/2000 [06:15<1:57:26,  3.78s/iteration, mean_rewards=26.2]\u001b[A\n",
            "Training:   7%|▋         | 136/2000 [06:17<1:58:43,  3.82s/iteration, mean_rewards=26.2]\u001b[A\n",
            "Training:   7%|▋         | 136/2000 [06:19<1:58:43,  3.82s/iteration, mean_rewards=4.58]\u001b[A\n",
            "Training:   7%|▋         | 137/2000 [06:21<1:55:34,  3.72s/iteration, mean_rewards=4.58]\u001b[A\n",
            "Training:   7%|▋         | 137/2000 [06:22<1:55:34,  3.72s/iteration, mean_rewards=7.43]\u001b[A\n",
            "Training:   7%|▋         | 138/2000 [06:24<1:56:06,  3.74s/iteration, mean_rewards=7.43]\u001b[A\n",
            "Training:   7%|▋         | 138/2000 [06:26<1:56:06,  3.74s/iteration, mean_rewards=-28.2]\u001b[A\n",
            "Training:   7%|▋         | 139/2000 [06:28<1:53:56,  3.67s/iteration, mean_rewards=-28.2]\u001b[A\n",
            "Training:   7%|▋         | 139/2000 [06:29<1:53:56,  3.67s/iteration, mean_rewards=-52.9]\u001b[A\n",
            "Training:   7%|▋         | 140/2000 [06:31<1:48:19,  3.49s/iteration, mean_rewards=-52.9]\u001b[A\n",
            "Training:   7%|▋         | 140/2000 [06:33<1:48:19,  3.49s/iteration, mean_rewards=3.67] \u001b[A\n",
            "Training:   7%|▋         | 141/2000 [06:35<1:49:39,  3.54s/iteration, mean_rewards=3.67]\u001b[A\n",
            "Training:   7%|▋         | 141/2000 [06:36<1:49:39,  3.54s/iteration, mean_rewards=16.8]\u001b[A\n",
            "Training:   7%|▋         | 142/2000 [06:39<1:54:13,  3.69s/iteration, mean_rewards=16.8]\u001b[A\n",
            "Training:   7%|▋         | 142/2000 [06:40<1:54:13,  3.69s/iteration, mean_rewards=-2.09]\u001b[A\n",
            "Training:   7%|▋         | 143/2000 [06:42<1:54:47,  3.71s/iteration, mean_rewards=-2.09]\u001b[A\n",
            "Training:   7%|▋         | 143/2000 [06:44<1:54:47,  3.71s/iteration, mean_rewards=3.3]  \u001b[A\n",
            "Training:   7%|▋         | 144/2000 [06:46<1:52:34,  3.64s/iteration, mean_rewards=3.3]\u001b[A\n",
            "Training:   7%|▋         | 144/2000 [06:48<1:52:34,  3.64s/iteration, mean_rewards=-6.01]\u001b[A\n",
            "Training:   7%|▋         | 145/2000 [06:50<1:54:40,  3.71s/iteration, mean_rewards=-6.01]\u001b[A\n",
            "Training:   7%|▋         | 145/2000 [06:52<1:54:40,  3.71s/iteration, mean_rewards=-15.5]\u001b[A\n",
            "Training:   7%|▋         | 146/2000 [06:54<1:57:11,  3.79s/iteration, mean_rewards=-15.5]\u001b[A\n",
            "Training:   7%|▋         | 146/2000 [06:55<1:57:11,  3.79s/iteration, mean_rewards=16.5] \u001b[A\n",
            "Training:   7%|▋         | 147/2000 [06:57<1:55:28,  3.74s/iteration, mean_rewards=16.5]\u001b[A\n",
            "Training:   7%|▋         | 147/2000 [06:59<1:55:28,  3.74s/iteration, mean_rewards=18.9]\u001b[A\n",
            "Training:   7%|▋         | 148/2000 [07:01<1:54:05,  3.70s/iteration, mean_rewards=18.9]\u001b[A\n",
            "Training:   7%|▋         | 148/2000 [07:02<1:54:05,  3.70s/iteration, mean_rewards=-61.9]\u001b[A\n",
            "Training:   7%|▋         | 149/2000 [07:04<1:45:44,  3.43s/iteration, mean_rewards=-61.9]\u001b[A\n",
            "Training:   7%|▋         | 149/2000 [07:06<1:45:44,  3.43s/iteration, mean_rewards=23.2] \u001b[A\n",
            "Training:   8%|▊         | 150/2000 [07:08<1:50:53,  3.60s/iteration, mean_rewards=23.2]\u001b[A\n",
            "Training:   8%|▊         | 150/2000 [07:09<1:50:53,  3.60s/iteration, mean_rewards=32.2]\u001b[A\n",
            "Training:   8%|▊         | 151/2000 [07:11<1:51:53,  3.63s/iteration, mean_rewards=32.2]\u001b[A\n",
            "Training:   8%|▊         | 151/2000 [07:13<1:51:53,  3.63s/iteration, mean_rewards=19.7]\u001b[A\n",
            "Training:   8%|▊         | 152/2000 [07:15<1:51:56,  3.63s/iteration, mean_rewards=19.7]\u001b[A\n",
            "Training:   8%|▊         | 152/2000 [07:17<1:51:56,  3.63s/iteration, mean_rewards=31.8]\u001b[A\n",
            "Training:   8%|▊         | 153/2000 [07:19<1:57:49,  3.83s/iteration, mean_rewards=31.8]\u001b[A\n",
            "Training:   8%|▊         | 153/2000 [07:21<1:57:49,  3.83s/iteration, mean_rewards=37.4]\u001b[A\n",
            "Training:   8%|▊         | 154/2000 [07:23<1:55:51,  3.77s/iteration, mean_rewards=37.4]\u001b[A\n",
            "Training:   8%|▊         | 154/2000 [07:25<1:55:51,  3.77s/iteration, mean_rewards=15.7]\u001b[A\n",
            "Training:   8%|▊         | 155/2000 [07:27<1:54:00,  3.71s/iteration, mean_rewards=15.7]\u001b[A\n",
            "Training:   8%|▊         | 155/2000 [07:28<1:54:00,  3.71s/iteration, mean_rewards=13.2]\u001b[A\n",
            "Training:   8%|▊         | 156/2000 [07:31<1:59:38,  3.89s/iteration, mean_rewards=13.2]\u001b[A\n",
            "Training:   8%|▊         | 156/2000 [07:32<1:59:38,  3.89s/iteration, mean_rewards=36.1]\u001b[A\n",
            "Training:   8%|▊         | 157/2000 [07:34<1:56:26,  3.79s/iteration, mean_rewards=36.1]\u001b[A\n",
            "Training:   8%|▊         | 157/2000 [07:36<1:56:26,  3.79s/iteration, mean_rewards=12.9]\u001b[A\n",
            "Training:   8%|▊         | 158/2000 [07:38<1:55:33,  3.76s/iteration, mean_rewards=12.9]\u001b[A\n",
            "Training:   8%|▊         | 158/2000 [07:40<1:55:33,  3.76s/iteration, mean_rewards=19.3]\u001b[A\n",
            "Training:   8%|▊         | 159/2000 [07:42<1:56:50,  3.81s/iteration, mean_rewards=19.3]\u001b[A\n",
            "Training:   8%|▊         | 159/2000 [07:44<1:56:50,  3.81s/iteration, mean_rewards=-3.63]\u001b[A\n",
            "Training:   8%|▊         | 160/2000 [07:46<1:59:30,  3.90s/iteration, mean_rewards=-3.63]\u001b[A\n",
            "Training:   8%|▊         | 160/2000 [07:48<1:59:30,  3.90s/iteration, mean_rewards=25]   \u001b[A\n",
            "Training:   8%|▊         | 161/2000 [07:50<1:57:17,  3.83s/iteration, mean_rewards=25]\u001b[A\n",
            "Training:   8%|▊         | 161/2000 [07:51<1:57:17,  3.83s/iteration, mean_rewards=31.9]\u001b[A\n",
            "Training:   8%|▊         | 162/2000 [07:53<1:55:23,  3.77s/iteration, mean_rewards=31.9]\u001b[A\n",
            "Training:   8%|▊         | 162/2000 [07:56<1:55:23,  3.77s/iteration, mean_rewards=23.3]\u001b[A\n",
            "Training:   8%|▊         | 163/2000 [07:58<2:00:17,  3.93s/iteration, mean_rewards=23.3]\u001b[A\n",
            "Training:   8%|▊         | 163/2000 [07:59<2:00:17,  3.93s/iteration, mean_rewards=1.67]\u001b[A\n",
            "Training:   8%|▊         | 164/2000 [08:01<1:58:11,  3.86s/iteration, mean_rewards=1.67]\u001b[A\n",
            "Training:   8%|▊         | 164/2000 [08:03<1:58:11,  3.86s/iteration, mean_rewards=22.3]\u001b[A\n",
            "Training:   8%|▊         | 165/2000 [08:05<1:55:35,  3.78s/iteration, mean_rewards=22.3]\u001b[A\n",
            "Training:   8%|▊         | 165/2000 [08:07<1:55:35,  3.78s/iteration, mean_rewards=4.99]\u001b[A\n",
            "Training:   8%|▊         | 166/2000 [08:10<2:03:28,  4.04s/iteration, mean_rewards=4.99]\u001b[A\n",
            "Training:   8%|▊         | 166/2000 [08:11<2:03:28,  4.04s/iteration, mean_rewards=9.99]\u001b[A\n",
            "Training:   8%|▊         | 167/2000 [08:13<2:00:24,  3.94s/iteration, mean_rewards=9.99]\u001b[A\n",
            "Training:   8%|▊         | 167/2000 [08:15<2:00:24,  3.94s/iteration, mean_rewards=21.2]\u001b[A\n",
            "Training:   8%|▊         | 168/2000 [08:17<1:58:00,  3.86s/iteration, mean_rewards=21.2]\u001b[A\n",
            "Training:   8%|▊         | 168/2000 [08:19<1:58:00,  3.86s/iteration, mean_rewards=37.6]\u001b[A\n",
            "Training:   8%|▊         | 169/2000 [08:21<2:00:27,  3.95s/iteration, mean_rewards=37.6]\u001b[A\n",
            "Training:   8%|▊         | 169/2000 [08:23<2:00:27,  3.95s/iteration, mean_rewards=-48.2]\u001b[A\n",
            "Training:   8%|▊         | 170/2000 [08:24<1:53:26,  3.72s/iteration, mean_rewards=-48.2]\u001b[A\n",
            "Training:   8%|▊         | 170/2000 [08:26<1:53:26,  3.72s/iteration, mean_rewards=23.4] \u001b[A\n",
            "Training:   9%|▊         | 171/2000 [08:28<1:51:36,  3.66s/iteration, mean_rewards=23.4]\u001b[A\n",
            "Training:   9%|▊         | 171/2000 [08:30<1:51:36,  3.66s/iteration, mean_rewards=40.7]\u001b[A\n",
            "Training:   9%|▊         | 172/2000 [08:31<1:50:20,  3.62s/iteration, mean_rewards=40.7]\u001b[A\n",
            "Training:   9%|▊         | 172/2000 [08:34<1:50:20,  3.62s/iteration, mean_rewards=22.1]\u001b[A\n",
            "Training:   9%|▊         | 173/2000 [08:36<1:57:19,  3.85s/iteration, mean_rewards=22.1]\u001b[A\n",
            "Training:   9%|▊         | 173/2000 [08:38<1:57:19,  3.85s/iteration, mean_rewards=33.5]\u001b[A\n",
            "Training:   9%|▊         | 174/2000 [08:39<1:55:28,  3.79s/iteration, mean_rewards=33.5]\u001b[A\n",
            "Training:   9%|▊         | 174/2000 [08:41<1:55:28,  3.79s/iteration, mean_rewards=18.8]\u001b[A\n",
            "Training:   9%|▉         | 175/2000 [08:43<1:53:05,  3.72s/iteration, mean_rewards=18.8]\u001b[A\n",
            "Training:   9%|▉         | 175/2000 [08:45<1:53:05,  3.72s/iteration, mean_rewards=31.8]\u001b[A\n",
            "Training:   9%|▉         | 176/2000 [08:48<1:59:54,  3.94s/iteration, mean_rewards=31.8]\u001b[A\n",
            "Training:   9%|▉         | 176/2000 [08:49<1:59:54,  3.94s/iteration, mean_rewards=16.1]\u001b[A\n",
            "Training:   9%|▉         | 177/2000 [08:51<1:56:45,  3.84s/iteration, mean_rewards=16.1]\u001b[A\n",
            "Training:   9%|▉         | 177/2000 [08:53<1:56:45,  3.84s/iteration, mean_rewards=55]  \u001b[A\n",
            "Training:   9%|▉         | 178/2000 [08:55<1:54:29,  3.77s/iteration, mean_rewards=55]\u001b[A\n",
            "Training:   9%|▉         | 178/2000 [08:56<1:54:29,  3.77s/iteration, mean_rewards=20.7]\u001b[A\n",
            "Training:   9%|▉         | 179/2000 [08:59<1:57:01,  3.86s/iteration, mean_rewards=20.7]\u001b[A\n",
            "Training:   9%|▉         | 179/2000 [09:01<1:57:01,  3.86s/iteration, mean_rewards=33.8]\u001b[A\n",
            "Training:   9%|▉         | 180/2000 [09:03<1:59:01,  3.92s/iteration, mean_rewards=33.8]\u001b[A\n",
            "Training:   9%|▉         | 180/2000 [09:05<1:59:01,  3.92s/iteration, mean_rewards=17.4]\u001b[A\n",
            "Training:   9%|▉         | 181/2000 [09:06<1:56:25,  3.84s/iteration, mean_rewards=17.4]\u001b[A\n",
            "Training:   9%|▉         | 181/2000 [09:08<1:56:25,  3.84s/iteration, mean_rewards=16.9]\u001b[A\n",
            "Training:   9%|▉         | 182/2000 [09:10<1:55:32,  3.81s/iteration, mean_rewards=16.9]\u001b[A\n",
            "Training:   9%|▉         | 182/2000 [09:13<1:55:32,  3.81s/iteration, mean_rewards=44.8]\u001b[A\n",
            "Training:   9%|▉         | 183/2000 [09:15<2:00:37,  3.98s/iteration, mean_rewards=44.8]\u001b[A\n",
            "Training:   9%|▉         | 183/2000 [09:16<2:00:37,  3.98s/iteration, mean_rewards=18.9]\u001b[A\n",
            "Training:   9%|▉         | 184/2000 [09:18<1:57:53,  3.89s/iteration, mean_rewards=18.9]\u001b[A\n",
            "Training:   9%|▉         | 184/2000 [09:20<1:57:53,  3.89s/iteration, mean_rewards=16.4]\u001b[A\n",
            "Training:   9%|▉         | 185/2000 [09:22<1:54:49,  3.80s/iteration, mean_rewards=16.4]\u001b[A\n",
            "Training:   9%|▉         | 185/2000 [09:24<1:54:49,  3.80s/iteration, mean_rewards=26.2]\u001b[A\n",
            "Training:   9%|▉         | 186/2000 [09:27<2:02:19,  4.05s/iteration, mean_rewards=26.2]\u001b[A\n",
            "Training:   9%|▉         | 186/2000 [09:28<2:02:19,  4.05s/iteration, mean_rewards=8.61]\u001b[A\n",
            "Training:   9%|▉         | 187/2000 [09:30<1:58:26,  3.92s/iteration, mean_rewards=8.61]\u001b[A\n",
            "Training:   9%|▉         | 187/2000 [09:32<1:58:26,  3.92s/iteration, mean_rewards=19.6]\u001b[A\n",
            "Training:   9%|▉         | 188/2000 [09:34<1:55:23,  3.82s/iteration, mean_rewards=19.6]\u001b[A\n",
            "Training:   9%|▉         | 188/2000 [09:35<1:55:23,  3.82s/iteration, mean_rewards=44.5]\u001b[A\n",
            "Training:   9%|▉         | 189/2000 [09:38<1:57:07,  3.88s/iteration, mean_rewards=44.5]\u001b[A\n",
            "Training:   9%|▉         | 189/2000 [09:40<1:57:07,  3.88s/iteration, mean_rewards=37.4]\u001b[A\n",
            "Training:  10%|▉         | 190/2000 [09:42<1:59:56,  3.98s/iteration, mean_rewards=37.4]\u001b[A\n",
            "Training:  10%|▉         | 190/2000 [09:44<1:59:56,  3.98s/iteration, mean_rewards=39.1]\u001b[A\n",
            "Training:  10%|▉         | 191/2000 [09:46<1:57:04,  3.88s/iteration, mean_rewards=39.1]\u001b[A\n",
            "Training:  10%|▉         | 191/2000 [09:47<1:57:04,  3.88s/iteration, mean_rewards=30.6]\u001b[A\n",
            "Training:  10%|▉         | 192/2000 [09:49<1:55:24,  3.83s/iteration, mean_rewards=30.6]\u001b[A\n",
            "Training:  10%|▉         | 192/2000 [09:52<1:55:24,  3.83s/iteration, mean_rewards=30.2]\u001b[A\n",
            "Training:  10%|▉         | 193/2000 [09:54<2:01:18,  4.03s/iteration, mean_rewards=30.2]\u001b[A\n",
            "Training:  10%|▉         | 193/2000 [09:55<2:01:18,  4.03s/iteration, mean_rewards=30.5]\u001b[A\n",
            "Training:  10%|▉         | 194/2000 [09:57<1:57:04,  3.89s/iteration, mean_rewards=30.5]\u001b[A\n",
            "Training:  10%|▉         | 194/2000 [09:59<1:57:04,  3.89s/iteration, mean_rewards=1.83]\u001b[A\n",
            "Training:  10%|▉         | 195/2000 [10:01<1:55:16,  3.83s/iteration, mean_rewards=1.83]\u001b[A\n",
            "Training:  10%|▉         | 195/2000 [10:03<1:55:16,  3.83s/iteration, mean_rewards=22.1]\u001b[A\n",
            "Training:  10%|▉         | 196/2000 [10:06<2:02:53,  4.09s/iteration, mean_rewards=22.1]\u001b[A\n",
            "Training:  10%|▉         | 196/2000 [10:07<2:02:53,  4.09s/iteration, mean_rewards=27.2]\u001b[A\n",
            "Training:  10%|▉         | 197/2000 [10:09<1:58:48,  3.95s/iteration, mean_rewards=27.2]\u001b[A\n",
            "Training:  10%|▉         | 197/2000 [10:11<1:58:48,  3.95s/iteration, mean_rewards=54.7]\u001b[A\n",
            "Training:  10%|▉         | 198/2000 [10:13<1:56:02,  3.86s/iteration, mean_rewards=54.7]\u001b[A\n",
            "Training:  10%|▉         | 198/2000 [10:15<1:56:02,  3.86s/iteration, mean_rewards=59.9]\u001b[A\n",
            "Training:  10%|▉         | 199/2000 [10:17<1:58:06,  3.94s/iteration, mean_rewards=59.9]\u001b[A\n",
            "Training:  10%|▉         | 199/2000 [10:19<1:58:06,  3.94s/iteration, mean_rewards=41.1]\u001b[A\n",
            "Training:  10%|█         | 200/2000 [10:21<1:57:48,  3.93s/iteration, mean_rewards=41.1]\u001b[A\n",
            "Training:  10%|█         | 200/2000 [10:21<1:57:48,  3.93s/iteration, mean_rewards=-409]\u001b[A\n",
            "Training:  10%|█         | 201/2000 [10:22<1:28:14,  2.94s/iteration, mean_rewards=-409]\u001b[A\n",
            "Training:  10%|█         | 201/2000 [10:22<1:28:14,  2.94s/iteration, mean_rewards=-114]\u001b[A\n",
            "Training:  10%|█         | 202/2000 [10:23<1:09:06,  2.31s/iteration, mean_rewards=-114]\u001b[A\n",
            "Training:  10%|█         | 202/2000 [10:23<1:09:06,  2.31s/iteration, mean_rewards=-232]\u001b[A\n",
            "Training:  10%|█         | 203/2000 [10:23<55:22,  1.85s/iteration, mean_rewards=-232]  \u001b[A\n",
            "Training:  10%|█         | 203/2000 [10:24<55:22,  1.85s/iteration, mean_rewards=-134]\u001b[A\n",
            "Training:  10%|█         | 204/2000 [10:24<48:38,  1.63s/iteration, mean_rewards=-134]\u001b[A\n",
            "Training:  10%|█         | 204/2000 [10:25<48:38,  1.63s/iteration, mean_rewards=-101]\u001b[A\n",
            "Training:  10%|█         | 205/2000 [10:26<43:54,  1.47s/iteration, mean_rewards=-101]\u001b[A\n",
            "Training:  10%|█         | 205/2000 [10:26<43:54,  1.47s/iteration, mean_rewards=-113]\u001b[A\n",
            "Training:  10%|█         | 206/2000 [10:26<36:49,  1.23s/iteration, mean_rewards=-113]\u001b[A\n",
            "Training:  10%|█         | 206/2000 [10:27<36:49,  1.23s/iteration, mean_rewards=-102]\u001b[A\n",
            "Training:  10%|█         | 207/2000 [10:27<34:13,  1.15s/iteration, mean_rewards=-102]\u001b[A\n",
            "Training:  10%|█         | 207/2000 [10:28<34:13,  1.15s/iteration, mean_rewards=-152]\u001b[A\n",
            "Training:  10%|█         | 208/2000 [10:28<35:11,  1.18s/iteration, mean_rewards=-152]\u001b[A\n",
            "Training:  10%|█         | 208/2000 [10:29<35:11,  1.18s/iteration, mean_rewards=-154]\u001b[A\n",
            "Training:  10%|█         | 209/2000 [10:30<37:29,  1.26s/iteration, mean_rewards=-154]\u001b[A\n",
            "Training:  10%|█         | 209/2000 [10:30<37:29,  1.26s/iteration, mean_rewards=-267]\u001b[A\n",
            "Training:  10%|█         | 210/2000 [10:31<38:45,  1.30s/iteration, mean_rewards=-267]\u001b[A\n",
            "Training:  10%|█         | 210/2000 [10:32<38:45,  1.30s/iteration, mean_rewards=-231]\u001b[A\n",
            "Training:  11%|█         | 211/2000 [10:32<35:03,  1.18s/iteration, mean_rewards=-231]\u001b[A\n",
            "Training:  11%|█         | 211/2000 [10:33<35:03,  1.18s/iteration, mean_rewards=-272]\u001b[A\n",
            "Training:  11%|█         | 212/2000 [10:33<34:04,  1.14s/iteration, mean_rewards=-272]\u001b[A\n",
            "Training:  11%|█         | 212/2000 [10:34<34:04,  1.14s/iteration, mean_rewards=-362]\u001b[A\n",
            "Training:  11%|█         | 213/2000 [10:34<32:04,  1.08s/iteration, mean_rewards=-362]\u001b[A\n",
            "Training:  11%|█         | 213/2000 [10:34<32:04,  1.08s/iteration, mean_rewards=-194]\u001b[A\n",
            "Training:  11%|█         | 214/2000 [10:35<29:29,  1.01iteration/s, mean_rewards=-194]\u001b[A\n",
            "Training:  11%|█         | 214/2000 [10:35<29:29,  1.01iteration/s, mean_rewards=-401]\u001b[A\n",
            "Training:  11%|█         | 215/2000 [10:36<27:39,  1.08iteration/s, mean_rewards=-401]\u001b[A\n",
            "Training:  11%|█         | 215/2000 [10:36<27:39,  1.08iteration/s, mean_rewards=-214]\u001b[A\n",
            "Training:  11%|█         | 216/2000 [10:36<26:08,  1.14iteration/s, mean_rewards=-214]\u001b[A\n",
            "Training:  11%|█         | 216/2000 [10:37<26:08,  1.14iteration/s, mean_rewards=-90.4]\u001b[A\n",
            "Training:  11%|█         | 217/2000 [10:38<27:47,  1.07iteration/s, mean_rewards=-90.4]\u001b[A\n",
            "Training:  11%|█         | 217/2000 [10:38<27:47,  1.07iteration/s, mean_rewards=-154] \u001b[A\n",
            "Training:  11%|█         | 218/2000 [10:38<27:54,  1.06iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  11%|█         | 218/2000 [10:39<27:54,  1.06iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  11%|█         | 219/2000 [10:39<26:44,  1.11iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  11%|█         | 219/2000 [10:40<26:44,  1.11iteration/s, mean_rewards=-371]\u001b[A\n",
            "Training:  11%|█         | 220/2000 [10:40<27:55,  1.06iteration/s, mean_rewards=-371]\u001b[A\n",
            "Training:  11%|█         | 220/2000 [10:41<27:55,  1.06iteration/s, mean_rewards=-306]\u001b[A\n",
            "Training:  11%|█         | 221/2000 [10:41<29:24,  1.01iteration/s, mean_rewards=-306]\u001b[A\n",
            "Training:  11%|█         | 221/2000 [10:42<29:24,  1.01iteration/s, mean_rewards=-202]\u001b[A\n",
            "Training:  11%|█         | 222/2000 [10:42<30:09,  1.02s/iteration, mean_rewards=-202]\u001b[A\n",
            "Training:  11%|█         | 222/2000 [10:43<30:09,  1.02s/iteration, mean_rewards=-247]\u001b[A\n",
            "Training:  11%|█         | 223/2000 [10:44<33:01,  1.12s/iteration, mean_rewards=-247]\u001b[A\n",
            "Training:  11%|█         | 223/2000 [10:44<33:01,  1.12s/iteration, mean_rewards=-152]\u001b[A\n",
            "Training:  11%|█         | 224/2000 [10:45<32:36,  1.10s/iteration, mean_rewards=-152]\u001b[A\n",
            "Training:  11%|█         | 224/2000 [10:45<32:36,  1.10s/iteration, mean_rewards=-151]\u001b[A\n",
            "Training:  11%|█▏        | 225/2000 [10:46<30:14,  1.02s/iteration, mean_rewards=-151]\u001b[A\n",
            "Training:  11%|█▏        | 225/2000 [10:46<30:14,  1.02s/iteration, mean_rewards=-110]\u001b[A\n",
            "Training:  11%|█▏        | 226/2000 [10:47<29:18,  1.01iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  11%|█▏        | 226/2000 [10:47<29:18,  1.01iteration/s, mean_rewards=-335]\u001b[A\n",
            "Training:  11%|█▏        | 227/2000 [10:48<29:49,  1.01s/iteration, mean_rewards=-335]\u001b[A\n",
            "Training:  11%|█▏        | 227/2000 [10:48<29:49,  1.01s/iteration, mean_rewards=-122]\u001b[A\n",
            "Training:  11%|█▏        | 228/2000 [10:48<27:37,  1.07iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  11%|█▏        | 228/2000 [10:49<27:37,  1.07iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:  11%|█▏        | 229/2000 [10:49<26:18,  1.12iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:  11%|█▏        | 229/2000 [10:50<26:18,  1.12iteration/s, mean_rewards=-81.4]\u001b[A\n",
            "Training:  12%|█▏        | 230/2000 [10:50<25:25,  1.16iteration/s, mean_rewards=-81.4]\u001b[A\n",
            "Training:  12%|█▏        | 230/2000 [10:50<25:25,  1.16iteration/s, mean_rewards=-332] \u001b[A\n",
            "Training:  12%|█▏        | 231/2000 [10:51<26:08,  1.13iteration/s, mean_rewards=-332]\u001b[A\n",
            "Training:  12%|█▏        | 231/2000 [10:51<26:08,  1.13iteration/s, mean_rewards=-305]\u001b[A\n",
            "Training:  12%|█▏        | 232/2000 [10:52<28:11,  1.05iteration/s, mean_rewards=-305]\u001b[A\n",
            "Training:  12%|█▏        | 232/2000 [10:53<28:11,  1.05iteration/s, mean_rewards=-88.5]\u001b[A\n",
            "Training:  12%|█▏        | 233/2000 [10:53<28:01,  1.05iteration/s, mean_rewards=-88.5]\u001b[A\n",
            "Training:  12%|█▏        | 233/2000 [10:53<28:01,  1.05iteration/s, mean_rewards=-131] \u001b[A\n",
            "Training:  12%|█▏        | 234/2000 [10:54<28:11,  1.04iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  12%|█▏        | 234/2000 [10:54<28:11,  1.04iteration/s, mean_rewards=-266]\u001b[A\n",
            "Training:  12%|█▏        | 235/2000 [10:55<29:09,  1.01iteration/s, mean_rewards=-266]\u001b[A\n",
            "Training:  12%|█▏        | 235/2000 [10:56<29:09,  1.01iteration/s, mean_rewards=-345]\u001b[A\n",
            "Training:  12%|█▏        | 236/2000 [10:56<32:29,  1.10s/iteration, mean_rewards=-345]\u001b[A\n",
            "Training:  12%|█▏        | 236/2000 [10:57<32:29,  1.10s/iteration, mean_rewards=-216]\u001b[A\n",
            "Training:  12%|█▏        | 237/2000 [10:57<30:54,  1.05s/iteration, mean_rewards=-216]\u001b[A\n",
            "Training:  12%|█▏        | 237/2000 [10:58<30:54,  1.05s/iteration, mean_rewards=-225]\u001b[A\n",
            "Training:  12%|█▏        | 238/2000 [10:58<28:27,  1.03iteration/s, mean_rewards=-225]\u001b[A\n",
            "Training:  12%|█▏        | 238/2000 [10:58<28:27,  1.03iteration/s, mean_rewards=-96] \u001b[A\n",
            "Training:  12%|█▏        | 239/2000 [10:59<26:32,  1.11iteration/s, mean_rewards=-96]\u001b[A\n",
            "Training:  12%|█▏        | 239/2000 [10:59<26:32,  1.11iteration/s, mean_rewards=-90.6]\u001b[A\n",
            "Training:  12%|█▏        | 240/2000 [11:00<26:36,  1.10iteration/s, mean_rewards=-90.6]\u001b[A\n",
            "Training:  12%|█▏        | 240/2000 [11:00<26:36,  1.10iteration/s, mean_rewards=-228] \u001b[A\n",
            "Training:  12%|█▏        | 241/2000 [11:01<25:43,  1.14iteration/s, mean_rewards=-228]\u001b[A\n",
            "Training:  12%|█▏        | 241/2000 [11:01<25:43,  1.14iteration/s, mean_rewards=-160]\u001b[A\n",
            "Training:  12%|█▏        | 242/2000 [11:01<25:11,  1.16iteration/s, mean_rewards=-160]\u001b[A\n",
            "Training:  12%|█▏        | 242/2000 [11:02<25:11,  1.16iteration/s, mean_rewards=-109]\u001b[A\n",
            "Training:  12%|█▏        | 243/2000 [11:02<24:40,  1.19iteration/s, mean_rewards=-109]\u001b[A\n",
            "Training:  12%|█▏        | 243/2000 [11:03<24:40,  1.19iteration/s, mean_rewards=-152]\u001b[A\n",
            "Training:  12%|█▏        | 244/2000 [11:03<26:47,  1.09iteration/s, mean_rewards=-152]\u001b[A\n",
            "Training:  12%|█▏        | 244/2000 [11:04<26:47,  1.09iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  12%|█▏        | 245/2000 [11:04<25:59,  1.13iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  12%|█▏        | 245/2000 [11:05<25:59,  1.13iteration/s, mean_rewards=-385]\u001b[A\n",
            "Training:  12%|█▏        | 246/2000 [11:05<28:30,  1.03iteration/s, mean_rewards=-385]\u001b[A\n",
            "Training:  12%|█▏        | 246/2000 [11:06<28:30,  1.03iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  12%|█▏        | 247/2000 [11:06<28:17,  1.03iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  12%|█▏        | 247/2000 [11:07<28:17,  1.03iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  12%|█▏        | 248/2000 [11:08<30:57,  1.06s/iteration, mean_rewards=-131]\u001b[A\n",
            "Training:  12%|█▏        | 248/2000 [11:08<30:57,  1.06s/iteration, mean_rewards=-205]\u001b[A\n",
            "Training:  12%|█▏        | 249/2000 [11:09<31:23,  1.08s/iteration, mean_rewards=-205]\u001b[A\n",
            "Training:  12%|█▏        | 249/2000 [11:09<31:23,  1.08s/iteration, mean_rewards=-271]\u001b[A\n",
            "Training:  12%|█▎        | 250/2000 [11:10<30:19,  1.04s/iteration, mean_rewards=-271]\u001b[A\n",
            "Training:  12%|█▎        | 250/2000 [11:10<30:19,  1.04s/iteration, mean_rewards=-208]\u001b[A\n",
            "Training:  13%|█▎        | 251/2000 [11:10<28:28,  1.02iteration/s, mean_rewards=-208]\u001b[A\n",
            "Training:  13%|█▎        | 251/2000 [11:11<28:28,  1.02iteration/s, mean_rewards=-230]\u001b[A\n",
            "Training:  13%|█▎        | 252/2000 [11:12<29:22,  1.01s/iteration, mean_rewards=-230]\u001b[A\n",
            "Training:  13%|█▎        | 252/2000 [11:12<29:22,  1.01s/iteration, mean_rewards=-256]\u001b[A\n",
            "Training:  13%|█▎        | 253/2000 [11:12<28:39,  1.02iteration/s, mean_rewards=-256]\u001b[A\n",
            "Training:  13%|█▎        | 253/2000 [11:13<28:39,  1.02iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  13%|█▎        | 254/2000 [11:13<25:57,  1.12iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  13%|█▎        | 254/2000 [11:14<25:57,  1.12iteration/s, mean_rewards=-88.3]\u001b[A\n",
            "Training:  13%|█▎        | 255/2000 [11:14<25:09,  1.16iteration/s, mean_rewards=-88.3]\u001b[A\n",
            "Training:  13%|█▎        | 255/2000 [11:14<25:09,  1.16iteration/s, mean_rewards=-366] \u001b[A\n",
            "Training:  13%|█▎        | 256/2000 [11:15<25:44,  1.13iteration/s, mean_rewards=-366]\u001b[A\n",
            "Training:  13%|█▎        | 256/2000 [11:15<25:44,  1.13iteration/s, mean_rewards=-209]\u001b[A\n",
            "Training:  13%|█▎        | 257/2000 [11:16<25:04,  1.16iteration/s, mean_rewards=-209]\u001b[A\n",
            "Training:  13%|█▎        | 257/2000 [11:16<25:04,  1.16iteration/s, mean_rewards=-203]\u001b[A\n",
            "Training:  13%|█▎        | 258/2000 [11:16<23:43,  1.22iteration/s, mean_rewards=-203]\u001b[A\n",
            "Training:  13%|█▎        | 258/2000 [11:17<23:43,  1.22iteration/s, mean_rewards=-309]\u001b[A\n",
            "Training:  13%|█▎        | 259/2000 [11:17<24:34,  1.18iteration/s, mean_rewards=-309]\u001b[A\n",
            "Training:  13%|█▎        | 259/2000 [11:18<24:34,  1.18iteration/s, mean_rewards=-243]\u001b[A\n",
            "Training:  13%|█▎        | 260/2000 [11:18<24:32,  1.18iteration/s, mean_rewards=-243]\u001b[A\n",
            "Training:  13%|█▎        | 260/2000 [11:19<24:32,  1.18iteration/s, mean_rewards=-237]\u001b[A\n",
            "Training:  13%|█▎        | 261/2000 [11:19<25:02,  1.16iteration/s, mean_rewards=-237]\u001b[A\n",
            "Training:  13%|█▎        | 261/2000 [11:19<25:02,  1.16iteration/s, mean_rewards=-212]\u001b[A\n",
            "Training:  13%|█▎        | 262/2000 [11:20<26:25,  1.10iteration/s, mean_rewards=-212]\u001b[A\n",
            "Training:  13%|█▎        | 262/2000 [11:21<26:25,  1.10iteration/s, mean_rewards=-256]\u001b[A\n",
            "Training:  13%|█▎        | 263/2000 [11:21<28:05,  1.03iteration/s, mean_rewards=-256]\u001b[A\n",
            "Training:  13%|█▎        | 263/2000 [11:22<28:05,  1.03iteration/s, mean_rewards=-258]\u001b[A\n",
            "Training:  13%|█▎        | 264/2000 [11:23<31:06,  1.08s/iteration, mean_rewards=-258]\u001b[A\n",
            "Training:  13%|█▎        | 264/2000 [11:23<31:06,  1.08s/iteration, mean_rewards=-215]\u001b[A\n",
            "Training:  13%|█▎        | 265/2000 [11:24<32:06,  1.11s/iteration, mean_rewards=-215]\u001b[A\n",
            "Training:  13%|█▎        | 265/2000 [11:24<32:06,  1.11s/iteration, mean_rewards=-181]\u001b[A\n",
            "Training:  13%|█▎        | 266/2000 [11:25<29:25,  1.02s/iteration, mean_rewards=-181]\u001b[A\n",
            "Training:  13%|█▎        | 266/2000 [11:25<29:25,  1.02s/iteration, mean_rewards=-97.8]\u001b[A\n",
            "Training:  13%|█▎        | 267/2000 [11:25<27:25,  1.05iteration/s, mean_rewards=-97.8]\u001b[A\n",
            "Training:  13%|█▎        | 267/2000 [11:26<27:25,  1.05iteration/s, mean_rewards=-107] \u001b[A\n",
            "Training:  13%|█▎        | 268/2000 [11:26<25:09,  1.15iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  13%|█▎        | 268/2000 [11:26<25:09,  1.15iteration/s, mean_rewards=-204]\u001b[A\n",
            "Training:  13%|█▎        | 269/2000 [11:27<23:39,  1.22iteration/s, mean_rewards=-204]\u001b[A\n",
            "Training:  13%|█▎        | 269/2000 [11:27<23:39,  1.22iteration/s, mean_rewards=-293]\u001b[A\n",
            "Training:  14%|█▎        | 270/2000 [11:28<23:30,  1.23iteration/s, mean_rewards=-293]\u001b[A\n",
            "Training:  14%|█▎        | 270/2000 [11:28<23:30,  1.23iteration/s, mean_rewards=-271]\u001b[A\n",
            "Training:  14%|█▎        | 271/2000 [11:28<23:27,  1.23iteration/s, mean_rewards=-271]\u001b[A\n",
            "Training:  14%|█▎        | 271/2000 [11:29<23:27,  1.23iteration/s, mean_rewards=-163]\u001b[A\n",
            "Training:  14%|█▎        | 272/2000 [11:29<22:25,  1.28iteration/s, mean_rewards=-163]\u001b[A\n",
            "Training:  14%|█▎        | 272/2000 [11:29<22:25,  1.28iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  14%|█▎        | 273/2000 [11:30<23:46,  1.21iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  14%|█▎        | 273/2000 [11:30<23:46,  1.21iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  14%|█▎        | 274/2000 [11:31<23:26,  1.23iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  14%|█▎        | 274/2000 [11:31<23:26,  1.23iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  14%|█▍        | 275/2000 [11:32<23:15,  1.24iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  14%|█▍        | 275/2000 [11:32<23:15,  1.24iteration/s, mean_rewards=-103]\u001b[A\n",
            "Training:  14%|█▍        | 276/2000 [11:32<22:37,  1.27iteration/s, mean_rewards=-103]\u001b[A\n",
            "Training:  14%|█▍        | 276/2000 [11:33<22:37,  1.27iteration/s, mean_rewards=-254]\u001b[A\n",
            "Training:  14%|█▍        | 277/2000 [11:33<25:08,  1.14iteration/s, mean_rewards=-254]\u001b[A\n",
            "Training:  14%|█▍        | 277/2000 [11:34<25:08,  1.14iteration/s, mean_rewards=-242]\u001b[A\n",
            "Training:  14%|█▍        | 278/2000 [11:35<27:21,  1.05iteration/s, mean_rewards=-242]\u001b[A\n",
            "Training:  14%|█▍        | 278/2000 [11:35<27:21,  1.05iteration/s, mean_rewards=-422]\u001b[A\n",
            "Training:  14%|█▍        | 279/2000 [11:36<27:57,  1.03iteration/s, mean_rewards=-422]\u001b[A\n",
            "Training:  14%|█▍        | 279/2000 [11:36<27:57,  1.03iteration/s, mean_rewards=-220]\u001b[A\n",
            "Training:  14%|█▍        | 280/2000 [11:36<27:21,  1.05iteration/s, mean_rewards=-220]\u001b[A\n",
            "Training:  14%|█▍        | 280/2000 [11:37<27:21,  1.05iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  14%|█▍        | 281/2000 [11:37<27:17,  1.05iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  14%|█▍        | 281/2000 [11:38<27:17,  1.05iteration/s, mean_rewards=-212]\u001b[A\n",
            "Training:  14%|█▍        | 282/2000 [11:38<24:54,  1.15iteration/s, mean_rewards=-212]\u001b[A\n",
            "Training:  14%|█▍        | 282/2000 [11:38<24:54,  1.15iteration/s, mean_rewards=-199]\u001b[A\n",
            "Training:  14%|█▍        | 283/2000 [11:39<25:12,  1.13iteration/s, mean_rewards=-199]\u001b[A\n",
            "Training:  14%|█▍        | 283/2000 [11:39<25:12,  1.13iteration/s, mean_rewards=-266]\u001b[A\n",
            "Training:  14%|█▍        | 284/2000 [11:40<26:01,  1.10iteration/s, mean_rewards=-266]\u001b[A\n",
            "Training:  14%|█▍        | 284/2000 [11:40<26:01,  1.10iteration/s, mean_rewards=-254]\u001b[A\n",
            "Training:  14%|█▍        | 285/2000 [11:41<25:10,  1.14iteration/s, mean_rewards=-254]\u001b[A\n",
            "Training:  14%|█▍        | 285/2000 [11:41<25:10,  1.14iteration/s, mean_rewards=-219]\u001b[A\n",
            "Training:  14%|█▍        | 286/2000 [11:42<24:50,  1.15iteration/s, mean_rewards=-219]\u001b[A\n",
            "Training:  14%|█▍        | 286/2000 [11:42<24:50,  1.15iteration/s, mean_rewards=-105]\u001b[A\n",
            "Training:  14%|█▍        | 287/2000 [11:42<23:32,  1.21iteration/s, mean_rewards=-105]\u001b[A\n",
            "Training:  14%|█▍        | 287/2000 [11:43<23:32,  1.21iteration/s, mean_rewards=-213]\u001b[A\n",
            "Training:  14%|█▍        | 288/2000 [11:43<23:14,  1.23iteration/s, mean_rewards=-213]\u001b[A\n",
            "Training:  14%|█▍        | 288/2000 [11:44<23:14,  1.23iteration/s, mean_rewards=-384]\u001b[A\n",
            "Training:  14%|█▍        | 289/2000 [11:44<26:12,  1.09iteration/s, mean_rewards=-384]\u001b[A\n",
            "Training:  14%|█▍        | 289/2000 [11:45<26:12,  1.09iteration/s, mean_rewards=-159]\u001b[A\n",
            "Training:  14%|█▍        | 290/2000 [11:46<30:14,  1.06s/iteration, mean_rewards=-159]\u001b[A\n",
            "Training:  14%|█▍        | 290/2000 [11:46<30:14,  1.06s/iteration, mean_rewards=-110]\u001b[A\n",
            "Training:  15%|█▍        | 291/2000 [11:47<31:07,  1.09s/iteration, mean_rewards=-110]\u001b[A\n",
            "Training:  15%|█▍        | 291/2000 [11:47<31:07,  1.09s/iteration, mean_rewards=-134]\u001b[A\n",
            "Training:  15%|█▍        | 292/2000 [11:48<32:06,  1.13s/iteration, mean_rewards=-134]\u001b[A\n",
            "Training:  15%|█▍        | 292/2000 [11:49<32:06,  1.13s/iteration, mean_rewards=-413]\u001b[A\n",
            "Training:  15%|█▍        | 293/2000 [11:49<32:29,  1.14s/iteration, mean_rewards=-413]\u001b[A\n",
            "Training:  15%|█▍        | 293/2000 [11:50<32:29,  1.14s/iteration, mean_rewards=-160]\u001b[A\n",
            "Training:  15%|█▍        | 294/2000 [11:50<30:44,  1.08s/iteration, mean_rewards=-160]\u001b[A\n",
            "Training:  15%|█▍        | 294/2000 [11:50<30:44,  1.08s/iteration, mean_rewards=-186]\u001b[A\n",
            "Training:  15%|█▍        | 295/2000 [11:51<28:15,  1.01iteration/s, mean_rewards=-186]\u001b[A\n",
            "Training:  15%|█▍        | 295/2000 [11:51<28:15,  1.01iteration/s, mean_rewards=-74.5]\u001b[A\n",
            "Training:  15%|█▍        | 296/2000 [11:52<29:10,  1.03s/iteration, mean_rewards=-74.5]\u001b[A\n",
            "Training:  15%|█▍        | 296/2000 [11:52<29:10,  1.03s/iteration, mean_rewards=-109] \u001b[A\n",
            "Training:  15%|█▍        | 297/2000 [11:53<28:50,  1.02s/iteration, mean_rewards=-109]\u001b[A\n",
            "Training:  15%|█▍        | 297/2000 [11:53<28:50,  1.02s/iteration, mean_rewards=-276]\u001b[A\n",
            "Training:  15%|█▍        | 298/2000 [11:54<28:59,  1.02s/iteration, mean_rewards=-276]\u001b[A\n",
            "Training:  15%|█▍        | 298/2000 [11:54<28:59,  1.02s/iteration, mean_rewards=-336]\u001b[A\n",
            "Training:  15%|█▍        | 299/2000 [11:55<27:16,  1.04iteration/s, mean_rewards=-336]\u001b[A\n",
            "Training:  15%|█▍        | 299/2000 [11:55<27:16,  1.04iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:  15%|█▌        | 300/2000 [11:56<28:22,  1.00s/iteration, mean_rewards=-161]\u001b[A\n",
            "Training:  15%|█▌        | 300/2000 [11:56<28:22,  1.00s/iteration, mean_rewards=-357]\u001b[A\n",
            "Training:  15%|█▌        | 301/2000 [11:57<30:55,  1.09s/iteration, mean_rewards=-357]\u001b[A\n",
            "Training:  15%|█▌        | 301/2000 [11:58<30:55,  1.09s/iteration, mean_rewards=-145]\u001b[A\n",
            "Training:  15%|█▌        | 302/2000 [11:59<33:27,  1.18s/iteration, mean_rewards=-145]\u001b[A\n",
            "Training:  15%|█▌        | 302/2000 [11:59<33:27,  1.18s/iteration, mean_rewards=-76.7]\u001b[A\n",
            "Training:  15%|█▌        | 303/2000 [12:00<31:33,  1.12s/iteration, mean_rewards=-76.7]\u001b[A\n",
            "Training:  15%|█▌        | 303/2000 [12:00<31:33,  1.12s/iteration, mean_rewards=-192] \u001b[A\n",
            "Training:  15%|█▌        | 304/2000 [12:00<27:45,  1.02iteration/s, mean_rewards=-192]\u001b[A\n",
            "Training:  15%|█▌        | 304/2000 [12:01<27:45,  1.02iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  15%|█▌        | 305/2000 [12:01<25:21,  1.11iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  15%|█▌        | 305/2000 [12:01<25:21,  1.11iteration/s, mean_rewards=-373]\u001b[A\n",
            "Training:  15%|█▌        | 306/2000 [12:02<26:51,  1.05iteration/s, mean_rewards=-373]\u001b[A\n",
            "Training:  15%|█▌        | 306/2000 [12:02<26:51,  1.05iteration/s, mean_rewards=-79.9]\u001b[A\n",
            "Training:  15%|█▌        | 307/2000 [12:03<25:43,  1.10iteration/s, mean_rewards=-79.9]\u001b[A\n",
            "Training:  15%|█▌        | 307/2000 [12:03<25:43,  1.10iteration/s, mean_rewards=-259] \u001b[A\n",
            "Training:  15%|█▌        | 308/2000 [12:04<25:07,  1.12iteration/s, mean_rewards=-259]\u001b[A\n",
            "Training:  15%|█▌        | 308/2000 [12:04<25:07,  1.12iteration/s, mean_rewards=-222]\u001b[A\n",
            "Training:  15%|█▌        | 309/2000 [12:05<25:38,  1.10iteration/s, mean_rewards=-222]\u001b[A\n",
            "Training:  15%|█▌        | 309/2000 [12:05<25:38,  1.10iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  16%|█▌        | 310/2000 [12:05<24:31,  1.15iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  16%|█▌        | 310/2000 [12:06<24:31,  1.15iteration/s, mean_rewards=-170]\u001b[A\n",
            "Training:  16%|█▌        | 311/2000 [12:06<23:45,  1.18iteration/s, mean_rewards=-170]\u001b[A\n",
            "Training:  16%|█▌        | 311/2000 [12:07<23:45,  1.18iteration/s, mean_rewards=-92.6]\u001b[A\n",
            "Training:  16%|█▌        | 312/2000 [12:07<26:23,  1.07iteration/s, mean_rewards=-92.6]\u001b[A\n",
            "Training:  16%|█▌        | 312/2000 [12:08<26:23,  1.07iteration/s, mean_rewards=-335] \u001b[A\n",
            "Training:  16%|█▌        | 313/2000 [12:08<26:35,  1.06iteration/s, mean_rewards=-335]\u001b[A\n",
            "Training:  16%|█▌        | 313/2000 [12:09<26:35,  1.06iteration/s, mean_rewards=-201]\u001b[A\n",
            "Training:  16%|█▌        | 314/2000 [12:09<26:15,  1.07iteration/s, mean_rewards=-201]\u001b[A\n",
            "Training:  16%|█▌        | 314/2000 [12:10<26:15,  1.07iteration/s, mean_rewards=-79.9]\u001b[A\n",
            "Training:  16%|█▌        | 315/2000 [12:10<26:36,  1.06iteration/s, mean_rewards=-79.9]\u001b[A\n",
            "Training:  16%|█▌        | 315/2000 [12:11<26:36,  1.06iteration/s, mean_rewards=-115] \u001b[A\n",
            "Training:  16%|█▌        | 316/2000 [12:11<27:36,  1.02iteration/s, mean_rewards=-115]\u001b[A\n",
            "Training:  16%|█▌        | 316/2000 [12:12<27:36,  1.02iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  16%|█▌        | 317/2000 [12:12<27:19,  1.03iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  16%|█▌        | 317/2000 [12:13<27:19,  1.03iteration/s, mean_rewards=-170]\u001b[A\n",
            "Training:  16%|█▌        | 318/2000 [12:13<25:47,  1.09iteration/s, mean_rewards=-170]\u001b[A\n",
            "Training:  16%|█▌        | 318/2000 [12:13<25:47,  1.09iteration/s, mean_rewards=28.1]\u001b[A\n",
            "Training:  16%|█▌        | 319/2000 [12:14<24:33,  1.14iteration/s, mean_rewards=28.1]\u001b[A\n",
            "Training:  16%|█▌        | 319/2000 [12:14<24:33,  1.14iteration/s, mean_rewards=-152]\u001b[A\n",
            "Training:  16%|█▌        | 320/2000 [12:15<24:54,  1.12iteration/s, mean_rewards=-152]\u001b[A\n",
            "Training:  16%|█▌        | 320/2000 [12:15<24:54,  1.12iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:  16%|█▌        | 321/2000 [12:16<25:32,  1.10iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:  16%|█▌        | 321/2000 [12:16<25:32,  1.10iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  16%|█▌        | 322/2000 [12:17<25:58,  1.08iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  16%|█▌        | 322/2000 [12:17<25:58,  1.08iteration/s, mean_rewards=-164]\u001b[A\n",
            "Training:  16%|█▌        | 323/2000 [12:17<24:01,  1.16iteration/s, mean_rewards=-164]\u001b[A\n",
            "Training:  16%|█▌        | 323/2000 [12:18<24:01,  1.16iteration/s, mean_rewards=-255]\u001b[A\n",
            "Training:  16%|█▌        | 324/2000 [12:18<24:52,  1.12iteration/s, mean_rewards=-255]\u001b[A\n",
            "Training:  16%|█▌        | 324/2000 [12:19<24:52,  1.12iteration/s, mean_rewards=-251]\u001b[A\n",
            "Training:  16%|█▋        | 325/2000 [12:19<24:20,  1.15iteration/s, mean_rewards=-251]\u001b[A\n",
            "Training:  16%|█▋        | 325/2000 [12:20<24:20,  1.15iteration/s, mean_rewards=-103]\u001b[A\n",
            "Training:  16%|█▋        | 326/2000 [12:20<24:51,  1.12iteration/s, mean_rewards=-103]\u001b[A\n",
            "Training:  16%|█▋        | 326/2000 [12:21<24:51,  1.12iteration/s, mean_rewards=-345]\u001b[A\n",
            "Training:  16%|█▋        | 327/2000 [12:21<25:59,  1.07iteration/s, mean_rewards=-345]\u001b[A\n",
            "Training:  16%|█▋        | 327/2000 [12:22<25:59,  1.07iteration/s, mean_rewards=-32] \u001b[A\n",
            "Training:  16%|█▋        | 328/2000 [12:22<27:26,  1.02iteration/s, mean_rewards=-32]\u001b[A\n",
            "Training:  16%|█▋        | 328/2000 [12:23<27:26,  1.02iteration/s, mean_rewards=-214]\u001b[A\n",
            "Training:  16%|█▋        | 329/2000 [12:23<27:44,  1.00iteration/s, mean_rewards=-214]\u001b[A\n",
            "Training:  16%|█▋        | 329/2000 [12:24<27:44,  1.00iteration/s, mean_rewards=-238]\u001b[A\n",
            "Training:  16%|█▋        | 330/2000 [12:25<29:32,  1.06s/iteration, mean_rewards=-238]\u001b[A\n",
            "Training:  16%|█▋        | 330/2000 [12:25<29:32,  1.06s/iteration, mean_rewards=-122]\u001b[A\n",
            "Training:  17%|█▋        | 331/2000 [12:26<30:01,  1.08s/iteration, mean_rewards=-122]\u001b[A\n",
            "Training:  17%|█▋        | 331/2000 [12:26<30:01,  1.08s/iteration, mean_rewards=-264]\u001b[A\n",
            "Training:  17%|█▋        | 332/2000 [12:27<29:46,  1.07s/iteration, mean_rewards=-264]\u001b[A\n",
            "Training:  17%|█▋        | 332/2000 [12:27<29:46,  1.07s/iteration, mean_rewards=-93.8]\u001b[A\n",
            "Training:  17%|█▋        | 333/2000 [12:28<28:49,  1.04s/iteration, mean_rewards=-93.8]\u001b[A\n",
            "Training:  17%|█▋        | 333/2000 [12:28<28:49,  1.04s/iteration, mean_rewards=-233] \u001b[A\n",
            "Training:  17%|█▋        | 334/2000 [12:28<26:41,  1.04iteration/s, mean_rewards=-233]\u001b[A\n",
            "Training:  17%|█▋        | 334/2000 [12:29<26:41,  1.04iteration/s, mean_rewards=-220]\u001b[A\n",
            "Training:  17%|█▋        | 335/2000 [12:29<25:12,  1.10iteration/s, mean_rewards=-220]\u001b[A\n",
            "Training:  17%|█▋        | 335/2000 [12:30<25:12,  1.10iteration/s, mean_rewards=-449]\u001b[A\n",
            "Training:  17%|█▋        | 336/2000 [12:30<26:26,  1.05iteration/s, mean_rewards=-449]\u001b[A\n",
            "Training:  17%|█▋        | 336/2000 [12:31<26:26,  1.05iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  17%|█▋        | 337/2000 [12:31<26:14,  1.06iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  17%|█▋        | 337/2000 [12:31<26:14,  1.06iteration/s, mean_rewards=-207]\u001b[A\n",
            "Training:  17%|█▋        | 338/2000 [12:32<23:48,  1.16iteration/s, mean_rewards=-207]\u001b[A\n",
            "Training:  17%|█▋        | 338/2000 [12:32<23:48,  1.16iteration/s, mean_rewards=-201]\u001b[A\n",
            "Training:  17%|█▋        | 339/2000 [12:33<23:27,  1.18iteration/s, mean_rewards=-201]\u001b[A\n",
            "Training:  17%|█▋        | 339/2000 [12:33<23:27,  1.18iteration/s, mean_rewards=0.705]\u001b[A\n",
            "Training:  17%|█▋        | 340/2000 [12:34<23:58,  1.15iteration/s, mean_rewards=0.705]\u001b[A\n",
            "Training:  17%|█▋        | 340/2000 [12:34<23:58,  1.15iteration/s, mean_rewards=-257] \u001b[A\n",
            "Training:  17%|█▋        | 341/2000 [12:35<24:45,  1.12iteration/s, mean_rewards=-257]\u001b[A\n",
            "Training:  17%|█▋        | 341/2000 [12:35<24:45,  1.12iteration/s, mean_rewards=-284]\u001b[A\n",
            "Training:  17%|█▋        | 342/2000 [12:36<25:10,  1.10iteration/s, mean_rewards=-284]\u001b[A\n",
            "Training:  17%|█▋        | 342/2000 [12:37<25:10,  1.10iteration/s, mean_rewards=-54.9]\u001b[A\n",
            "Training:  17%|█▋        | 343/2000 [12:38<38:57,  1.41s/iteration, mean_rewards=-54.9]\u001b[A\n",
            "Training:  17%|█▋        | 343/2000 [12:38<38:57,  1.41s/iteration, mean_rewards=-86.1]\u001b[A\n",
            "Training:  17%|█▋        | 344/2000 [12:39<34:52,  1.26s/iteration, mean_rewards=-86.1]\u001b[A\n",
            "Training:  17%|█▋        | 344/2000 [12:39<34:52,  1.26s/iteration, mean_rewards=-392] \u001b[A\n",
            "Training:  17%|█▋        | 345/2000 [12:40<31:55,  1.16s/iteration, mean_rewards=-392]\u001b[A\n",
            "Training:  17%|█▋        | 345/2000 [12:40<31:55,  1.16s/iteration, mean_rewards=-151]\u001b[A\n",
            "Training:  17%|█▋        | 346/2000 [12:41<29:00,  1.05s/iteration, mean_rewards=-151]\u001b[A\n",
            "Training:  17%|█▋        | 346/2000 [12:41<29:00,  1.05s/iteration, mean_rewards=-32] \u001b[A\n",
            "Training:  17%|█▋        | 347/2000 [12:42<26:56,  1.02iteration/s, mean_rewards=-32]\u001b[A\n",
            "Training:  17%|█▋        | 347/2000 [12:42<26:56,  1.02iteration/s, mean_rewards=-254]\u001b[A\n",
            "Training:  17%|█▋        | 348/2000 [12:43<27:23,  1.01iteration/s, mean_rewards=-254]\u001b[A\n",
            "Training:  17%|█▋        | 348/2000 [12:43<27:23,  1.01iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  17%|█▋        | 349/2000 [12:43<26:47,  1.03iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  17%|█▋        | 349/2000 [12:44<26:47,  1.03iteration/s, mean_rewards=-168]\u001b[A\n",
            "Training:  18%|█▊        | 350/2000 [12:44<25:14,  1.09iteration/s, mean_rewards=-168]\u001b[A\n",
            "Training:  18%|█▊        | 350/2000 [12:45<25:14,  1.09iteration/s, mean_rewards=-96.4]\u001b[A\n",
            "Training:  18%|█▊        | 351/2000 [12:45<24:01,  1.14iteration/s, mean_rewards=-96.4]\u001b[A\n",
            "Training:  18%|█▊        | 351/2000 [12:45<24:01,  1.14iteration/s, mean_rewards=-141] \u001b[A\n",
            "Training:  18%|█▊        | 352/2000 [12:46<23:22,  1.18iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  18%|█▊        | 352/2000 [12:46<23:22,  1.18iteration/s, mean_rewards=-106]\u001b[A\n",
            "Training:  18%|█▊        | 353/2000 [12:47<21:52,  1.26iteration/s, mean_rewards=-106]\u001b[A\n",
            "Training:  18%|█▊        | 353/2000 [12:47<21:52,  1.26iteration/s, mean_rewards=-318]\u001b[A\n",
            "Training:  18%|█▊        | 354/2000 [12:47<22:14,  1.23iteration/s, mean_rewards=-318]\u001b[A\n",
            "Training:  18%|█▊        | 354/2000 [12:48<22:14,  1.23iteration/s, mean_rewards=-214]\u001b[A\n",
            "Training:  18%|█▊        | 355/2000 [12:48<24:18,  1.13iteration/s, mean_rewards=-214]\u001b[A\n",
            "Training:  18%|█▊        | 355/2000 [12:49<24:18,  1.13iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:  18%|█▊        | 356/2000 [12:50<28:11,  1.03s/iteration, mean_rewards=-138]\u001b[A\n",
            "Training:  18%|█▊        | 356/2000 [12:50<28:11,  1.03s/iteration, mean_rewards=-337]\u001b[A\n",
            "Training:  18%|█▊        | 357/2000 [12:51<27:27,  1.00s/iteration, mean_rewards=-337]\u001b[A\n",
            "Training:  18%|█▊        | 357/2000 [12:51<27:27,  1.00s/iteration, mean_rewards=-335]\u001b[A\n",
            "Training:  18%|█▊        | 358/2000 [12:52<26:42,  1.02iteration/s, mean_rewards=-335]\u001b[A\n",
            "Training:  18%|█▊        | 358/2000 [12:52<26:42,  1.02iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  18%|█▊        | 359/2000 [12:53<27:22,  1.00s/iteration, mean_rewards=-144]\u001b[A\n",
            "Training:  18%|█▊        | 359/2000 [12:53<27:22,  1.00s/iteration, mean_rewards=-120]\u001b[A\n",
            "Training:  18%|█▊        | 360/2000 [12:54<26:13,  1.04iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  18%|█▊        | 360/2000 [12:54<26:13,  1.04iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  18%|█▊        | 361/2000 [12:54<25:10,  1.09iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  18%|█▊        | 361/2000 [12:55<25:10,  1.09iteration/s, mean_rewards=-165]\u001b[A\n",
            "Training:  18%|█▊        | 362/2000 [12:55<24:25,  1.12iteration/s, mean_rewards=-165]\u001b[A\n",
            "Training:  18%|█▊        | 362/2000 [12:56<24:25,  1.12iteration/s, mean_rewards=-165]\u001b[A\n",
            "Training:  18%|█▊        | 363/2000 [12:56<24:55,  1.09iteration/s, mean_rewards=-165]\u001b[A\n",
            "Training:  18%|█▊        | 363/2000 [12:56<24:55,  1.09iteration/s, mean_rewards=-257]\u001b[A\n",
            "Training:  18%|█▊        | 364/2000 [12:57<23:23,  1.17iteration/s, mean_rewards=-257]\u001b[A\n",
            "Training:  18%|█▊        | 364/2000 [12:57<23:23,  1.17iteration/s, mean_rewards=-76.3]\u001b[A\n",
            "Training:  18%|█▊        | 365/2000 [12:58<24:06,  1.13iteration/s, mean_rewards=-76.3]\u001b[A\n",
            "Training:  18%|█▊        | 365/2000 [12:58<24:06,  1.13iteration/s, mean_rewards=-106] \u001b[A\n",
            "Training:  18%|█▊        | 366/2000 [12:59<23:33,  1.16iteration/s, mean_rewards=-106]\u001b[A\n",
            "Training:  18%|█▊        | 366/2000 [12:59<23:33,  1.16iteration/s, mean_rewards=-261]\u001b[A\n",
            "Training:  18%|█▊        | 367/2000 [13:00<24:20,  1.12iteration/s, mean_rewards=-261]\u001b[A\n",
            "Training:  18%|█▊        | 367/2000 [13:00<24:20,  1.12iteration/s, mean_rewards=-255]\u001b[A\n",
            "Training:  18%|█▊        | 368/2000 [13:01<24:07,  1.13iteration/s, mean_rewards=-255]\u001b[A\n",
            "Training:  18%|█▊        | 368/2000 [13:01<24:07,  1.13iteration/s, mean_rewards=-216]\u001b[A\n",
            "Training:  18%|█▊        | 369/2000 [13:02<28:34,  1.05s/iteration, mean_rewards=-216]\u001b[A\n",
            "Training:  18%|█▊        | 369/2000 [13:02<28:34,  1.05s/iteration, mean_rewards=-273]\u001b[A\n",
            "Training:  18%|█▊        | 370/2000 [13:03<27:51,  1.03s/iteration, mean_rewards=-273]\u001b[A\n",
            "Training:  18%|█▊        | 370/2000 [13:03<27:51,  1.03s/iteration, mean_rewards=-239]\u001b[A\n",
            "Training:  19%|█▊        | 371/2000 [13:04<26:35,  1.02iteration/s, mean_rewards=-239]\u001b[A\n",
            "Training:  19%|█▊        | 371/2000 [13:04<26:35,  1.02iteration/s, mean_rewards=-43] \u001b[A\n",
            "Training:  19%|█▊        | 372/2000 [13:04<24:06,  1.13iteration/s, mean_rewards=-43]\u001b[A\n",
            "Training:  19%|█▊        | 372/2000 [13:05<24:06,  1.13iteration/s, mean_rewards=-329]\u001b[A\n",
            "Training:  19%|█▊        | 373/2000 [13:05<24:36,  1.10iteration/s, mean_rewards=-329]\u001b[A\n",
            "Training:  19%|█▊        | 373/2000 [13:06<24:36,  1.10iteration/s, mean_rewards=-337]\u001b[A\n",
            "Training:  19%|█▊        | 374/2000 [13:06<24:50,  1.09iteration/s, mean_rewards=-337]\u001b[A\n",
            "Training:  19%|█▊        | 374/2000 [13:07<24:50,  1.09iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  19%|█▉        | 375/2000 [13:07<23:03,  1.17iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  19%|█▉        | 375/2000 [13:07<23:03,  1.17iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  19%|█▉        | 376/2000 [13:08<22:54,  1.18iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  19%|█▉        | 376/2000 [13:08<22:54,  1.18iteration/s, mean_rewards=-391]\u001b[A\n",
            "Training:  19%|█▉        | 377/2000 [13:09<25:04,  1.08iteration/s, mean_rewards=-391]\u001b[A\n",
            "Training:  19%|█▉        | 377/2000 [13:09<25:04,  1.08iteration/s, mean_rewards=-265]\u001b[A\n",
            "Training:  19%|█▉        | 378/2000 [13:10<26:13,  1.03iteration/s, mean_rewards=-265]\u001b[A\n",
            "Training:  19%|█▉        | 378/2000 [13:10<26:13,  1.03iteration/s, mean_rewards=-306]\u001b[A\n",
            "Training:  19%|█▉        | 379/2000 [13:11<24:58,  1.08iteration/s, mean_rewards=-306]\u001b[A\n",
            "Training:  19%|█▉        | 379/2000 [13:11<24:58,  1.08iteration/s, mean_rewards=-215]\u001b[A\n",
            "Training:  19%|█▉        | 380/2000 [13:12<25:12,  1.07iteration/s, mean_rewards=-215]\u001b[A\n",
            "Training:  19%|█▉        | 380/2000 [13:12<25:12,  1.07iteration/s, mean_rewards=-226]\u001b[A\n",
            "Training:  19%|█▉        | 381/2000 [13:13<24:07,  1.12iteration/s, mean_rewards=-226]\u001b[A\n",
            "Training:  19%|█▉        | 381/2000 [13:13<24:07,  1.12iteration/s, mean_rewards=-160]\u001b[A\n",
            "Training:  19%|█▉        | 382/2000 [13:14<24:55,  1.08iteration/s, mean_rewards=-160]\u001b[A\n",
            "Training:  19%|█▉        | 382/2000 [13:14<24:55,  1.08iteration/s, mean_rewards=-373]\u001b[A\n",
            "Training:  19%|█▉        | 383/2000 [13:15<27:55,  1.04s/iteration, mean_rewards=-373]\u001b[A\n",
            "Training:  19%|█▉        | 383/2000 [13:15<27:55,  1.04s/iteration, mean_rewards=-182]\u001b[A\n",
            "Training:  19%|█▉        | 384/2000 [13:16<28:39,  1.06s/iteration, mean_rewards=-182]\u001b[A\n",
            "Training:  19%|█▉        | 384/2000 [13:16<28:39,  1.06s/iteration, mean_rewards=-347]\u001b[A\n",
            "Training:  19%|█▉        | 385/2000 [13:17<26:35,  1.01iteration/s, mean_rewards=-347]\u001b[A\n",
            "Training:  19%|█▉        | 385/2000 [13:17<26:35,  1.01iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  19%|█▉        | 386/2000 [13:18<26:13,  1.03iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  19%|█▉        | 386/2000 [13:18<26:13,  1.03iteration/s, mean_rewards=-244]\u001b[A\n",
            "Training:  19%|█▉        | 387/2000 [13:19<25:02,  1.07iteration/s, mean_rewards=-244]\u001b[A\n",
            "Training:  19%|█▉        | 387/2000 [13:19<25:02,  1.07iteration/s, mean_rewards=-304]\u001b[A\n",
            "Training:  19%|█▉        | 388/2000 [13:20<25:23,  1.06iteration/s, mean_rewards=-304]\u001b[A\n",
            "Training:  19%|█▉        | 388/2000 [13:20<25:23,  1.06iteration/s, mean_rewards=-104]\u001b[A\n",
            "Training:  19%|█▉        | 389/2000 [13:20<23:21,  1.15iteration/s, mean_rewards=-104]\u001b[A\n",
            "Training:  19%|█▉        | 389/2000 [13:21<23:21,  1.15iteration/s, mean_rewards=-193]\u001b[A\n",
            "Training:  20%|█▉        | 390/2000 [13:22<26:54,  1.00s/iteration, mean_rewards=-193]\u001b[A\n",
            "Training:  20%|█▉        | 390/2000 [13:22<26:54,  1.00s/iteration, mean_rewards=-83.4]\u001b[A\n",
            "Training:  20%|█▉        | 391/2000 [13:23<26:28,  1.01iteration/s, mean_rewards=-83.4]\u001b[A\n",
            "Training:  20%|█▉        | 391/2000 [13:23<26:28,  1.01iteration/s, mean_rewards=-224] \u001b[A\n",
            "Training:  20%|█▉        | 392/2000 [13:23<25:52,  1.04iteration/s, mean_rewards=-224]\u001b[A\n",
            "Training:  20%|█▉        | 392/2000 [13:24<25:52,  1.04iteration/s, mean_rewards=-196]\u001b[A\n",
            "Training:  20%|█▉        | 393/2000 [13:24<24:16,  1.10iteration/s, mean_rewards=-196]\u001b[A\n",
            "Training:  20%|█▉        | 393/2000 [13:25<24:16,  1.10iteration/s, mean_rewards=-210]\u001b[A\n",
            "Training:  20%|█▉        | 394/2000 [13:25<23:25,  1.14iteration/s, mean_rewards=-210]\u001b[A\n",
            "Training:  20%|█▉        | 394/2000 [13:25<23:25,  1.14iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:  20%|█▉        | 395/2000 [13:26<22:47,  1.17iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:  20%|█▉        | 395/2000 [13:26<22:47,  1.17iteration/s, mean_rewards=-203]\u001b[A\n",
            "Training:  20%|█▉        | 396/2000 [13:27<24:06,  1.11iteration/s, mean_rewards=-203]\u001b[A\n",
            "Training:  20%|█▉        | 396/2000 [13:27<24:06,  1.11iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  20%|█▉        | 397/2000 [13:28<28:04,  1.05s/iteration, mean_rewards=-135]\u001b[A\n",
            "Training:  20%|█▉        | 397/2000 [13:29<28:04,  1.05s/iteration, mean_rewards=-182]\u001b[A\n",
            "Training:  20%|█▉        | 398/2000 [13:29<27:07,  1.02s/iteration, mean_rewards=-182]\u001b[A\n",
            "Training:  20%|█▉        | 398/2000 [13:30<27:07,  1.02s/iteration, mean_rewards=-328]\u001b[A\n",
            "Training:  20%|█▉        | 399/2000 [13:30<27:35,  1.03s/iteration, mean_rewards=-328]\u001b[A\n",
            "Training:  20%|█▉        | 399/2000 [13:31<27:35,  1.03s/iteration, mean_rewards=-288]\u001b[A\n",
            "Training:  20%|██        | 400/2000 [13:31<25:49,  1.03iteration/s, mean_rewards=-288]\u001b[A\n",
            "Training:  20%|██        | 400/2000 [13:32<25:49,  1.03iteration/s, mean_rewards=-239]\u001b[A\n",
            "Training:  20%|██        | 401/2000 [13:32<26:37,  1.00iteration/s, mean_rewards=-239]\u001b[A\n",
            "Training:  20%|██        | 401/2000 [13:32<26:37,  1.00iteration/s, mean_rewards=-79.3]\u001b[A\n",
            "Training:  20%|██        | 402/2000 [13:33<23:58,  1.11iteration/s, mean_rewards=-79.3]\u001b[A\n",
            "Training:  20%|██        | 402/2000 [13:33<23:58,  1.11iteration/s, mean_rewards=-233] \u001b[A\n",
            "Training:  20%|██        | 403/2000 [13:34<23:17,  1.14iteration/s, mean_rewards=-233]\u001b[A\n",
            "Training:  20%|██        | 403/2000 [13:34<23:17,  1.14iteration/s, mean_rewards=-346]\u001b[A\n",
            "Training:  20%|██        | 404/2000 [13:35<23:02,  1.15iteration/s, mean_rewards=-346]\u001b[A\n",
            "Training:  20%|██        | 404/2000 [13:35<23:02,  1.15iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  20%|██        | 405/2000 [13:35<23:26,  1.13iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  20%|██        | 405/2000 [13:36<23:26,  1.13iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  20%|██        | 406/2000 [13:36<22:58,  1.16iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  20%|██        | 406/2000 [13:37<22:58,  1.16iteration/s, mean_rewards=-115]\u001b[A\n",
            "Training:  20%|██        | 407/2000 [13:37<23:11,  1.15iteration/s, mean_rewards=-115]\u001b[A\n",
            "Training:  20%|██        | 407/2000 [13:38<23:11,  1.15iteration/s, mean_rewards=-194]\u001b[A\n",
            "Training:  20%|██        | 408/2000 [13:38<23:24,  1.13iteration/s, mean_rewards=-194]\u001b[A\n",
            "Training:  20%|██        | 408/2000 [13:39<23:24,  1.13iteration/s, mean_rewards=-163]\u001b[A\n",
            "Training:  20%|██        | 409/2000 [13:39<27:45,  1.05s/iteration, mean_rewards=-163]\u001b[A\n",
            "Training:  20%|██        | 409/2000 [13:40<27:45,  1.05s/iteration, mean_rewards=-108]\u001b[A\n",
            "Training:  20%|██        | 410/2000 [13:41<28:29,  1.08s/iteration, mean_rewards=-108]\u001b[A\n",
            "Training:  20%|██        | 410/2000 [13:41<28:29,  1.08s/iteration, mean_rewards=-117]\u001b[A\n",
            "Training:  21%|██        | 411/2000 [13:42<27:46,  1.05s/iteration, mean_rewards=-117]\u001b[A\n",
            "Training:  21%|██        | 411/2000 [13:42<27:46,  1.05s/iteration, mean_rewards=-307]\u001b[A\n",
            "Training:  21%|██        | 412/2000 [13:43<28:13,  1.07s/iteration, mean_rewards=-307]\u001b[A\n",
            "Training:  21%|██        | 412/2000 [13:43<28:13,  1.07s/iteration, mean_rewards=-154]\u001b[A\n",
            "Training:  21%|██        | 413/2000 [13:43<25:19,  1.04iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  21%|██        | 413/2000 [13:44<25:19,  1.04iteration/s, mean_rewards=-249]\u001b[A\n",
            "Training:  21%|██        | 414/2000 [13:44<23:51,  1.11iteration/s, mean_rewards=-249]\u001b[A\n",
            "Training:  21%|██        | 414/2000 [13:44<23:51,  1.11iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  21%|██        | 415/2000 [13:45<23:03,  1.15iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  21%|██        | 415/2000 [13:45<23:03,  1.15iteration/s, mean_rewards=-191]\u001b[A\n",
            "Training:  21%|██        | 416/2000 [13:46<23:29,  1.12iteration/s, mean_rewards=-191]\u001b[A\n",
            "Training:  21%|██        | 416/2000 [13:46<23:29,  1.12iteration/s, mean_rewards=-195]\u001b[A\n",
            "Training:  21%|██        | 417/2000 [13:47<23:58,  1.10iteration/s, mean_rewards=-195]\u001b[A\n",
            "Training:  21%|██        | 417/2000 [13:47<23:58,  1.10iteration/s, mean_rewards=-313]\u001b[A\n",
            "Training:  21%|██        | 418/2000 [13:48<24:11,  1.09iteration/s, mean_rewards=-313]\u001b[A\n",
            "Training:  21%|██        | 418/2000 [13:48<24:11,  1.09iteration/s, mean_rewards=-164]\u001b[A\n",
            "Training:  21%|██        | 419/2000 [13:49<23:28,  1.12iteration/s, mean_rewards=-164]\u001b[A\n",
            "Training:  21%|██        | 419/2000 [13:49<23:28,  1.12iteration/s, mean_rewards=-106]\u001b[A\n",
            "Training:  21%|██        | 420/2000 [13:50<23:50,  1.10iteration/s, mean_rewards=-106]\u001b[A\n",
            "Training:  21%|██        | 420/2000 [13:50<23:50,  1.10iteration/s, mean_rewards=-313]\u001b[A\n",
            "Training:  21%|██        | 421/2000 [13:50<23:08,  1.14iteration/s, mean_rewards=-313]\u001b[A\n",
            "Training:  21%|██        | 421/2000 [13:51<23:08,  1.14iteration/s, mean_rewards=-166]\u001b[A\n",
            "Training:  21%|██        | 422/2000 [13:51<22:10,  1.19iteration/s, mean_rewards=-166]\u001b[A\n",
            "Training:  21%|██        | 422/2000 [13:51<22:10,  1.19iteration/s, mean_rewards=-159]\u001b[A\n",
            "Training:  21%|██        | 423/2000 [13:52<21:00,  1.25iteration/s, mean_rewards=-159]\u001b[A\n",
            "Training:  21%|██        | 423/2000 [13:52<21:00,  1.25iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  21%|██        | 424/2000 [13:53<23:17,  1.13iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  21%|██        | 424/2000 [13:54<23:17,  1.13iteration/s, mean_rewards=-185]\u001b[A\n",
            "Training:  21%|██▏       | 425/2000 [13:55<28:41,  1.09s/iteration, mean_rewards=-185]\u001b[A\n",
            "Training:  21%|██▏       | 425/2000 [13:55<28:41,  1.09s/iteration, mean_rewards=-236]\u001b[A\n",
            "Training:  21%|██▏       | 426/2000 [13:56<27:47,  1.06s/iteration, mean_rewards=-236]\u001b[A\n",
            "Training:  21%|██▏       | 426/2000 [13:56<27:47,  1.06s/iteration, mean_rewards=-283]\u001b[A\n",
            "Training:  21%|██▏       | 427/2000 [13:56<25:45,  1.02iteration/s, mean_rewards=-283]\u001b[A\n",
            "Training:  21%|██▏       | 427/2000 [13:57<25:45,  1.02iteration/s, mean_rewards=-274]\u001b[A\n",
            "Training:  21%|██▏       | 428/2000 [13:57<23:18,  1.12iteration/s, mean_rewards=-274]\u001b[A\n",
            "Training:  21%|██▏       | 428/2000 [13:57<23:18,  1.12iteration/s, mean_rewards=-238]\u001b[A\n",
            "Training:  21%|██▏       | 429/2000 [13:58<22:44,  1.15iteration/s, mean_rewards=-238]\u001b[A\n",
            "Training:  21%|██▏       | 429/2000 [13:58<22:44,  1.15iteration/s, mean_rewards=-208]\u001b[A\n",
            "Training:  22%|██▏       | 430/2000 [13:59<25:04,  1.04iteration/s, mean_rewards=-208]\u001b[A\n",
            "Training:  22%|██▏       | 430/2000 [13:59<25:04,  1.04iteration/s, mean_rewards=-63.6]\u001b[A\n",
            "Training:  22%|██▏       | 431/2000 [14:00<23:55,  1.09iteration/s, mean_rewards=-63.6]\u001b[A\n",
            "Training:  22%|██▏       | 431/2000 [14:00<23:55,  1.09iteration/s, mean_rewards=-448] \u001b[A\n",
            "Training:  22%|██▏       | 432/2000 [14:01<25:06,  1.04iteration/s, mean_rewards=-448]\u001b[A\n",
            "Training:  22%|██▏       | 432/2000 [14:01<25:06,  1.04iteration/s, mean_rewards=-174]\u001b[A\n",
            "Training:  22%|██▏       | 433/2000 [14:02<25:03,  1.04iteration/s, mean_rewards=-174]\u001b[A\n",
            "Training:  22%|██▏       | 433/2000 [14:02<25:03,  1.04iteration/s, mean_rewards=-15.2]\u001b[A\n",
            "Training:  22%|██▏       | 434/2000 [14:03<23:32,  1.11iteration/s, mean_rewards=-15.2]\u001b[A\n",
            "Training:  22%|██▏       | 434/2000 [14:03<23:32,  1.11iteration/s, mean_rewards=-171] \u001b[A\n",
            "Training:  22%|██▏       | 435/2000 [14:03<21:33,  1.21iteration/s, mean_rewards=-171]\u001b[A\n",
            "Training:  22%|██▏       | 435/2000 [14:04<21:33,  1.21iteration/s, mean_rewards=-193]\u001b[A\n",
            "Training:  22%|██▏       | 436/2000 [14:04<21:09,  1.23iteration/s, mean_rewards=-193]\u001b[A\n",
            "Training:  22%|██▏       | 436/2000 [14:04<21:09,  1.23iteration/s, mean_rewards=-89.7]\u001b[A\n",
            "Training:  22%|██▏       | 437/2000 [14:05<21:02,  1.24iteration/s, mean_rewards=-89.7]\u001b[A\n",
            "Training:  22%|██▏       | 437/2000 [14:05<21:02,  1.24iteration/s, mean_rewards=-292] \u001b[A\n",
            "Training:  22%|██▏       | 438/2000 [14:06<25:12,  1.03iteration/s, mean_rewards=-292]\u001b[A\n",
            "Training:  22%|██▏       | 438/2000 [14:07<25:12,  1.03iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  22%|██▏       | 439/2000 [14:08<31:12,  1.20s/iteration, mean_rewards=-146]\u001b[A\n",
            "Training:  22%|██▏       | 439/2000 [14:08<31:12,  1.20s/iteration, mean_rewards=-230]\u001b[A\n",
            "Training:  22%|██▏       | 440/2000 [14:09<29:24,  1.13s/iteration, mean_rewards=-230]\u001b[A\n",
            "Training:  22%|██▏       | 440/2000 [14:09<29:24,  1.13s/iteration, mean_rewards=-232]\u001b[A\n",
            "Training:  22%|██▏       | 441/2000 [14:10<28:03,  1.08s/iteration, mean_rewards=-232]\u001b[A\n",
            "Training:  22%|██▏       | 441/2000 [14:10<28:03,  1.08s/iteration, mean_rewards=-68.6]\u001b[A\n",
            "Training:  22%|██▏       | 442/2000 [14:11<25:38,  1.01iteration/s, mean_rewards=-68.6]\u001b[A\n",
            "Training:  22%|██▏       | 442/2000 [14:11<25:38,  1.01iteration/s, mean_rewards=-269] \u001b[A\n",
            "Training:  22%|██▏       | 443/2000 [14:11<24:19,  1.07iteration/s, mean_rewards=-269]\u001b[A\n",
            "Training:  22%|██▏       | 443/2000 [14:12<24:19,  1.07iteration/s, mean_rewards=-190]\u001b[A\n",
            "Training:  22%|██▏       | 444/2000 [14:12<24:10,  1.07iteration/s, mean_rewards=-190]\u001b[A\n",
            "Training:  22%|██▏       | 444/2000 [14:13<24:10,  1.07iteration/s, mean_rewards=-182]\u001b[A\n",
            "Training:  22%|██▏       | 445/2000 [14:13<23:17,  1.11iteration/s, mean_rewards=-182]\u001b[A\n",
            "Training:  22%|██▏       | 445/2000 [14:13<23:17,  1.11iteration/s, mean_rewards=-180]\u001b[A\n",
            "Training:  22%|██▏       | 446/2000 [14:14<21:37,  1.20iteration/s, mean_rewards=-180]\u001b[A\n",
            "Training:  22%|██▏       | 446/2000 [14:14<21:37,  1.20iteration/s, mean_rewards=-219]\u001b[A\n",
            "Training:  22%|██▏       | 447/2000 [14:15<23:28,  1.10iteration/s, mean_rewards=-219]\u001b[A\n",
            "Training:  22%|██▏       | 447/2000 [14:15<23:28,  1.10iteration/s, mean_rewards=-371]\u001b[A\n",
            "Training:  22%|██▏       | 448/2000 [14:16<23:54,  1.08iteration/s, mean_rewards=-371]\u001b[A\n",
            "Training:  22%|██▏       | 448/2000 [14:16<23:54,  1.08iteration/s, mean_rewards=-152]\u001b[A\n",
            "Training:  22%|██▏       | 449/2000 [14:17<21:55,  1.18iteration/s, mean_rewards=-152]\u001b[A\n",
            "Training:  22%|██▏       | 449/2000 [14:17<21:55,  1.18iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  22%|██▎       | 450/2000 [14:18<23:44,  1.09iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  22%|██▎       | 450/2000 [14:18<23:44,  1.09iteration/s, mean_rewards=-268]\u001b[A\n",
            "Training:  23%|██▎       | 451/2000 [14:18<22:42,  1.14iteration/s, mean_rewards=-268]\u001b[A\n",
            "Training:  23%|██▎       | 451/2000 [14:19<22:42,  1.14iteration/s, mean_rewards=-112]\u001b[A\n",
            "Training:  23%|██▎       | 452/2000 [14:20<25:40,  1.01iteration/s, mean_rewards=-112]\u001b[A\n",
            "Training:  23%|██▎       | 452/2000 [14:20<25:40,  1.01iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  23%|██▎       | 453/2000 [14:21<26:36,  1.03s/iteration, mean_rewards=-125]\u001b[A\n",
            "Training:  23%|██▎       | 453/2000 [14:21<26:36,  1.03s/iteration, mean_rewards=-152]\u001b[A\n",
            "Training:  23%|██▎       | 454/2000 [14:22<25:48,  1.00s/iteration, mean_rewards=-152]\u001b[A\n",
            "Training:  23%|██▎       | 454/2000 [14:22<25:48,  1.00s/iteration, mean_rewards=-365]\u001b[A\n",
            "Training:  23%|██▎       | 455/2000 [14:23<24:09,  1.07iteration/s, mean_rewards=-365]\u001b[A\n",
            "Training:  23%|██▎       | 455/2000 [14:23<24:09,  1.07iteration/s, mean_rewards=-101]\u001b[A\n",
            "Training:  23%|██▎       | 456/2000 [14:23<24:23,  1.06iteration/s, mean_rewards=-101]\u001b[A\n",
            "Training:  23%|██▎       | 456/2000 [14:24<24:23,  1.06iteration/s, mean_rewards=-364]\u001b[A\n",
            "Training:  23%|██▎       | 457/2000 [14:24<24:13,  1.06iteration/s, mean_rewards=-364]\u001b[A\n",
            "Training:  23%|██▎       | 457/2000 [14:25<24:13,  1.06iteration/s, mean_rewards=-200]\u001b[A\n",
            "Training:  23%|██▎       | 458/2000 [14:25<22:52,  1.12iteration/s, mean_rewards=-200]\u001b[A\n",
            "Training:  23%|██▎       | 458/2000 [14:26<22:52,  1.12iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  23%|██▎       | 459/2000 [14:26<23:16,  1.10iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  23%|██▎       | 459/2000 [14:26<23:16,  1.10iteration/s, mean_rewards=-222]\u001b[A\n",
            "Training:  23%|██▎       | 460/2000 [14:27<22:25,  1.14iteration/s, mean_rewards=-222]\u001b[A\n",
            "Training:  23%|██▎       | 460/2000 [14:27<22:25,  1.14iteration/s, mean_rewards=-284]\u001b[A\n",
            "Training:  23%|██▎       | 461/2000 [14:28<23:06,  1.11iteration/s, mean_rewards=-284]\u001b[A\n",
            "Training:  23%|██▎       | 461/2000 [14:28<23:06,  1.11iteration/s, mean_rewards=-193]\u001b[A\n",
            "Training:  23%|██▎       | 462/2000 [14:29<23:09,  1.11iteration/s, mean_rewards=-193]\u001b[A\n",
            "Training:  23%|██▎       | 462/2000 [14:29<23:09,  1.11iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  23%|██▎       | 463/2000 [14:29<21:10,  1.21iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  23%|██▎       | 463/2000 [14:30<21:10,  1.21iteration/s, mean_rewards=-235]\u001b[A\n",
            "Training:  23%|██▎       | 464/2000 [14:30<22:03,  1.16iteration/s, mean_rewards=-235]\u001b[A\n",
            "Training:  23%|██▎       | 464/2000 [14:31<22:03,  1.16iteration/s, mean_rewards=-91.8]\u001b[A\n",
            "Training:  23%|██▎       | 465/2000 [14:32<24:37,  1.04iteration/s, mean_rewards=-91.8]\u001b[A\n",
            "Training:  23%|██▎       | 465/2000 [14:32<24:37,  1.04iteration/s, mean_rewards=-96.5]\u001b[A\n",
            "Training:  23%|██▎       | 466/2000 [14:33<26:57,  1.05s/iteration, mean_rewards=-96.5]\u001b[A\n",
            "Training:  23%|██▎       | 466/2000 [14:33<26:57,  1.05s/iteration, mean_rewards=-176] \u001b[A\n",
            "Training:  23%|██▎       | 467/2000 [14:34<26:33,  1.04s/iteration, mean_rewards=-176]\u001b[A\n",
            "Training:  23%|██▎       | 467/2000 [14:34<26:33,  1.04s/iteration, mean_rewards=-187]\u001b[A\n",
            "Training:  23%|██▎       | 468/2000 [14:35<25:37,  1.00s/iteration, mean_rewards=-187]\u001b[A\n",
            "Training:  23%|██▎       | 468/2000 [14:35<25:37,  1.00s/iteration, mean_rewards=-138]\u001b[A\n",
            "Training:  23%|██▎       | 469/2000 [14:36<25:00,  1.02iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:  23%|██▎       | 469/2000 [14:36<25:00,  1.02iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  24%|██▎       | 470/2000 [14:37<24:25,  1.04iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  24%|██▎       | 470/2000 [14:37<24:25,  1.04iteration/s, mean_rewards=-288]\u001b[A\n",
            "Training:  24%|██▎       | 471/2000 [14:38<24:02,  1.06iteration/s, mean_rewards=-288]\u001b[A\n",
            "Training:  24%|██▎       | 471/2000 [14:38<24:02,  1.06iteration/s, mean_rewards=-178]\u001b[A\n",
            "Training:  24%|██▎       | 472/2000 [14:38<21:48,  1.17iteration/s, mean_rewards=-178]\u001b[A\n",
            "Training:  24%|██▎       | 472/2000 [14:38<21:48,  1.17iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  24%|██▎       | 473/2000 [14:39<20:19,  1.25iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  24%|██▎       | 473/2000 [14:39<20:19,  1.25iteration/s, mean_rewards=-237]\u001b[A\n",
            "Training:  24%|██▎       | 474/2000 [14:40<20:15,  1.26iteration/s, mean_rewards=-237]\u001b[A\n",
            "Training:  24%|██▎       | 474/2000 [14:40<20:15,  1.26iteration/s, mean_rewards=-233]\u001b[A\n",
            "Training:  24%|██▍       | 475/2000 [14:40<20:19,  1.25iteration/s, mean_rewards=-233]\u001b[A\n",
            "Training:  24%|██▍       | 475/2000 [14:41<20:19,  1.25iteration/s, mean_rewards=-164]\u001b[A\n",
            "Training:  24%|██▍       | 476/2000 [14:41<19:03,  1.33iteration/s, mean_rewards=-164]\u001b[A\n",
            "Training:  24%|██▍       | 476/2000 [14:41<19:03,  1.33iteration/s, mean_rewards=-85.8]\u001b[A\n",
            "Training:  24%|██▍       | 477/2000 [14:42<20:06,  1.26iteration/s, mean_rewards=-85.8]\u001b[A\n",
            "Training:  24%|██▍       | 477/2000 [14:42<20:06,  1.26iteration/s, mean_rewards=-292] \u001b[A\n",
            "Training:  24%|██▍       | 478/2000 [14:43<21:15,  1.19iteration/s, mean_rewards=-292]\u001b[A\n",
            "Training:  24%|██▍       | 478/2000 [14:43<21:15,  1.19iteration/s, mean_rewards=-289]\u001b[A\n",
            "Training:  24%|██▍       | 479/2000 [14:44<21:46,  1.16iteration/s, mean_rewards=-289]\u001b[A\n",
            "Training:  24%|██▍       | 479/2000 [14:44<21:46,  1.16iteration/s, mean_rewards=-167]\u001b[A\n",
            "Training:  24%|██▍       | 480/2000 [14:45<24:23,  1.04iteration/s, mean_rewards=-167]\u001b[A\n",
            "Training:  24%|██▍       | 480/2000 [14:45<24:23,  1.04iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:  24%|██▍       | 481/2000 [14:46<26:07,  1.03s/iteration, mean_rewards=-145]\u001b[A\n",
            "Training:  24%|██▍       | 481/2000 [14:47<26:07,  1.03s/iteration, mean_rewards=-152]\u001b[A\n",
            "Training:  24%|██▍       | 482/2000 [14:47<25:37,  1.01s/iteration, mean_rewards=-152]\u001b[A\n",
            "Training:  24%|██▍       | 482/2000 [14:48<25:37,  1.01s/iteration, mean_rewards=-127]\u001b[A\n",
            "Training:  24%|██▍       | 483/2000 [14:48<24:07,  1.05iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  24%|██▍       | 483/2000 [14:48<24:07,  1.05iteration/s, mean_rewards=-160]\u001b[A\n",
            "Training:  24%|██▍       | 484/2000 [14:49<22:40,  1.11iteration/s, mean_rewards=-160]\u001b[A\n",
            "Training:  24%|██▍       | 484/2000 [14:49<22:40,  1.11iteration/s, mean_rewards=-194]\u001b[A\n",
            "Training:  24%|██▍       | 485/2000 [14:50<23:37,  1.07iteration/s, mean_rewards=-194]\u001b[A\n",
            "Training:  24%|██▍       | 485/2000 [14:50<23:37,  1.07iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  24%|██▍       | 486/2000 [14:50<21:28,  1.17iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  24%|██▍       | 486/2000 [14:51<21:28,  1.17iteration/s, mean_rewards=-229]\u001b[A\n",
            "Training:  24%|██▍       | 487/2000 [14:52<23:12,  1.09iteration/s, mean_rewards=-229]\u001b[A\n",
            "Training:  24%|██▍       | 487/2000 [14:52<23:12,  1.09iteration/s, mean_rewards=-209]\u001b[A\n",
            "Training:  24%|██▍       | 488/2000 [14:52<22:10,  1.14iteration/s, mean_rewards=-209]\u001b[A\n",
            "Training:  24%|██▍       | 488/2000 [14:53<22:10,  1.14iteration/s, mean_rewards=-206]\u001b[A\n",
            "Training:  24%|██▍       | 489/2000 [14:53<22:27,  1.12iteration/s, mean_rewards=-206]\u001b[A\n",
            "Training:  24%|██▍       | 489/2000 [14:54<22:27,  1.12iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  24%|██▍       | 490/2000 [14:54<21:45,  1.16iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  24%|██▍       | 490/2000 [14:54<21:45,  1.16iteration/s, mean_rewards=-311]\u001b[A\n",
            "Training:  25%|██▍       | 491/2000 [14:55<21:23,  1.18iteration/s, mean_rewards=-311]\u001b[A\n",
            "Training:  25%|██▍       | 491/2000 [14:55<21:23,  1.18iteration/s, mean_rewards=-97.5]\u001b[A\n",
            "Training:  25%|██▍       | 492/2000 [14:56<20:15,  1.24iteration/s, mean_rewards=-97.5]\u001b[A\n",
            "Training:  25%|██▍       | 492/2000 [14:56<20:15,  1.24iteration/s, mean_rewards=-265] \u001b[A\n",
            "Training:  25%|██▍       | 493/2000 [14:56<20:14,  1.24iteration/s, mean_rewards=-265]\u001b[A\n",
            "Training:  25%|██▍       | 493/2000 [14:57<20:14,  1.24iteration/s, mean_rewards=-209]\u001b[A\n",
            "Training:  25%|██▍       | 494/2000 [14:57<22:36,  1.11iteration/s, mean_rewards=-209]\u001b[A\n",
            "Training:  25%|██▍       | 494/2000 [14:58<22:36,  1.11iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  25%|██▍       | 495/2000 [14:59<25:00,  1.00iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  25%|██▍       | 495/2000 [14:59<25:00,  1.00iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:  25%|██▍       | 496/2000 [15:00<24:52,  1.01iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:  25%|██▍       | 496/2000 [15:00<24:52,  1.01iteration/s, mean_rewards=-170]\u001b[A\n",
            "Training:  25%|██▍       | 497/2000 [15:01<24:35,  1.02iteration/s, mean_rewards=-170]\u001b[A\n",
            "Training:  25%|██▍       | 497/2000 [15:01<24:35,  1.02iteration/s, mean_rewards=-95.1]\u001b[A\n",
            "Training:  25%|██▍       | 498/2000 [15:01<21:55,  1.14iteration/s, mean_rewards=-95.1]\u001b[A\n",
            "Training:  25%|██▍       | 498/2000 [15:02<21:55,  1.14iteration/s, mean_rewards=-285] \u001b[A\n",
            "Training:  25%|██▍       | 499/2000 [15:02<22:18,  1.12iteration/s, mean_rewards=-285]\u001b[A\n",
            "Training:  25%|██▍       | 499/2000 [15:03<22:18,  1.12iteration/s, mean_rewards=-297]\u001b[A\n",
            "Training:  25%|██▌       | 500/2000 [15:03<23:16,  1.07iteration/s, mean_rewards=-297]\u001b[A\n",
            "Training:  25%|██▌       | 500/2000 [15:04<23:16,  1.07iteration/s, mean_rewards=-171]\u001b[A\n",
            "Training:  25%|██▌       | 501/2000 [15:04<23:14,  1.08iteration/s, mean_rewards=-171]\u001b[A\n",
            "Training:  25%|██▌       | 501/2000 [15:04<23:14,  1.08iteration/s, mean_rewards=-100]\u001b[A\n",
            "Training:  25%|██▌       | 502/2000 [15:05<22:02,  1.13iteration/s, mean_rewards=-100]\u001b[A\n",
            "Training:  25%|██▌       | 502/2000 [15:05<22:02,  1.13iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  25%|██▌       | 503/2000 [15:06<23:25,  1.06iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  25%|██▌       | 503/2000 [15:06<23:25,  1.06iteration/s, mean_rewards=-244]\u001b[A\n",
            "Training:  25%|██▌       | 504/2000 [15:07<23:13,  1.07iteration/s, mean_rewards=-244]\u001b[A\n",
            "Training:  25%|██▌       | 504/2000 [15:07<23:13,  1.07iteration/s, mean_rewards=-189]\u001b[A\n",
            "Training:  25%|██▌       | 505/2000 [15:08<23:17,  1.07iteration/s, mean_rewards=-189]\u001b[A\n",
            "Training:  25%|██▌       | 505/2000 [15:08<23:17,  1.07iteration/s, mean_rewards=-198]\u001b[A\n",
            "Training:  25%|██▌       | 506/2000 [15:09<22:05,  1.13iteration/s, mean_rewards=-198]\u001b[A\n",
            "Training:  25%|██▌       | 506/2000 [15:09<22:05,  1.13iteration/s, mean_rewards=-294]\u001b[A\n",
            "Training:  25%|██▌       | 507/2000 [15:10<24:21,  1.02iteration/s, mean_rewards=-294]\u001b[A\n",
            "Training:  25%|██▌       | 507/2000 [15:10<24:21,  1.02iteration/s, mean_rewards=-191]\u001b[A\n",
            "Training:  25%|██▌       | 508/2000 [15:11<26:09,  1.05s/iteration, mean_rewards=-191]\u001b[A\n",
            "Training:  25%|██▌       | 508/2000 [15:11<26:09,  1.05s/iteration, mean_rewards=-167]\u001b[A\n",
            "Training:  25%|██▌       | 509/2000 [15:12<26:28,  1.07s/iteration, mean_rewards=-167]\u001b[A\n",
            "Training:  25%|██▌       | 509/2000 [15:13<26:28,  1.07s/iteration, mean_rewards=-126]\u001b[A\n",
            "Training:  26%|██▌       | 510/2000 [15:13<26:07,  1.05s/iteration, mean_rewards=-126]\u001b[A\n",
            "Training:  26%|██▌       | 510/2000 [15:13<26:07,  1.05s/iteration, mean_rewards=-87.4]\u001b[A\n",
            "Training:  26%|██▌       | 511/2000 [15:14<24:01,  1.03iteration/s, mean_rewards=-87.4]\u001b[A\n",
            "Training:  26%|██▌       | 511/2000 [15:14<24:01,  1.03iteration/s, mean_rewards=-141] \u001b[A\n",
            "Training:  26%|██▌       | 512/2000 [15:15<22:27,  1.10iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  26%|██▌       | 512/2000 [15:15<22:27,  1.10iteration/s, mean_rewards=-356]\u001b[A\n",
            "Training:  26%|██▌       | 513/2000 [15:16<24:01,  1.03iteration/s, mean_rewards=-356]\u001b[A\n",
            "Training:  26%|██▌       | 513/2000 [15:16<24:01,  1.03iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  26%|██▌       | 514/2000 [15:17<23:46,  1.04iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  26%|██▌       | 514/2000 [15:17<23:46,  1.04iteration/s, mean_rewards=-252]\u001b[A\n",
            "Training:  26%|██▌       | 515/2000 [15:18<25:29,  1.03s/iteration, mean_rewards=-252]\u001b[A\n",
            "Training:  26%|██▌       | 515/2000 [15:18<25:29,  1.03s/iteration, mean_rewards=-161]\u001b[A\n",
            "Training:  26%|██▌       | 516/2000 [15:19<23:45,  1.04iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:  26%|██▌       | 516/2000 [15:19<23:45,  1.04iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  26%|██▌       | 517/2000 [15:20<22:42,  1.09iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  26%|██▌       | 517/2000 [15:20<22:42,  1.09iteration/s, mean_rewards=-160]\u001b[A\n",
            "Training:  26%|██▌       | 518/2000 [15:20<22:50,  1.08iteration/s, mean_rewards=-160]\u001b[A\n",
            "Training:  26%|██▌       | 518/2000 [15:21<22:50,  1.08iteration/s, mean_rewards=-224]\u001b[A\n",
            "Training:  26%|██▌       | 519/2000 [15:21<21:56,  1.12iteration/s, mean_rewards=-224]\u001b[A\n",
            "Training:  26%|██▌       | 519/2000 [15:22<21:56,  1.12iteration/s, mean_rewards=-181]\u001b[A\n",
            "Training:  26%|██▌       | 520/2000 [15:22<21:58,  1.12iteration/s, mean_rewards=-181]\u001b[A\n",
            "Training:  26%|██▌       | 520/2000 [15:23<21:58,  1.12iteration/s, mean_rewards=-64.1]\u001b[A\n",
            "Training:  26%|██▌       | 521/2000 [15:23<23:51,  1.03iteration/s, mean_rewards=-64.1]\u001b[A\n",
            "Training:  26%|██▌       | 521/2000 [15:24<23:51,  1.03iteration/s, mean_rewards=-192] \u001b[A\n",
            "Training:  26%|██▌       | 522/2000 [15:24<24:57,  1.01s/iteration, mean_rewards=-192]\u001b[A\n",
            "Training:  26%|██▌       | 522/2000 [15:25<24:57,  1.01s/iteration, mean_rewards=-166]\u001b[A\n",
            "Training:  26%|██▌       | 523/2000 [15:26<26:56,  1.09s/iteration, mean_rewards=-166]\u001b[A\n",
            "Training:  26%|██▌       | 523/2000 [15:26<26:56,  1.09s/iteration, mean_rewards=-37.1]\u001b[A\n",
            "Training:  26%|██▌       | 524/2000 [15:26<23:39,  1.04iteration/s, mean_rewards=-37.1]\u001b[A\n",
            "Training:  26%|██▌       | 524/2000 [15:27<23:39,  1.04iteration/s, mean_rewards=-152] \u001b[A\n",
            "Training:  26%|██▋       | 525/2000 [15:27<24:31,  1.00iteration/s, mean_rewards=-152]\u001b[A\n",
            "Training:  26%|██▋       | 525/2000 [15:28<24:31,  1.00iteration/s, mean_rewards=-263]\u001b[A\n",
            "Training:  26%|██▋       | 526/2000 [15:28<22:13,  1.11iteration/s, mean_rewards=-263]\u001b[A\n",
            "Training:  26%|██▋       | 526/2000 [15:29<22:13,  1.11iteration/s, mean_rewards=-236]\u001b[A\n",
            "Training:  26%|██▋       | 527/2000 [15:29<21:47,  1.13iteration/s, mean_rewards=-236]\u001b[A\n",
            "Training:  26%|██▋       | 527/2000 [15:29<21:47,  1.13iteration/s, mean_rewards=-192]\u001b[A\n",
            "Training:  26%|██▋       | 528/2000 [15:30<22:13,  1.10iteration/s, mean_rewards=-192]\u001b[A\n",
            "Training:  26%|██▋       | 528/2000 [15:30<22:13,  1.10iteration/s, mean_rewards=-421]\u001b[A\n",
            "Training:  26%|██▋       | 529/2000 [15:31<23:26,  1.05iteration/s, mean_rewards=-421]\u001b[A\n",
            "Training:  26%|██▋       | 529/2000 [15:31<23:26,  1.05iteration/s, mean_rewards=-233]\u001b[A\n",
            "Training:  26%|██▋       | 530/2000 [15:32<22:10,  1.10iteration/s, mean_rewards=-233]\u001b[A\n",
            "Training:  26%|██▋       | 530/2000 [15:32<22:10,  1.10iteration/s, mean_rewards=-322]\u001b[A\n",
            "Training:  27%|██▋       | 531/2000 [15:33<23:17,  1.05iteration/s, mean_rewards=-322]\u001b[A\n",
            "Training:  27%|██▋       | 531/2000 [15:33<23:17,  1.05iteration/s, mean_rewards=-176]\u001b[A\n",
            "Training:  27%|██▋       | 532/2000 [15:34<21:08,  1.16iteration/s, mean_rewards=-176]\u001b[A\n",
            "Training:  27%|██▋       | 532/2000 [15:34<21:08,  1.16iteration/s, mean_rewards=-208]\u001b[A\n",
            "Training:  27%|██▋       | 533/2000 [15:35<22:29,  1.09iteration/s, mean_rewards=-208]\u001b[A\n",
            "Training:  27%|██▋       | 533/2000 [15:35<22:29,  1.09iteration/s, mean_rewards=-202]\u001b[A\n",
            "Training:  27%|██▋       | 534/2000 [15:36<23:35,  1.04iteration/s, mean_rewards=-202]\u001b[A\n",
            "Training:  27%|██▋       | 534/2000 [15:36<23:35,  1.04iteration/s, mean_rewards=-276]\u001b[A\n",
            "Training:  27%|██▋       | 535/2000 [15:37<24:05,  1.01iteration/s, mean_rewards=-276]\u001b[A\n",
            "Training:  27%|██▋       | 535/2000 [15:37<24:05,  1.01iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  27%|██▋       | 536/2000 [15:38<26:40,  1.09s/iteration, mean_rewards=-124]\u001b[A\n",
            "Training:  27%|██▋       | 536/2000 [15:38<26:40,  1.09s/iteration, mean_rewards=-131]\u001b[A\n",
            "Training:  27%|██▋       | 537/2000 [15:39<24:37,  1.01s/iteration, mean_rewards=-131]\u001b[A\n",
            "Training:  27%|██▋       | 537/2000 [15:39<24:37,  1.01s/iteration, mean_rewards=-211]\u001b[A\n",
            "Training:  27%|██▋       | 538/2000 [15:40<21:58,  1.11iteration/s, mean_rewards=-211]\u001b[A\n",
            "Training:  27%|██▋       | 538/2000 [15:40<21:58,  1.11iteration/s, mean_rewards=-240]\u001b[A\n",
            "Training:  27%|██▋       | 539/2000 [15:40<21:13,  1.15iteration/s, mean_rewards=-240]\u001b[A\n",
            "Training:  27%|██▋       | 539/2000 [15:41<21:13,  1.15iteration/s, mean_rewards=-266]\u001b[A\n",
            "Training:  27%|██▋       | 540/2000 [15:41<21:43,  1.12iteration/s, mean_rewards=-266]\u001b[A\n",
            "Training:  27%|██▋       | 540/2000 [15:42<21:43,  1.12iteration/s, mean_rewards=-165]\u001b[A\n",
            "Training:  27%|██▋       | 541/2000 [15:42<20:54,  1.16iteration/s, mean_rewards=-165]\u001b[A\n",
            "Training:  27%|██▋       | 541/2000 [15:42<20:54,  1.16iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:  27%|██▋       | 542/2000 [15:43<21:21,  1.14iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:  27%|██▋       | 542/2000 [15:43<21:21,  1.14iteration/s, mean_rewards=-305]\u001b[A\n",
            "Training:  27%|██▋       | 543/2000 [15:44<21:10,  1.15iteration/s, mean_rewards=-305]\u001b[A\n",
            "Training:  27%|██▋       | 543/2000 [15:44<21:10,  1.15iteration/s, mean_rewards=-271]\u001b[A\n",
            "Training:  27%|██▋       | 544/2000 [15:45<21:55,  1.11iteration/s, mean_rewards=-271]\u001b[A\n",
            "Training:  27%|██▋       | 544/2000 [15:45<21:55,  1.11iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  27%|██▋       | 545/2000 [15:45<20:20,  1.19iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  27%|██▋       | 545/2000 [15:46<20:20,  1.19iteration/s, mean_rewards=-214]\u001b[A\n",
            "Training:  27%|██▋       | 546/2000 [15:47<21:56,  1.10iteration/s, mean_rewards=-214]\u001b[A\n",
            "Training:  27%|██▋       | 546/2000 [15:47<21:56,  1.10iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  27%|██▋       | 547/2000 [15:47<21:07,  1.15iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  27%|██▋       | 547/2000 [15:48<21:07,  1.15iteration/s, mean_rewards=-293]\u001b[A\n",
            "Training:  27%|██▋       | 548/2000 [15:48<20:33,  1.18iteration/s, mean_rewards=-293]\u001b[A\n",
            "Training:  27%|██▋       | 548/2000 [15:49<20:33,  1.18iteration/s, mean_rewards=-175]\u001b[A\n",
            "Training:  27%|██▋       | 549/2000 [15:49<23:18,  1.04iteration/s, mean_rewards=-175]\u001b[A\n",
            "Training:  27%|██▋       | 549/2000 [15:50<23:18,  1.04iteration/s, mean_rewards=-239]\u001b[A\n",
            "Training:  28%|██▊       | 550/2000 [15:50<24:27,  1.01s/iteration, mean_rewards=-239]\u001b[A\n",
            "Training:  28%|██▊       | 550/2000 [15:51<24:27,  1.01s/iteration, mean_rewards=-263]\u001b[A\n",
            "Training:  28%|██▊       | 551/2000 [15:52<25:00,  1.04s/iteration, mean_rewards=-263]\u001b[A\n",
            "Training:  28%|██▊       | 551/2000 [15:52<25:00,  1.04s/iteration, mean_rewards=-246]\u001b[A\n",
            "Training:  28%|██▊       | 552/2000 [15:53<24:32,  1.02s/iteration, mean_rewards=-246]\u001b[A\n",
            "Training:  28%|██▊       | 552/2000 [15:53<24:32,  1.02s/iteration, mean_rewards=-295]\u001b[A\n",
            "Training:  28%|██▊       | 553/2000 [15:54<25:12,  1.05s/iteration, mean_rewards=-295]\u001b[A\n",
            "Training:  28%|██▊       | 553/2000 [15:54<25:12,  1.05s/iteration, mean_rewards=-261]\u001b[A\n",
            "Training:  28%|██▊       | 554/2000 [15:55<23:47,  1.01iteration/s, mean_rewards=-261]\u001b[A\n",
            "Training:  28%|██▊       | 554/2000 [15:55<23:47,  1.01iteration/s, mean_rewards=-242]\u001b[A\n",
            "Training:  28%|██▊       | 555/2000 [15:55<22:38,  1.06iteration/s, mean_rewards=-242]\u001b[A\n",
            "Training:  28%|██▊       | 555/2000 [15:56<22:38,  1.06iteration/s, mean_rewards=-208]\u001b[A\n",
            "Training:  28%|██▊       | 556/2000 [15:56<21:36,  1.11iteration/s, mean_rewards=-208]\u001b[A\n",
            "Training:  28%|██▊       | 556/2000 [15:56<21:36,  1.11iteration/s, mean_rewards=-213]\u001b[A\n",
            "Training:  28%|██▊       | 557/2000 [15:57<20:52,  1.15iteration/s, mean_rewards=-213]\u001b[A\n",
            "Training:  28%|██▊       | 557/2000 [15:57<20:52,  1.15iteration/s, mean_rewards=-187]\u001b[A\n",
            "Training:  28%|██▊       | 558/2000 [15:58<21:29,  1.12iteration/s, mean_rewards=-187]\u001b[A\n",
            "Training:  28%|██▊       | 558/2000 [15:58<21:29,  1.12iteration/s, mean_rewards=-398]\u001b[A\n",
            "Training:  28%|██▊       | 559/2000 [15:59<22:38,  1.06iteration/s, mean_rewards=-398]\u001b[A\n",
            "Training:  28%|██▊       | 559/2000 [15:59<22:38,  1.06iteration/s, mean_rewards=-47.7]\u001b[A\n",
            "Training:  28%|██▊       | 560/2000 [16:00<22:38,  1.06iteration/s, mean_rewards=-47.7]\u001b[A\n",
            "Training:  28%|██▊       | 560/2000 [16:00<22:38,  1.06iteration/s, mean_rewards=-244] \u001b[A\n",
            "Training:  28%|██▊       | 561/2000 [16:01<21:32,  1.11iteration/s, mean_rewards=-244]\u001b[A\n",
            "Training:  28%|██▊       | 561/2000 [16:01<21:32,  1.11iteration/s, mean_rewards=-67] \u001b[A\n",
            "Training:  28%|██▊       | 562/2000 [16:01<19:43,  1.22iteration/s, mean_rewards=-67]\u001b[A\n",
            "Training:  28%|██▊       | 562/2000 [16:02<19:43,  1.22iteration/s, mean_rewards=-260]\u001b[A\n",
            "Training:  28%|██▊       | 563/2000 [16:03<22:09,  1.08iteration/s, mean_rewards=-260]\u001b[A\n",
            "Training:  28%|██▊       | 563/2000 [16:03<22:09,  1.08iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:  28%|██▊       | 564/2000 [16:04<23:19,  1.03iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:  28%|██▊       | 564/2000 [16:04<23:19,  1.03iteration/s, mean_rewards=-374]\u001b[A\n",
            "Training:  28%|██▊       | 565/2000 [16:05<26:31,  1.11s/iteration, mean_rewards=-374]\u001b[A\n",
            "Training:  28%|██▊       | 565/2000 [16:05<26:31,  1.11s/iteration, mean_rewards=-254]\u001b[A\n",
            "Training:  28%|██▊       | 566/2000 [16:06<25:18,  1.06s/iteration, mean_rewards=-254]\u001b[A\n",
            "Training:  28%|██▊       | 566/2000 [16:06<25:18,  1.06s/iteration, mean_rewards=-209]\u001b[A\n",
            "Training:  28%|██▊       | 567/2000 [16:07<24:09,  1.01s/iteration, mean_rewards=-209]\u001b[A\n",
            "Training:  28%|██▊       | 567/2000 [16:07<24:09,  1.01s/iteration, mean_rewards=-234]\u001b[A\n",
            "Training:  28%|██▊       | 568/2000 [16:08<22:37,  1.05iteration/s, mean_rewards=-234]\u001b[A\n",
            "Training:  28%|██▊       | 568/2000 [16:08<22:37,  1.05iteration/s, mean_rewards=-245]\u001b[A\n",
            "Training:  28%|██▊       | 569/2000 [16:08<21:45,  1.10iteration/s, mean_rewards=-245]\u001b[A\n",
            "Training:  28%|██▊       | 569/2000 [16:09<21:45,  1.10iteration/s, mean_rewards=-28] \u001b[A\n",
            "Training:  28%|██▊       | 570/2000 [16:09<20:02,  1.19iteration/s, mean_rewards=-28]\u001b[A\n",
            "Training:  28%|██▊       | 570/2000 [16:09<20:02,  1.19iteration/s, mean_rewards=-282]\u001b[A\n",
            "Training:  29%|██▊       | 571/2000 [16:10<19:44,  1.21iteration/s, mean_rewards=-282]\u001b[A\n",
            "Training:  29%|██▊       | 571/2000 [16:10<19:44,  1.21iteration/s, mean_rewards=-219]\u001b[A\n",
            "Training:  29%|██▊       | 572/2000 [16:11<18:47,  1.27iteration/s, mean_rewards=-219]\u001b[A\n",
            "Training:  29%|██▊       | 572/2000 [16:11<18:47,  1.27iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:  29%|██▊       | 573/2000 [16:11<18:54,  1.26iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:  29%|██▊       | 573/2000 [16:12<18:54,  1.26iteration/s, mean_rewards=-170]\u001b[A\n",
            "Training:  29%|██▊       | 574/2000 [16:13<21:06,  1.13iteration/s, mean_rewards=-170]\u001b[A\n",
            "Training:  29%|██▊       | 574/2000 [16:13<21:06,  1.13iteration/s, mean_rewards=-212]\u001b[A\n",
            "Training:  29%|██▉       | 575/2000 [16:13<20:32,  1.16iteration/s, mean_rewards=-212]\u001b[A\n",
            "Training:  29%|██▉       | 575/2000 [16:14<20:32,  1.16iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  29%|██▉       | 576/2000 [16:15<22:27,  1.06iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  29%|██▉       | 576/2000 [16:15<22:27,  1.06iteration/s, mean_rewards=-271]\u001b[A\n",
            "Training:  29%|██▉       | 577/2000 [16:16<25:45,  1.09s/iteration, mean_rewards=-271]\u001b[A\n",
            "Training:  29%|██▉       | 577/2000 [16:16<25:45,  1.09s/iteration, mean_rewards=-172]\u001b[A\n",
            "Training:  29%|██▉       | 578/2000 [16:17<26:39,  1.12s/iteration, mean_rewards=-172]\u001b[A\n",
            "Training:  29%|██▉       | 578/2000 [16:17<26:39,  1.12s/iteration, mean_rewards=-133]\u001b[A\n",
            "Training:  29%|██▉       | 579/2000 [16:18<24:39,  1.04s/iteration, mean_rewards=-133]\u001b[A\n",
            "Training:  29%|██▉       | 579/2000 [16:18<24:39,  1.04s/iteration, mean_rewards=-220]\u001b[A\n",
            "Training:  29%|██▉       | 580/2000 [16:19<22:48,  1.04iteration/s, mean_rewards=-220]\u001b[A\n",
            "Training:  29%|██▉       | 580/2000 [16:19<22:48,  1.04iteration/s, mean_rewards=-222]\u001b[A\n",
            "Training:  29%|██▉       | 581/2000 [16:20<21:37,  1.09iteration/s, mean_rewards=-222]\u001b[A\n",
            "Training:  29%|██▉       | 581/2000 [16:20<21:37,  1.09iteration/s, mean_rewards=-225]\u001b[A\n",
            "Training:  29%|██▉       | 582/2000 [16:21<22:57,  1.03iteration/s, mean_rewards=-225]\u001b[A\n",
            "Training:  29%|██▉       | 582/2000 [16:21<22:57,  1.03iteration/s, mean_rewards=-278]\u001b[A\n",
            "Training:  29%|██▉       | 583/2000 [16:22<22:39,  1.04iteration/s, mean_rewards=-278]\u001b[A\n",
            "Training:  29%|██▉       | 583/2000 [16:22<22:39,  1.04iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  29%|██▉       | 584/2000 [16:22<21:28,  1.10iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  29%|██▉       | 584/2000 [16:23<21:28,  1.10iteration/s, mean_rewards=-287]\u001b[A\n",
            "Training:  29%|██▉       | 585/2000 [16:23<21:26,  1.10iteration/s, mean_rewards=-287]\u001b[A\n",
            "Training:  29%|██▉       | 585/2000 [16:24<21:26,  1.10iteration/s, mean_rewards=-294]\u001b[A\n",
            "Training:  29%|██▉       | 586/2000 [16:24<21:33,  1.09iteration/s, mean_rewards=-294]\u001b[A\n",
            "Training:  29%|██▉       | 586/2000 [16:25<21:33,  1.09iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:  29%|██▉       | 587/2000 [16:25<23:15,  1.01iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:  29%|██▉       | 587/2000 [16:26<23:15,  1.01iteration/s, mean_rewards=-164]\u001b[A\n",
            "Training:  29%|██▉       | 588/2000 [16:26<23:31,  1.00iteration/s, mean_rewards=-164]\u001b[A\n",
            "Training:  29%|██▉       | 588/2000 [16:27<23:31,  1.00iteration/s, mean_rewards=-195]\u001b[A\n",
            "Training:  29%|██▉       | 589/2000 [16:27<22:27,  1.05iteration/s, mean_rewards=-195]\u001b[A\n",
            "Training:  29%|██▉       | 589/2000 [16:28<22:27,  1.05iteration/s, mean_rewards=-289]\u001b[A\n",
            "Training:  30%|██▉       | 590/2000 [16:29<24:29,  1.04s/iteration, mean_rewards=-289]\u001b[A\n",
            "Training:  30%|██▉       | 590/2000 [16:29<24:29,  1.04s/iteration, mean_rewards=-236]\u001b[A\n",
            "Training:  30%|██▉       | 591/2000 [16:30<28:20,  1.21s/iteration, mean_rewards=-236]\u001b[A\n",
            "Training:  30%|██▉       | 591/2000 [16:30<28:20,  1.21s/iteration, mean_rewards=-110]\u001b[A\n",
            "Training:  30%|██▉       | 592/2000 [16:31<25:46,  1.10s/iteration, mean_rewards=-110]\u001b[A\n",
            "Training:  30%|██▉       | 592/2000 [16:31<25:46,  1.10s/iteration, mean_rewards=-75] \u001b[A\n",
            "Training:  30%|██▉       | 593/2000 [16:32<23:46,  1.01s/iteration, mean_rewards=-75]\u001b[A\n",
            "Training:  30%|██▉       | 593/2000 [16:32<23:46,  1.01s/iteration, mean_rewards=-198]\u001b[A\n",
            "Training:  30%|██▉       | 594/2000 [16:33<23:27,  1.00s/iteration, mean_rewards=-198]\u001b[A\n",
            "Training:  30%|██▉       | 594/2000 [16:33<23:27,  1.00s/iteration, mean_rewards=-179]\u001b[A\n",
            "Training:  30%|██▉       | 595/2000 [16:34<23:15,  1.01iteration/s, mean_rewards=-179]\u001b[A\n",
            "Training:  30%|██▉       | 595/2000 [16:34<23:15,  1.01iteration/s, mean_rewards=-95.3]\u001b[A\n",
            "Training:  30%|██▉       | 596/2000 [16:34<21:10,  1.10iteration/s, mean_rewards=-95.3]\u001b[A\n",
            "Training:  30%|██▉       | 596/2000 [16:35<21:10,  1.10iteration/s, mean_rewards=-199] \u001b[A\n",
            "Training:  30%|██▉       | 597/2000 [16:35<21:38,  1.08iteration/s, mean_rewards=-199]\u001b[A\n",
            "Training:  30%|██▉       | 597/2000 [16:36<21:38,  1.08iteration/s, mean_rewards=-231]\u001b[A\n",
            "Training:  30%|██▉       | 598/2000 [16:36<21:39,  1.08iteration/s, mean_rewards=-231]\u001b[A\n",
            "Training:  30%|██▉       | 598/2000 [16:37<21:39,  1.08iteration/s, mean_rewards=-223]\u001b[A\n",
            "Training:  30%|██▉       | 599/2000 [16:37<21:14,  1.10iteration/s, mean_rewards=-223]\u001b[A\n",
            "Training:  30%|██▉       | 599/2000 [16:37<21:14,  1.10iteration/s, mean_rewards=-84.3]\u001b[A\n",
            "Training:  30%|███       | 600/2000 [16:38<19:32,  1.19iteration/s, mean_rewards=-84.3]\u001b[A\n",
            "Training:  30%|███       | 600/2000 [16:38<19:32,  1.19iteration/s, mean_rewards=-90.6]\u001b[A\n",
            "Training:  30%|███       | 601/2000 [16:39<18:29,  1.26iteration/s, mean_rewards=-90.6]\u001b[A\n",
            "Training:  30%|███       | 601/2000 [16:39<18:29,  1.26iteration/s, mean_rewards=-299] \u001b[A\n",
            "Training:  30%|███       | 602/2000 [16:39<18:28,  1.26iteration/s, mean_rewards=-299]\u001b[A\n",
            "Training:  30%|███       | 602/2000 [16:40<18:28,  1.26iteration/s, mean_rewards=-349]\u001b[A\n",
            "Training:  30%|███       | 603/2000 [16:40<19:16,  1.21iteration/s, mean_rewards=-349]\u001b[A\n",
            "Training:  30%|███       | 603/2000 [16:41<19:16,  1.21iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  30%|███       | 604/2000 [16:42<24:29,  1.05s/iteration, mean_rewards=-151]\u001b[A\n",
            "Training:  30%|███       | 604/2000 [16:42<24:29,  1.05s/iteration, mean_rewards=-392]\u001b[A\n",
            "Training:  30%|███       | 605/2000 [16:43<24:57,  1.07s/iteration, mean_rewards=-392]\u001b[A\n",
            "Training:  30%|███       | 605/2000 [16:43<24:57,  1.07s/iteration, mean_rewards=-185]\u001b[A\n",
            "Training:  30%|███       | 606/2000 [16:44<23:02,  1.01iteration/s, mean_rewards=-185]\u001b[A\n",
            "Training:  30%|███       | 606/2000 [16:44<23:02,  1.01iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  30%|███       | 607/2000 [16:45<22:38,  1.03iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  30%|███       | 607/2000 [16:45<22:38,  1.03iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  30%|███       | 608/2000 [16:45<21:19,  1.09iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  30%|███       | 608/2000 [16:46<21:19,  1.09iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  30%|███       | 609/2000 [16:47<22:20,  1.04iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  30%|███       | 609/2000 [16:47<22:20,  1.04iteration/s, mean_rewards=-104]\u001b[A\n",
            "Training:  30%|███       | 610/2000 [16:47<20:13,  1.15iteration/s, mean_rewards=-104]\u001b[A\n",
            "Training:  30%|███       | 610/2000 [16:48<20:13,  1.15iteration/s, mean_rewards=-459]\u001b[A\n",
            "Training:  31%|███       | 611/2000 [16:48<20:48,  1.11iteration/s, mean_rewards=-459]\u001b[A\n",
            "Training:  31%|███       | 611/2000 [16:49<20:48,  1.11iteration/s, mean_rewards=-165]\u001b[A\n",
            "Training:  31%|███       | 612/2000 [16:49<20:56,  1.10iteration/s, mean_rewards=-165]\u001b[A\n",
            "Training:  31%|███       | 612/2000 [16:49<20:56,  1.10iteration/s, mean_rewards=-64.2]\u001b[A\n",
            "Training:  31%|███       | 613/2000 [16:50<19:05,  1.21iteration/s, mean_rewards=-64.2]\u001b[A\n",
            "Training:  31%|███       | 613/2000 [16:50<19:05,  1.21iteration/s, mean_rewards=-185] \u001b[A\n",
            "Training:  31%|███       | 614/2000 [16:50<18:02,  1.28iteration/s, mean_rewards=-185]\u001b[A\n",
            "Training:  31%|███       | 614/2000 [16:51<18:02,  1.28iteration/s, mean_rewards=-266]\u001b[A\n",
            "Training:  31%|███       | 615/2000 [16:51<18:07,  1.27iteration/s, mean_rewards=-266]\u001b[A\n",
            "Training:  31%|███       | 615/2000 [16:51<18:07,  1.27iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  31%|███       | 616/2000 [16:52<17:20,  1.33iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  31%|███       | 616/2000 [16:52<17:20,  1.33iteration/s, mean_rewards=-84.9]\u001b[A\n",
            "Training:  31%|███       | 617/2000 [16:53<16:35,  1.39iteration/s, mean_rewards=-84.9]\u001b[A\n",
            "Training:  31%|███       | 617/2000 [16:53<16:35,  1.39iteration/s, mean_rewards=-245] \u001b[A\n",
            "Training:  31%|███       | 618/2000 [16:54<19:17,  1.19iteration/s, mean_rewards=-245]\u001b[A\n",
            "Training:  31%|███       | 618/2000 [16:54<19:17,  1.19iteration/s, mean_rewards=-171]\u001b[A\n",
            "Training:  31%|███       | 619/2000 [16:55<19:43,  1.17iteration/s, mean_rewards=-171]\u001b[A\n",
            "Training:  31%|███       | 619/2000 [16:55<19:43,  1.17iteration/s, mean_rewards=-246]\u001b[A\n",
            "Training:  31%|███       | 620/2000 [16:56<21:34,  1.07iteration/s, mean_rewards=-246]\u001b[A\n",
            "Training:  31%|███       | 620/2000 [16:56<21:34,  1.07iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  31%|███       | 621/2000 [16:56<20:44,  1.11iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  31%|███       | 621/2000 [16:57<20:44,  1.11iteration/s, mean_rewards=-195]\u001b[A\n",
            "Training:  31%|███       | 622/2000 [16:57<20:20,  1.13iteration/s, mean_rewards=-195]\u001b[A\n",
            "Training:  31%|███       | 622/2000 [16:58<20:20,  1.13iteration/s, mean_rewards=-240]\u001b[A\n",
            "Training:  31%|███       | 623/2000 [16:58<20:02,  1.15iteration/s, mean_rewards=-240]\u001b[A\n",
            "Training:  31%|███       | 623/2000 [16:58<20:02,  1.15iteration/s, mean_rewards=-234]\u001b[A\n",
            "Training:  31%|███       | 624/2000 [16:59<19:28,  1.18iteration/s, mean_rewards=-234]\u001b[A\n",
            "Training:  31%|███       | 624/2000 [16:59<19:28,  1.18iteration/s, mean_rewards=-163]\u001b[A\n",
            "Training:  31%|███▏      | 625/2000 [17:00<20:13,  1.13iteration/s, mean_rewards=-163]\u001b[A\n",
            "Training:  31%|███▏      | 625/2000 [17:00<20:13,  1.13iteration/s, mean_rewards=-218]\u001b[A\n",
            "Training:  31%|███▏      | 626/2000 [17:01<20:29,  1.12iteration/s, mean_rewards=-218]\u001b[A\n",
            "Training:  31%|███▏      | 626/2000 [17:01<20:29,  1.12iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  31%|███▏      | 627/2000 [17:02<19:03,  1.20iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  31%|███▏      | 627/2000 [17:02<19:03,  1.20iteration/s, mean_rewards=-264]\u001b[A\n",
            "Training:  31%|███▏      | 628/2000 [17:02<18:45,  1.22iteration/s, mean_rewards=-264]\u001b[A\n",
            "Training:  31%|███▏      | 628/2000 [17:03<18:45,  1.22iteration/s, mean_rewards=-163]\u001b[A\n",
            "Training:  31%|███▏      | 629/2000 [17:03<18:28,  1.24iteration/s, mean_rewards=-163]\u001b[A\n",
            "Training:  31%|███▏      | 629/2000 [17:03<18:28,  1.24iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  32%|███▏      | 630/2000 [17:04<18:09,  1.26iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  32%|███▏      | 630/2000 [17:04<18:09,  1.26iteration/s, mean_rewards=-319]\u001b[A\n",
            "Training:  32%|███▏      | 631/2000 [17:05<17:19,  1.32iteration/s, mean_rewards=-319]\u001b[A\n",
            "Training:  32%|███▏      | 631/2000 [17:05<17:19,  1.32iteration/s, mean_rewards=-197]\u001b[A\n",
            "Training:  32%|███▏      | 632/2000 [17:05<18:20,  1.24iteration/s, mean_rewards=-197]\u001b[A\n",
            "Training:  32%|███▏      | 632/2000 [17:06<18:20,  1.24iteration/s, mean_rewards=-103]\u001b[A\n",
            "Training:  32%|███▏      | 633/2000 [17:07<21:07,  1.08iteration/s, mean_rewards=-103]\u001b[A\n",
            "Training:  32%|███▏      | 633/2000 [17:07<21:07,  1.08iteration/s, mean_rewards=-247]\u001b[A\n",
            "Training:  32%|███▏      | 634/2000 [17:08<24:32,  1.08s/iteration, mean_rewards=-247]\u001b[A\n",
            "Training:  32%|███▏      | 634/2000 [17:08<24:32,  1.08s/iteration, mean_rewards=-197]\u001b[A\n",
            "Training:  32%|███▏      | 635/2000 [17:09<22:30,  1.01iteration/s, mean_rewards=-197]\u001b[A\n",
            "Training:  32%|███▏      | 635/2000 [17:09<22:30,  1.01iteration/s, mean_rewards=-213]\u001b[A\n",
            "Training:  32%|███▏      | 636/2000 [17:10<21:50,  1.04iteration/s, mean_rewards=-213]\u001b[A\n",
            "Training:  32%|███▏      | 636/2000 [17:10<21:50,  1.04iteration/s, mean_rewards=-326]\u001b[A\n",
            "Training:  32%|███▏      | 637/2000 [17:11<21:46,  1.04iteration/s, mean_rewards=-326]\u001b[A\n",
            "Training:  32%|███▏      | 637/2000 [17:11<21:46,  1.04iteration/s, mean_rewards=-116]\u001b[A\n",
            "Training:  32%|███▏      | 638/2000 [17:12<21:24,  1.06iteration/s, mean_rewards=-116]\u001b[A\n",
            "Training:  32%|███▏      | 638/2000 [17:12<21:24,  1.06iteration/s, mean_rewards=-183]\u001b[A\n",
            "Training:  32%|███▏      | 639/2000 [17:12<20:21,  1.11iteration/s, mean_rewards=-183]\u001b[A\n",
            "Training:  32%|███▏      | 639/2000 [17:13<20:21,  1.11iteration/s, mean_rewards=-212]\u001b[A\n",
            "Training:  32%|███▏      | 640/2000 [17:14<21:37,  1.05iteration/s, mean_rewards=-212]\u001b[A\n",
            "Training:  32%|███▏      | 640/2000 [17:14<21:37,  1.05iteration/s, mean_rewards=-207]\u001b[A\n",
            "Training:  32%|███▏      | 641/2000 [17:14<19:48,  1.14iteration/s, mean_rewards=-207]\u001b[A\n",
            "Training:  32%|███▏      | 641/2000 [17:15<19:48,  1.14iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  32%|███▏      | 642/2000 [17:15<20:06,  1.13iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  32%|███▏      | 642/2000 [17:16<20:06,  1.13iteration/s, mean_rewards=-186]\u001b[A\n",
            "Training:  32%|███▏      | 643/2000 [17:16<21:24,  1.06iteration/s, mean_rewards=-186]\u001b[A\n",
            "Training:  32%|███▏      | 643/2000 [17:17<21:24,  1.06iteration/s, mean_rewards=-193]\u001b[A\n",
            "Training:  32%|███▏      | 644/2000 [17:17<22:15,  1.02iteration/s, mean_rewards=-193]\u001b[A\n",
            "Training:  32%|███▏      | 644/2000 [17:18<22:15,  1.02iteration/s, mean_rewards=-289]\u001b[A\n",
            "Training:  32%|███▏      | 645/2000 [17:18<22:01,  1.03iteration/s, mean_rewards=-289]\u001b[A\n",
            "Training:  32%|███▏      | 645/2000 [17:19<22:01,  1.03iteration/s, mean_rewards=-302]\u001b[A\n",
            "Training:  32%|███▏      | 646/2000 [17:20<24:36,  1.09s/iteration, mean_rewards=-302]\u001b[A\n",
            "Training:  32%|███▏      | 646/2000 [17:20<24:36,  1.09s/iteration, mean_rewards=-256]\u001b[A\n",
            "Training:  32%|███▏      | 647/2000 [17:21<25:00,  1.11s/iteration, mean_rewards=-256]\u001b[A\n",
            "Training:  32%|███▏      | 647/2000 [17:21<25:00,  1.11s/iteration, mean_rewards=-325]\u001b[A\n",
            "Training:  32%|███▏      | 648/2000 [17:22<25:04,  1.11s/iteration, mean_rewards=-325]\u001b[A\n",
            "Training:  32%|███▏      | 648/2000 [17:22<25:04,  1.11s/iteration, mean_rewards=-151]\u001b[A\n",
            "Training:  32%|███▏      | 649/2000 [17:23<23:55,  1.06s/iteration, mean_rewards=-151]\u001b[A\n",
            "Training:  32%|███▏      | 649/2000 [17:23<23:55,  1.06s/iteration, mean_rewards=-146]\u001b[A\n",
            "Training:  32%|███▎      | 650/2000 [17:24<22:54,  1.02s/iteration, mean_rewards=-146]\u001b[A\n",
            "Training:  32%|███▎      | 650/2000 [17:24<22:54,  1.02s/iteration, mean_rewards=-175]\u001b[A\n",
            "Training:  33%|███▎      | 651/2000 [17:25<21:20,  1.05iteration/s, mean_rewards=-175]\u001b[A\n",
            "Training:  33%|███▎      | 651/2000 [17:25<21:20,  1.05iteration/s, mean_rewards=-221]\u001b[A\n",
            "Training:  33%|███▎      | 652/2000 [17:26<22:08,  1.01iteration/s, mean_rewards=-221]\u001b[A\n",
            "Training:  33%|███▎      | 652/2000 [17:26<22:08,  1.01iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  33%|███▎      | 653/2000 [17:26<20:54,  1.07iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  33%|███▎      | 653/2000 [17:27<20:54,  1.07iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  33%|███▎      | 654/2000 [17:27<19:56,  1.13iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  33%|███▎      | 654/2000 [17:28<19:56,  1.13iteration/s, mean_rewards=-244]\u001b[A\n",
            "Training:  33%|███▎      | 655/2000 [17:28<20:19,  1.10iteration/s, mean_rewards=-244]\u001b[A\n",
            "Training:  33%|███▎      | 655/2000 [17:28<20:19,  1.10iteration/s, mean_rewards=-256]\u001b[A\n",
            "Training:  33%|███▎      | 656/2000 [17:29<19:34,  1.14iteration/s, mean_rewards=-256]\u001b[A\n",
            "Training:  33%|███▎      | 656/2000 [17:29<19:34,  1.14iteration/s, mean_rewards=-91.8]\u001b[A\n",
            "Training:  33%|███▎      | 657/2000 [17:30<18:58,  1.18iteration/s, mean_rewards=-91.8]\u001b[A\n",
            "Training:  33%|███▎      | 657/2000 [17:30<18:58,  1.18iteration/s, mean_rewards=-104] \u001b[A\n",
            "Training:  33%|███▎      | 658/2000 [17:31<19:38,  1.14iteration/s, mean_rewards=-104]\u001b[A\n",
            "Training:  33%|███▎      | 658/2000 [17:31<19:38,  1.14iteration/s, mean_rewards=-85.7]\u001b[A\n",
            "Training:  33%|███▎      | 659/2000 [17:31<19:00,  1.18iteration/s, mean_rewards=-85.7]\u001b[A\n",
            "Training:  33%|███▎      | 659/2000 [17:32<19:00,  1.18iteration/s, mean_rewards=-150] \u001b[A\n",
            "Training:  33%|███▎      | 660/2000 [17:32<18:28,  1.21iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  33%|███▎      | 660/2000 [17:33<18:28,  1.21iteration/s, mean_rewards=-220]\u001b[A\n",
            "Training:  33%|███▎      | 661/2000 [17:33<20:17,  1.10iteration/s, mean_rewards=-220]\u001b[A\n",
            "Training:  33%|███▎      | 661/2000 [17:34<20:17,  1.10iteration/s, mean_rewards=-202]\u001b[A\n",
            "Training:  33%|███▎      | 662/2000 [17:34<21:03,  1.06iteration/s, mean_rewards=-202]\u001b[A\n",
            "Training:  33%|███▎      | 662/2000 [17:35<21:03,  1.06iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  33%|███▎      | 663/2000 [17:35<20:46,  1.07iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  33%|███▎      | 663/2000 [17:36<20:46,  1.07iteration/s, mean_rewards=-226]\u001b[A\n",
            "Training:  33%|███▎      | 664/2000 [17:36<20:26,  1.09iteration/s, mean_rewards=-226]\u001b[A\n",
            "Training:  33%|███▎      | 664/2000 [17:36<20:26,  1.09iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  33%|███▎      | 665/2000 [17:37<18:30,  1.20iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  33%|███▎      | 665/2000 [17:37<18:30,  1.20iteration/s, mean_rewards=-165]\u001b[A\n",
            "Training:  33%|███▎      | 666/2000 [17:38<20:05,  1.11iteration/s, mean_rewards=-165]\u001b[A\n",
            "Training:  33%|███▎      | 666/2000 [17:38<20:05,  1.11iteration/s, mean_rewards=-91.3]\u001b[A\n",
            "Training:  33%|███▎      | 667/2000 [17:39<19:19,  1.15iteration/s, mean_rewards=-91.3]\u001b[A\n",
            "Training:  33%|███▎      | 667/2000 [17:39<19:19,  1.15iteration/s, mean_rewards=-110] \u001b[A\n",
            "Training:  33%|███▎      | 668/2000 [17:39<18:37,  1.19iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  33%|███▎      | 668/2000 [17:40<18:37,  1.19iteration/s, mean_rewards=-262]\u001b[A\n",
            "Training:  33%|███▎      | 669/2000 [17:40<19:03,  1.16iteration/s, mean_rewards=-262]\u001b[A\n",
            "Training:  33%|███▎      | 669/2000 [17:41<19:03,  1.16iteration/s, mean_rewards=-233]\u001b[A\n",
            "Training:  34%|███▎      | 670/2000 [17:41<19:48,  1.12iteration/s, mean_rewards=-233]\u001b[A\n",
            "Training:  34%|███▎      | 670/2000 [17:42<19:48,  1.12iteration/s, mean_rewards=-272]\u001b[A\n",
            "Training:  34%|███▎      | 671/2000 [17:42<20:05,  1.10iteration/s, mean_rewards=-272]\u001b[A\n",
            "Training:  34%|███▎      | 671/2000 [17:43<20:05,  1.10iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  34%|███▎      | 672/2000 [17:43<19:09,  1.16iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  34%|███▎      | 672/2000 [17:43<19:09,  1.16iteration/s, mean_rewards=-109]\u001b[A\n",
            "Training:  34%|███▎      | 673/2000 [17:44<17:36,  1.26iteration/s, mean_rewards=-109]\u001b[A\n",
            "Training:  34%|███▎      | 673/2000 [17:44<17:36,  1.26iteration/s, mean_rewards=-179]\u001b[A\n",
            "Training:  34%|███▎      | 674/2000 [17:45<19:17,  1.15iteration/s, mean_rewards=-179]\u001b[A\n",
            "Training:  34%|███▎      | 674/2000 [17:45<19:17,  1.15iteration/s, mean_rewards=-229]\u001b[A\n",
            "Training:  34%|███▍      | 675/2000 [17:46<20:51,  1.06iteration/s, mean_rewards=-229]\u001b[A\n",
            "Training:  34%|███▍      | 675/2000 [17:46<20:51,  1.06iteration/s, mean_rewards=-267]\u001b[A\n",
            "Training:  34%|███▍      | 676/2000 [17:47<22:35,  1.02s/iteration, mean_rewards=-267]\u001b[A\n",
            "Training:  34%|███▍      | 676/2000 [17:47<22:35,  1.02s/iteration, mean_rewards=-266]\u001b[A\n",
            "Training:  34%|███▍      | 677/2000 [17:48<20:57,  1.05iteration/s, mean_rewards=-266]\u001b[A\n",
            "Training:  34%|███▍      | 677/2000 [17:48<20:57,  1.05iteration/s, mean_rewards=-269]\u001b[A\n",
            "Training:  34%|███▍      | 678/2000 [17:49<22:03,  1.00s/iteration, mean_rewards=-269]\u001b[A\n",
            "Training:  34%|███▍      | 678/2000 [17:49<22:03,  1.00s/iteration, mean_rewards=-112]\u001b[A\n",
            "Training:  34%|███▍      | 679/2000 [17:50<22:22,  1.02s/iteration, mean_rewards=-112]\u001b[A\n",
            "Training:  34%|███▍      | 679/2000 [17:50<22:22,  1.02s/iteration, mean_rewards=-75.9]\u001b[A\n",
            "Training:  34%|███▍      | 680/2000 [17:51<23:23,  1.06s/iteration, mean_rewards=-75.9]\u001b[A\n",
            "Training:  34%|███▍      | 680/2000 [17:51<23:23,  1.06s/iteration, mean_rewards=-118] \u001b[A\n",
            "Training:  34%|███▍      | 681/2000 [17:52<21:40,  1.01iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  34%|███▍      | 681/2000 [17:52<21:40,  1.01iteration/s, mean_rewards=-299]\u001b[A\n",
            "Training:  34%|███▍      | 682/2000 [17:53<21:26,  1.02iteration/s, mean_rewards=-299]\u001b[A\n",
            "Training:  34%|███▍      | 682/2000 [17:53<21:26,  1.02iteration/s, mean_rewards=-335]\u001b[A\n",
            "Training:  34%|███▍      | 683/2000 [17:54<21:07,  1.04iteration/s, mean_rewards=-335]\u001b[A\n",
            "Training:  34%|███▍      | 683/2000 [17:54<21:07,  1.04iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  34%|███▍      | 684/2000 [17:55<20:57,  1.05iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  34%|███▍      | 684/2000 [17:55<20:57,  1.05iteration/s, mean_rewards=-376]\u001b[A\n",
            "Training:  34%|███▍      | 685/2000 [17:56<19:53,  1.10iteration/s, mean_rewards=-376]\u001b[A\n",
            "Training:  34%|███▍      | 685/2000 [17:56<19:53,  1.10iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  34%|███▍      | 686/2000 [17:56<18:16,  1.20iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  34%|███▍      | 686/2000 [17:57<18:16,  1.20iteration/s, mean_rewards=-224]\u001b[A\n",
            "Training:  34%|███▍      | 687/2000 [17:57<17:52,  1.22iteration/s, mean_rewards=-224]\u001b[A\n",
            "Training:  34%|███▍      | 687/2000 [17:57<17:52,  1.22iteration/s, mean_rewards=-112]\u001b[A\n",
            "Training:  34%|███▍      | 688/2000 [17:58<19:44,  1.11iteration/s, mean_rewards=-112]\u001b[A\n",
            "Training:  34%|███▍      | 688/2000 [17:58<19:44,  1.11iteration/s, mean_rewards=-206]\u001b[A\n",
            "Training:  34%|███▍      | 689/2000 [17:59<21:20,  1.02iteration/s, mean_rewards=-206]\u001b[A\n",
            "Training:  34%|███▍      | 689/2000 [18:00<21:20,  1.02iteration/s, mean_rewards=-193]\u001b[A\n",
            "Training:  34%|███▍      | 690/2000 [18:00<22:13,  1.02s/iteration, mean_rewards=-193]\u001b[A\n",
            "Training:  34%|███▍      | 690/2000 [18:01<22:13,  1.02s/iteration, mean_rewards=-219]\u001b[A\n",
            "Training:  35%|███▍      | 691/2000 [18:01<21:36,  1.01iteration/s, mean_rewards=-219]\u001b[A\n",
            "Training:  35%|███▍      | 691/2000 [18:02<21:36,  1.01iteration/s, mean_rewards=-276]\u001b[A\n",
            "Training:  35%|███▍      | 692/2000 [18:02<20:41,  1.05iteration/s, mean_rewards=-276]\u001b[A\n",
            "Training:  35%|███▍      | 692/2000 [18:02<20:41,  1.05iteration/s, mean_rewards=-89.7]\u001b[A\n",
            "Training:  35%|███▍      | 693/2000 [18:03<18:55,  1.15iteration/s, mean_rewards=-89.7]\u001b[A\n",
            "Training:  35%|███▍      | 693/2000 [18:03<18:55,  1.15iteration/s, mean_rewards=-106] \u001b[A\n",
            "Training:  35%|███▍      | 694/2000 [18:04<18:31,  1.18iteration/s, mean_rewards=-106]\u001b[A\n",
            "Training:  35%|███▍      | 694/2000 [18:04<18:31,  1.18iteration/s, mean_rewards=-232]\u001b[A\n",
            "Training:  35%|███▍      | 695/2000 [18:05<20:04,  1.08iteration/s, mean_rewards=-232]\u001b[A\n",
            "Training:  35%|███▍      | 695/2000 [18:05<20:04,  1.08iteration/s, mean_rewards=-104]\u001b[A\n",
            "Training:  35%|███▍      | 696/2000 [18:05<18:18,  1.19iteration/s, mean_rewards=-104]\u001b[A\n",
            "Training:  35%|███▍      | 696/2000 [18:06<18:18,  1.19iteration/s, mean_rewards=-223]\u001b[A\n",
            "Training:  35%|███▍      | 697/2000 [18:06<19:29,  1.11iteration/s, mean_rewards=-223]\u001b[A\n",
            "Training:  35%|███▍      | 697/2000 [18:07<19:29,  1.11iteration/s, mean_rewards=-208]\u001b[A\n",
            "Training:  35%|███▍      | 698/2000 [18:07<18:50,  1.15iteration/s, mean_rewards=-208]\u001b[A\n",
            "Training:  35%|███▍      | 698/2000 [18:08<18:50,  1.15iteration/s, mean_rewards=-249]\u001b[A\n",
            "Training:  35%|███▍      | 699/2000 [18:08<19:08,  1.13iteration/s, mean_rewards=-249]\u001b[A\n",
            "Training:  35%|███▍      | 699/2000 [18:08<19:08,  1.13iteration/s, mean_rewards=-290]\u001b[A\n",
            "Training:  35%|███▌      | 700/2000 [18:09<18:37,  1.16iteration/s, mean_rewards=-290]\u001b[A\n",
            "Training:  35%|███▌      | 700/2000 [18:09<18:37,  1.16iteration/s, mean_rewards=-70.6]\u001b[A\n",
            "Training:  35%|███▌      | 701/2000 [18:10<17:33,  1.23iteration/s, mean_rewards=-70.6]\u001b[A\n",
            "Training:  35%|███▌      | 701/2000 [18:10<17:33,  1.23iteration/s, mean_rewards=13.9] \u001b[A\n",
            "Training:  35%|███▌      | 702/2000 [18:11<21:31,  1.01iteration/s, mean_rewards=13.9]\u001b[A\n",
            "Training:  35%|███▌      | 702/2000 [18:11<21:31,  1.01iteration/s, mean_rewards=-200]\u001b[A\n",
            "Training:  35%|███▌      | 703/2000 [18:12<21:04,  1.03iteration/s, mean_rewards=-200]\u001b[A\n",
            "Training:  35%|███▌      | 703/2000 [18:12<21:04,  1.03iteration/s, mean_rewards=-185]\u001b[A\n",
            "Training:  35%|███▌      | 704/2000 [18:13<21:30,  1.00iteration/s, mean_rewards=-185]\u001b[A\n",
            "Training:  35%|███▌      | 704/2000 [18:13<21:30,  1.00iteration/s, mean_rewards=-210]\u001b[A\n",
            "Training:  35%|███▌      | 705/2000 [18:14<20:14,  1.07iteration/s, mean_rewards=-210]\u001b[A\n",
            "Training:  35%|███▌      | 705/2000 [18:14<20:14,  1.07iteration/s, mean_rewards=-41.5]\u001b[A\n",
            "Training:  35%|███▌      | 706/2000 [18:15<19:21,  1.11iteration/s, mean_rewards=-41.5]\u001b[A\n",
            "Training:  35%|███▌      | 706/2000 [18:15<19:21,  1.11iteration/s, mean_rewards=-167] \u001b[A\n",
            "Training:  35%|███▌      | 707/2000 [18:15<18:40,  1.15iteration/s, mean_rewards=-167]\u001b[A\n",
            "Training:  35%|███▌      | 707/2000 [18:16<18:40,  1.15iteration/s, mean_rewards=-212]\u001b[A\n",
            "Training:  35%|███▌      | 708/2000 [18:18<28:32,  1.33s/iteration, mean_rewards=-212]\u001b[A\n",
            "Training:  35%|███▌      | 708/2000 [18:18<28:32,  1.33s/iteration, mean_rewards=-97.8]\u001b[A\n",
            "Training:  35%|███▌      | 709/2000 [18:19<26:06,  1.21s/iteration, mean_rewards=-97.8]\u001b[A\n",
            "Training:  35%|███▌      | 709/2000 [18:19<26:06,  1.21s/iteration, mean_rewards=-108] \u001b[A\n",
            "Training:  36%|███▌      | 710/2000 [18:20<23:41,  1.10s/iteration, mean_rewards=-108]\u001b[A\n",
            "Training:  36%|███▌      | 710/2000 [18:20<23:41,  1.10s/iteration, mean_rewards=-118]\u001b[A\n",
            "Training:  36%|███▌      | 711/2000 [18:21<22:39,  1.05s/iteration, mean_rewards=-118]\u001b[A\n",
            "Training:  36%|███▌      | 711/2000 [18:21<22:39,  1.05s/iteration, mean_rewards=-271]\u001b[A\n",
            "Training:  36%|███▌      | 712/2000 [18:21<20:54,  1.03iteration/s, mean_rewards=-271]\u001b[A\n",
            "Training:  36%|███▌      | 712/2000 [18:22<20:54,  1.03iteration/s, mean_rewards=-325]\u001b[A\n",
            "Training:  36%|███▌      | 713/2000 [18:22<19:26,  1.10iteration/s, mean_rewards=-325]\u001b[A\n",
            "Training:  36%|███▌      | 713/2000 [18:22<19:26,  1.10iteration/s, mean_rewards=-417]\u001b[A\n",
            "Training:  36%|███▌      | 714/2000 [18:23<19:19,  1.11iteration/s, mean_rewards=-417]\u001b[A\n",
            "Training:  36%|███▌      | 714/2000 [18:23<19:19,  1.11iteration/s, mean_rewards=-218]\u001b[A\n",
            "Training:  36%|███▌      | 715/2000 [18:24<20:16,  1.06iteration/s, mean_rewards=-218]\u001b[A\n",
            "Training:  36%|███▌      | 715/2000 [18:24<20:16,  1.06iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  36%|███▌      | 716/2000 [18:25<20:18,  1.05iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  36%|███▌      | 716/2000 [18:25<20:18,  1.05iteration/s, mean_rewards=-85.7]\u001b[A\n",
            "Training:  36%|███▌      | 717/2000 [18:26<21:31,  1.01s/iteration, mean_rewards=-85.7]\u001b[A\n",
            "Training:  36%|███▌      | 717/2000 [18:26<21:31,  1.01s/iteration, mean_rewards=-123] \u001b[A\n",
            "Training:  36%|███▌      | 718/2000 [18:27<19:22,  1.10iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  36%|███▌      | 718/2000 [18:27<19:22,  1.10iteration/s, mean_rewards=-104]\u001b[A\n",
            "Training:  36%|███▌      | 719/2000 [18:27<17:45,  1.20iteration/s, mean_rewards=-104]\u001b[A\n",
            "Training:  36%|███▌      | 719/2000 [18:28<17:45,  1.20iteration/s, mean_rewards=-367]\u001b[A\n",
            "Training:  36%|███▌      | 720/2000 [18:28<18:17,  1.17iteration/s, mean_rewards=-367]\u001b[A\n",
            "Training:  36%|███▌      | 720/2000 [18:29<18:17,  1.17iteration/s, mean_rewards=-227]\u001b[A\n",
            "Training:  36%|███▌      | 721/2000 [18:29<18:35,  1.15iteration/s, mean_rewards=-227]\u001b[A\n",
            "Training:  36%|███▌      | 721/2000 [18:30<18:35,  1.15iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  36%|███▌      | 722/2000 [18:30<17:46,  1.20iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  36%|███▌      | 722/2000 [18:30<17:46,  1.20iteration/s, mean_rewards=-301]\u001b[A\n",
            "Training:  36%|███▌      | 723/2000 [18:31<19:07,  1.11iteration/s, mean_rewards=-301]\u001b[A\n",
            "Training:  36%|███▌      | 723/2000 [18:31<19:07,  1.11iteration/s, mean_rewards=-341]\u001b[A\n",
            "Training:  36%|███▌      | 724/2000 [18:32<19:11,  1.11iteration/s, mean_rewards=-341]\u001b[A\n",
            "Training:  36%|███▌      | 724/2000 [18:32<19:11,  1.11iteration/s, mean_rewards=-268]\u001b[A\n",
            "Training:  36%|███▋      | 725/2000 [18:33<19:57,  1.06iteration/s, mean_rewards=-268]\u001b[A\n",
            "Training:  36%|███▋      | 725/2000 [18:33<19:57,  1.06iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  36%|███▋      | 726/2000 [18:34<19:44,  1.08iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  36%|███▋      | 726/2000 [18:34<19:44,  1.08iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  36%|███▋      | 727/2000 [18:35<19:52,  1.07iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  36%|███▋      | 727/2000 [18:35<19:52,  1.07iteration/s, mean_rewards=-208]\u001b[A\n",
            "Training:  36%|███▋      | 728/2000 [18:36<19:59,  1.06iteration/s, mean_rewards=-208]\u001b[A\n",
            "Training:  36%|███▋      | 728/2000 [18:36<19:59,  1.06iteration/s, mean_rewards=-289]\u001b[A\n",
            "Training:  36%|███▋      | 729/2000 [18:37<20:30,  1.03iteration/s, mean_rewards=-289]\u001b[A\n",
            "Training:  36%|███▋      | 729/2000 [18:37<20:30,  1.03iteration/s, mean_rewards=-106]\u001b[A\n",
            "Training:  36%|███▋      | 730/2000 [18:38<19:59,  1.06iteration/s, mean_rewards=-106]\u001b[A\n",
            "Training:  36%|███▋      | 730/2000 [18:38<19:59,  1.06iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:  37%|███▋      | 731/2000 [18:39<21:47,  1.03s/iteration, mean_rewards=-147]\u001b[A\n",
            "Training:  37%|███▋      | 731/2000 [18:39<21:47,  1.03s/iteration, mean_rewards=-103]\u001b[A\n",
            "Training:  37%|███▋      | 732/2000 [18:40<20:57,  1.01iteration/s, mean_rewards=-103]\u001b[A\n",
            "Training:  37%|███▋      | 732/2000 [18:40<20:57,  1.01iteration/s, mean_rewards=-172]\u001b[A\n",
            "Training:  37%|███▋      | 733/2000 [18:41<19:48,  1.07iteration/s, mean_rewards=-172]\u001b[A\n",
            "Training:  37%|███▋      | 733/2000 [18:41<19:48,  1.07iteration/s, mean_rewards=-241]\u001b[A\n",
            "Training:  37%|███▋      | 734/2000 [18:42<20:37,  1.02iteration/s, mean_rewards=-241]\u001b[A\n",
            "Training:  37%|███▋      | 734/2000 [18:42<20:37,  1.02iteration/s, mean_rewards=-173]\u001b[A\n",
            "Training:  37%|███▋      | 735/2000 [18:43<20:11,  1.04iteration/s, mean_rewards=-173]\u001b[A\n",
            "Training:  37%|███▋      | 735/2000 [18:43<20:11,  1.04iteration/s, mean_rewards=-194]\u001b[A\n",
            "Training:  37%|███▋      | 736/2000 [18:43<18:27,  1.14iteration/s, mean_rewards=-194]\u001b[A\n",
            "Training:  37%|███▋      | 736/2000 [18:44<18:27,  1.14iteration/s, mean_rewards=-319]\u001b[A\n",
            "Training:  37%|███▋      | 737/2000 [18:44<19:36,  1.07iteration/s, mean_rewards=-319]\u001b[A\n",
            "Training:  37%|███▋      | 737/2000 [18:45<19:36,  1.07iteration/s, mean_rewards=-58.4]\u001b[A\n",
            "Training:  37%|███▋      | 738/2000 [18:45<18:30,  1.14iteration/s, mean_rewards=-58.4]\u001b[A\n",
            "Training:  37%|███▋      | 738/2000 [18:46<18:30,  1.14iteration/s, mean_rewards=-192] \u001b[A\n",
            "Training:  37%|███▋      | 739/2000 [18:46<17:59,  1.17iteration/s, mean_rewards=-192]\u001b[A\n",
            "Training:  37%|███▋      | 739/2000 [18:46<17:59,  1.17iteration/s, mean_rewards=-80.1]\u001b[A\n",
            "Training:  37%|███▋      | 740/2000 [18:47<16:57,  1.24iteration/s, mean_rewards=-80.1]\u001b[A\n",
            "Training:  37%|███▋      | 740/2000 [18:47<16:57,  1.24iteration/s, mean_rewards=-274] \u001b[A\n",
            "Training:  37%|███▋      | 741/2000 [18:47<16:49,  1.25iteration/s, mean_rewards=-274]\u001b[A\n",
            "Training:  37%|███▋      | 741/2000 [18:48<16:49,  1.25iteration/s, mean_rewards=-252]\u001b[A\n",
            "Training:  37%|███▋      | 742/2000 [18:48<17:33,  1.19iteration/s, mean_rewards=-252]\u001b[A\n",
            "Training:  37%|███▋      | 742/2000 [18:49<17:33,  1.19iteration/s, mean_rewards=-194]\u001b[A\n",
            "Training:  37%|███▋      | 743/2000 [18:49<18:19,  1.14iteration/s, mean_rewards=-194]\u001b[A\n",
            "Training:  37%|███▋      | 743/2000 [18:50<18:19,  1.14iteration/s, mean_rewards=-83.6]\u001b[A\n",
            "Training:  37%|███▋      | 744/2000 [18:50<17:04,  1.23iteration/s, mean_rewards=-83.6]\u001b[A\n",
            "Training:  37%|███▋      | 744/2000 [18:50<17:04,  1.23iteration/s, mean_rewards=-244] \u001b[A\n",
            "Training:  37%|███▋      | 745/2000 [18:51<19:36,  1.07iteration/s, mean_rewards=-244]\u001b[A\n",
            "Training:  37%|███▋      | 745/2000 [18:52<19:36,  1.07iteration/s, mean_rewards=-76.8]\u001b[A\n",
            "Training:  37%|███▋      | 746/2000 [18:52<20:16,  1.03iteration/s, mean_rewards=-76.8]\u001b[A\n",
            "Training:  37%|███▋      | 746/2000 [18:53<20:16,  1.03iteration/s, mean_rewards=-111] \u001b[A\n",
            "Training:  37%|███▋      | 747/2000 [18:53<19:03,  1.10iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  37%|███▋      | 747/2000 [18:53<19:03,  1.10iteration/s, mean_rewards=-75.9]\u001b[A\n",
            "Training:  37%|███▋      | 748/2000 [18:54<16:51,  1.24iteration/s, mean_rewards=-75.9]\u001b[A\n",
            "Training:  37%|███▋      | 748/2000 [18:54<16:51,  1.24iteration/s, mean_rewards=-225] \u001b[A\n",
            "Training:  37%|███▋      | 749/2000 [18:54<16:41,  1.25iteration/s, mean_rewards=-225]\u001b[A\n",
            "Training:  37%|███▋      | 749/2000 [18:55<16:41,  1.25iteration/s, mean_rewards=-214]\u001b[A\n",
            "Training:  38%|███▊      | 750/2000 [18:55<17:25,  1.20iteration/s, mean_rewards=-214]\u001b[A\n",
            "Training:  38%|███▊      | 750/2000 [18:56<17:25,  1.20iteration/s, mean_rewards=-219]\u001b[A\n",
            "Training:  38%|███▊      | 751/2000 [18:56<16:46,  1.24iteration/s, mean_rewards=-219]\u001b[A\n",
            "Training:  38%|███▊      | 751/2000 [18:56<16:46,  1.24iteration/s, mean_rewards=-203]\u001b[A\n",
            "Training:  38%|███▊      | 752/2000 [18:57<16:36,  1.25iteration/s, mean_rewards=-203]\u001b[A\n",
            "Training:  38%|███▊      | 752/2000 [18:57<16:36,  1.25iteration/s, mean_rewards=-193]\u001b[A\n",
            "Training:  38%|███▊      | 753/2000 [18:58<17:10,  1.21iteration/s, mean_rewards=-193]\u001b[A\n",
            "Training:  38%|███▊      | 753/2000 [18:58<17:10,  1.21iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  38%|███▊      | 754/2000 [18:59<16:52,  1.23iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  38%|███▊      | 754/2000 [18:59<16:52,  1.23iteration/s, mean_rewards=-232]\u001b[A\n",
            "Training:  38%|███▊      | 755/2000 [18:59<17:38,  1.18iteration/s, mean_rewards=-232]\u001b[A\n",
            "Training:  38%|███▊      | 755/2000 [19:00<17:38,  1.18iteration/s, mean_rewards=-95.1]\u001b[A\n",
            "Training:  38%|███▊      | 756/2000 [19:00<18:08,  1.14iteration/s, mean_rewards=-95.1]\u001b[A\n",
            "Training:  38%|███▊      | 756/2000 [19:01<18:08,  1.14iteration/s, mean_rewards=-127] \u001b[A\n",
            "Training:  38%|███▊      | 757/2000 [19:01<17:09,  1.21iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  38%|███▊      | 757/2000 [19:01<17:09,  1.21iteration/s, mean_rewards=-112]\u001b[A\n",
            "Training:  38%|███▊      | 758/2000 [19:02<17:52,  1.16iteration/s, mean_rewards=-112]\u001b[A\n",
            "Training:  38%|███▊      | 758/2000 [19:03<17:52,  1.16iteration/s, mean_rewards=-383]\u001b[A\n",
            "Training:  38%|███▊      | 759/2000 [19:03<20:57,  1.01s/iteration, mean_rewards=-383]\u001b[A\n",
            "Training:  38%|███▊      | 759/2000 [19:04<20:57,  1.01s/iteration, mean_rewards=-108]\u001b[A\n",
            "Training:  38%|███▊      | 760/2000 [19:04<20:37,  1.00iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:  38%|███▊      | 760/2000 [19:05<20:37,  1.00iteration/s, mean_rewards=-202]\u001b[A\n",
            "Training:  38%|███▊      | 761/2000 [19:05<19:23,  1.06iteration/s, mean_rewards=-202]\u001b[A\n",
            "Training:  38%|███▊      | 761/2000 [19:06<19:23,  1.06iteration/s, mean_rewards=-88.9]\u001b[A\n",
            "Training:  38%|███▊      | 762/2000 [19:06<18:39,  1.11iteration/s, mean_rewards=-88.9]\u001b[A\n",
            "Training:  38%|███▊      | 762/2000 [19:06<18:39,  1.11iteration/s, mean_rewards=-195] \u001b[A\n",
            "Training:  38%|███▊      | 763/2000 [19:07<18:53,  1.09iteration/s, mean_rewards=-195]\u001b[A\n",
            "Training:  38%|███▊      | 763/2000 [19:07<18:53,  1.09iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  38%|███▊      | 764/2000 [19:08<17:22,  1.19iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  38%|███▊      | 764/2000 [19:08<17:22,  1.19iteration/s, mean_rewards=-239]\u001b[A\n",
            "Training:  38%|███▊      | 765/2000 [19:08<17:10,  1.20iteration/s, mean_rewards=-239]\u001b[A\n",
            "Training:  38%|███▊      | 765/2000 [19:09<17:10,  1.20iteration/s, mean_rewards=-73.6]\u001b[A\n",
            "Training:  38%|███▊      | 766/2000 [19:09<16:09,  1.27iteration/s, mean_rewards=-73.6]\u001b[A\n",
            "Training:  38%|███▊      | 766/2000 [19:09<16:09,  1.27iteration/s, mean_rewards=-75.5]\u001b[A\n",
            "Training:  38%|███▊      | 767/2000 [19:10<15:32,  1.32iteration/s, mean_rewards=-75.5]\u001b[A\n",
            "Training:  38%|███▊      | 767/2000 [19:10<15:32,  1.32iteration/s, mean_rewards=-97.4]\u001b[A\n",
            "Training:  38%|███▊      | 768/2000 [19:11<17:36,  1.17iteration/s, mean_rewards=-97.4]\u001b[A\n",
            "Training:  38%|███▊      | 768/2000 [19:11<17:36,  1.17iteration/s, mean_rewards=-134] \u001b[A\n",
            "Training:  38%|███▊      | 769/2000 [19:12<16:41,  1.23iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  38%|███▊      | 769/2000 [19:12<16:41,  1.23iteration/s, mean_rewards=-184]\u001b[A\n",
            "Training:  38%|███▊      | 770/2000 [19:13<17:31,  1.17iteration/s, mean_rewards=-184]\u001b[A\n",
            "Training:  38%|███▊      | 770/2000 [19:13<17:31,  1.17iteration/s, mean_rewards=-270]\u001b[A\n",
            "Training:  39%|███▊      | 771/2000 [19:13<17:52,  1.15iteration/s, mean_rewards=-270]\u001b[A\n",
            "Training:  39%|███▊      | 771/2000 [19:14<17:52,  1.15iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  39%|███▊      | 772/2000 [19:14<18:52,  1.08iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  39%|███▊      | 772/2000 [19:15<18:52,  1.08iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  39%|███▊      | 773/2000 [19:15<18:38,  1.10iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  39%|███▊      | 773/2000 [19:16<18:38,  1.10iteration/s, mean_rewards=-303]\u001b[A\n",
            "Training:  39%|███▊      | 774/2000 [19:17<21:13,  1.04s/iteration, mean_rewards=-303]\u001b[A\n",
            "Training:  39%|███▊      | 774/2000 [19:17<21:13,  1.04s/iteration, mean_rewards=-81.1]\u001b[A\n",
            "Training:  39%|███▉      | 775/2000 [19:18<19:48,  1.03iteration/s, mean_rewards=-81.1]\u001b[A\n",
            "Training:  39%|███▉      | 775/2000 [19:18<19:48,  1.03iteration/s, mean_rewards=-123] \u001b[A\n",
            "Training:  39%|███▉      | 776/2000 [19:18<18:05,  1.13iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  39%|███▉      | 776/2000 [19:19<18:05,  1.13iteration/s, mean_rewards=-167]\u001b[A\n",
            "Training:  39%|███▉      | 777/2000 [19:19<17:33,  1.16iteration/s, mean_rewards=-167]\u001b[A\n",
            "Training:  39%|███▉      | 777/2000 [19:19<17:33,  1.16iteration/s, mean_rewards=-274]\u001b[A\n",
            "Training:  39%|███▉      | 778/2000 [19:20<18:10,  1.12iteration/s, mean_rewards=-274]\u001b[A\n",
            "Training:  39%|███▉      | 778/2000 [19:20<18:10,  1.12iteration/s, mean_rewards=-97] \u001b[A\n",
            "Training:  39%|███▉      | 779/2000 [19:21<17:29,  1.16iteration/s, mean_rewards=-97]\u001b[A\n",
            "Training:  39%|███▉      | 779/2000 [19:21<17:29,  1.16iteration/s, mean_rewards=-89.4]\u001b[A\n",
            "Training:  39%|███▉      | 780/2000 [19:21<16:23,  1.24iteration/s, mean_rewards=-89.4]\u001b[A\n",
            "Training:  39%|███▉      | 780/2000 [19:22<16:23,  1.24iteration/s, mean_rewards=-240] \u001b[A\n",
            "Training:  39%|███▉      | 781/2000 [19:22<17:12,  1.18iteration/s, mean_rewards=-240]\u001b[A\n",
            "Training:  39%|███▉      | 781/2000 [19:23<17:12,  1.18iteration/s, mean_rewards=-260]\u001b[A\n",
            "Training:  39%|███▉      | 782/2000 [19:23<17:59,  1.13iteration/s, mean_rewards=-260]\u001b[A\n",
            "Training:  39%|███▉      | 782/2000 [19:24<17:59,  1.13iteration/s, mean_rewards=-105]\u001b[A\n",
            "Training:  39%|███▉      | 783/2000 [19:24<17:41,  1.15iteration/s, mean_rewards=-105]\u001b[A\n",
            "Training:  39%|███▉      | 783/2000 [19:25<17:41,  1.15iteration/s, mean_rewards=-267]\u001b[A\n",
            "Training:  39%|███▉      | 784/2000 [19:25<17:47,  1.14iteration/s, mean_rewards=-267]\u001b[A\n",
            "Training:  39%|███▉      | 784/2000 [19:25<17:47,  1.14iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  39%|███▉      | 785/2000 [19:26<16:37,  1.22iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  39%|███▉      | 785/2000 [19:26<16:37,  1.22iteration/s, mean_rewards=-291]\u001b[A\n",
            "Training:  39%|███▉      | 786/2000 [19:27<16:25,  1.23iteration/s, mean_rewards=-291]\u001b[A\n",
            "Training:  39%|███▉      | 786/2000 [19:27<16:25,  1.23iteration/s, mean_rewards=-296]\u001b[A\n",
            "Training:  39%|███▉      | 787/2000 [19:28<18:00,  1.12iteration/s, mean_rewards=-296]\u001b[A\n",
            "Training:  39%|███▉      | 787/2000 [19:28<18:00,  1.12iteration/s, mean_rewards=-193]\u001b[A\n",
            "Training:  39%|███▉      | 788/2000 [19:29<21:11,  1.05s/iteration, mean_rewards=-193]\u001b[A\n",
            "Training:  39%|███▉      | 788/2000 [19:29<21:11,  1.05s/iteration, mean_rewards=-321]\u001b[A\n",
            "Training:  39%|███▉      | 789/2000 [19:30<19:36,  1.03iteration/s, mean_rewards=-321]\u001b[A\n",
            "Training:  39%|███▉      | 789/2000 [19:30<19:36,  1.03iteration/s, mean_rewards=-90.6]\u001b[A\n",
            "Training:  40%|███▉      | 790/2000 [19:31<20:06,  1.00iteration/s, mean_rewards=-90.6]\u001b[A\n",
            "Training:  40%|███▉      | 790/2000 [19:31<20:06,  1.00iteration/s, mean_rewards=-217] \u001b[A\n",
            "Training:  40%|███▉      | 791/2000 [19:32<19:05,  1.06iteration/s, mean_rewards=-217]\u001b[A\n",
            "Training:  40%|███▉      | 791/2000 [19:32<19:05,  1.06iteration/s, mean_rewards=-253]\u001b[A\n",
            "Training:  40%|███▉      | 792/2000 [19:33<17:54,  1.12iteration/s, mean_rewards=-253]\u001b[A\n",
            "Training:  40%|███▉      | 792/2000 [19:33<17:54,  1.12iteration/s, mean_rewards=-182]\u001b[A\n",
            "Training:  40%|███▉      | 793/2000 [19:33<17:53,  1.12iteration/s, mean_rewards=-182]\u001b[A\n",
            "Training:  40%|███▉      | 793/2000 [19:34<17:53,  1.12iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  40%|███▉      | 794/2000 [19:34<18:06,  1.11iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  40%|███▉      | 794/2000 [19:35<18:06,  1.11iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  40%|███▉      | 795/2000 [19:35<18:27,  1.09iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  40%|███▉      | 795/2000 [19:36<18:27,  1.09iteration/s, mean_rewards=-406]\u001b[A\n",
            "Training:  40%|███▉      | 796/2000 [19:36<17:55,  1.12iteration/s, mean_rewards=-406]\u001b[A\n",
            "Training:  40%|███▉      | 796/2000 [19:36<17:55,  1.12iteration/s, mean_rewards=-88.2]\u001b[A\n",
            "Training:  40%|███▉      | 797/2000 [19:37<17:18,  1.16iteration/s, mean_rewards=-88.2]\u001b[A\n",
            "Training:  40%|███▉      | 797/2000 [19:37<17:18,  1.16iteration/s, mean_rewards=-151] \u001b[A\n",
            "Training:  40%|███▉      | 798/2000 [19:38<16:16,  1.23iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  40%|███▉      | 798/2000 [19:38<16:16,  1.23iteration/s, mean_rewards=-220]\u001b[A\n",
            "Training:  40%|███▉      | 799/2000 [19:38<15:15,  1.31iteration/s, mean_rewards=-220]\u001b[A\n",
            "Training:  40%|███▉      | 799/2000 [19:39<15:15,  1.31iteration/s, mean_rewards=-198]\u001b[A\n",
            "Training:  40%|████      | 800/2000 [19:39<14:36,  1.37iteration/s, mean_rewards=-198]\u001b[A\n",
            "Training:  40%|████      | 800/2000 [19:39<14:36,  1.37iteration/s, mean_rewards=-195]\u001b[A\n",
            "Training:  40%|████      | 801/2000 [19:40<15:15,  1.31iteration/s, mean_rewards=-195]\u001b[A\n",
            "Training:  40%|████      | 801/2000 [19:40<15:15,  1.31iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  40%|████      | 802/2000 [19:41<18:01,  1.11iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  40%|████      | 802/2000 [19:41<18:01,  1.11iteration/s, mean_rewards=-233]\u001b[A\n",
            "Training:  40%|████      | 803/2000 [19:42<19:16,  1.04iteration/s, mean_rewards=-233]\u001b[A\n",
            "Training:  40%|████      | 803/2000 [19:42<19:16,  1.04iteration/s, mean_rewards=-338]\u001b[A\n",
            "Training:  40%|████      | 804/2000 [19:43<18:22,  1.08iteration/s, mean_rewards=-338]\u001b[A\n",
            "Training:  40%|████      | 804/2000 [19:43<18:22,  1.08iteration/s, mean_rewards=-105]\u001b[A\n",
            "Training:  40%|████      | 805/2000 [19:44<18:29,  1.08iteration/s, mean_rewards=-105]\u001b[A\n",
            "Training:  40%|████      | 805/2000 [19:44<18:29,  1.08iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  40%|████      | 806/2000 [19:45<17:42,  1.12iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  40%|████      | 806/2000 [19:45<17:42,  1.12iteration/s, mean_rewards=-188]\u001b[A\n",
            "Training:  40%|████      | 807/2000 [19:46<18:34,  1.07iteration/s, mean_rewards=-188]\u001b[A\n",
            "Training:  40%|████      | 807/2000 [19:46<18:34,  1.07iteration/s, mean_rewards=-264]\u001b[A\n",
            "Training:  40%|████      | 808/2000 [19:46<17:10,  1.16iteration/s, mean_rewards=-264]\u001b[A\n",
            "Training:  40%|████      | 808/2000 [19:47<17:10,  1.16iteration/s, mean_rewards=-231]\u001b[A\n",
            "Training:  40%|████      | 809/2000 [19:47<16:16,  1.22iteration/s, mean_rewards=-231]\u001b[A\n",
            "Training:  40%|████      | 809/2000 [19:47<16:16,  1.22iteration/s, mean_rewards=-101]\u001b[A\n",
            "Training:  40%|████      | 810/2000 [19:48<15:37,  1.27iteration/s, mean_rewards=-101]\u001b[A\n",
            "Training:  40%|████      | 810/2000 [19:48<15:37,  1.27iteration/s, mean_rewards=-167]\u001b[A\n",
            "Training:  41%|████      | 811/2000 [19:49<15:48,  1.25iteration/s, mean_rewards=-167]\u001b[A\n",
            "Training:  41%|████      | 811/2000 [19:49<15:48,  1.25iteration/s, mean_rewards=-152]\u001b[A\n",
            "Training:  41%|████      | 812/2000 [19:49<15:52,  1.25iteration/s, mean_rewards=-152]\u001b[A\n",
            "Training:  41%|████      | 812/2000 [19:50<15:52,  1.25iteration/s, mean_rewards=-334]\u001b[A\n",
            "Training:  41%|████      | 813/2000 [19:50<16:06,  1.23iteration/s, mean_rewards=-334]\u001b[A\n",
            "Training:  41%|████      | 813/2000 [19:51<16:06,  1.23iteration/s, mean_rewards=-402]\u001b[A\n",
            "Training:  41%|████      | 814/2000 [19:51<16:56,  1.17iteration/s, mean_rewards=-402]\u001b[A\n",
            "Training:  41%|████      | 814/2000 [19:52<16:56,  1.17iteration/s, mean_rewards=-216]\u001b[A\n",
            "Training:  41%|████      | 815/2000 [19:52<17:57,  1.10iteration/s, mean_rewards=-216]\u001b[A\n",
            "Training:  41%|████      | 815/2000 [19:53<17:57,  1.10iteration/s, mean_rewards=-168]\u001b[A\n",
            "Training:  41%|████      | 816/2000 [19:53<18:38,  1.06iteration/s, mean_rewards=-168]\u001b[A\n",
            "Training:  41%|████      | 816/2000 [19:54<18:38,  1.06iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  41%|████      | 817/2000 [19:54<19:54,  1.01s/iteration, mean_rewards=-123]\u001b[A\n",
            "Training:  41%|████      | 817/2000 [19:55<19:54,  1.01s/iteration, mean_rewards=-174]\u001b[A\n",
            "Training:  41%|████      | 818/2000 [19:56<20:09,  1.02s/iteration, mean_rewards=-174]\u001b[A\n",
            "Training:  41%|████      | 818/2000 [19:56<20:09,  1.02s/iteration, mean_rewards=-82.7]\u001b[A\n",
            "Training:  41%|████      | 819/2000 [19:56<19:30,  1.01iteration/s, mean_rewards=-82.7]\u001b[A\n",
            "Training:  41%|████      | 819/2000 [19:57<19:30,  1.01iteration/s, mean_rewards=-318] \u001b[A\n",
            "Training:  41%|████      | 820/2000 [19:57<19:11,  1.02iteration/s, mean_rewards=-318]\u001b[A\n",
            "Training:  41%|████      | 820/2000 [19:58<19:11,  1.02iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  41%|████      | 821/2000 [19:58<17:14,  1.14iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  41%|████      | 821/2000 [19:58<17:14,  1.14iteration/s, mean_rewards=-337]\u001b[A\n",
            "Training:  41%|████      | 822/2000 [19:59<18:14,  1.08iteration/s, mean_rewards=-337]\u001b[A\n",
            "Training:  41%|████      | 822/2000 [19:59<18:14,  1.08iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  41%|████      | 823/2000 [20:00<18:26,  1.06iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  41%|████      | 823/2000 [20:00<18:26,  1.06iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  41%|████      | 824/2000 [20:01<19:09,  1.02iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  41%|████      | 824/2000 [20:01<19:09,  1.02iteration/s, mean_rewards=-80.8]\u001b[A\n",
            "Training:  41%|████▏     | 825/2000 [20:02<18:49,  1.04iteration/s, mean_rewards=-80.8]\u001b[A\n",
            "Training:  41%|████▏     | 825/2000 [20:02<18:49,  1.04iteration/s, mean_rewards=-196] \u001b[A\n",
            "Training:  41%|████▏     | 826/2000 [20:03<17:12,  1.14iteration/s, mean_rewards=-196]\u001b[A\n",
            "Training:  41%|████▏     | 826/2000 [20:03<17:12,  1.14iteration/s, mean_rewards=-169]\u001b[A\n",
            "Training:  41%|████▏     | 827/2000 [20:04<18:21,  1.06iteration/s, mean_rewards=-169]\u001b[A\n",
            "Training:  41%|████▏     | 827/2000 [20:04<18:21,  1.06iteration/s, mean_rewards=-182]\u001b[A\n",
            "Training:  41%|████▏     | 828/2000 [20:05<18:43,  1.04iteration/s, mean_rewards=-182]\u001b[A\n",
            "Training:  41%|████▏     | 828/2000 [20:05<18:43,  1.04iteration/s, mean_rewards=-341]\u001b[A\n",
            "Training:  41%|████▏     | 829/2000 [20:06<19:49,  1.02s/iteration, mean_rewards=-341]\u001b[A\n",
            "Training:  41%|████▏     | 829/2000 [20:06<19:49,  1.02s/iteration, mean_rewards=-185]\u001b[A\n",
            "Training:  42%|████▏     | 830/2000 [20:07<19:33,  1.00s/iteration, mean_rewards=-185]\u001b[A\n",
            "Training:  42%|████▏     | 830/2000 [20:07<19:33,  1.00s/iteration, mean_rewards=-107]\u001b[A\n",
            "Training:  42%|████▏     | 831/2000 [20:08<20:08,  1.03s/iteration, mean_rewards=-107]\u001b[A\n",
            "Training:  42%|████▏     | 831/2000 [20:08<20:08,  1.03s/iteration, mean_rewards=-258]\u001b[A\n",
            "Training:  42%|████▏     | 832/2000 [20:09<20:08,  1.03s/iteration, mean_rewards=-258]\u001b[A\n",
            "Training:  42%|████▏     | 832/2000 [20:09<20:08,  1.03s/iteration, mean_rewards=-227]\u001b[A\n",
            "Training:  42%|████▏     | 833/2000 [20:10<19:10,  1.01iteration/s, mean_rewards=-227]\u001b[A\n",
            "Training:  42%|████▏     | 833/2000 [20:10<19:10,  1.01iteration/s, mean_rewards=-101]\u001b[A\n",
            "Training:  42%|████▏     | 834/2000 [20:11<18:22,  1.06iteration/s, mean_rewards=-101]\u001b[A\n",
            "Training:  42%|████▏     | 834/2000 [20:11<18:22,  1.06iteration/s, mean_rewards=-179]\u001b[A\n",
            "Training:  42%|████▏     | 835/2000 [20:12<17:46,  1.09iteration/s, mean_rewards=-179]\u001b[A\n",
            "Training:  42%|████▏     | 835/2000 [20:12<17:46,  1.09iteration/s, mean_rewards=-244]\u001b[A\n",
            "Training:  42%|████▏     | 836/2000 [20:13<17:50,  1.09iteration/s, mean_rewards=-244]\u001b[A\n",
            "Training:  42%|████▏     | 836/2000 [20:13<17:50,  1.09iteration/s, mean_rewards=-223]\u001b[A\n",
            "Training:  42%|████▏     | 837/2000 [20:14<18:04,  1.07iteration/s, mean_rewards=-223]\u001b[A\n",
            "Training:  42%|████▏     | 837/2000 [20:14<18:04,  1.07iteration/s, mean_rewards=-159]\u001b[A\n",
            "Training:  42%|████▏     | 838/2000 [20:14<17:15,  1.12iteration/s, mean_rewards=-159]\u001b[A\n",
            "Training:  42%|████▏     | 838/2000 [20:15<17:15,  1.12iteration/s, mean_rewards=-252]\u001b[A\n",
            "Training:  42%|████▏     | 839/2000 [20:15<18:05,  1.07iteration/s, mean_rewards=-252]\u001b[A\n",
            "Training:  42%|████▏     | 839/2000 [20:16<18:05,  1.07iteration/s, mean_rewards=-237]\u001b[A\n",
            "Training:  42%|████▏     | 840/2000 [20:16<17:22,  1.11iteration/s, mean_rewards=-237]\u001b[A\n",
            "Training:  42%|████▏     | 840/2000 [20:17<17:22,  1.11iteration/s, mean_rewards=-264]\u001b[A\n",
            "Training:  42%|████▏     | 841/2000 [20:17<16:51,  1.15iteration/s, mean_rewards=-264]\u001b[A\n",
            "Training:  42%|████▏     | 841/2000 [20:17<16:51,  1.15iteration/s, mean_rewards=-236]\u001b[A\n",
            "Training:  42%|████▏     | 842/2000 [20:18<17:07,  1.13iteration/s, mean_rewards=-236]\u001b[A\n",
            "Training:  42%|████▏     | 842/2000 [20:18<17:07,  1.13iteration/s, mean_rewards=-262]\u001b[A\n",
            "Training:  42%|████▏     | 843/2000 [20:19<18:51,  1.02iteration/s, mean_rewards=-262]\u001b[A\n",
            "Training:  42%|████▏     | 843/2000 [20:20<18:51,  1.02iteration/s, mean_rewards=-68.4]\u001b[A\n",
            "Training:  42%|████▏     | 844/2000 [20:21<21:25,  1.11s/iteration, mean_rewards=-68.4]\u001b[A\n",
            "Training:  42%|████▏     | 844/2000 [20:21<21:25,  1.11s/iteration, mean_rewards=-141] \u001b[A\n",
            "Training:  42%|████▏     | 845/2000 [20:22<21:00,  1.09s/iteration, mean_rewards=-141]\u001b[A\n",
            "Training:  42%|████▏     | 845/2000 [20:22<21:00,  1.09s/iteration, mean_rewards=-358]\u001b[A\n",
            "Training:  42%|████▏     | 846/2000 [20:22<19:32,  1.02s/iteration, mean_rewards=-358]\u001b[A\n",
            "Training:  42%|████▏     | 846/2000 [20:23<19:32,  1.02s/iteration, mean_rewards=-210]\u001b[A\n",
            "Training:  42%|████▏     | 847/2000 [20:23<18:34,  1.03iteration/s, mean_rewards=-210]\u001b[A\n",
            "Training:  42%|████▏     | 847/2000 [20:24<18:34,  1.03iteration/s, mean_rewards=-325]\u001b[A\n",
            "Training:  42%|████▏     | 848/2000 [20:24<17:41,  1.09iteration/s, mean_rewards=-325]\u001b[A\n",
            "Training:  42%|████▏     | 848/2000 [20:24<17:41,  1.09iteration/s, mean_rewards=-233]\u001b[A\n",
            "Training:  42%|████▏     | 849/2000 [20:25<17:27,  1.10iteration/s, mean_rewards=-233]\u001b[A\n",
            "Training:  42%|████▏     | 849/2000 [20:25<17:27,  1.10iteration/s, mean_rewards=-337]\u001b[A\n",
            "Training:  42%|████▎     | 850/2000 [20:26<17:00,  1.13iteration/s, mean_rewards=-337]\u001b[A\n",
            "Training:  42%|████▎     | 850/2000 [20:26<17:00,  1.13iteration/s, mean_rewards=-257]\u001b[A\n",
            "Training:  43%|████▎     | 851/2000 [20:26<15:53,  1.21iteration/s, mean_rewards=-257]\u001b[A\n",
            "Training:  43%|████▎     | 851/2000 [20:27<15:53,  1.21iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  43%|████▎     | 852/2000 [20:27<16:08,  1.18iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  43%|████▎     | 852/2000 [20:28<16:08,  1.18iteration/s, mean_rewards=-201]\u001b[A\n",
            "Training:  43%|████▎     | 853/2000 [20:28<16:56,  1.13iteration/s, mean_rewards=-201]\u001b[A\n",
            "Training:  43%|████▎     | 853/2000 [20:29<16:56,  1.13iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  43%|████▎     | 854/2000 [20:29<16:13,  1.18iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  43%|████▎     | 854/2000 [20:29<16:13,  1.18iteration/s, mean_rewards=-295]\u001b[A\n",
            "Training:  43%|████▎     | 855/2000 [20:30<16:22,  1.17iteration/s, mean_rewards=-295]\u001b[A\n",
            "Training:  43%|████▎     | 855/2000 [20:30<16:22,  1.17iteration/s, mean_rewards=-298]\u001b[A\n",
            "Training:  43%|████▎     | 856/2000 [20:31<18:29,  1.03iteration/s, mean_rewards=-298]\u001b[A\n",
            "Training:  43%|████▎     | 856/2000 [20:32<18:29,  1.03iteration/s, mean_rewards=-226]\u001b[A\n",
            "Training:  43%|████▎     | 857/2000 [20:32<18:45,  1.02iteration/s, mean_rewards=-226]\u001b[A\n",
            "Training:  43%|████▎     | 857/2000 [20:33<18:45,  1.02iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  43%|████▎     | 858/2000 [20:33<19:10,  1.01s/iteration, mean_rewards=-131]\u001b[A\n",
            "Training:  43%|████▎     | 858/2000 [20:34<19:10,  1.01s/iteration, mean_rewards=-282]\u001b[A\n",
            "Training:  43%|████▎     | 859/2000 [20:34<18:35,  1.02iteration/s, mean_rewards=-282]\u001b[A\n",
            "Training:  43%|████▎     | 859/2000 [20:35<18:35,  1.02iteration/s, mean_rewards=-239]\u001b[A\n",
            "Training:  43%|████▎     | 860/2000 [20:35<18:21,  1.03iteration/s, mean_rewards=-239]\u001b[A\n",
            "Training:  43%|████▎     | 860/2000 [20:35<18:21,  1.03iteration/s, mean_rewards=-163]\u001b[A\n",
            "Training:  43%|████▎     | 861/2000 [20:36<17:29,  1.08iteration/s, mean_rewards=-163]\u001b[A\n",
            "Training:  43%|████▎     | 861/2000 [20:36<17:29,  1.08iteration/s, mean_rewards=-186]\u001b[A\n",
            "Training:  43%|████▎     | 862/2000 [20:37<16:42,  1.13iteration/s, mean_rewards=-186]\u001b[A\n",
            "Training:  43%|████▎     | 862/2000 [20:37<16:42,  1.13iteration/s, mean_rewards=-89.7]\u001b[A\n",
            "Training:  43%|████▎     | 863/2000 [20:37<15:24,  1.23iteration/s, mean_rewards=-89.7]\u001b[A\n",
            "Training:  43%|████▎     | 863/2000 [20:38<15:24,  1.23iteration/s, mean_rewards=-171] \u001b[A\n",
            "Training:  43%|████▎     | 864/2000 [20:38<14:34,  1.30iteration/s, mean_rewards=-171]\u001b[A\n",
            "Training:  43%|████▎     | 864/2000 [20:38<14:34,  1.30iteration/s, mean_rewards=-64.9]\u001b[A\n",
            "Training:  43%|████▎     | 865/2000 [20:39<14:46,  1.28iteration/s, mean_rewards=-64.9]\u001b[A\n",
            "Training:  43%|████▎     | 865/2000 [20:39<14:46,  1.28iteration/s, mean_rewards=-197] \u001b[A\n",
            "Training:  43%|████▎     | 866/2000 [20:40<15:52,  1.19iteration/s, mean_rewards=-197]\u001b[A\n",
            "Training:  43%|████▎     | 866/2000 [20:40<15:52,  1.19iteration/s, mean_rewards=-119]\u001b[A\n",
            "Training:  43%|████▎     | 867/2000 [20:41<15:04,  1.25iteration/s, mean_rewards=-119]\u001b[A\n",
            "Training:  43%|████▎     | 867/2000 [20:41<15:04,  1.25iteration/s, mean_rewards=-207]\u001b[A\n",
            "Training:  43%|████▎     | 868/2000 [20:41<15:39,  1.20iteration/s, mean_rewards=-207]\u001b[A\n",
            "Training:  43%|████▎     | 868/2000 [20:42<15:39,  1.20iteration/s, mean_rewards=-289]\u001b[A\n",
            "Training:  43%|████▎     | 869/2000 [20:43<16:59,  1.11iteration/s, mean_rewards=-289]\u001b[A\n",
            "Training:  43%|████▎     | 869/2000 [20:43<16:59,  1.11iteration/s, mean_rewards=-252]\u001b[A\n",
            "Training:  44%|████▎     | 870/2000 [20:43<17:06,  1.10iteration/s, mean_rewards=-252]\u001b[A\n",
            "Training:  44%|████▎     | 870/2000 [20:44<17:06,  1.10iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:  44%|████▎     | 871/2000 [20:44<16:57,  1.11iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:  44%|████▎     | 871/2000 [20:45<16:57,  1.11iteration/s, mean_rewards=-285]\u001b[A\n",
            "Training:  44%|████▎     | 872/2000 [20:45<17:20,  1.08iteration/s, mean_rewards=-285]\u001b[A\n",
            "Training:  44%|████▎     | 872/2000 [20:46<17:20,  1.08iteration/s, mean_rewards=-164]\u001b[A\n",
            "Training:  44%|████▎     | 873/2000 [20:46<18:22,  1.02iteration/s, mean_rewards=-164]\u001b[A\n",
            "Training:  44%|████▎     | 873/2000 [20:47<18:22,  1.02iteration/s, mean_rewards=-109]\u001b[A\n",
            "Training:  44%|████▎     | 874/2000 [20:47<18:10,  1.03iteration/s, mean_rewards=-109]\u001b[A\n",
            "Training:  44%|████▎     | 874/2000 [20:48<18:10,  1.03iteration/s, mean_rewards=-320]\u001b[A\n",
            "Training:  44%|████▍     | 875/2000 [20:49<19:25,  1.04s/iteration, mean_rewards=-320]\u001b[A\n",
            "Training:  44%|████▍     | 875/2000 [20:49<19:25,  1.04s/iteration, mean_rewards=-187]\u001b[A\n",
            "Training:  44%|████▍     | 876/2000 [20:50<18:53,  1.01s/iteration, mean_rewards=-187]\u001b[A\n",
            "Training:  44%|████▍     | 876/2000 [20:50<18:53,  1.01s/iteration, mean_rewards=-192]\u001b[A\n",
            "Training:  44%|████▍     | 877/2000 [20:51<19:27,  1.04s/iteration, mean_rewards=-192]\u001b[A\n",
            "Training:  44%|████▍     | 877/2000 [20:51<19:27,  1.04s/iteration, mean_rewards=-241]\u001b[A\n",
            "Training:  44%|████▍     | 878/2000 [20:51<18:16,  1.02iteration/s, mean_rewards=-241]\u001b[A\n",
            "Training:  44%|████▍     | 878/2000 [20:52<18:16,  1.02iteration/s, mean_rewards=-231]\u001b[A\n",
            "Training:  44%|████▍     | 879/2000 [20:53<18:52,  1.01s/iteration, mean_rewards=-231]\u001b[A\n",
            "Training:  44%|████▍     | 879/2000 [20:53<18:52,  1.01s/iteration, mean_rewards=-178]\u001b[A\n",
            "Training:  44%|████▍     | 880/2000 [20:53<17:44,  1.05iteration/s, mean_rewards=-178]\u001b[A\n",
            "Training:  44%|████▍     | 880/2000 [20:54<17:44,  1.05iteration/s, mean_rewards=-322]\u001b[A\n",
            "Training:  44%|████▍     | 881/2000 [20:54<16:49,  1.11iteration/s, mean_rewards=-322]\u001b[A\n",
            "Training:  44%|████▍     | 881/2000 [20:54<16:49,  1.11iteration/s, mean_rewards=-232]\u001b[A\n",
            "Training:  44%|████▍     | 882/2000 [20:55<15:41,  1.19iteration/s, mean_rewards=-232]\u001b[A\n",
            "Training:  44%|████▍     | 882/2000 [20:55<15:41,  1.19iteration/s, mean_rewards=-172]\u001b[A\n",
            "Training:  44%|████▍     | 883/2000 [20:56<15:23,  1.21iteration/s, mean_rewards=-172]\u001b[A\n",
            "Training:  44%|████▍     | 883/2000 [20:56<15:23,  1.21iteration/s, mean_rewards=-189]\u001b[A\n",
            "Training:  44%|████▍     | 884/2000 [20:57<16:17,  1.14iteration/s, mean_rewards=-189]\u001b[A\n",
            "Training:  44%|████▍     | 884/2000 [20:57<16:17,  1.14iteration/s, mean_rewards=-221]\u001b[A\n",
            "Training:  44%|████▍     | 885/2000 [20:58<16:47,  1.11iteration/s, mean_rewards=-221]\u001b[A\n",
            "Training:  44%|████▍     | 885/2000 [20:58<16:47,  1.11iteration/s, mean_rewards=-258]\u001b[A\n",
            "Training:  44%|████▍     | 886/2000 [20:59<20:23,  1.10s/iteration, mean_rewards=-258]\u001b[A\n",
            "Training:  44%|████▍     | 886/2000 [21:00<20:23,  1.10s/iteration, mean_rewards=-254]\u001b[A\n",
            "Training:  44%|████▍     | 887/2000 [21:00<20:27,  1.10s/iteration, mean_rewards=-254]\u001b[A\n",
            "Training:  44%|████▍     | 887/2000 [21:01<20:27,  1.10s/iteration, mean_rewards=-119]\u001b[A\n",
            "Training:  44%|████▍     | 888/2000 [21:01<19:30,  1.05s/iteration, mean_rewards=-119]\u001b[A\n",
            "Training:  44%|████▍     | 888/2000 [21:02<19:30,  1.05s/iteration, mean_rewards=-39.7]\u001b[A\n",
            "Training:  44%|████▍     | 889/2000 [21:02<18:03,  1.02iteration/s, mean_rewards=-39.7]\u001b[A\n",
            "Training:  44%|████▍     | 889/2000 [21:02<18:03,  1.02iteration/s, mean_rewards=-227] \u001b[A\n",
            "Training:  44%|████▍     | 890/2000 [21:03<17:13,  1.07iteration/s, mean_rewards=-227]\u001b[A\n",
            "Training:  44%|████▍     | 890/2000 [21:03<17:13,  1.07iteration/s, mean_rewards=-353]\u001b[A\n",
            "Training:  45%|████▍     | 891/2000 [21:04<16:36,  1.11iteration/s, mean_rewards=-353]\u001b[A\n",
            "Training:  45%|████▍     | 891/2000 [21:04<16:36,  1.11iteration/s, mean_rewards=-212]\u001b[A\n",
            "Training:  45%|████▍     | 892/2000 [21:05<17:47,  1.04iteration/s, mean_rewards=-212]\u001b[A\n",
            "Training:  45%|████▍     | 892/2000 [21:05<17:47,  1.04iteration/s, mean_rewards=-87] \u001b[A\n",
            "Training:  45%|████▍     | 893/2000 [21:06<17:31,  1.05iteration/s, mean_rewards=-87]\u001b[A\n",
            "Training:  45%|████▍     | 893/2000 [21:06<17:31,  1.05iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  45%|████▍     | 894/2000 [21:07<16:50,  1.09iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  45%|████▍     | 894/2000 [21:07<16:50,  1.09iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  45%|████▍     | 895/2000 [21:07<16:45,  1.10iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  45%|████▍     | 895/2000 [21:08<16:45,  1.10iteration/s, mean_rewards=-157]\u001b[A\n",
            "Training:  45%|████▍     | 896/2000 [21:08<15:30,  1.19iteration/s, mean_rewards=-157]\u001b[A\n",
            "Training:  45%|████▍     | 896/2000 [21:08<15:30,  1.19iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  45%|████▍     | 897/2000 [21:09<17:10,  1.07iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  45%|████▍     | 897/2000 [21:10<17:10,  1.07iteration/s, mean_rewards=-81.2]\u001b[A\n",
            "Training:  45%|████▍     | 898/2000 [21:10<16:43,  1.10iteration/s, mean_rewards=-81.2]\u001b[A\n",
            "Training:  45%|████▍     | 898/2000 [21:11<16:43,  1.10iteration/s, mean_rewards=-296] \u001b[A\n",
            "Training:  45%|████▍     | 899/2000 [21:11<18:43,  1.02s/iteration, mean_rewards=-296]\u001b[A\n",
            "Training:  45%|████▍     | 899/2000 [21:12<18:43,  1.02s/iteration, mean_rewards=-203]\u001b[A\n",
            "Training:  45%|████▌     | 900/2000 [21:12<17:59,  1.02iteration/s, mean_rewards=-203]\u001b[A\n",
            "Training:  45%|████▌     | 900/2000 [21:13<17:59,  1.02iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:  45%|████▌     | 901/2000 [21:13<17:31,  1.04iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:  45%|████▌     | 901/2000 [21:13<17:31,  1.04iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  45%|████▌     | 902/2000 [21:14<16:06,  1.14iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  45%|████▌     | 902/2000 [21:14<16:06,  1.14iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  45%|████▌     | 903/2000 [21:15<16:28,  1.11iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  45%|████▌     | 903/2000 [21:15<16:28,  1.11iteration/s, mean_rewards=-289]\u001b[A\n",
            "Training:  45%|████▌     | 904/2000 [21:15<15:03,  1.21iteration/s, mean_rewards=-289]\u001b[A\n",
            "Training:  45%|████▌     | 904/2000 [21:16<15:03,  1.21iteration/s, mean_rewards=-258]\u001b[A\n",
            "Training:  45%|████▌     | 905/2000 [21:16<14:54,  1.22iteration/s, mean_rewards=-258]\u001b[A\n",
            "Training:  45%|████▌     | 905/2000 [21:17<14:54,  1.22iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  45%|████▌     | 906/2000 [21:17<13:56,  1.31iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  45%|████▌     | 906/2000 [21:17<13:56,  1.31iteration/s, mean_rewards=-239]\u001b[A\n",
            "Training:  45%|████▌     | 907/2000 [21:18<14:00,  1.30iteration/s, mean_rewards=-239]\u001b[A\n",
            "Training:  45%|████▌     | 907/2000 [21:18<14:00,  1.30iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  45%|████▌     | 908/2000 [21:19<14:47,  1.23iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  45%|████▌     | 908/2000 [21:19<14:47,  1.23iteration/s, mean_rewards=-174]\u001b[A\n",
            "Training:  45%|████▌     | 909/2000 [21:19<14:54,  1.22iteration/s, mean_rewards=-174]\u001b[A\n",
            "Training:  45%|████▌     | 909/2000 [21:20<14:54,  1.22iteration/s, mean_rewards=-254]\u001b[A\n",
            "Training:  46%|████▌     | 910/2000 [21:21<16:48,  1.08iteration/s, mean_rewards=-254]\u001b[A\n",
            "Training:  46%|████▌     | 910/2000 [21:21<16:48,  1.08iteration/s, mean_rewards=-209]\u001b[A\n",
            "Training:  46%|████▌     | 911/2000 [21:22<16:44,  1.08iteration/s, mean_rewards=-209]\u001b[A\n",
            "Training:  46%|████▌     | 911/2000 [21:22<16:44,  1.08iteration/s, mean_rewards=-282]\u001b[A\n",
            "Training:  46%|████▌     | 912/2000 [21:23<17:33,  1.03iteration/s, mean_rewards=-282]\u001b[A\n",
            "Training:  46%|████▌     | 912/2000 [21:23<17:33,  1.03iteration/s, mean_rewards=-191]\u001b[A\n",
            "Training:  46%|████▌     | 913/2000 [21:24<18:31,  1.02s/iteration, mean_rewards=-191]\u001b[A\n",
            "Training:  46%|████▌     | 913/2000 [21:24<18:31,  1.02s/iteration, mean_rewards=-238]\u001b[A\n",
            "Training:  46%|████▌     | 914/2000 [21:25<19:08,  1.06s/iteration, mean_rewards=-238]\u001b[A\n",
            "Training:  46%|████▌     | 914/2000 [21:25<19:08,  1.06s/iteration, mean_rewards=-47.5]\u001b[A\n",
            "Training:  46%|████▌     | 915/2000 [21:26<18:33,  1.03s/iteration, mean_rewards=-47.5]\u001b[A\n",
            "Training:  46%|████▌     | 915/2000 [21:26<18:33,  1.03s/iteration, mean_rewards=-166] \u001b[A\n",
            "Training:  46%|████▌     | 916/2000 [21:27<19:08,  1.06s/iteration, mean_rewards=-166]\u001b[A\n",
            "Training:  46%|████▌     | 916/2000 [21:27<19:08,  1.06s/iteration, mean_rewards=-40] \u001b[A\n",
            "Training:  46%|████▌     | 917/2000 [21:28<18:25,  1.02s/iteration, mean_rewards=-40]\u001b[A\n",
            "Training:  46%|████▌     | 917/2000 [21:28<18:25,  1.02s/iteration, mean_rewards=-209]\u001b[A\n",
            "Training:  46%|████▌     | 918/2000 [21:29<18:43,  1.04s/iteration, mean_rewards=-209]\u001b[A\n",
            "Training:  46%|████▌     | 918/2000 [21:29<18:43,  1.04s/iteration, mean_rewards=-158]\u001b[A\n",
            "Training:  46%|████▌     | 919/2000 [21:30<17:23,  1.04iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  46%|████▌     | 919/2000 [21:30<17:23,  1.04iteration/s, mean_rewards=-522]\u001b[A\n",
            "Training:  46%|████▌     | 920/2000 [21:31<17:09,  1.05iteration/s, mean_rewards=-522]\u001b[A\n",
            "Training:  46%|████▌     | 920/2000 [21:31<17:09,  1.05iteration/s, mean_rewards=-163]\u001b[A\n",
            "Training:  46%|████▌     | 921/2000 [21:32<17:45,  1.01iteration/s, mean_rewards=-163]\u001b[A\n",
            "Training:  46%|████▌     | 921/2000 [21:32<17:45,  1.01iteration/s, mean_rewards=-230]\u001b[A\n",
            "Training:  46%|████▌     | 922/2000 [21:33<16:51,  1.07iteration/s, mean_rewards=-230]\u001b[A\n",
            "Training:  46%|████▌     | 922/2000 [21:33<16:51,  1.07iteration/s, mean_rewards=-249]\u001b[A\n",
            "Training:  46%|████▌     | 923/2000 [21:34<16:56,  1.06iteration/s, mean_rewards=-249]\u001b[A\n",
            "Training:  46%|████▌     | 923/2000 [21:34<16:56,  1.06iteration/s, mean_rewards=-208]\u001b[A\n",
            "Training:  46%|████▌     | 924/2000 [21:35<17:58,  1.00s/iteration, mean_rewards=-208]\u001b[A\n",
            "Training:  46%|████▌     | 924/2000 [21:35<17:58,  1.00s/iteration, mean_rewards=-115]\u001b[A\n",
            "Training:  46%|████▋     | 925/2000 [21:36<17:38,  1.02iteration/s, mean_rewards=-115]\u001b[A\n",
            "Training:  46%|████▋     | 925/2000 [21:36<17:38,  1.02iteration/s, mean_rewards=-168]\u001b[A\n",
            "Training:  46%|████▋     | 926/2000 [21:37<18:22,  1.03s/iteration, mean_rewards=-168]\u001b[A\n",
            "Training:  46%|████▋     | 926/2000 [21:38<18:22,  1.03s/iteration, mean_rewards=-39.5]\u001b[A\n",
            "Training:  46%|████▋     | 927/2000 [21:39<26:06,  1.46s/iteration, mean_rewards=-39.5]\u001b[A\n",
            "Training:  46%|████▋     | 927/2000 [21:40<26:06,  1.46s/iteration, mean_rewards=-165] \u001b[A\n",
            "Training:  46%|████▋     | 928/2000 [21:40<22:24,  1.25s/iteration, mean_rewards=-165]\u001b[A\n",
            "Training:  46%|████▋     | 928/2000 [21:40<22:24,  1.25s/iteration, mean_rewards=-276]\u001b[A\n",
            "Training:  46%|████▋     | 929/2000 [21:41<21:20,  1.20s/iteration, mean_rewards=-276]\u001b[A\n",
            "Training:  46%|████▋     | 929/2000 [21:41<21:20,  1.20s/iteration, mean_rewards=-236]\u001b[A\n",
            "Training:  46%|████▋     | 930/2000 [21:42<19:46,  1.11s/iteration, mean_rewards=-236]\u001b[A\n",
            "Training:  46%|████▋     | 930/2000 [21:42<19:46,  1.11s/iteration, mean_rewards=-186]\u001b[A\n",
            "Training:  47%|████▋     | 931/2000 [21:43<18:16,  1.03s/iteration, mean_rewards=-186]\u001b[A\n",
            "Training:  47%|████▋     | 931/2000 [21:43<18:16,  1.03s/iteration, mean_rewards=-170]\u001b[A\n",
            "Training:  47%|████▋     | 932/2000 [21:44<17:06,  1.04iteration/s, mean_rewards=-170]\u001b[A\n",
            "Training:  47%|████▋     | 932/2000 [21:44<17:06,  1.04iteration/s, mean_rewards=-246]\u001b[A\n",
            "Training:  47%|████▋     | 933/2000 [21:44<16:06,  1.10iteration/s, mean_rewards=-246]\u001b[A\n",
            "Training:  47%|████▋     | 933/2000 [21:45<16:06,  1.10iteration/s, mean_rewards=-238]\u001b[A\n",
            "Training:  47%|████▋     | 934/2000 [21:45<15:31,  1.14iteration/s, mean_rewards=-238]\u001b[A\n",
            "Training:  47%|████▋     | 934/2000 [21:46<15:31,  1.14iteration/s, mean_rewards=-359]\u001b[A\n",
            "Training:  47%|████▋     | 935/2000 [21:46<16:39,  1.07iteration/s, mean_rewards=-359]\u001b[A\n",
            "Training:  47%|████▋     | 935/2000 [21:47<16:39,  1.07iteration/s, mean_rewards=-92.4]\u001b[A\n",
            "Training:  47%|████▋     | 936/2000 [21:47<17:27,  1.02iteration/s, mean_rewards=-92.4]\u001b[A\n",
            "Training:  47%|████▋     | 936/2000 [21:48<17:27,  1.02iteration/s, mean_rewards=-75.9]\u001b[A\n",
            "Training:  47%|████▋     | 937/2000 [21:49<20:12,  1.14s/iteration, mean_rewards=-75.9]\u001b[A\n",
            "Training:  47%|████▋     | 937/2000 [21:50<20:12,  1.14s/iteration, mean_rewards=-253] \u001b[A\n",
            "Training:  47%|████▋     | 938/2000 [21:50<21:09,  1.20s/iteration, mean_rewards=-253]\u001b[A\n",
            "Training:  47%|████▋     | 938/2000 [21:51<21:09,  1.20s/iteration, mean_rewards=-96.5]\u001b[A\n",
            "Training:  47%|████▋     | 939/2000 [21:51<20:35,  1.16s/iteration, mean_rewards=-96.5]\u001b[A\n",
            "Training:  47%|████▋     | 939/2000 [21:52<20:35,  1.16s/iteration, mean_rewards=-213] \u001b[A\n",
            "Training:  47%|████▋     | 940/2000 [21:52<19:24,  1.10s/iteration, mean_rewards=-213]\u001b[A\n",
            "Training:  47%|████▋     | 940/2000 [21:53<19:24,  1.10s/iteration, mean_rewards=-96.2]\u001b[A\n",
            "Training:  47%|████▋     | 941/2000 [21:53<17:18,  1.02iteration/s, mean_rewards=-96.2]\u001b[A\n",
            "Training:  47%|████▋     | 941/2000 [21:53<17:18,  1.02iteration/s, mean_rewards=-223] \u001b[A\n",
            "Training:  47%|████▋     | 942/2000 [21:54<16:19,  1.08iteration/s, mean_rewards=-223]\u001b[A\n",
            "Training:  47%|████▋     | 942/2000 [21:54<16:19,  1.08iteration/s, mean_rewards=-212]\u001b[A\n",
            "Training:  47%|████▋     | 943/2000 [21:55<15:37,  1.13iteration/s, mean_rewards=-212]\u001b[A\n",
            "Training:  47%|████▋     | 943/2000 [21:55<15:37,  1.13iteration/s, mean_rewards=-230]\u001b[A\n",
            "Training:  47%|████▋     | 944/2000 [21:55<15:13,  1.16iteration/s, mean_rewards=-230]\u001b[A\n",
            "Training:  47%|████▋     | 944/2000 [21:56<15:13,  1.16iteration/s, mean_rewards=-167]\u001b[A\n",
            "Training:  47%|████▋     | 945/2000 [21:56<16:18,  1.08iteration/s, mean_rewards=-167]\u001b[A\n",
            "Training:  47%|████▋     | 945/2000 [21:57<16:18,  1.08iteration/s, mean_rewards=-91.4]\u001b[A\n",
            "Training:  47%|████▋     | 946/2000 [21:57<15:07,  1.16iteration/s, mean_rewards=-91.4]\u001b[A\n",
            "Training:  47%|████▋     | 946/2000 [21:57<15:07,  1.16iteration/s, mean_rewards=-87.7]\u001b[A\n",
            "Training:  47%|████▋     | 947/2000 [21:58<14:52,  1.18iteration/s, mean_rewards=-87.7]\u001b[A\n",
            "Training:  47%|████▋     | 947/2000 [21:58<14:52,  1.18iteration/s, mean_rewards=-222] \u001b[A\n",
            "Training:  47%|████▋     | 948/2000 [21:59<14:35,  1.20iteration/s, mean_rewards=-222]\u001b[A\n",
            "Training:  47%|████▋     | 948/2000 [21:59<14:35,  1.20iteration/s, mean_rewards=-157]\u001b[A\n",
            "Training:  47%|████▋     | 949/2000 [21:59<13:49,  1.27iteration/s, mean_rewards=-157]\u001b[A\n",
            "Training:  47%|████▋     | 949/2000 [22:00<13:49,  1.27iteration/s, mean_rewards=-232]\u001b[A\n",
            "Training:  48%|████▊     | 950/2000 [22:01<16:11,  1.08iteration/s, mean_rewards=-232]\u001b[A\n",
            "Training:  48%|████▊     | 950/2000 [22:01<16:11,  1.08iteration/s, mean_rewards=-280]\u001b[A\n",
            "Training:  48%|████▊     | 951/2000 [22:02<18:36,  1.06s/iteration, mean_rewards=-280]\u001b[A\n",
            "Training:  48%|████▊     | 951/2000 [22:02<18:36,  1.06s/iteration, mean_rewards=-57.9]\u001b[A\n",
            "Training:  48%|████▊     | 952/2000 [22:03<17:34,  1.01s/iteration, mean_rewards=-57.9]\u001b[A\n",
            "Training:  48%|████▊     | 952/2000 [22:03<17:34,  1.01s/iteration, mean_rewards=-125] \u001b[A\n",
            "Training:  48%|████▊     | 953/2000 [22:04<17:17,  1.01iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  48%|████▊     | 953/2000 [22:04<17:17,  1.01iteration/s, mean_rewards=-77.3]\u001b[A\n",
            "Training:  48%|████▊     | 954/2000 [22:05<15:40,  1.11iteration/s, mean_rewards=-77.3]\u001b[A\n",
            "Training:  48%|████▊     | 954/2000 [22:05<15:40,  1.11iteration/s, mean_rewards=-43.5]\u001b[A\n",
            "Training:  48%|████▊     | 955/2000 [22:05<15:09,  1.15iteration/s, mean_rewards=-43.5]\u001b[A\n",
            "Training:  48%|████▊     | 955/2000 [22:06<15:09,  1.15iteration/s, mean_rewards=-52]  \u001b[A\n",
            "Training:  48%|████▊     | 956/2000 [22:06<15:30,  1.12iteration/s, mean_rewards=-52]\u001b[A\n",
            "Training:  48%|████▊     | 956/2000 [22:07<15:30,  1.12iteration/s, mean_rewards=-115]\u001b[A\n",
            "Training:  48%|████▊     | 957/2000 [22:07<15:08,  1.15iteration/s, mean_rewards=-115]\u001b[A\n",
            "Training:  48%|████▊     | 957/2000 [22:08<15:08,  1.15iteration/s, mean_rewards=-287]\u001b[A\n",
            "Training:  48%|████▊     | 958/2000 [22:08<16:29,  1.05iteration/s, mean_rewards=-287]\u001b[A\n",
            "Training:  48%|████▊     | 958/2000 [22:09<16:29,  1.05iteration/s, mean_rewards=-279]\u001b[A\n",
            "Training:  48%|████▊     | 959/2000 [22:09<16:14,  1.07iteration/s, mean_rewards=-279]\u001b[A\n",
            "Training:  48%|████▊     | 959/2000 [22:10<16:14,  1.07iteration/s, mean_rewards=-247]\u001b[A\n",
            "Training:  48%|████▊     | 960/2000 [22:10<16:47,  1.03iteration/s, mean_rewards=-247]\u001b[A\n",
            "Training:  48%|████▊     | 960/2000 [22:11<16:47,  1.03iteration/s, mean_rewards=-211]\u001b[A\n",
            "Training:  48%|████▊     | 961/2000 [22:11<16:27,  1.05iteration/s, mean_rewards=-211]\u001b[A\n",
            "Training:  48%|████▊     | 961/2000 [22:12<16:27,  1.05iteration/s, mean_rewards=-179]\u001b[A\n",
            "Training:  48%|████▊     | 962/2000 [22:12<16:26,  1.05iteration/s, mean_rewards=-179]\u001b[A\n",
            "Training:  48%|████▊     | 962/2000 [22:12<16:26,  1.05iteration/s, mean_rewards=-104]\u001b[A\n",
            "Training:  48%|████▊     | 963/2000 [22:13<17:05,  1.01iteration/s, mean_rewards=-104]\u001b[A\n",
            "Training:  48%|████▊     | 963/2000 [22:14<17:05,  1.01iteration/s, mean_rewards=-233]\u001b[A\n",
            "Training:  48%|████▊     | 964/2000 [22:15<19:27,  1.13s/iteration, mean_rewards=-233]\u001b[A\n",
            "Training:  48%|████▊     | 964/2000 [22:15<19:27,  1.13s/iteration, mean_rewards=-219]\u001b[A\n",
            "Training:  48%|████▊     | 965/2000 [22:16<20:07,  1.17s/iteration, mean_rewards=-219]\u001b[A\n",
            "Training:  48%|████▊     | 965/2000 [22:16<20:07,  1.17s/iteration, mean_rewards=-146]\u001b[A\n",
            "Training:  48%|████▊     | 966/2000 [22:17<18:08,  1.05s/iteration, mean_rewards=-146]\u001b[A\n",
            "Training:  48%|████▊     | 966/2000 [22:17<18:08,  1.05s/iteration, mean_rewards=-144]\u001b[A\n",
            "Training:  48%|████▊     | 967/2000 [22:18<17:32,  1.02s/iteration, mean_rewards=-144]\u001b[A\n",
            "Training:  48%|████▊     | 967/2000 [22:18<17:32,  1.02s/iteration, mean_rewards=-372]\u001b[A\n",
            "Training:  48%|████▊     | 968/2000 [22:18<16:10,  1.06iteration/s, mean_rewards=-372]\u001b[A\n",
            "Training:  48%|████▊     | 968/2000 [22:19<16:10,  1.06iteration/s, mean_rewards=-225]\u001b[A\n",
            "Training:  48%|████▊     | 969/2000 [22:19<15:27,  1.11iteration/s, mean_rewards=-225]\u001b[A\n",
            "Training:  48%|████▊     | 969/2000 [22:20<15:27,  1.11iteration/s, mean_rewards=-215]\u001b[A\n",
            "Training:  48%|████▊     | 970/2000 [22:20<16:18,  1.05iteration/s, mean_rewards=-215]\u001b[A\n",
            "Training:  48%|████▊     | 970/2000 [22:21<16:18,  1.05iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  49%|████▊     | 971/2000 [22:21<15:25,  1.11iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  49%|████▊     | 971/2000 [22:21<15:25,  1.11iteration/s, mean_rewards=-190]\u001b[A\n",
            "Training:  49%|████▊     | 972/2000 [22:22<14:52,  1.15iteration/s, mean_rewards=-190]\u001b[A\n",
            "Training:  49%|████▊     | 972/2000 [22:22<14:52,  1.15iteration/s, mean_rewards=-179]\u001b[A\n",
            "Training:  49%|████▊     | 973/2000 [22:23<15:07,  1.13iteration/s, mean_rewards=-179]\u001b[A\n",
            "Training:  49%|████▊     | 973/2000 [22:23<15:07,  1.13iteration/s, mean_rewards=-119]\u001b[A\n",
            "Training:  49%|████▊     | 974/2000 [22:23<13:59,  1.22iteration/s, mean_rewards=-119]\u001b[A\n",
            "Training:  49%|████▊     | 974/2000 [22:24<13:59,  1.22iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  49%|████▉     | 975/2000 [22:24<13:22,  1.28iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  49%|████▉     | 975/2000 [22:24<13:22,  1.28iteration/s, mean_rewards=-213]\u001b[A\n",
            "Training:  49%|████▉     | 976/2000 [22:25<14:03,  1.21iteration/s, mean_rewards=-213]\u001b[A\n",
            "Training:  49%|████▉     | 976/2000 [22:25<14:03,  1.21iteration/s, mean_rewards=-300]\u001b[A\n",
            "Training:  49%|████▉     | 977/2000 [22:26<14:51,  1.15iteration/s, mean_rewards=-300]\u001b[A\n",
            "Training:  49%|████▉     | 977/2000 [22:26<14:51,  1.15iteration/s, mean_rewards=-198]\u001b[A\n",
            "Training:  49%|████▉     | 978/2000 [22:27<18:00,  1.06s/iteration, mean_rewards=-198]\u001b[A\n",
            "Training:  49%|████▉     | 978/2000 [22:28<18:00,  1.06s/iteration, mean_rewards=-108]\u001b[A\n",
            "Training:  49%|████▉     | 979/2000 [22:29<17:53,  1.05s/iteration, mean_rewards=-108]\u001b[A\n",
            "Training:  49%|████▉     | 979/2000 [22:29<17:53,  1.05s/iteration, mean_rewards=-289]\u001b[A\n",
            "Training:  49%|████▉     | 980/2000 [22:29<16:46,  1.01iteration/s, mean_rewards=-289]\u001b[A\n",
            "Training:  49%|████▉     | 980/2000 [22:30<16:46,  1.01iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  49%|████▉     | 981/2000 [22:30<15:12,  1.12iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  49%|████▉     | 981/2000 [22:30<15:12,  1.12iteration/s, mean_rewards=-320]\u001b[A\n",
            "Training:  49%|████▉     | 982/2000 [22:31<15:33,  1.09iteration/s, mean_rewards=-320]\u001b[A\n",
            "Training:  49%|████▉     | 982/2000 [22:31<15:33,  1.09iteration/s, mean_rewards=-262]\u001b[A\n",
            "Training:  49%|████▉     | 983/2000 [22:32<14:51,  1.14iteration/s, mean_rewards=-262]\u001b[A\n",
            "Training:  49%|████▉     | 983/2000 [22:32<14:51,  1.14iteration/s, mean_rewards=-92] \u001b[A\n",
            "Training:  49%|████▉     | 984/2000 [22:33<15:03,  1.12iteration/s, mean_rewards=-92]\u001b[A\n",
            "Training:  49%|████▉     | 984/2000 [22:33<15:03,  1.12iteration/s, mean_rewards=-217]\u001b[A\n",
            "Training:  49%|████▉     | 985/2000 [22:33<14:09,  1.19iteration/s, mean_rewards=-217]\u001b[A\n",
            "Training:  49%|████▉     | 985/2000 [22:34<14:09,  1.19iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:  49%|████▉     | 986/2000 [22:35<15:31,  1.09iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:  49%|████▉     | 986/2000 [22:35<15:31,  1.09iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  49%|████▉     | 987/2000 [22:35<14:18,  1.18iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  49%|████▉     | 987/2000 [22:36<14:18,  1.18iteration/s, mean_rewards=-109]\u001b[A\n",
            "Training:  49%|████▉     | 988/2000 [22:36<14:44,  1.14iteration/s, mean_rewards=-109]\u001b[A\n",
            "Training:  49%|████▉     | 988/2000 [22:36<14:44,  1.14iteration/s, mean_rewards=-234]\u001b[A\n",
            "Training:  49%|████▉     | 989/2000 [22:37<13:49,  1.22iteration/s, mean_rewards=-234]\u001b[A\n",
            "Training:  49%|████▉     | 989/2000 [22:37<13:49,  1.22iteration/s, mean_rewards=-285]\u001b[A\n",
            "Training:  50%|████▉     | 990/2000 [22:38<14:19,  1.18iteration/s, mean_rewards=-285]\u001b[A\n",
            "Training:  50%|████▉     | 990/2000 [22:38<14:19,  1.18iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:  50%|████▉     | 991/2000 [22:39<14:50,  1.13iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:  50%|████▉     | 991/2000 [22:39<14:50,  1.13iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:  50%|████▉     | 992/2000 [22:40<14:57,  1.12iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:  50%|████▉     | 992/2000 [22:40<14:57,  1.12iteration/s, mean_rewards=-163]\u001b[A\n",
            "Training:  50%|████▉     | 993/2000 [22:41<17:23,  1.04s/iteration, mean_rewards=-163]\u001b[A\n",
            "Training:  50%|████▉     | 993/2000 [22:41<17:23,  1.04s/iteration, mean_rewards=-94.6]\u001b[A\n",
            "Training:  50%|████▉     | 994/2000 [22:42<15:49,  1.06iteration/s, mean_rewards=-94.6]\u001b[A\n",
            "Training:  50%|████▉     | 994/2000 [22:42<15:49,  1.06iteration/s, mean_rewards=-66.1]\u001b[A\n",
            "Training:  50%|████▉     | 995/2000 [22:42<14:42,  1.14iteration/s, mean_rewards=-66.1]\u001b[A\n",
            "Training:  50%|████▉     | 995/2000 [22:43<14:42,  1.14iteration/s, mean_rewards=-417] \u001b[A\n",
            "Training:  50%|████▉     | 996/2000 [22:43<15:32,  1.08iteration/s, mean_rewards=-417]\u001b[A\n",
            "Training:  50%|████▉     | 996/2000 [22:44<15:32,  1.08iteration/s, mean_rewards=-115]\u001b[A\n",
            "Training:  50%|████▉     | 997/2000 [22:44<14:05,  1.19iteration/s, mean_rewards=-115]\u001b[A\n",
            "Training:  50%|████▉     | 997/2000 [22:44<14:05,  1.19iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  50%|████▉     | 998/2000 [22:45<13:09,  1.27iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  50%|████▉     | 998/2000 [22:45<13:09,  1.27iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  50%|████▉     | 999/2000 [22:46<13:15,  1.26iteration/s, mean_rewards=-132]\u001b[A\n",
            "Training:  50%|████▉     | 999/2000 [22:46<13:15,  1.26iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  50%|█████     | 1000/2000 [22:47<13:51,  1.20iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  50%|█████     | 1000/2000 [22:47<13:51,  1.20iteration/s, mean_rewards=-234]\u001b[A\n",
            "Training:  50%|█████     | 1001/2000 [22:47<13:47,  1.21iteration/s, mean_rewards=-234]\u001b[A\n",
            "Training:  50%|█████     | 1001/2000 [22:48<13:47,  1.21iteration/s, mean_rewards=-77.6]\u001b[A\n",
            "Training:  50%|█████     | 1002/2000 [22:48<13:28,  1.23iteration/s, mean_rewards=-77.6]\u001b[A\n",
            "Training:  50%|█████     | 1002/2000 [22:49<13:28,  1.23iteration/s, mean_rewards=-120] \u001b[A\n",
            "Training:  50%|█████     | 1003/2000 [22:49<14:28,  1.15iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  50%|█████     | 1003/2000 [22:49<14:28,  1.15iteration/s, mean_rewards=-382]\u001b[A\n",
            "Training:  50%|█████     | 1004/2000 [22:50<14:37,  1.13iteration/s, mean_rewards=-382]\u001b[A\n",
            "Training:  50%|█████     | 1004/2000 [22:50<14:37,  1.13iteration/s, mean_rewards=-206]\u001b[A\n",
            "Training:  50%|█████     | 1005/2000 [22:51<14:49,  1.12iteration/s, mean_rewards=-206]\u001b[A\n",
            "Training:  50%|█████     | 1005/2000 [22:51<14:49,  1.12iteration/s, mean_rewards=-197]\u001b[A\n",
            "Training:  50%|█████     | 1006/2000 [22:52<16:23,  1.01iteration/s, mean_rewards=-197]\u001b[A\n",
            "Training:  50%|█████     | 1006/2000 [22:53<16:23,  1.01iteration/s, mean_rewards=-264]\u001b[A\n",
            "Training:  50%|█████     | 1007/2000 [22:54<18:09,  1.10s/iteration, mean_rewards=-264]\u001b[A\n",
            "Training:  50%|█████     | 1007/2000 [22:54<18:09,  1.10s/iteration, mean_rewards=-314]\u001b[A\n",
            "Training:  50%|█████     | 1008/2000 [22:55<18:18,  1.11s/iteration, mean_rewards=-314]\u001b[A\n",
            "Training:  50%|█████     | 1008/2000 [22:55<18:18,  1.11s/iteration, mean_rewards=-279]\u001b[A\n",
            "Training:  50%|█████     | 1009/2000 [22:55<16:54,  1.02s/iteration, mean_rewards=-279]\u001b[A\n",
            "Training:  50%|█████     | 1009/2000 [22:56<16:54,  1.02s/iteration, mean_rewards=-362]\u001b[A\n",
            "Training:  50%|█████     | 1010/2000 [22:56<15:39,  1.05iteration/s, mean_rewards=-362]\u001b[A\n",
            "Training:  50%|█████     | 1010/2000 [22:57<15:39,  1.05iteration/s, mean_rewards=-93.3]\u001b[A\n",
            "Training:  51%|█████     | 1011/2000 [22:57<14:13,  1.16iteration/s, mean_rewards=-93.3]\u001b[A\n",
            "Training:  51%|█████     | 1011/2000 [22:57<14:13,  1.16iteration/s, mean_rewards=-215] \u001b[A\n",
            "Training:  51%|█████     | 1012/2000 [22:58<13:52,  1.19iteration/s, mean_rewards=-215]\u001b[A\n",
            "Training:  51%|█████     | 1012/2000 [22:58<13:52,  1.19iteration/s, mean_rewards=-195]\u001b[A\n",
            "Training:  51%|█████     | 1013/2000 [22:58<13:02,  1.26iteration/s, mean_rewards=-195]\u001b[A\n",
            "Training:  51%|█████     | 1013/2000 [22:59<13:02,  1.26iteration/s, mean_rewards=-63.5]\u001b[A\n",
            "Training:  51%|█████     | 1014/2000 [22:59<12:58,  1.27iteration/s, mean_rewards=-63.5]\u001b[A\n",
            "Training:  51%|█████     | 1014/2000 [22:59<12:58,  1.27iteration/s, mean_rewards=-47.8]\u001b[A\n",
            "Training:  51%|█████     | 1015/2000 [23:00<12:33,  1.31iteration/s, mean_rewards=-47.8]\u001b[A\n",
            "Training:  51%|█████     | 1015/2000 [23:00<12:33,  1.31iteration/s, mean_rewards=-245] \u001b[A\n",
            "Training:  51%|█████     | 1016/2000 [23:01<13:20,  1.23iteration/s, mean_rewards=-245]\u001b[A\n",
            "Training:  51%|█████     | 1016/2000 [23:01<13:20,  1.23iteration/s, mean_rewards=-383]\u001b[A\n",
            "Training:  51%|█████     | 1017/2000 [23:02<13:52,  1.18iteration/s, mean_rewards=-383]\u001b[A\n",
            "Training:  51%|█████     | 1017/2000 [23:02<13:52,  1.18iteration/s, mean_rewards=-321]\u001b[A\n",
            "Training:  51%|█████     | 1018/2000 [23:03<15:31,  1.05iteration/s, mean_rewards=-321]\u001b[A\n",
            "Training:  51%|█████     | 1018/2000 [23:03<15:31,  1.05iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:  51%|█████     | 1019/2000 [23:04<14:14,  1.15iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:  51%|█████     | 1019/2000 [23:04<14:14,  1.15iteration/s, mean_rewards=-251]\u001b[A\n",
            "Training:  51%|█████     | 1020/2000 [23:05<15:26,  1.06iteration/s, mean_rewards=-251]\u001b[A\n",
            "Training:  51%|█████     | 1020/2000 [23:05<15:26,  1.06iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  51%|█████     | 1021/2000 [23:06<16:08,  1.01iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  51%|█████     | 1021/2000 [23:06<16:08,  1.01iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  51%|█████     | 1022/2000 [23:07<16:13,  1.00iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  51%|█████     | 1022/2000 [23:07<16:13,  1.00iteration/s, mean_rewards=-58.7]\u001b[A\n",
            "Training:  51%|█████     | 1023/2000 [23:08<15:15,  1.07iteration/s, mean_rewards=-58.7]\u001b[A\n",
            "Training:  51%|█████     | 1023/2000 [23:08<15:15,  1.07iteration/s, mean_rewards=-174] \u001b[A\n",
            "Training:  51%|█████     | 1024/2000 [23:08<14:23,  1.13iteration/s, mean_rewards=-174]\u001b[A\n",
            "Training:  51%|█████     | 1024/2000 [23:09<14:23,  1.13iteration/s, mean_rewards=-175]\u001b[A\n",
            "Training:  51%|█████▏    | 1025/2000 [23:09<13:21,  1.22iteration/s, mean_rewards=-175]\u001b[A\n",
            "Training:  51%|█████▏    | 1025/2000 [23:09<13:21,  1.22iteration/s, mean_rewards=-256]\u001b[A\n",
            "Training:  51%|█████▏    | 1026/2000 [23:10<14:23,  1.13iteration/s, mean_rewards=-256]\u001b[A\n",
            "Training:  51%|█████▏    | 1026/2000 [23:11<14:23,  1.13iteration/s, mean_rewards=-315]\u001b[A\n",
            "Training:  51%|█████▏    | 1027/2000 [23:11<15:19,  1.06iteration/s, mean_rewards=-315]\u001b[A\n",
            "Training:  51%|█████▏    | 1027/2000 [23:12<15:19,  1.06iteration/s, mean_rewards=-232]\u001b[A\n",
            "Training:  51%|█████▏    | 1028/2000 [23:12<15:44,  1.03iteration/s, mean_rewards=-232]\u001b[A\n",
            "Training:  51%|█████▏    | 1028/2000 [23:13<15:44,  1.03iteration/s, mean_rewards=-227]\u001b[A\n",
            "Training:  51%|█████▏    | 1029/2000 [23:13<16:01,  1.01iteration/s, mean_rewards=-227]\u001b[A\n",
            "Training:  51%|█████▏    | 1029/2000 [23:14<16:01,  1.01iteration/s, mean_rewards=-42.3]\u001b[A\n",
            "Training:  52%|█████▏    | 1030/2000 [23:14<15:44,  1.03iteration/s, mean_rewards=-42.3]\u001b[A\n",
            "Training:  52%|█████▏    | 1030/2000 [23:15<15:44,  1.03iteration/s, mean_rewards=-159] \u001b[A\n",
            "Training:  52%|█████▏    | 1031/2000 [23:15<15:39,  1.03iteration/s, mean_rewards=-159]\u001b[A\n",
            "Training:  52%|█████▏    | 1031/2000 [23:16<15:39,  1.03iteration/s, mean_rewards=-277]\u001b[A\n",
            "Training:  52%|█████▏    | 1032/2000 [23:16<16:26,  1.02s/iteration, mean_rewards=-277]\u001b[A\n",
            "Training:  52%|█████▏    | 1032/2000 [23:17<16:26,  1.02s/iteration, mean_rewards=-211]\u001b[A\n",
            "Training:  52%|█████▏    | 1033/2000 [23:18<17:44,  1.10s/iteration, mean_rewards=-211]\u001b[A\n",
            "Training:  52%|█████▏    | 1033/2000 [23:18<17:44,  1.10s/iteration, mean_rewards=-101]\u001b[A\n",
            "Training:  52%|█████▏    | 1034/2000 [23:19<18:56,  1.18s/iteration, mean_rewards=-101]\u001b[A\n",
            "Training:  52%|█████▏    | 1034/2000 [23:19<18:56,  1.18s/iteration, mean_rewards=-100]\u001b[A\n",
            "Training:  52%|█████▏    | 1035/2000 [23:20<17:01,  1.06s/iteration, mean_rewards=-100]\u001b[A\n",
            "Training:  52%|█████▏    | 1035/2000 [23:20<17:01,  1.06s/iteration, mean_rewards=-334]\u001b[A\n",
            "Training:  52%|█████▏    | 1036/2000 [23:21<15:58,  1.01iteration/s, mean_rewards=-334]\u001b[A\n",
            "Training:  52%|█████▏    | 1036/2000 [23:21<15:58,  1.01iteration/s, mean_rewards=-103]\u001b[A\n",
            "Training:  52%|█████▏    | 1037/2000 [23:22<15:47,  1.02iteration/s, mean_rewards=-103]\u001b[A\n",
            "Training:  52%|█████▏    | 1037/2000 [23:22<15:47,  1.02iteration/s, mean_rewards=-89.9]\u001b[A\n",
            "Training:  52%|█████▏    | 1038/2000 [23:22<14:18,  1.12iteration/s, mean_rewards=-89.9]\u001b[A\n",
            "Training:  52%|█████▏    | 1038/2000 [23:23<14:18,  1.12iteration/s, mean_rewards=-207] \u001b[A\n",
            "Training:  52%|█████▏    | 1039/2000 [23:23<13:52,  1.15iteration/s, mean_rewards=-207]\u001b[A\n",
            "Training:  52%|█████▏    | 1039/2000 [23:23<13:52,  1.15iteration/s, mean_rewards=-187]\u001b[A\n",
            "Training:  52%|█████▏    | 1040/2000 [23:24<15:22,  1.04iteration/s, mean_rewards=-187]\u001b[A\n",
            "Training:  52%|█████▏    | 1040/2000 [23:24<15:22,  1.04iteration/s, mean_rewards=-189]\u001b[A\n",
            "Training:  52%|█████▏    | 1041/2000 [23:25<14:29,  1.10iteration/s, mean_rewards=-189]\u001b[A\n",
            "Training:  52%|█████▏    | 1041/2000 [23:25<14:29,  1.10iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  52%|█████▏    | 1042/2000 [23:26<13:40,  1.17iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  52%|█████▏    | 1042/2000 [23:26<13:40,  1.17iteration/s, mean_rewards=-210]\u001b[A\n",
            "Training:  52%|█████▏    | 1043/2000 [23:27<14:02,  1.14iteration/s, mean_rewards=-210]\u001b[A\n",
            "Training:  52%|█████▏    | 1043/2000 [23:27<14:02,  1.14iteration/s, mean_rewards=-201]\u001b[A\n",
            "Training:  52%|█████▏    | 1044/2000 [23:28<14:46,  1.08iteration/s, mean_rewards=-201]\u001b[A\n",
            "Training:  52%|█████▏    | 1044/2000 [23:28<14:46,  1.08iteration/s, mean_rewards=-266]\u001b[A\n",
            "Training:  52%|█████▏    | 1045/2000 [23:29<15:27,  1.03iteration/s, mean_rewards=-266]\u001b[A\n",
            "Training:  52%|█████▏    | 1045/2000 [23:29<15:27,  1.03iteration/s, mean_rewards=-186]\u001b[A\n",
            "Training:  52%|█████▏    | 1046/2000 [23:30<16:07,  1.01s/iteration, mean_rewards=-186]\u001b[A\n",
            "Training:  52%|█████▏    | 1046/2000 [23:30<16:07,  1.01s/iteration, mean_rewards=-108]\u001b[A\n",
            "Training:  52%|█████▏    | 1047/2000 [23:31<15:26,  1.03iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:  52%|█████▏    | 1047/2000 [23:31<15:26,  1.03iteration/s, mean_rewards=-244]\u001b[A\n",
            "Training:  52%|█████▏    | 1048/2000 [23:32<16:10,  1.02s/iteration, mean_rewards=-244]\u001b[A\n",
            "Training:  52%|█████▏    | 1048/2000 [23:32<16:10,  1.02s/iteration, mean_rewards=-130]\u001b[A\n",
            "Training:  52%|█████▏    | 1049/2000 [23:33<16:41,  1.05s/iteration, mean_rewards=-130]\u001b[A\n",
            "Training:  52%|█████▏    | 1049/2000 [23:33<16:41,  1.05s/iteration, mean_rewards=-342]\u001b[A\n",
            "Training:  52%|█████▎    | 1050/2000 [23:34<15:23,  1.03iteration/s, mean_rewards=-342]\u001b[A\n",
            "Training:  52%|█████▎    | 1050/2000 [23:34<15:23,  1.03iteration/s, mean_rewards=-152]\u001b[A\n",
            "Training:  53%|█████▎    | 1051/2000 [23:35<15:33,  1.02iteration/s, mean_rewards=-152]\u001b[A\n",
            "Training:  53%|█████▎    | 1051/2000 [23:35<15:33,  1.02iteration/s, mean_rewards=-271]\u001b[A\n",
            "Training:  53%|█████▎    | 1052/2000 [23:36<14:39,  1.08iteration/s, mean_rewards=-271]\u001b[A\n",
            "Training:  53%|█████▎    | 1052/2000 [23:36<14:39,  1.08iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  53%|█████▎    | 1053/2000 [23:36<14:28,  1.09iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  53%|█████▎    | 1053/2000 [23:37<14:28,  1.09iteration/s, mean_rewards=-152]\u001b[A\n",
            "Training:  53%|█████▎    | 1054/2000 [23:37<13:55,  1.13iteration/s, mean_rewards=-152]\u001b[A\n",
            "Training:  53%|█████▎    | 1054/2000 [23:38<13:55,  1.13iteration/s, mean_rewards=-221]\u001b[A\n",
            "Training:  53%|█████▎    | 1055/2000 [23:38<13:28,  1.17iteration/s, mean_rewards=-221]\u001b[A\n",
            "Training:  53%|█████▎    | 1055/2000 [23:38<13:28,  1.17iteration/s, mean_rewards=-115]\u001b[A\n",
            "Training:  53%|█████▎    | 1056/2000 [23:39<13:13,  1.19iteration/s, mean_rewards=-115]\u001b[A\n",
            "Training:  53%|█████▎    | 1056/2000 [23:39<13:13,  1.19iteration/s, mean_rewards=-82.6]\u001b[A\n",
            "Training:  53%|█████▎    | 1057/2000 [23:40<14:17,  1.10iteration/s, mean_rewards=-82.6]\u001b[A\n",
            "Training:  53%|█████▎    | 1057/2000 [23:40<14:17,  1.10iteration/s, mean_rewards=-202] \u001b[A\n",
            "Training:  53%|█████▎    | 1058/2000 [23:41<14:59,  1.05iteration/s, mean_rewards=-202]\u001b[A\n",
            "Training:  53%|█████▎    | 1058/2000 [23:41<14:59,  1.05iteration/s, mean_rewards=-242]\u001b[A\n",
            "Training:  53%|█████▎    | 1059/2000 [23:42<14:17,  1.10iteration/s, mean_rewards=-242]\u001b[A\n",
            "Training:  53%|█████▎    | 1059/2000 [23:42<14:17,  1.10iteration/s, mean_rewards=-313]\u001b[A\n",
            "Training:  53%|█████▎    | 1060/2000 [23:43<15:49,  1.01s/iteration, mean_rewards=-313]\u001b[A\n",
            "Training:  53%|█████▎    | 1060/2000 [23:44<15:49,  1.01s/iteration, mean_rewards=-199]\u001b[A\n",
            "Training:  53%|█████▎    | 1061/2000 [23:44<16:57,  1.08s/iteration, mean_rewards=-199]\u001b[A\n",
            "Training:  53%|█████▎    | 1061/2000 [23:45<16:57,  1.08s/iteration, mean_rewards=-385]\u001b[A\n",
            "Training:  53%|█████▎    | 1062/2000 [23:45<17:03,  1.09s/iteration, mean_rewards=-385]\u001b[A\n",
            "Training:  53%|█████▎    | 1062/2000 [23:46<17:03,  1.09s/iteration, mean_rewards=-196]\u001b[A\n",
            "Training:  53%|█████▎    | 1063/2000 [23:46<15:42,  1.01s/iteration, mean_rewards=-196]\u001b[A\n",
            "Training:  53%|█████▎    | 1063/2000 [23:47<15:42,  1.01s/iteration, mean_rewards=-293]\u001b[A\n",
            "Training:  53%|█████▎    | 1064/2000 [23:47<14:29,  1.08iteration/s, mean_rewards=-293]\u001b[A\n",
            "Training:  53%|█████▎    | 1064/2000 [23:47<14:29,  1.08iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  53%|█████▎    | 1065/2000 [23:48<14:27,  1.08iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  53%|█████▎    | 1065/2000 [23:48<14:27,  1.08iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  53%|█████▎    | 1066/2000 [23:49<15:03,  1.03iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  53%|█████▎    | 1066/2000 [23:49<15:03,  1.03iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  53%|█████▎    | 1067/2000 [23:50<14:25,  1.08iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  53%|█████▎    | 1067/2000 [23:50<14:25,  1.08iteration/s, mean_rewards=-301]\u001b[A\n",
            "Training:  53%|█████▎    | 1068/2000 [23:51<15:05,  1.03iteration/s, mean_rewards=-301]\u001b[A\n",
            "Training:  53%|█████▎    | 1068/2000 [23:51<15:05,  1.03iteration/s, mean_rewards=-219]\u001b[A\n",
            "Training:  53%|█████▎    | 1069/2000 [23:52<16:12,  1.04s/iteration, mean_rewards=-219]\u001b[A\n",
            "Training:  53%|█████▎    | 1069/2000 [23:52<16:12,  1.04s/iteration, mean_rewards=-235]\u001b[A\n",
            "Training:  54%|█████▎    | 1070/2000 [23:53<15:41,  1.01s/iteration, mean_rewards=-235]\u001b[A\n",
            "Training:  54%|█████▎    | 1070/2000 [23:53<15:41,  1.01s/iteration, mean_rewards=-122]\u001b[A\n",
            "Training:  54%|█████▎    | 1071/2000 [23:54<14:48,  1.05iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  54%|█████▎    | 1071/2000 [23:54<14:48,  1.05iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  54%|█████▎    | 1072/2000 [23:55<14:04,  1.10iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  54%|█████▎    | 1072/2000 [23:55<14:04,  1.10iteration/s, mean_rewards=-209]\u001b[A\n",
            "Training:  54%|█████▎    | 1073/2000 [23:56<14:36,  1.06iteration/s, mean_rewards=-209]\u001b[A\n",
            "Training:  54%|█████▎    | 1073/2000 [23:56<14:36,  1.06iteration/s, mean_rewards=-209]\u001b[A\n",
            "Training:  54%|█████▎    | 1074/2000 [23:57<16:58,  1.10s/iteration, mean_rewards=-209]\u001b[A\n",
            "Training:  54%|█████▎    | 1074/2000 [23:58<16:58,  1.10s/iteration, mean_rewards=-219]\u001b[A\n",
            "Training:  54%|█████▍    | 1075/2000 [23:58<17:27,  1.13s/iteration, mean_rewards=-219]\u001b[A\n",
            "Training:  54%|█████▍    | 1075/2000 [23:59<17:27,  1.13s/iteration, mean_rewards=-276]\u001b[A\n",
            "Training:  54%|█████▍    | 1076/2000 [23:59<15:27,  1.00s/iteration, mean_rewards=-276]\u001b[A\n",
            "Training:  54%|█████▍    | 1076/2000 [23:59<15:27,  1.00s/iteration, mean_rewards=-310]\u001b[A\n",
            "Training:  54%|█████▍    | 1077/2000 [24:00<15:16,  1.01iteration/s, mean_rewards=-310]\u001b[A\n",
            "Training:  54%|█████▍    | 1077/2000 [24:00<15:16,  1.01iteration/s, mean_rewards=-170]\u001b[A\n",
            "Training:  54%|█████▍    | 1078/2000 [24:01<14:50,  1.04iteration/s, mean_rewards=-170]\u001b[A\n",
            "Training:  54%|█████▍    | 1078/2000 [24:01<14:50,  1.04iteration/s, mean_rewards=-159]\u001b[A\n",
            "Training:  54%|█████▍    | 1079/2000 [24:02<14:41,  1.05iteration/s, mean_rewards=-159]\u001b[A\n",
            "Training:  54%|█████▍    | 1079/2000 [24:02<14:41,  1.05iteration/s, mean_rewards=-217]\u001b[A\n",
            "Training:  54%|█████▍    | 1080/2000 [24:03<15:17,  1.00iteration/s, mean_rewards=-217]\u001b[A\n",
            "Training:  54%|█████▍    | 1080/2000 [24:03<15:17,  1.00iteration/s, mean_rewards=-212]\u001b[A\n",
            "Training:  54%|█████▍    | 1081/2000 [24:04<15:01,  1.02iteration/s, mean_rewards=-212]\u001b[A\n",
            "Training:  54%|█████▍    | 1081/2000 [24:04<15:01,  1.02iteration/s, mean_rewards=-238]\u001b[A\n",
            "Training:  54%|█████▍    | 1082/2000 [24:05<14:26,  1.06iteration/s, mean_rewards=-238]\u001b[A\n",
            "Training:  54%|█████▍    | 1082/2000 [24:05<14:26,  1.06iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  54%|█████▍    | 1083/2000 [24:06<13:42,  1.11iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  54%|█████▍    | 1083/2000 [24:06<13:42,  1.11iteration/s, mean_rewards=-172]\u001b[A\n",
            "Training:  54%|█████▍    | 1084/2000 [24:06<13:18,  1.15iteration/s, mean_rewards=-172]\u001b[A\n",
            "Training:  54%|█████▍    | 1084/2000 [24:07<13:18,  1.15iteration/s, mean_rewards=-469]\u001b[A\n",
            "Training:  54%|█████▍    | 1085/2000 [24:07<14:05,  1.08iteration/s, mean_rewards=-469]\u001b[A\n",
            "Training:  54%|█████▍    | 1085/2000 [24:08<14:05,  1.08iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  54%|█████▍    | 1086/2000 [24:08<13:49,  1.10iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  54%|█████▍    | 1086/2000 [24:09<13:49,  1.10iteration/s, mean_rewards=-112]\u001b[A\n",
            "Training:  54%|█████▍    | 1087/2000 [24:09<13:45,  1.11iteration/s, mean_rewards=-112]\u001b[A\n",
            "Training:  54%|█████▍    | 1087/2000 [24:10<13:45,  1.11iteration/s, mean_rewards=-303]\u001b[A\n",
            "Training:  54%|█████▍    | 1088/2000 [24:11<16:18,  1.07s/iteration, mean_rewards=-303]\u001b[A\n",
            "Training:  54%|█████▍    | 1088/2000 [24:11<16:18,  1.07s/iteration, mean_rewards=-64] \u001b[A\n",
            "Training:  54%|█████▍    | 1089/2000 [24:12<15:49,  1.04s/iteration, mean_rewards=-64]\u001b[A\n",
            "Training:  54%|█████▍    | 1089/2000 [24:12<15:49,  1.04s/iteration, mean_rewards=-224]\u001b[A\n",
            "Training:  55%|█████▍    | 1090/2000 [24:13<15:57,  1.05s/iteration, mean_rewards=-224]\u001b[A\n",
            "Training:  55%|█████▍    | 1090/2000 [24:13<15:57,  1.05s/iteration, mean_rewards=-342]\u001b[A\n",
            "Training:  55%|█████▍    | 1091/2000 [24:13<14:50,  1.02iteration/s, mean_rewards=-342]\u001b[A\n",
            "Training:  55%|█████▍    | 1091/2000 [24:14<14:50,  1.02iteration/s, mean_rewards=-49] \u001b[A\n",
            "Training:  55%|█████▍    | 1092/2000 [24:14<14:38,  1.03iteration/s, mean_rewards=-49]\u001b[A\n",
            "Training:  55%|█████▍    | 1092/2000 [24:15<14:38,  1.03iteration/s, mean_rewards=-231]\u001b[A\n",
            "Training:  55%|█████▍    | 1093/2000 [24:15<15:05,  1.00iteration/s, mean_rewards=-231]\u001b[A\n",
            "Training:  55%|█████▍    | 1093/2000 [24:16<15:05,  1.00iteration/s, mean_rewards=-159]\u001b[A\n",
            "Training:  55%|█████▍    | 1094/2000 [24:16<14:15,  1.06iteration/s, mean_rewards=-159]\u001b[A\n",
            "Training:  55%|█████▍    | 1094/2000 [24:17<14:15,  1.06iteration/s, mean_rewards=-234]\u001b[A\n",
            "Training:  55%|█████▍    | 1095/2000 [24:17<13:44,  1.10iteration/s, mean_rewards=-234]\u001b[A\n",
            "Training:  55%|█████▍    | 1095/2000 [24:18<13:44,  1.10iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  55%|█████▍    | 1096/2000 [24:18<13:44,  1.10iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  55%|█████▍    | 1096/2000 [24:18<13:44,  1.10iteration/s, mean_rewards=-340]\u001b[A\n",
            "Training:  55%|█████▍    | 1097/2000 [24:19<13:19,  1.13iteration/s, mean_rewards=-340]\u001b[A\n",
            "Training:  55%|█████▍    | 1097/2000 [24:19<13:19,  1.13iteration/s, mean_rewards=-239]\u001b[A\n",
            "Training:  55%|█████▍    | 1098/2000 [24:20<12:26,  1.21iteration/s, mean_rewards=-239]\u001b[A\n",
            "Training:  55%|█████▍    | 1098/2000 [24:20<12:26,  1.21iteration/s, mean_rewards=-171]\u001b[A\n",
            "Training:  55%|█████▍    | 1099/2000 [24:20<11:13,  1.34iteration/s, mean_rewards=-171]\u001b[A\n",
            "Training:  55%|█████▍    | 1099/2000 [24:20<11:13,  1.34iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  55%|█████▌    | 1100/2000 [24:21<12:27,  1.20iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  55%|█████▌    | 1100/2000 [24:22<12:27,  1.20iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  55%|█████▌    | 1101/2000 [24:23<15:13,  1.02s/iteration, mean_rewards=-151]\u001b[A\n",
            "Training:  55%|█████▌    | 1101/2000 [24:23<15:13,  1.02s/iteration, mean_rewards=-77.3]\u001b[A\n",
            "Training:  55%|█████▌    | 1102/2000 [24:24<14:45,  1.01iteration/s, mean_rewards=-77.3]\u001b[A\n",
            "Training:  55%|█████▌    | 1102/2000 [24:24<14:45,  1.01iteration/s, mean_rewards=-188] \u001b[A\n",
            "Training:  55%|█████▌    | 1103/2000 [24:24<13:57,  1.07iteration/s, mean_rewards=-188]\u001b[A\n",
            "Training:  55%|█████▌    | 1103/2000 [24:25<13:57,  1.07iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:  55%|█████▌    | 1104/2000 [24:25<13:21,  1.12iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:  55%|█████▌    | 1104/2000 [24:26<13:21,  1.12iteration/s, mean_rewards=-354]\u001b[A\n",
            "Training:  55%|█████▌    | 1105/2000 [24:26<13:45,  1.08iteration/s, mean_rewards=-354]\u001b[A\n",
            "Training:  55%|█████▌    | 1105/2000 [24:27<13:45,  1.08iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  55%|█████▌    | 1106/2000 [24:27<13:52,  1.07iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  55%|█████▌    | 1106/2000 [24:27<13:52,  1.07iteration/s, mean_rewards=-157]\u001b[A\n",
            "Training:  55%|█████▌    | 1107/2000 [24:28<13:15,  1.12iteration/s, mean_rewards=-157]\u001b[A\n",
            "Training:  55%|█████▌    | 1107/2000 [24:28<13:15,  1.12iteration/s, mean_rewards=-226]\u001b[A\n",
            "Training:  55%|█████▌    | 1108/2000 [24:29<14:41,  1.01iteration/s, mean_rewards=-226]\u001b[A\n",
            "Training:  55%|█████▌    | 1108/2000 [24:29<14:41,  1.01iteration/s, mean_rewards=-220]\u001b[A\n",
            "Training:  55%|█████▌    | 1109/2000 [24:30<13:53,  1.07iteration/s, mean_rewards=-220]\u001b[A\n",
            "Training:  55%|█████▌    | 1109/2000 [24:30<13:53,  1.07iteration/s, mean_rewards=-447]\u001b[A\n",
            "Training:  56%|█████▌    | 1110/2000 [24:31<14:23,  1.03iteration/s, mean_rewards=-447]\u001b[A\n",
            "Training:  56%|█████▌    | 1110/2000 [24:31<14:23,  1.03iteration/s, mean_rewards=-317]\u001b[A\n",
            "Training:  56%|█████▌    | 1111/2000 [24:32<14:04,  1.05iteration/s, mean_rewards=-317]\u001b[A\n",
            "Training:  56%|█████▌    | 1111/2000 [24:32<14:04,  1.05iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  56%|█████▌    | 1112/2000 [24:33<13:27,  1.10iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  56%|█████▌    | 1112/2000 [24:33<13:27,  1.10iteration/s, mean_rewards=-249]\u001b[A\n",
            "Training:  56%|█████▌    | 1113/2000 [24:34<14:39,  1.01iteration/s, mean_rewards=-249]\u001b[A\n",
            "Training:  56%|█████▌    | 1113/2000 [24:34<14:39,  1.01iteration/s, mean_rewards=-299]\u001b[A\n",
            "Training:  56%|█████▌    | 1114/2000 [24:35<16:17,  1.10s/iteration, mean_rewards=-299]\u001b[A\n",
            "Training:  56%|█████▌    | 1114/2000 [24:36<16:17,  1.10s/iteration, mean_rewards=-292]\u001b[A\n",
            "Training:  56%|█████▌    | 1115/2000 [24:37<18:21,  1.24s/iteration, mean_rewards=-292]\u001b[A\n",
            "Training:  56%|█████▌    | 1115/2000 [24:37<18:21,  1.24s/iteration, mean_rewards=-115]\u001b[A\n",
            "Training:  56%|█████▌    | 1116/2000 [24:38<16:33,  1.12s/iteration, mean_rewards=-115]\u001b[A\n",
            "Training:  56%|█████▌    | 1116/2000 [24:38<16:33,  1.12s/iteration, mean_rewards=-70.9]\u001b[A\n",
            "Training:  56%|█████▌    | 1117/2000 [24:38<14:37,  1.01iteration/s, mean_rewards=-70.9]\u001b[A\n",
            "Training:  56%|█████▌    | 1117/2000 [24:39<14:37,  1.01iteration/s, mean_rewards=-129] \u001b[A\n",
            "Training:  56%|█████▌    | 1118/2000 [24:40<15:34,  1.06s/iteration, mean_rewards=-129]\u001b[A\n",
            "Training:  56%|█████▌    | 1118/2000 [24:40<15:34,  1.06s/iteration, mean_rewards=-224]\u001b[A\n",
            "Training:  56%|█████▌    | 1119/2000 [24:41<15:44,  1.07s/iteration, mean_rewards=-224]\u001b[A\n",
            "Training:  56%|█████▌    | 1119/2000 [24:41<15:44,  1.07s/iteration, mean_rewards=-99.2]\u001b[A\n",
            "Training:  56%|█████▌    | 1120/2000 [24:42<15:19,  1.04s/iteration, mean_rewards=-99.2]\u001b[A\n",
            "Training:  56%|█████▌    | 1120/2000 [24:42<15:19,  1.04s/iteration, mean_rewards=-174] \u001b[A\n",
            "Training:  56%|█████▌    | 1121/2000 [24:42<13:44,  1.07iteration/s, mean_rewards=-174]\u001b[A\n",
            "Training:  56%|█████▌    | 1121/2000 [24:43<13:44,  1.07iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  56%|█████▌    | 1122/2000 [24:43<12:35,  1.16iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  56%|█████▌    | 1122/2000 [24:43<12:35,  1.16iteration/s, mean_rewards=-254]\u001b[A\n",
            "Training:  56%|█████▌    | 1123/2000 [24:44<13:34,  1.08iteration/s, mean_rewards=-254]\u001b[A\n",
            "Training:  56%|█████▌    | 1123/2000 [24:44<13:34,  1.08iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:  56%|█████▌    | 1124/2000 [24:45<13:31,  1.08iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:  56%|█████▌    | 1124/2000 [24:45<13:31,  1.08iteration/s, mean_rewards=-179]\u001b[A\n",
            "Training:  56%|█████▋    | 1125/2000 [24:46<12:56,  1.13iteration/s, mean_rewards=-179]\u001b[A\n",
            "Training:  56%|█████▋    | 1125/2000 [24:46<12:56,  1.13iteration/s, mean_rewards=-86.7]\u001b[A\n",
            "Training:  56%|█████▋    | 1126/2000 [24:47<12:33,  1.16iteration/s, mean_rewards=-86.7]\u001b[A\n",
            "Training:  56%|█████▋    | 1126/2000 [24:47<12:33,  1.16iteration/s, mean_rewards=-323] \u001b[A\n",
            "Training:  56%|█████▋    | 1127/2000 [24:48<14:58,  1.03s/iteration, mean_rewards=-323]\u001b[A\n",
            "Training:  56%|█████▋    | 1127/2000 [24:48<14:58,  1.03s/iteration, mean_rewards=-283]\u001b[A\n",
            "Training:  56%|█████▋    | 1128/2000 [24:49<15:19,  1.06s/iteration, mean_rewards=-283]\u001b[A\n",
            "Training:  56%|█████▋    | 1128/2000 [24:49<15:19,  1.06s/iteration, mean_rewards=-102]\u001b[A\n",
            "Training:  56%|█████▋    | 1129/2000 [24:50<14:20,  1.01iteration/s, mean_rewards=-102]\u001b[A\n",
            "Training:  56%|█████▋    | 1129/2000 [24:50<14:20,  1.01iteration/s, mean_rewards=-236]\u001b[A\n",
            "Training:  56%|█████▋    | 1130/2000 [24:51<13:26,  1.08iteration/s, mean_rewards=-236]\u001b[A\n",
            "Training:  56%|█████▋    | 1130/2000 [24:51<13:26,  1.08iteration/s, mean_rewards=-260]\u001b[A\n",
            "Training:  57%|█████▋    | 1131/2000 [24:52<12:55,  1.12iteration/s, mean_rewards=-260]\u001b[A\n",
            "Training:  57%|█████▋    | 1131/2000 [24:52<12:55,  1.12iteration/s, mean_rewards=-289]\u001b[A\n",
            "Training:  57%|█████▋    | 1132/2000 [24:52<13:03,  1.11iteration/s, mean_rewards=-289]\u001b[A\n",
            "Training:  57%|█████▋    | 1132/2000 [24:53<13:03,  1.11iteration/s, mean_rewards=-80] \u001b[A\n",
            "Training:  57%|█████▋    | 1133/2000 [24:53<13:22,  1.08iteration/s, mean_rewards=-80]\u001b[A\n",
            "Training:  57%|█████▋    | 1133/2000 [24:54<13:22,  1.08iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  57%|█████▋    | 1134/2000 [24:54<12:17,  1.17iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  57%|█████▋    | 1134/2000 [24:55<12:17,  1.17iteration/s, mean_rewards=-337]\u001b[A\n",
            "Training:  57%|█████▋    | 1135/2000 [24:55<12:36,  1.14iteration/s, mean_rewards=-337]\u001b[A\n",
            "Training:  57%|█████▋    | 1135/2000 [24:56<12:36,  1.14iteration/s, mean_rewards=-241]\u001b[A\n",
            "Training:  57%|█████▋    | 1136/2000 [24:56<13:21,  1.08iteration/s, mean_rewards=-241]\u001b[A\n",
            "Training:  57%|█████▋    | 1136/2000 [24:56<13:21,  1.08iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  57%|█████▋    | 1137/2000 [24:57<12:28,  1.15iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  57%|█████▋    | 1137/2000 [24:57<12:28,  1.15iteration/s, mean_rewards=-227]\u001b[A\n",
            "Training:  57%|█████▋    | 1138/2000 [24:58<14:32,  1.01s/iteration, mean_rewards=-227]\u001b[A\n",
            "Training:  57%|█████▋    | 1138/2000 [24:58<14:32,  1.01s/iteration, mean_rewards=-175]\u001b[A\n",
            "Training:  57%|█████▋    | 1139/2000 [24:59<13:26,  1.07iteration/s, mean_rewards=-175]\u001b[A\n",
            "Training:  57%|█████▋    | 1139/2000 [24:59<13:26,  1.07iteration/s, mean_rewards=-396]\u001b[A\n",
            "Training:  57%|█████▋    | 1140/2000 [25:00<14:16,  1.00iteration/s, mean_rewards=-396]\u001b[A\n",
            "Training:  57%|█████▋    | 1140/2000 [25:00<14:16,  1.00iteration/s, mean_rewards=-73.5]\u001b[A\n",
            "Training:  57%|█████▋    | 1141/2000 [25:01<13:57,  1.03iteration/s, mean_rewards=-73.5]\u001b[A\n",
            "Training:  57%|█████▋    | 1141/2000 [25:01<13:57,  1.03iteration/s, mean_rewards=-104] \u001b[A\n",
            "Training:  57%|█████▋    | 1142/2000 [25:02<13:28,  1.06iteration/s, mean_rewards=-104]\u001b[A\n",
            "Training:  57%|█████▋    | 1142/2000 [25:02<13:28,  1.06iteration/s, mean_rewards=-194]\u001b[A\n",
            "Training:  57%|█████▋    | 1143/2000 [25:03<12:55,  1.11iteration/s, mean_rewards=-194]\u001b[A\n",
            "Training:  57%|█████▋    | 1143/2000 [25:03<12:55,  1.11iteration/s, mean_rewards=-109]\u001b[A\n",
            "Training:  57%|█████▋    | 1144/2000 [25:04<12:28,  1.14iteration/s, mean_rewards=-109]\u001b[A\n",
            "Training:  57%|█████▋    | 1144/2000 [25:04<12:28,  1.14iteration/s, mean_rewards=-92.5]\u001b[A\n",
            "Training:  57%|█████▋    | 1145/2000 [25:04<12:34,  1.13iteration/s, mean_rewards=-92.5]\u001b[A\n",
            "Training:  57%|█████▋    | 1145/2000 [25:05<12:34,  1.13iteration/s, mean_rewards=-250] \u001b[A\n",
            "Training:  57%|█████▋    | 1146/2000 [25:05<12:29,  1.14iteration/s, mean_rewards=-250]\u001b[A\n",
            "Training:  57%|█████▋    | 1146/2000 [25:06<12:29,  1.14iteration/s, mean_rewards=-241]\u001b[A\n",
            "Training:  57%|█████▋    | 1147/2000 [25:06<12:10,  1.17iteration/s, mean_rewards=-241]\u001b[A\n",
            "Training:  57%|█████▋    | 1147/2000 [25:06<12:10,  1.17iteration/s, mean_rewards=-290]\u001b[A\n",
            "Training:  57%|█████▋    | 1148/2000 [25:07<12:24,  1.14iteration/s, mean_rewards=-290]\u001b[A\n",
            "Training:  57%|█████▋    | 1148/2000 [25:07<12:24,  1.14iteration/s, mean_rewards=-366]\u001b[A\n",
            "Training:  57%|█████▋    | 1149/2000 [25:08<12:15,  1.16iteration/s, mean_rewards=-366]\u001b[A\n",
            "Training:  57%|█████▋    | 1149/2000 [25:08<12:15,  1.16iteration/s, mean_rewards=-392]\u001b[A\n",
            "Training:  57%|█████▊    | 1150/2000 [25:09<13:09,  1.08iteration/s, mean_rewards=-392]\u001b[A\n",
            "Training:  57%|█████▊    | 1150/2000 [25:09<13:09,  1.08iteration/s, mean_rewards=-335]\u001b[A\n",
            "Training:  58%|█████▊    | 1151/2000 [25:10<12:34,  1.13iteration/s, mean_rewards=-335]\u001b[A\n",
            "Training:  58%|█████▊    | 1151/2000 [25:10<12:34,  1.13iteration/s, mean_rewards=-295]\u001b[A\n",
            "Training:  58%|█████▊    | 1152/2000 [25:11<12:25,  1.14iteration/s, mean_rewards=-295]\u001b[A\n",
            "Training:  58%|█████▊    | 1152/2000 [25:11<12:25,  1.14iteration/s, mean_rewards=-276]\u001b[A\n",
            "Training:  58%|█████▊    | 1153/2000 [25:11<12:31,  1.13iteration/s, mean_rewards=-276]\u001b[A\n",
            "Training:  58%|█████▊    | 1153/2000 [25:12<12:31,  1.13iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  58%|█████▊    | 1154/2000 [25:13<13:55,  1.01iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  58%|█████▊    | 1154/2000 [25:13<13:55,  1.01iteration/s, mean_rewards=-202]\u001b[A\n",
            "Training:  58%|█████▊    | 1155/2000 [25:14<16:16,  1.16s/iteration, mean_rewards=-202]\u001b[A\n",
            "Training:  58%|█████▊    | 1155/2000 [25:15<16:16,  1.16s/iteration, mean_rewards=-228]\u001b[A\n",
            "Training:  58%|█████▊    | 1156/2000 [25:15<16:30,  1.17s/iteration, mean_rewards=-228]\u001b[A\n",
            "Training:  58%|█████▊    | 1156/2000 [25:16<16:30,  1.17s/iteration, mean_rewards=-151]\u001b[A\n",
            "Training:  58%|█████▊    | 1157/2000 [25:16<14:54,  1.06s/iteration, mean_rewards=-151]\u001b[A\n",
            "Training:  58%|█████▊    | 1157/2000 [25:17<14:54,  1.06s/iteration, mean_rewards=-424]\u001b[A\n",
            "Training:  58%|█████▊    | 1158/2000 [25:17<15:01,  1.07s/iteration, mean_rewards=-424]\u001b[A\n",
            "Training:  58%|█████▊    | 1158/2000 [25:18<15:01,  1.07s/iteration, mean_rewards=-141]\u001b[A\n",
            "Training:  58%|█████▊    | 1159/2000 [25:18<13:55,  1.01iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  58%|█████▊    | 1159/2000 [25:19<13:55,  1.01iteration/s, mean_rewards=-262]\u001b[A\n",
            "Training:  58%|█████▊    | 1160/2000 [25:19<14:14,  1.02s/iteration, mean_rewards=-262]\u001b[A\n",
            "Training:  58%|█████▊    | 1160/2000 [25:20<14:14,  1.02s/iteration, mean_rewards=-213]\u001b[A\n",
            "Training:  58%|█████▊    | 1161/2000 [25:20<14:21,  1.03s/iteration, mean_rewards=-213]\u001b[A\n",
            "Training:  58%|█████▊    | 1161/2000 [25:21<14:21,  1.03s/iteration, mean_rewards=-271]\u001b[A\n",
            "Training:  58%|█████▊    | 1162/2000 [25:21<14:36,  1.05s/iteration, mean_rewards=-271]\u001b[A\n",
            "Training:  58%|█████▊    | 1162/2000 [25:22<14:36,  1.05s/iteration, mean_rewards=-118]\u001b[A\n",
            "Training:  58%|█████▊    | 1163/2000 [25:22<13:14,  1.05iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  58%|█████▊    | 1163/2000 [25:23<13:14,  1.05iteration/s, mean_rewards=-269]\u001b[A\n",
            "Training:  58%|█████▊    | 1164/2000 [25:23<13:44,  1.01iteration/s, mean_rewards=-269]\u001b[A\n",
            "Training:  58%|█████▊    | 1164/2000 [25:24<13:44,  1.01iteration/s, mean_rewards=-258]\u001b[A\n",
            "Training:  58%|█████▊    | 1165/2000 [25:24<13:04,  1.06iteration/s, mean_rewards=-258]\u001b[A\n",
            "Training:  58%|█████▊    | 1165/2000 [25:25<13:04,  1.06iteration/s, mean_rewards=-176]\u001b[A\n",
            "Training:  58%|█████▊    | 1166/2000 [25:25<15:01,  1.08s/iteration, mean_rewards=-176]\u001b[A\n",
            "Training:  58%|█████▊    | 1166/2000 [25:26<15:01,  1.08s/iteration, mean_rewards=-374]\u001b[A\n",
            "Training:  58%|█████▊    | 1167/2000 [25:26<14:58,  1.08s/iteration, mean_rewards=-374]\u001b[A\n",
            "Training:  58%|█████▊    | 1167/2000 [25:27<14:58,  1.08s/iteration, mean_rewards=-135]\u001b[A\n",
            "Training:  58%|█████▊    | 1168/2000 [25:28<15:26,  1.11s/iteration, mean_rewards=-135]\u001b[A\n",
            "Training:  58%|█████▊    | 1168/2000 [25:28<15:26,  1.11s/iteration, mean_rewards=-140]\u001b[A\n",
            "Training:  58%|█████▊    | 1169/2000 [25:29<15:46,  1.14s/iteration, mean_rewards=-140]\u001b[A\n",
            "Training:  58%|█████▊    | 1169/2000 [25:29<15:46,  1.14s/iteration, mean_rewards=-275]\u001b[A\n",
            "Training:  58%|█████▊    | 1170/2000 [25:30<14:27,  1.05s/iteration, mean_rewards=-275]\u001b[A\n",
            "Training:  58%|█████▊    | 1170/2000 [25:30<14:27,  1.05s/iteration, mean_rewards=-122]\u001b[A\n",
            "Training:  59%|█████▊    | 1171/2000 [25:31<13:32,  1.02iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  59%|█████▊    | 1171/2000 [25:31<13:32,  1.02iteration/s, mean_rewards=-187]\u001b[A\n",
            "Training:  59%|█████▊    | 1172/2000 [25:31<13:20,  1.03iteration/s, mean_rewards=-187]\u001b[A\n",
            "Training:  59%|█████▊    | 1172/2000 [25:32<13:20,  1.03iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  59%|█████▊    | 1173/2000 [25:32<12:09,  1.13iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  59%|█████▊    | 1173/2000 [25:33<12:09,  1.13iteration/s, mean_rewards=-83.9]\u001b[A\n",
            "Training:  59%|█████▊    | 1174/2000 [25:33<12:20,  1.12iteration/s, mean_rewards=-83.9]\u001b[A\n",
            "Training:  59%|█████▊    | 1174/2000 [25:33<12:20,  1.12iteration/s, mean_rewards=-124] \u001b[A\n",
            "Training:  59%|█████▉    | 1175/2000 [25:34<11:24,  1.21iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  59%|█████▉    | 1175/2000 [25:34<11:24,  1.21iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:  59%|█████▉    | 1176/2000 [25:34<10:43,  1.28iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:  59%|█████▉    | 1176/2000 [25:35<10:43,  1.28iteration/s, mean_rewards=-280]\u001b[A\n",
            "Training:  59%|█████▉    | 1177/2000 [25:35<10:51,  1.26iteration/s, mean_rewards=-280]\u001b[A\n",
            "Training:  59%|█████▉    | 1177/2000 [25:36<10:51,  1.26iteration/s, mean_rewards=-313]\u001b[A\n",
            "Training:  59%|█████▉    | 1178/2000 [25:36<11:00,  1.24iteration/s, mean_rewards=-313]\u001b[A\n",
            "Training:  59%|█████▉    | 1178/2000 [25:36<11:00,  1.24iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  59%|█████▉    | 1179/2000 [25:37<10:56,  1.25iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  59%|█████▉    | 1179/2000 [25:37<10:56,  1.25iteration/s, mean_rewards=-374]\u001b[A\n",
            "Training:  59%|█████▉    | 1180/2000 [25:38<11:29,  1.19iteration/s, mean_rewards=-374]\u001b[A\n",
            "Training:  59%|█████▉    | 1180/2000 [25:38<11:29,  1.19iteration/s, mean_rewards=-333]\u001b[A\n",
            "Training:  59%|█████▉    | 1181/2000 [25:39<12:15,  1.11iteration/s, mean_rewards=-333]\u001b[A\n",
            "Training:  59%|█████▉    | 1181/2000 [25:39<12:15,  1.11iteration/s, mean_rewards=-165]\u001b[A\n",
            "Training:  59%|█████▉    | 1182/2000 [25:40<14:19,  1.05s/iteration, mean_rewards=-165]\u001b[A\n",
            "Training:  59%|█████▉    | 1182/2000 [25:40<14:19,  1.05s/iteration, mean_rewards=-173]\u001b[A\n",
            "Training:  59%|█████▉    | 1183/2000 [25:41<12:46,  1.07iteration/s, mean_rewards=-173]\u001b[A\n",
            "Training:  59%|█████▉    | 1183/2000 [25:41<12:46,  1.07iteration/s, mean_rewards=-175]\u001b[A\n",
            "Training:  59%|█████▉    | 1184/2000 [25:42<12:49,  1.06iteration/s, mean_rewards=-175]\u001b[A\n",
            "Training:  59%|█████▉    | 1184/2000 [25:42<12:49,  1.06iteration/s, mean_rewards=-217]\u001b[A\n",
            "Training:  59%|█████▉    | 1185/2000 [25:43<13:20,  1.02iteration/s, mean_rewards=-217]\u001b[A\n",
            "Training:  59%|█████▉    | 1185/2000 [25:43<13:20,  1.02iteration/s, mean_rewards=-174]\u001b[A\n",
            "Training:  59%|█████▉    | 1186/2000 [25:44<12:31,  1.08iteration/s, mean_rewards=-174]\u001b[A\n",
            "Training:  59%|█████▉    | 1186/2000 [25:44<12:31,  1.08iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  59%|█████▉    | 1187/2000 [25:45<12:37,  1.07iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  59%|█████▉    | 1187/2000 [25:45<12:37,  1.07iteration/s, mean_rewards=-186]\u001b[A\n",
            "Training:  59%|█████▉    | 1188/2000 [25:46<12:33,  1.08iteration/s, mean_rewards=-186]\u001b[A\n",
            "Training:  59%|█████▉    | 1188/2000 [25:46<12:33,  1.08iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  59%|█████▉    | 1189/2000 [25:47<12:39,  1.07iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  59%|█████▉    | 1189/2000 [25:47<12:39,  1.07iteration/s, mean_rewards=-414]\u001b[A\n",
            "Training:  60%|█████▉    | 1190/2000 [25:47<12:20,  1.09iteration/s, mean_rewards=-414]\u001b[A\n",
            "Training:  60%|█████▉    | 1190/2000 [25:48<12:20,  1.09iteration/s, mean_rewards=-281]\u001b[A\n",
            "Training:  60%|█████▉    | 1191/2000 [25:48<12:20,  1.09iteration/s, mean_rewards=-281]\u001b[A\n",
            "Training:  60%|█████▉    | 1191/2000 [25:49<12:20,  1.09iteration/s, mean_rewards=-162]\u001b[A\n",
            "Training:  60%|█████▉    | 1192/2000 [25:49<11:53,  1.13iteration/s, mean_rewards=-162]\u001b[A\n",
            "Training:  60%|█████▉    | 1192/2000 [25:50<11:53,  1.13iteration/s, mean_rewards=-425]\u001b[A\n",
            "Training:  60%|█████▉    | 1193/2000 [25:50<12:00,  1.12iteration/s, mean_rewards=-425]\u001b[A\n",
            "Training:  60%|█████▉    | 1193/2000 [25:51<12:00,  1.12iteration/s, mean_rewards=-366]\u001b[A\n",
            "Training:  60%|█████▉    | 1194/2000 [25:51<13:45,  1.02s/iteration, mean_rewards=-366]\u001b[A\n",
            "Training:  60%|█████▉    | 1194/2000 [25:52<13:45,  1.02s/iteration, mean_rewards=-58.5]\u001b[A\n",
            "Training:  60%|█████▉    | 1195/2000 [25:53<14:34,  1.09s/iteration, mean_rewards=-58.5]\u001b[A\n",
            "Training:  60%|█████▉    | 1195/2000 [25:53<14:34,  1.09s/iteration, mean_rewards=-283] \u001b[A\n",
            "Training:  60%|█████▉    | 1196/2000 [25:53<13:36,  1.02s/iteration, mean_rewards=-283]\u001b[A\n",
            "Training:  60%|█████▉    | 1196/2000 [25:54<13:36,  1.02s/iteration, mean_rewards=-156]\u001b[A\n",
            "Training:  60%|█████▉    | 1197/2000 [25:54<13:17,  1.01iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  60%|█████▉    | 1197/2000 [25:55<13:17,  1.01iteration/s, mean_rewards=-200]\u001b[A\n",
            "Training:  60%|█████▉    | 1198/2000 [25:55<13:11,  1.01iteration/s, mean_rewards=-200]\u001b[A\n",
            "Training:  60%|█████▉    | 1198/2000 [25:56<13:11,  1.01iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  60%|█████▉    | 1199/2000 [25:56<12:37,  1.06iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  60%|█████▉    | 1199/2000 [25:57<12:37,  1.06iteration/s, mean_rewards=-199]\u001b[A\n",
            "Training:  60%|██████    | 1200/2000 [25:57<13:13,  1.01iteration/s, mean_rewards=-199]\u001b[A\n",
            "Training:  60%|██████    | 1200/2000 [25:58<13:13,  1.01iteration/s, mean_rewards=-248]\u001b[A\n",
            "Training:  60%|██████    | 1201/2000 [25:58<12:06,  1.10iteration/s, mean_rewards=-248]\u001b[A\n",
            "Training:  60%|██████    | 1201/2000 [25:59<12:06,  1.10iteration/s, mean_rewards=-80.2]\u001b[A\n",
            "Training:  60%|██████    | 1202/2000 [25:59<12:49,  1.04iteration/s, mean_rewards=-80.2]\u001b[A\n",
            "Training:  60%|██████    | 1202/2000 [26:00<12:49,  1.04iteration/s, mean_rewards=-305] \u001b[A\n",
            "Training:  60%|██████    | 1203/2000 [26:00<12:34,  1.06iteration/s, mean_rewards=-305]\u001b[A\n",
            "Training:  60%|██████    | 1203/2000 [26:00<12:34,  1.06iteration/s, mean_rewards=-192]\u001b[A\n",
            "Training:  60%|██████    | 1204/2000 [26:01<11:56,  1.11iteration/s, mean_rewards=-192]\u001b[A\n",
            "Training:  60%|██████    | 1204/2000 [26:01<11:56,  1.11iteration/s, mean_rewards=-249]\u001b[A\n",
            "Training:  60%|██████    | 1205/2000 [26:02<11:36,  1.14iteration/s, mean_rewards=-249]\u001b[A\n",
            "Training:  60%|██████    | 1205/2000 [26:02<11:36,  1.14iteration/s, mean_rewards=-400]\u001b[A\n",
            "Training:  60%|██████    | 1206/2000 [26:03<11:48,  1.12iteration/s, mean_rewards=-400]\u001b[A\n",
            "Training:  60%|██████    | 1206/2000 [26:03<11:48,  1.12iteration/s, mean_rewards=-239]\u001b[A\n",
            "Training:  60%|██████    | 1207/2000 [26:04<14:19,  1.08s/iteration, mean_rewards=-239]\u001b[A\n",
            "Training:  60%|██████    | 1207/2000 [26:05<14:19,  1.08s/iteration, mean_rewards=-104]\u001b[A\n",
            "Training:  60%|██████    | 1208/2000 [26:05<14:34,  1.10s/iteration, mean_rewards=-104]\u001b[A\n",
            "Training:  60%|██████    | 1208/2000 [26:06<14:34,  1.10s/iteration, mean_rewards=-94.1]\u001b[A\n",
            "Training:  60%|██████    | 1209/2000 [26:06<13:02,  1.01iteration/s, mean_rewards=-94.1]\u001b[A\n",
            "Training:  60%|██████    | 1209/2000 [26:06<13:02,  1.01iteration/s, mean_rewards=-147] \u001b[A\n",
            "Training:  60%|██████    | 1210/2000 [26:07<12:50,  1.02iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:  60%|██████    | 1210/2000 [26:07<12:50,  1.02iteration/s, mean_rewards=-106]\u001b[A\n",
            "Training:  61%|██████    | 1211/2000 [26:08<11:49,  1.11iteration/s, mean_rewards=-106]\u001b[A\n",
            "Training:  61%|██████    | 1211/2000 [26:08<11:49,  1.11iteration/s, mean_rewards=-163]\u001b[A\n",
            "Training:  61%|██████    | 1212/2000 [26:08<11:23,  1.15iteration/s, mean_rewards=-163]\u001b[A\n",
            "Training:  61%|██████    | 1212/2000 [26:09<11:23,  1.15iteration/s, mean_rewards=-105]\u001b[A\n",
            "Training:  61%|██████    | 1213/2000 [26:09<10:31,  1.25iteration/s, mean_rewards=-105]\u001b[A\n",
            "Training:  61%|██████    | 1213/2000 [26:09<10:31,  1.25iteration/s, mean_rewards=-310]\u001b[A\n",
            "Training:  61%|██████    | 1214/2000 [26:10<10:56,  1.20iteration/s, mean_rewards=-310]\u001b[A\n",
            "Training:  61%|██████    | 1214/2000 [26:10<10:56,  1.20iteration/s, mean_rewards=-319]\u001b[A\n",
            "Training:  61%|██████    | 1215/2000 [26:11<11:21,  1.15iteration/s, mean_rewards=-319]\u001b[A\n",
            "Training:  61%|██████    | 1215/2000 [26:11<11:21,  1.15iteration/s, mean_rewards=-285]\u001b[A\n",
            "Training:  61%|██████    | 1216/2000 [26:12<12:08,  1.08iteration/s, mean_rewards=-285]\u001b[A\n",
            "Training:  61%|██████    | 1216/2000 [26:12<12:08,  1.08iteration/s, mean_rewards=-347]\u001b[A\n",
            "Training:  61%|██████    | 1217/2000 [26:13<12:03,  1.08iteration/s, mean_rewards=-347]\u001b[A\n",
            "Training:  61%|██████    | 1217/2000 [26:13<12:03,  1.08iteration/s, mean_rewards=-190]\u001b[A\n",
            "Training:  61%|██████    | 1218/2000 [26:14<11:40,  1.12iteration/s, mean_rewards=-190]\u001b[A\n",
            "Training:  61%|██████    | 1218/2000 [26:14<11:40,  1.12iteration/s, mean_rewards=-183]\u001b[A\n",
            "Training:  61%|██████    | 1219/2000 [26:15<12:21,  1.05iteration/s, mean_rewards=-183]\u001b[A\n",
            "Training:  61%|██████    | 1219/2000 [26:15<12:21,  1.05iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  61%|██████    | 1220/2000 [26:16<12:25,  1.05iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  61%|██████    | 1220/2000 [26:16<12:25,  1.05iteration/s, mean_rewards=-291]\u001b[A\n",
            "Training:  61%|██████    | 1221/2000 [26:17<13:24,  1.03s/iteration, mean_rewards=-291]\u001b[A\n",
            "Training:  61%|██████    | 1221/2000 [26:17<13:24,  1.03s/iteration, mean_rewards=-213]\u001b[A\n",
            "Training:  61%|██████    | 1222/2000 [26:18<13:57,  1.08s/iteration, mean_rewards=-213]\u001b[A\n",
            "Training:  61%|██████    | 1222/2000 [26:19<13:57,  1.08s/iteration, mean_rewards=-153]\u001b[A\n",
            "Training:  61%|██████    | 1223/2000 [26:19<13:35,  1.05s/iteration, mean_rewards=-153]\u001b[A\n",
            "Training:  61%|██████    | 1223/2000 [26:20<13:35,  1.05s/iteration, mean_rewards=-88.5]\u001b[A\n",
            "Training:  61%|██████    | 1224/2000 [26:20<12:36,  1.03iteration/s, mean_rewards=-88.5]\u001b[A\n",
            "Training:  61%|██████    | 1224/2000 [26:20<12:36,  1.03iteration/s, mean_rewards=-137] \u001b[A\n",
            "Training:  61%|██████▏   | 1225/2000 [26:21<11:22,  1.14iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  61%|██████▏   | 1225/2000 [26:21<11:22,  1.14iteration/s, mean_rewards=-323]\u001b[A\n",
            "Training:  61%|██████▏   | 1226/2000 [26:22<12:06,  1.07iteration/s, mean_rewards=-323]\u001b[A\n",
            "Training:  61%|██████▏   | 1226/2000 [26:22<12:06,  1.07iteration/s, mean_rewards=-177]\u001b[A\n",
            "Training:  61%|██████▏   | 1227/2000 [26:23<12:04,  1.07iteration/s, mean_rewards=-177]\u001b[A\n",
            "Training:  61%|██████▏   | 1227/2000 [26:23<12:04,  1.07iteration/s, mean_rewards=-173]\u001b[A\n",
            "Training:  61%|██████▏   | 1228/2000 [26:24<12:31,  1.03iteration/s, mean_rewards=-173]\u001b[A\n",
            "Training:  61%|██████▏   | 1228/2000 [26:24<12:31,  1.03iteration/s, mean_rewards=-254]\u001b[A\n",
            "Training:  61%|██████▏   | 1229/2000 [26:25<11:55,  1.08iteration/s, mean_rewards=-254]\u001b[A\n",
            "Training:  61%|██████▏   | 1229/2000 [26:25<11:55,  1.08iteration/s, mean_rewards=-103]\u001b[A\n",
            "Training:  62%|██████▏   | 1230/2000 [26:25<11:26,  1.12iteration/s, mean_rewards=-103]\u001b[A\n",
            "Training:  62%|██████▏   | 1230/2000 [26:26<11:26,  1.12iteration/s, mean_rewards=-310]\u001b[A\n",
            "Training:  62%|██████▏   | 1231/2000 [26:26<11:09,  1.15iteration/s, mean_rewards=-310]\u001b[A\n",
            "Training:  62%|██████▏   | 1231/2000 [26:27<11:09,  1.15iteration/s, mean_rewards=-342]\u001b[A\n",
            "Training:  62%|██████▏   | 1232/2000 [26:27<11:01,  1.16iteration/s, mean_rewards=-342]\u001b[A\n",
            "Training:  62%|██████▏   | 1232/2000 [26:27<11:01,  1.16iteration/s, mean_rewards=-355]\u001b[A\n",
            "Training:  62%|██████▏   | 1233/2000 [26:28<11:56,  1.07iteration/s, mean_rewards=-355]\u001b[A\n",
            "Training:  62%|██████▏   | 1233/2000 [26:29<11:56,  1.07iteration/s, mean_rewards=-486]\u001b[A\n",
            "Training:  62%|██████▏   | 1234/2000 [26:29<12:26,  1.03iteration/s, mean_rewards=-486]\u001b[A\n",
            "Training:  62%|██████▏   | 1234/2000 [26:29<12:26,  1.03iteration/s, mean_rewards=-195]\u001b[A\n",
            "Training:  62%|██████▏   | 1235/2000 [26:30<11:50,  1.08iteration/s, mean_rewards=-195]\u001b[A\n",
            "Training:  62%|██████▏   | 1235/2000 [26:31<11:50,  1.08iteration/s, mean_rewards=-318]\u001b[A\n",
            "Training:  62%|██████▏   | 1236/2000 [26:32<14:19,  1.12s/iteration, mean_rewards=-318]\u001b[A\n",
            "Training:  62%|██████▏   | 1236/2000 [26:32<14:19,  1.12s/iteration, mean_rewards=-106]\u001b[A\n",
            "Training:  62%|██████▏   | 1237/2000 [26:32<12:42,  1.00iteration/s, mean_rewards=-106]\u001b[A\n",
            "Training:  62%|██████▏   | 1237/2000 [26:33<12:42,  1.00iteration/s, mean_rewards=-190]\u001b[A\n",
            "Training:  62%|██████▏   | 1238/2000 [26:33<11:30,  1.10iteration/s, mean_rewards=-190]\u001b[A\n",
            "Training:  62%|██████▏   | 1238/2000 [26:33<11:30,  1.10iteration/s, mean_rewards=-201]\u001b[A\n",
            "Training:  62%|██████▏   | 1239/2000 [26:34<12:03,  1.05iteration/s, mean_rewards=-201]\u001b[A\n",
            "Training:  62%|██████▏   | 1239/2000 [26:35<12:03,  1.05iteration/s, mean_rewards=-87.7]\u001b[A\n",
            "Training:  62%|██████▏   | 1240/2000 [26:35<13:01,  1.03s/iteration, mean_rewards=-87.7]\u001b[A\n",
            "Training:  62%|██████▏   | 1240/2000 [26:36<13:01,  1.03s/iteration, mean_rewards=-147] \u001b[A\n",
            "Training:  62%|██████▏   | 1241/2000 [26:36<12:46,  1.01s/iteration, mean_rewards=-147]\u001b[A\n",
            "Training:  62%|██████▏   | 1241/2000 [26:37<12:46,  1.01s/iteration, mean_rewards=-130]\u001b[A\n",
            "Training:  62%|██████▏   | 1242/2000 [26:37<12:28,  1.01iteration/s, mean_rewards=-130]\u001b[A\n",
            "Training:  62%|██████▏   | 1242/2000 [26:37<12:28,  1.01iteration/s, mean_rewards=-216]\u001b[A\n",
            "Training:  62%|██████▏   | 1243/2000 [26:38<11:50,  1.07iteration/s, mean_rewards=-216]\u001b[A\n",
            "Training:  62%|██████▏   | 1243/2000 [26:38<11:50,  1.07iteration/s, mean_rewards=-189]\u001b[A\n",
            "Training:  62%|██████▏   | 1244/2000 [26:39<10:50,  1.16iteration/s, mean_rewards=-189]\u001b[A\n",
            "Training:  62%|██████▏   | 1244/2000 [26:39<10:50,  1.16iteration/s, mean_rewards=-261]\u001b[A\n",
            "Training:  62%|██████▏   | 1245/2000 [26:40<11:27,  1.10iteration/s, mean_rewards=-261]\u001b[A\n",
            "Training:  62%|██████▏   | 1245/2000 [26:40<11:27,  1.10iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  62%|██████▏   | 1246/2000 [26:41<11:34,  1.09iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  62%|██████▏   | 1246/2000 [26:41<11:34,  1.09iteration/s, mean_rewards=-259]\u001b[A\n",
            "Training:  62%|██████▏   | 1247/2000 [26:42<11:43,  1.07iteration/s, mean_rewards=-259]\u001b[A\n",
            "Training:  62%|██████▏   | 1247/2000 [26:42<11:43,  1.07iteration/s, mean_rewards=-212]\u001b[A\n",
            "Training:  62%|██████▏   | 1248/2000 [26:43<12:13,  1.02iteration/s, mean_rewards=-212]\u001b[A\n",
            "Training:  62%|██████▏   | 1248/2000 [26:43<12:13,  1.02iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  62%|██████▏   | 1249/2000 [26:44<13:03,  1.04s/iteration, mean_rewards=-155]\u001b[A\n",
            "Training:  62%|██████▏   | 1249/2000 [26:44<13:03,  1.04s/iteration, mean_rewards=-181]\u001b[A\n",
            "Training:  62%|██████▎   | 1250/2000 [26:45<12:06,  1.03iteration/s, mean_rewards=-181]\u001b[A\n",
            "Training:  62%|██████▎   | 1250/2000 [26:45<12:06,  1.03iteration/s, mean_rewards=-240]\u001b[A\n",
            "Training:  63%|██████▎   | 1251/2000 [26:46<11:51,  1.05iteration/s, mean_rewards=-240]\u001b[A\n",
            "Training:  63%|██████▎   | 1251/2000 [26:46<11:51,  1.05iteration/s, mean_rewards=-163]\u001b[A\n",
            "Training:  63%|██████▎   | 1252/2000 [26:46<11:45,  1.06iteration/s, mean_rewards=-163]\u001b[A\n",
            "Training:  63%|██████▎   | 1252/2000 [26:47<11:45,  1.06iteration/s, mean_rewards=-88.4]\u001b[A\n",
            "Training:  63%|██████▎   | 1253/2000 [26:47<11:10,  1.11iteration/s, mean_rewards=-88.4]\u001b[A\n",
            "Training:  63%|██████▎   | 1253/2000 [26:48<11:10,  1.11iteration/s, mean_rewards=-175] \u001b[A\n",
            "Training:  63%|██████▎   | 1254/2000 [26:48<10:44,  1.16iteration/s, mean_rewards=-175]\u001b[A\n",
            "Training:  63%|██████▎   | 1254/2000 [26:48<10:44,  1.16iteration/s, mean_rewards=-192]\u001b[A\n",
            "Training:  63%|██████▎   | 1255/2000 [26:49<10:05,  1.23iteration/s, mean_rewards=-192]\u001b[A\n",
            "Training:  63%|██████▎   | 1255/2000 [26:49<10:05,  1.23iteration/s, mean_rewards=-244]\u001b[A\n",
            "Training:  63%|██████▎   | 1256/2000 [26:49<09:31,  1.30iteration/s, mean_rewards=-244]\u001b[A\n",
            "Training:  63%|██████▎   | 1256/2000 [26:50<09:31,  1.30iteration/s, mean_rewards=-237]\u001b[A\n",
            "Training:  63%|██████▎   | 1257/2000 [26:50<09:46,  1.27iteration/s, mean_rewards=-237]\u001b[A\n",
            "Training:  63%|██████▎   | 1257/2000 [26:51<09:46,  1.27iteration/s, mean_rewards=-186]\u001b[A\n",
            "Training:  63%|██████▎   | 1258/2000 [26:51<09:55,  1.25iteration/s, mean_rewards=-186]\u001b[A\n",
            "Training:  63%|██████▎   | 1258/2000 [26:51<09:55,  1.25iteration/s, mean_rewards=-297]\u001b[A\n",
            "Training:  63%|██████▎   | 1259/2000 [26:52<10:05,  1.22iteration/s, mean_rewards=-297]\u001b[A\n",
            "Training:  63%|██████▎   | 1259/2000 [26:52<10:05,  1.22iteration/s, mean_rewards=-106]\u001b[A\n",
            "Training:  63%|██████▎   | 1260/2000 [26:53<10:15,  1.20iteration/s, mean_rewards=-106]\u001b[A\n",
            "Training:  63%|██████▎   | 1260/2000 [26:53<10:15,  1.20iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  63%|██████▎   | 1261/2000 [26:53<09:40,  1.27iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  63%|██████▎   | 1261/2000 [26:54<09:40,  1.27iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  63%|██████▎   | 1262/2000 [26:55<10:35,  1.16iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  63%|██████▎   | 1262/2000 [26:55<10:35,  1.16iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  63%|██████▎   | 1263/2000 [26:56<12:51,  1.05s/iteration, mean_rewards=-110]\u001b[A\n",
            "Training:  63%|██████▎   | 1263/2000 [26:56<12:51,  1.05s/iteration, mean_rewards=-164]\u001b[A\n",
            "Training:  63%|██████▎   | 1264/2000 [26:57<13:12,  1.08s/iteration, mean_rewards=-164]\u001b[A\n",
            "Training:  63%|██████▎   | 1264/2000 [26:57<13:12,  1.08s/iteration, mean_rewards=-153]\u001b[A\n",
            "Training:  63%|██████▎   | 1265/2000 [26:58<12:16,  1.00s/iteration, mean_rewards=-153]\u001b[A\n",
            "Training:  63%|██████▎   | 1265/2000 [26:58<12:16,  1.00s/iteration, mean_rewards=-187]\u001b[A\n",
            "Training:  63%|██████▎   | 1266/2000 [26:59<12:04,  1.01iteration/s, mean_rewards=-187]\u001b[A\n",
            "Training:  63%|██████▎   | 1266/2000 [26:59<12:04,  1.01iteration/s, mean_rewards=-240]\u001b[A\n",
            "Training:  63%|██████▎   | 1267/2000 [27:00<10:56,  1.12iteration/s, mean_rewards=-240]\u001b[A\n",
            "Training:  63%|██████▎   | 1267/2000 [27:00<10:56,  1.12iteration/s, mean_rewards=-284]\u001b[A\n",
            "Training:  63%|██████▎   | 1268/2000 [27:01<11:05,  1.10iteration/s, mean_rewards=-284]\u001b[A\n",
            "Training:  63%|██████▎   | 1268/2000 [27:01<11:05,  1.10iteration/s, mean_rewards=-188]\u001b[A\n",
            "Training:  63%|██████▎   | 1269/2000 [27:02<11:13,  1.09iteration/s, mean_rewards=-188]\u001b[A\n",
            "Training:  63%|██████▎   | 1269/2000 [27:02<11:13,  1.09iteration/s, mean_rewards=-160]\u001b[A\n",
            "Training:  64%|██████▎   | 1270/2000 [27:02<11:21,  1.07iteration/s, mean_rewards=-160]\u001b[A\n",
            "Training:  64%|██████▎   | 1270/2000 [27:03<11:21,  1.07iteration/s, mean_rewards=-43.1]\u001b[A\n",
            "Training:  64%|██████▎   | 1271/2000 [27:03<10:33,  1.15iteration/s, mean_rewards=-43.1]\u001b[A\n",
            "Training:  64%|██████▎   | 1271/2000 [27:03<10:33,  1.15iteration/s, mean_rewards=-153] \u001b[A\n",
            "Training:  64%|██████▎   | 1272/2000 [27:04<09:50,  1.23iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  64%|██████▎   | 1272/2000 [27:04<09:50,  1.23iteration/s, mean_rewards=-171]\u001b[A\n",
            "Training:  64%|██████▎   | 1273/2000 [27:05<10:46,  1.12iteration/s, mean_rewards=-171]\u001b[A\n",
            "Training:  64%|██████▎   | 1273/2000 [27:05<10:46,  1.12iteration/s, mean_rewards=-84.1]\u001b[A\n",
            "Training:  64%|██████▎   | 1274/2000 [27:06<11:20,  1.07iteration/s, mean_rewards=-84.1]\u001b[A\n",
            "Training:  64%|██████▎   | 1274/2000 [27:06<11:20,  1.07iteration/s, mean_rewards=-159] \u001b[A\n",
            "Training:  64%|██████▍   | 1275/2000 [27:07<10:57,  1.10iteration/s, mean_rewards=-159]\u001b[A\n",
            "Training:  64%|██████▍   | 1275/2000 [27:07<10:57,  1.10iteration/s, mean_rewards=-259]\u001b[A\n",
            "Training:  64%|██████▍   | 1276/2000 [27:08<11:20,  1.06iteration/s, mean_rewards=-259]\u001b[A\n",
            "Training:  64%|██████▍   | 1276/2000 [27:08<11:20,  1.06iteration/s, mean_rewards=-206]\u001b[A\n",
            "Training:  64%|██████▍   | 1277/2000 [27:09<12:19,  1.02s/iteration, mean_rewards=-206]\u001b[A\n",
            "Training:  64%|██████▍   | 1277/2000 [27:09<12:19,  1.02s/iteration, mean_rewards=-123]\u001b[A\n",
            "Training:  64%|██████▍   | 1278/2000 [27:10<12:45,  1.06s/iteration, mean_rewards=-123]\u001b[A\n",
            "Training:  64%|██████▍   | 1278/2000 [27:11<12:45,  1.06s/iteration, mean_rewards=-339]\u001b[A\n",
            "Training:  64%|██████▍   | 1279/2000 [27:11<12:09,  1.01s/iteration, mean_rewards=-339]\u001b[A\n",
            "Training:  64%|██████▍   | 1279/2000 [27:12<12:09,  1.01s/iteration, mean_rewards=-185]\u001b[A\n",
            "Training:  64%|██████▍   | 1280/2000 [27:12<12:01,  1.00s/iteration, mean_rewards=-185]\u001b[A\n",
            "Training:  64%|██████▍   | 1280/2000 [27:12<12:01,  1.00s/iteration, mean_rewards=-249]\u001b[A\n",
            "Training:  64%|██████▍   | 1281/2000 [27:13<11:42,  1.02iteration/s, mean_rewards=-249]\u001b[A\n",
            "Training:  64%|██████▍   | 1281/2000 [27:13<11:42,  1.02iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  64%|██████▍   | 1282/2000 [27:14<10:39,  1.12iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  64%|██████▍   | 1282/2000 [27:14<10:39,  1.12iteration/s, mean_rewards=-211]\u001b[A\n",
            "Training:  64%|██████▍   | 1283/2000 [27:15<10:50,  1.10iteration/s, mean_rewards=-211]\u001b[A\n",
            "Training:  64%|██████▍   | 1283/2000 [27:15<10:50,  1.10iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  64%|██████▍   | 1284/2000 [27:16<10:57,  1.09iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  64%|██████▍   | 1284/2000 [27:16<10:57,  1.09iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  64%|██████▍   | 1285/2000 [27:16<10:46,  1.11iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  64%|██████▍   | 1285/2000 [27:17<10:46,  1.11iteration/s, mean_rewards=-263]\u001b[A\n",
            "Training:  64%|██████▍   | 1286/2000 [27:17<10:25,  1.14iteration/s, mean_rewards=-263]\u001b[A\n",
            "Training:  64%|██████▍   | 1286/2000 [27:18<10:25,  1.14iteration/s, mean_rewards=-331]\u001b[A\n",
            "Training:  64%|██████▍   | 1287/2000 [27:18<10:38,  1.12iteration/s, mean_rewards=-331]\u001b[A\n",
            "Training:  64%|██████▍   | 1287/2000 [27:19<10:38,  1.12iteration/s, mean_rewards=-342]\u001b[A\n",
            "Training:  64%|██████▍   | 1288/2000 [27:19<11:13,  1.06iteration/s, mean_rewards=-342]\u001b[A\n",
            "Training:  64%|██████▍   | 1288/2000 [27:20<11:13,  1.06iteration/s, mean_rewards=-233]\u001b[A\n",
            "Training:  64%|██████▍   | 1289/2000 [27:20<11:10,  1.06iteration/s, mean_rewards=-233]\u001b[A\n",
            "Training:  64%|██████▍   | 1289/2000 [27:21<11:10,  1.06iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  64%|██████▍   | 1290/2000 [27:21<11:27,  1.03iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  64%|██████▍   | 1290/2000 [27:22<11:27,  1.03iteration/s, mean_rewards=-249]\u001b[A\n",
            "Training:  65%|██████▍   | 1291/2000 [27:22<11:11,  1.06iteration/s, mean_rewards=-249]\u001b[A\n",
            "Training:  65%|██████▍   | 1291/2000 [27:23<11:11,  1.06iteration/s, mean_rewards=-325]\u001b[A\n",
            "Training:  65%|██████▍   | 1292/2000 [27:23<12:28,  1.06s/iteration, mean_rewards=-325]\u001b[A\n",
            "Training:  65%|██████▍   | 1292/2000 [27:24<12:28,  1.06s/iteration, mean_rewards=-300]\u001b[A\n",
            "Training:  65%|██████▍   | 1293/2000 [27:24<12:25,  1.05s/iteration, mean_rewards=-300]\u001b[A\n",
            "Training:  65%|██████▍   | 1293/2000 [27:25<12:25,  1.05s/iteration, mean_rewards=-113]\u001b[A\n",
            "Training:  65%|██████▍   | 1294/2000 [27:25<11:31,  1.02iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  65%|██████▍   | 1294/2000 [27:26<11:31,  1.02iteration/s, mean_rewards=-266]\u001b[A\n",
            "Training:  65%|██████▍   | 1295/2000 [27:26<11:04,  1.06iteration/s, mean_rewards=-266]\u001b[A\n",
            "Training:  65%|██████▍   | 1295/2000 [27:26<11:04,  1.06iteration/s, mean_rewards=-92] \u001b[A\n",
            "Training:  65%|██████▍   | 1296/2000 [27:27<10:03,  1.17iteration/s, mean_rewards=-92]\u001b[A\n",
            "Training:  65%|██████▍   | 1296/2000 [27:27<10:03,  1.17iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  65%|██████▍   | 1297/2000 [27:28<09:34,  1.22iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  65%|██████▍   | 1297/2000 [27:28<09:34,  1.22iteration/s, mean_rewards=-271]\u001b[A\n",
            "Training:  65%|██████▍   | 1298/2000 [27:28<09:59,  1.17iteration/s, mean_rewards=-271]\u001b[A\n",
            "Training:  65%|██████▍   | 1298/2000 [27:29<09:59,  1.17iteration/s, mean_rewards=-204]\u001b[A\n",
            "Training:  65%|██████▍   | 1299/2000 [27:29<10:26,  1.12iteration/s, mean_rewards=-204]\u001b[A\n",
            "Training:  65%|██████▍   | 1299/2000 [27:30<10:26,  1.12iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  65%|██████▌   | 1300/2000 [27:31<11:06,  1.05iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  65%|██████▌   | 1300/2000 [27:31<11:06,  1.05iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  65%|██████▌   | 1301/2000 [27:32<11:06,  1.05iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  65%|██████▌   | 1301/2000 [27:32<11:06,  1.05iteration/s, mean_rewards=-260]\u001b[A\n",
            "Training:  65%|██████▌   | 1302/2000 [27:32<10:41,  1.09iteration/s, mean_rewards=-260]\u001b[A\n",
            "Training:  65%|██████▌   | 1302/2000 [27:33<10:41,  1.09iteration/s, mean_rewards=-157]\u001b[A\n",
            "Training:  65%|██████▌   | 1303/2000 [27:33<10:21,  1.12iteration/s, mean_rewards=-157]\u001b[A\n",
            "Training:  65%|██████▌   | 1303/2000 [27:34<10:21,  1.12iteration/s, mean_rewards=-291]\u001b[A\n",
            "Training:  65%|██████▌   | 1304/2000 [27:34<11:49,  1.02s/iteration, mean_rewards=-291]\u001b[A\n",
            "Training:  65%|██████▌   | 1304/2000 [27:35<11:49,  1.02s/iteration, mean_rewards=-237]\u001b[A\n",
            "Training:  65%|██████▌   | 1305/2000 [27:36<12:55,  1.12s/iteration, mean_rewards=-237]\u001b[A\n",
            "Training:  65%|██████▌   | 1305/2000 [27:36<12:55,  1.12s/iteration, mean_rewards=-352]\u001b[A\n",
            "Training:  65%|██████▌   | 1306/2000 [27:37<14:02,  1.21s/iteration, mean_rewards=-352]\u001b[A\n",
            "Training:  65%|██████▌   | 1306/2000 [27:38<14:02,  1.21s/iteration, mean_rewards=-217]\u001b[A\n",
            "Training:  65%|██████▌   | 1307/2000 [27:38<12:16,  1.06s/iteration, mean_rewards=-217]\u001b[A\n",
            "Training:  65%|██████▌   | 1307/2000 [27:38<12:16,  1.06s/iteration, mean_rewards=-116]\u001b[A\n",
            "Training:  65%|██████▌   | 1308/2000 [27:39<11:01,  1.05iteration/s, mean_rewards=-116]\u001b[A\n",
            "Training:  65%|██████▌   | 1308/2000 [27:39<11:01,  1.05iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  65%|██████▌   | 1309/2000 [27:39<10:01,  1.15iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  65%|██████▌   | 1309/2000 [27:40<10:01,  1.15iteration/s, mean_rewards=-243]\u001b[A\n",
            "Training:  66%|██████▌   | 1310/2000 [27:40<09:19,  1.23iteration/s, mean_rewards=-243]\u001b[A\n",
            "Training:  66%|██████▌   | 1310/2000 [27:40<09:19,  1.23iteration/s, mean_rewards=-96.9]\u001b[A\n",
            "Training:  66%|██████▌   | 1311/2000 [27:41<08:47,  1.31iteration/s, mean_rewards=-96.9]\u001b[A\n",
            "Training:  66%|██████▌   | 1311/2000 [27:41<08:47,  1.31iteration/s, mean_rewards=-120] \u001b[A\n",
            "Training:  66%|██████▌   | 1312/2000 [27:41<08:56,  1.28iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  66%|██████▌   | 1312/2000 [27:42<08:56,  1.28iteration/s, mean_rewards=-240]\u001b[A\n",
            "Training:  66%|██████▌   | 1313/2000 [27:42<08:57,  1.28iteration/s, mean_rewards=-240]\u001b[A\n",
            "Training:  66%|██████▌   | 1313/2000 [27:43<08:57,  1.28iteration/s, mean_rewards=-209]\u001b[A\n",
            "Training:  66%|██████▌   | 1314/2000 [27:43<09:32,  1.20iteration/s, mean_rewards=-209]\u001b[A\n",
            "Training:  66%|██████▌   | 1314/2000 [27:44<09:32,  1.20iteration/s, mean_rewards=-280]\u001b[A\n",
            "Training:  66%|██████▌   | 1315/2000 [27:44<09:47,  1.17iteration/s, mean_rewards=-280]\u001b[A\n",
            "Training:  66%|██████▌   | 1315/2000 [27:45<09:47,  1.17iteration/s, mean_rewards=-309]\u001b[A\n",
            "Training:  66%|██████▌   | 1316/2000 [27:45<10:07,  1.13iteration/s, mean_rewards=-309]\u001b[A\n",
            "Training:  66%|██████▌   | 1316/2000 [27:45<10:07,  1.13iteration/s, mean_rewards=-221]\u001b[A\n",
            "Training:  66%|██████▌   | 1317/2000 [27:46<09:50,  1.16iteration/s, mean_rewards=-221]\u001b[A\n",
            "Training:  66%|██████▌   | 1317/2000 [27:46<09:50,  1.16iteration/s, mean_rewards=-50.3]\u001b[A\n",
            "Training:  66%|██████▌   | 1318/2000 [27:47<09:40,  1.18iteration/s, mean_rewards=-50.3]\u001b[A\n",
            "Training:  66%|██████▌   | 1318/2000 [27:47<09:40,  1.18iteration/s, mean_rewards=-192] \u001b[A\n",
            "Training:  66%|██████▌   | 1319/2000 [27:48<10:30,  1.08iteration/s, mean_rewards=-192]\u001b[A\n",
            "Training:  66%|██████▌   | 1319/2000 [27:48<10:30,  1.08iteration/s, mean_rewards=-249]\u001b[A\n",
            "Training:  66%|██████▌   | 1320/2000 [27:49<12:30,  1.10s/iteration, mean_rewards=-249]\u001b[A\n",
            "Training:  66%|██████▌   | 1320/2000 [27:50<12:30,  1.10s/iteration, mean_rewards=-135]\u001b[A\n",
            "Training:  66%|██████▌   | 1321/2000 [27:50<11:32,  1.02s/iteration, mean_rewards=-135]\u001b[A\n",
            "Training:  66%|██████▌   | 1321/2000 [27:50<11:32,  1.02s/iteration, mean_rewards=-254]\u001b[A\n",
            "Training:  66%|██████▌   | 1322/2000 [27:51<10:20,  1.09iteration/s, mean_rewards=-254]\u001b[A\n",
            "Training:  66%|██████▌   | 1322/2000 [27:51<10:20,  1.09iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  66%|██████▌   | 1323/2000 [27:52<09:27,  1.19iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  66%|██████▌   | 1323/2000 [27:52<09:27,  1.19iteration/s, mean_rewards=-259]\u001b[A\n",
            "Training:  66%|██████▌   | 1324/2000 [27:53<10:13,  1.10iteration/s, mean_rewards=-259]\u001b[A\n",
            "Training:  66%|██████▌   | 1324/2000 [27:53<10:13,  1.10iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:  66%|██████▋   | 1325/2000 [27:54<10:18,  1.09iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:  66%|██████▋   | 1325/2000 [27:54<10:18,  1.09iteration/s, mean_rewards=-159]\u001b[A\n",
            "Training:  66%|██████▋   | 1326/2000 [27:54<10:04,  1.12iteration/s, mean_rewards=-159]\u001b[A\n",
            "Training:  66%|██████▋   | 1326/2000 [27:55<10:04,  1.12iteration/s, mean_rewards=-168]\u001b[A\n",
            "Training:  66%|██████▋   | 1327/2000 [27:55<09:17,  1.21iteration/s, mean_rewards=-168]\u001b[A\n",
            "Training:  66%|██████▋   | 1327/2000 [27:55<09:17,  1.21iteration/s, mean_rewards=-310]\u001b[A\n",
            "Training:  66%|██████▋   | 1328/2000 [27:56<09:34,  1.17iteration/s, mean_rewards=-310]\u001b[A\n",
            "Training:  66%|██████▋   | 1328/2000 [27:56<09:34,  1.17iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:  66%|██████▋   | 1329/2000 [27:57<09:19,  1.20iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:  66%|██████▋   | 1329/2000 [27:57<09:19,  1.20iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  66%|██████▋   | 1330/2000 [27:58<09:38,  1.16iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  66%|██████▋   | 1330/2000 [27:58<09:38,  1.16iteration/s, mean_rewards=-242]\u001b[A\n",
            "Training:  67%|██████▋   | 1331/2000 [27:59<09:52,  1.13iteration/s, mean_rewards=-242]\u001b[A\n",
            "Training:  67%|██████▋   | 1331/2000 [27:59<09:52,  1.13iteration/s, mean_rewards=-270]\u001b[A\n",
            "Training:  67%|██████▋   | 1332/2000 [27:59<09:46,  1.14iteration/s, mean_rewards=-270]\u001b[A\n",
            "Training:  67%|██████▋   | 1332/2000 [28:00<09:46,  1.14iteration/s, mean_rewards=-175]\u001b[A\n",
            "Training:  67%|██████▋   | 1333/2000 [28:01<10:54,  1.02iteration/s, mean_rewards=-175]\u001b[A\n",
            "Training:  67%|██████▋   | 1333/2000 [28:01<10:54,  1.02iteration/s, mean_rewards=-199]\u001b[A\n",
            "Training:  67%|██████▋   | 1334/2000 [28:02<11:45,  1.06s/iteration, mean_rewards=-199]\u001b[A\n",
            "Training:  67%|██████▋   | 1334/2000 [28:02<11:45,  1.06s/iteration, mean_rewards=-248]\u001b[A\n",
            "Training:  67%|██████▋   | 1335/2000 [28:03<11:26,  1.03s/iteration, mean_rewards=-248]\u001b[A\n",
            "Training:  67%|██████▋   | 1335/2000 [28:03<11:26,  1.03s/iteration, mean_rewards=-231]\u001b[A\n",
            "Training:  67%|██████▋   | 1336/2000 [28:04<10:20,  1.07iteration/s, mean_rewards=-231]\u001b[A\n",
            "Training:  67%|██████▋   | 1336/2000 [28:04<10:20,  1.07iteration/s, mean_rewards=-268]\u001b[A\n",
            "Training:  67%|██████▋   | 1337/2000 [28:04<09:58,  1.11iteration/s, mean_rewards=-268]\u001b[A\n",
            "Training:  67%|██████▋   | 1337/2000 [28:05<09:58,  1.11iteration/s, mean_rewards=-254]\u001b[A\n",
            "Training:  67%|██████▋   | 1338/2000 [28:05<10:19,  1.07iteration/s, mean_rewards=-254]\u001b[A\n",
            "Training:  67%|██████▋   | 1338/2000 [28:06<10:19,  1.07iteration/s, mean_rewards=-186]\u001b[A\n",
            "Training:  67%|██████▋   | 1339/2000 [28:06<09:57,  1.11iteration/s, mean_rewards=-186]\u001b[A\n",
            "Training:  67%|██████▋   | 1339/2000 [28:07<09:57,  1.11iteration/s, mean_rewards=-343]\u001b[A\n",
            "Training:  67%|██████▋   | 1340/2000 [28:07<10:02,  1.10iteration/s, mean_rewards=-343]\u001b[A\n",
            "Training:  67%|██████▋   | 1340/2000 [28:08<10:02,  1.10iteration/s, mean_rewards=-97] \u001b[A\n",
            "Training:  67%|██████▋   | 1341/2000 [28:08<09:19,  1.18iteration/s, mean_rewards=-97]\u001b[A\n",
            "Training:  67%|██████▋   | 1341/2000 [28:08<09:19,  1.18iteration/s, mean_rewards=-99.5]\u001b[A\n",
            "Training:  67%|██████▋   | 1342/2000 [28:09<09:09,  1.20iteration/s, mean_rewards=-99.5]\u001b[A\n",
            "Training:  67%|██████▋   | 1342/2000 [28:09<09:09,  1.20iteration/s, mean_rewards=-375] \u001b[A\n",
            "Training:  67%|██████▋   | 1343/2000 [28:10<09:27,  1.16iteration/s, mean_rewards=-375]\u001b[A\n",
            "Training:  67%|██████▋   | 1343/2000 [28:10<09:27,  1.16iteration/s, mean_rewards=-256]\u001b[A\n",
            "Training:  67%|██████▋   | 1344/2000 [28:10<09:07,  1.20iteration/s, mean_rewards=-256]\u001b[A\n",
            "Training:  67%|██████▋   | 1344/2000 [28:11<09:07,  1.20iteration/s, mean_rewards=-317]\u001b[A\n",
            "Training:  67%|██████▋   | 1345/2000 [28:11<09:33,  1.14iteration/s, mean_rewards=-317]\u001b[A\n",
            "Training:  67%|██████▋   | 1345/2000 [28:12<09:33,  1.14iteration/s, mean_rewards=-279]\u001b[A\n",
            "Training:  67%|██████▋   | 1346/2000 [28:12<08:56,  1.22iteration/s, mean_rewards=-279]\u001b[A\n",
            "Training:  67%|██████▋   | 1346/2000 [28:12<08:56,  1.22iteration/s, mean_rewards=-91.3]\u001b[A\n",
            "Training:  67%|██████▋   | 1347/2000 [28:13<09:56,  1.10iteration/s, mean_rewards=-91.3]\u001b[A\n",
            "Training:  67%|██████▋   | 1347/2000 [28:14<09:56,  1.10iteration/s, mean_rewards=-269] \u001b[A\n",
            "Training:  67%|██████▋   | 1348/2000 [28:14<11:06,  1.02s/iteration, mean_rewards=-269]\u001b[A\n",
            "Training:  67%|██████▋   | 1348/2000 [28:15<11:06,  1.02s/iteration, mean_rewards=-71] \u001b[A\n",
            "Training:  67%|██████▋   | 1349/2000 [28:15<10:48,  1.00iteration/s, mean_rewards=-71]\u001b[A\n",
            "Training:  67%|██████▋   | 1349/2000 [28:16<10:48,  1.00iteration/s, mean_rewards=-259]\u001b[A\n",
            "Training:  68%|██████▊   | 1350/2000 [28:16<10:07,  1.07iteration/s, mean_rewards=-259]\u001b[A\n",
            "Training:  68%|██████▊   | 1350/2000 [28:17<10:07,  1.07iteration/s, mean_rewards=-249]\u001b[A\n",
            "Training:  68%|██████▊   | 1351/2000 [28:17<10:00,  1.08iteration/s, mean_rewards=-249]\u001b[A\n",
            "Training:  68%|██████▊   | 1351/2000 [28:17<10:00,  1.08iteration/s, mean_rewards=-252]\u001b[A\n",
            "Training:  68%|██████▊   | 1352/2000 [28:18<09:36,  1.12iteration/s, mean_rewards=-252]\u001b[A\n",
            "Training:  68%|██████▊   | 1352/2000 [28:18<09:36,  1.12iteration/s, mean_rewards=-242]\u001b[A\n",
            "Training:  68%|██████▊   | 1353/2000 [28:19<08:54,  1.21iteration/s, mean_rewards=-242]\u001b[A\n",
            "Training:  68%|██████▊   | 1353/2000 [28:19<08:54,  1.21iteration/s, mean_rewards=-87.6]\u001b[A\n",
            "Training:  68%|██████▊   | 1354/2000 [28:19<08:41,  1.24iteration/s, mean_rewards=-87.6]\u001b[A\n",
            "Training:  68%|██████▊   | 1354/2000 [28:20<08:41,  1.24iteration/s, mean_rewards=-70.2]\u001b[A\n",
            "Training:  68%|██████▊   | 1355/2000 [28:20<08:16,  1.30iteration/s, mean_rewards=-70.2]\u001b[A\n",
            "Training:  68%|██████▊   | 1355/2000 [28:20<08:16,  1.30iteration/s, mean_rewards=-98.7]\u001b[A\n",
            "Training:  68%|██████▊   | 1356/2000 [28:21<07:57,  1.35iteration/s, mean_rewards=-98.7]\u001b[A\n",
            "Training:  68%|██████▊   | 1356/2000 [28:21<07:57,  1.35iteration/s, mean_rewards=-226] \u001b[A\n",
            "Training:  68%|██████▊   | 1357/2000 [28:22<09:05,  1.18iteration/s, mean_rewards=-226]\u001b[A\n",
            "Training:  68%|██████▊   | 1357/2000 [28:22<09:05,  1.18iteration/s, mean_rewards=-399]\u001b[A\n",
            "Training:  68%|██████▊   | 1358/2000 [28:23<08:56,  1.20iteration/s, mean_rewards=-399]\u001b[A\n",
            "Training:  68%|██████▊   | 1358/2000 [28:23<08:56,  1.20iteration/s, mean_rewards=-241]\u001b[A\n",
            "Training:  68%|██████▊   | 1359/2000 [28:24<09:24,  1.14iteration/s, mean_rewards=-241]\u001b[A\n",
            "Training:  68%|██████▊   | 1359/2000 [28:24<09:24,  1.14iteration/s, mean_rewards=-333]\u001b[A\n",
            "Training:  68%|██████▊   | 1360/2000 [28:25<09:29,  1.12iteration/s, mean_rewards=-333]\u001b[A\n",
            "Training:  68%|██████▊   | 1360/2000 [28:25<09:29,  1.12iteration/s, mean_rewards=-348]\u001b[A\n",
            "Training:  68%|██████▊   | 1361/2000 [28:25<09:05,  1.17iteration/s, mean_rewards=-348]\u001b[A\n",
            "Training:  68%|██████▊   | 1361/2000 [28:26<09:05,  1.17iteration/s, mean_rewards=-104]\u001b[A\n",
            "Training:  68%|██████▊   | 1362/2000 [28:27<10:28,  1.02iteration/s, mean_rewards=-104]\u001b[A\n",
            "Training:  68%|██████▊   | 1362/2000 [28:27<10:28,  1.02iteration/s, mean_rewards=-409]\u001b[A\n",
            "Training:  68%|██████▊   | 1363/2000 [28:28<11:39,  1.10s/iteration, mean_rewards=-409]\u001b[A\n",
            "Training:  68%|██████▊   | 1363/2000 [28:28<11:39,  1.10s/iteration, mean_rewards=-98.8]\u001b[A\n",
            "Training:  68%|██████▊   | 1364/2000 [28:29<11:18,  1.07s/iteration, mean_rewards=-98.8]\u001b[A\n",
            "Training:  68%|██████▊   | 1364/2000 [28:29<11:18,  1.07s/iteration, mean_rewards=-84.1]\u001b[A\n",
            "Training:  68%|██████▊   | 1365/2000 [28:30<10:07,  1.05iteration/s, mean_rewards=-84.1]\u001b[A\n",
            "Training:  68%|██████▊   | 1365/2000 [28:30<10:07,  1.05iteration/s, mean_rewards=-160] \u001b[A\n",
            "Training:  68%|██████▊   | 1366/2000 [28:30<09:17,  1.14iteration/s, mean_rewards=-160]\u001b[A\n",
            "Training:  68%|██████▊   | 1366/2000 [28:31<09:17,  1.14iteration/s, mean_rewards=-360]\u001b[A\n",
            "Training:  68%|██████▊   | 1367/2000 [28:31<09:55,  1.06iteration/s, mean_rewards=-360]\u001b[A\n",
            "Training:  68%|██████▊   | 1367/2000 [28:32<09:55,  1.06iteration/s, mean_rewards=-287]\u001b[A\n",
            "Training:  68%|██████▊   | 1368/2000 [28:32<09:59,  1.05iteration/s, mean_rewards=-287]\u001b[A\n",
            "Training:  68%|██████▊   | 1368/2000 [28:33<09:59,  1.05iteration/s, mean_rewards=-224]\u001b[A\n",
            "Training:  68%|██████▊   | 1369/2000 [28:33<09:58,  1.05iteration/s, mean_rewards=-224]\u001b[A\n",
            "Training:  68%|██████▊   | 1369/2000 [28:34<09:58,  1.05iteration/s, mean_rewards=-280]\u001b[A\n",
            "Training:  68%|██████▊   | 1370/2000 [28:34<10:16,  1.02iteration/s, mean_rewards=-280]\u001b[A\n",
            "Training:  68%|██████▊   | 1370/2000 [28:35<10:16,  1.02iteration/s, mean_rewards=-287]\u001b[A\n",
            "Training:  69%|██████▊   | 1371/2000 [28:35<10:33,  1.01s/iteration, mean_rewards=-287]\u001b[A\n",
            "Training:  69%|██████▊   | 1371/2000 [28:36<10:33,  1.01s/iteration, mean_rewards=-137]\u001b[A\n",
            "Training:  69%|██████▊   | 1372/2000 [28:36<10:22,  1.01iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  69%|██████▊   | 1372/2000 [28:37<10:22,  1.01iteration/s, mean_rewards=-197]\u001b[A\n",
            "Training:  69%|██████▊   | 1373/2000 [28:37<09:45,  1.07iteration/s, mean_rewards=-197]\u001b[A\n",
            "Training:  69%|██████▊   | 1373/2000 [28:37<09:45,  1.07iteration/s, mean_rewards=-98.5]\u001b[A\n",
            "Training:  69%|██████▊   | 1374/2000 [28:38<09:02,  1.15iteration/s, mean_rewards=-98.5]\u001b[A\n",
            "Training:  69%|██████▊   | 1374/2000 [28:38<09:02,  1.15iteration/s, mean_rewards=-263] \u001b[A\n",
            "Training:  69%|██████▉   | 1375/2000 [28:39<09:42,  1.07iteration/s, mean_rewards=-263]\u001b[A\n",
            "Training:  69%|██████▉   | 1375/2000 [28:39<09:42,  1.07iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  69%|██████▉   | 1376/2000 [28:40<10:17,  1.01iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  69%|██████▉   | 1376/2000 [28:41<10:17,  1.01iteration/s, mean_rewards=-239]\u001b[A\n",
            "Training:  69%|██████▉   | 1377/2000 [28:41<10:41,  1.03s/iteration, mean_rewards=-239]\u001b[A\n",
            "Training:  69%|██████▉   | 1377/2000 [28:42<10:41,  1.03s/iteration, mean_rewards=-166]\u001b[A\n",
            "Training:  69%|██████▉   | 1378/2000 [28:42<10:26,  1.01s/iteration, mean_rewards=-166]\u001b[A\n",
            "Training:  69%|██████▉   | 1378/2000 [28:42<10:26,  1.01s/iteration, mean_rewards=-163]\u001b[A\n",
            "Training:  69%|██████▉   | 1379/2000 [28:43<09:24,  1.10iteration/s, mean_rewards=-163]\u001b[A\n",
            "Training:  69%|██████▉   | 1379/2000 [28:43<09:24,  1.10iteration/s, mean_rewards=-180]\u001b[A\n",
            "Training:  69%|██████▉   | 1380/2000 [28:44<09:07,  1.13iteration/s, mean_rewards=-180]\u001b[A\n",
            "Training:  69%|██████▉   | 1380/2000 [28:44<09:07,  1.13iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  69%|██████▉   | 1381/2000 [28:44<08:45,  1.18iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  69%|██████▉   | 1381/2000 [28:45<08:45,  1.18iteration/s, mean_rewards=-57.5]\u001b[A\n",
            "Training:  69%|██████▉   | 1382/2000 [28:45<08:08,  1.26iteration/s, mean_rewards=-57.5]\u001b[A\n",
            "Training:  69%|██████▉   | 1382/2000 [28:45<08:08,  1.26iteration/s, mean_rewards=-79.4]\u001b[A\n",
            "Training:  69%|██████▉   | 1383/2000 [28:46<07:44,  1.33iteration/s, mean_rewards=-79.4]\u001b[A\n",
            "Training:  69%|██████▉   | 1383/2000 [28:46<07:44,  1.33iteration/s, mean_rewards=-117] \u001b[A\n",
            "Training:  69%|██████▉   | 1384/2000 [28:47<07:53,  1.30iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  69%|██████▉   | 1384/2000 [28:47<07:53,  1.30iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  69%|██████▉   | 1385/2000 [28:47<07:35,  1.35iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  69%|██████▉   | 1385/2000 [28:48<07:35,  1.35iteration/s, mean_rewards=-296]\u001b[A\n",
            "Training:  69%|██████▉   | 1386/2000 [28:48<07:46,  1.32iteration/s, mean_rewards=-296]\u001b[A\n",
            "Training:  69%|██████▉   | 1386/2000 [28:48<07:46,  1.32iteration/s, mean_rewards=-240]\u001b[A\n",
            "Training:  69%|██████▉   | 1387/2000 [28:49<07:50,  1.30iteration/s, mean_rewards=-240]\u001b[A\n",
            "Training:  69%|██████▉   | 1387/2000 [28:49<07:50,  1.30iteration/s, mean_rewards=-229]\u001b[A\n",
            "Training:  69%|██████▉   | 1388/2000 [28:50<07:58,  1.28iteration/s, mean_rewards=-229]\u001b[A\n",
            "Training:  69%|██████▉   | 1388/2000 [28:50<07:58,  1.28iteration/s, mean_rewards=-179]\u001b[A\n",
            "Training:  69%|██████▉   | 1389/2000 [28:50<07:55,  1.28iteration/s, mean_rewards=-179]\u001b[A\n",
            "Training:  69%|██████▉   | 1389/2000 [28:51<07:55,  1.28iteration/s, mean_rewards=-243]\u001b[A\n",
            "Training:  70%|██████▉   | 1390/2000 [28:51<08:25,  1.21iteration/s, mean_rewards=-243]\u001b[A\n",
            "Training:  70%|██████▉   | 1390/2000 [28:52<08:25,  1.21iteration/s, mean_rewards=-172]\u001b[A\n",
            "Training:  70%|██████▉   | 1391/2000 [28:52<08:54,  1.14iteration/s, mean_rewards=-172]\u001b[A\n",
            "Training:  70%|██████▉   | 1391/2000 [28:53<08:54,  1.14iteration/s, mean_rewards=-77.5]\u001b[A\n",
            "Training:  70%|██████▉   | 1392/2000 [28:53<08:50,  1.15iteration/s, mean_rewards=-77.5]\u001b[A\n",
            "Training:  70%|██████▉   | 1392/2000 [28:54<08:50,  1.15iteration/s, mean_rewards=-61.8]\u001b[A\n",
            "Training:  70%|██████▉   | 1393/2000 [28:54<09:10,  1.10iteration/s, mean_rewards=-61.8]\u001b[A\n",
            "Training:  70%|██████▉   | 1393/2000 [28:55<09:10,  1.10iteration/s, mean_rewards=-126] \u001b[A\n",
            "Training:  70%|██████▉   | 1394/2000 [28:55<08:39,  1.17iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  70%|██████▉   | 1394/2000 [28:55<08:39,  1.17iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  70%|██████▉   | 1395/2000 [28:56<08:45,  1.15iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  70%|██████▉   | 1395/2000 [28:56<08:45,  1.15iteration/s, mean_rewards=-356]\u001b[A\n",
            "Training:  70%|██████▉   | 1396/2000 [28:57<08:57,  1.12iteration/s, mean_rewards=-356]\u001b[A\n",
            "Training:  70%|██████▉   | 1396/2000 [28:57<08:57,  1.12iteration/s, mean_rewards=-112]\u001b[A\n",
            "Training:  70%|██████▉   | 1397/2000 [28:58<08:43,  1.15iteration/s, mean_rewards=-112]\u001b[A\n",
            "Training:  70%|██████▉   | 1397/2000 [28:58<08:43,  1.15iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  70%|██████▉   | 1398/2000 [28:58<08:08,  1.23iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  70%|██████▉   | 1398/2000 [28:59<08:08,  1.23iteration/s, mean_rewards=-94.5]\u001b[A\n",
            "Training:  70%|██████▉   | 1399/2000 [28:59<08:02,  1.25iteration/s, mean_rewards=-94.5]\u001b[A\n",
            "Training:  70%|██████▉   | 1399/2000 [28:59<08:02,  1.25iteration/s, mean_rewards=-158] \u001b[A\n",
            "Training:  70%|███████   | 1400/2000 [29:00<07:36,  1.31iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  70%|███████   | 1400/2000 [29:00<07:36,  1.31iteration/s, mean_rewards=-343]\u001b[A\n",
            "Training:  70%|███████   | 1401/2000 [29:01<08:06,  1.23iteration/s, mean_rewards=-343]\u001b[A\n",
            "Training:  70%|███████   | 1401/2000 [29:01<08:06,  1.23iteration/s, mean_rewards=-207]\u001b[A\n",
            "Training:  70%|███████   | 1402/2000 [29:02<08:05,  1.23iteration/s, mean_rewards=-207]\u001b[A\n",
            "Training:  70%|███████   | 1402/2000 [29:02<08:05,  1.23iteration/s, mean_rewards=-167]\u001b[A\n",
            "Training:  70%|███████   | 1403/2000 [29:02<08:33,  1.16iteration/s, mean_rewards=-167]\u001b[A\n",
            "Training:  70%|███████   | 1403/2000 [29:03<08:33,  1.16iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  70%|███████   | 1404/2000 [29:03<08:28,  1.17iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  70%|███████   | 1404/2000 [29:04<08:28,  1.17iteration/s, mean_rewards=-82.2]\u001b[A\n",
            "Training:  70%|███████   | 1405/2000 [29:04<08:17,  1.20iteration/s, mean_rewards=-82.2]\u001b[A\n",
            "Training:  70%|███████   | 1405/2000 [29:05<08:17,  1.20iteration/s, mean_rewards=-117] \u001b[A\n",
            "Training:  70%|███████   | 1406/2000 [29:06<10:04,  1.02s/iteration, mean_rewards=-117]\u001b[A\n",
            "Training:  70%|███████   | 1406/2000 [29:06<10:04,  1.02s/iteration, mean_rewards=-231]\u001b[A\n",
            "Training:  70%|███████   | 1407/2000 [29:07<11:05,  1.12s/iteration, mean_rewards=-231]\u001b[A\n",
            "Training:  70%|███████   | 1407/2000 [29:07<11:05,  1.12s/iteration, mean_rewards=-244]\u001b[A\n",
            "Training:  70%|███████   | 1408/2000 [29:08<10:18,  1.05s/iteration, mean_rewards=-244]\u001b[A\n",
            "Training:  70%|███████   | 1408/2000 [29:08<10:18,  1.05s/iteration, mean_rewards=-175]\u001b[A\n",
            "Training:  70%|███████   | 1409/2000 [29:09<09:19,  1.06iteration/s, mean_rewards=-175]\u001b[A\n",
            "Training:  70%|███████   | 1409/2000 [29:09<09:19,  1.06iteration/s, mean_rewards=-216]\u001b[A\n",
            "Training:  70%|███████   | 1410/2000 [29:09<09:03,  1.09iteration/s, mean_rewards=-216]\u001b[A\n",
            "Training:  70%|███████   | 1410/2000 [29:10<09:03,  1.09iteration/s, mean_rewards=-363]\u001b[A\n",
            "Training:  71%|███████   | 1411/2000 [29:10<09:01,  1.09iteration/s, mean_rewards=-363]\u001b[A\n",
            "Training:  71%|███████   | 1411/2000 [29:11<09:01,  1.09iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:  71%|███████   | 1412/2000 [29:11<08:18,  1.18iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:  71%|███████   | 1412/2000 [29:11<08:18,  1.18iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  71%|███████   | 1413/2000 [29:12<07:53,  1.24iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  71%|███████   | 1413/2000 [29:12<07:53,  1.24iteration/s, mean_rewards=-102]\u001b[A\n",
            "Training:  71%|███████   | 1414/2000 [29:12<07:52,  1.24iteration/s, mean_rewards=-102]\u001b[A\n",
            "Training:  71%|███████   | 1414/2000 [29:13<07:52,  1.24iteration/s, mean_rewards=-244]\u001b[A\n",
            "Training:  71%|███████   | 1415/2000 [29:13<08:16,  1.18iteration/s, mean_rewards=-244]\u001b[A\n",
            "Training:  71%|███████   | 1415/2000 [29:14<08:16,  1.18iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  71%|███████   | 1416/2000 [29:14<08:12,  1.19iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  71%|███████   | 1416/2000 [29:15<08:12,  1.19iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  71%|███████   | 1417/2000 [29:15<08:25,  1.15iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  71%|███████   | 1417/2000 [29:16<08:25,  1.15iteration/s, mean_rewards=-357]\u001b[A\n",
            "Training:  71%|███████   | 1418/2000 [29:16<08:30,  1.14iteration/s, mean_rewards=-357]\u001b[A\n",
            "Training:  71%|███████   | 1418/2000 [29:16<08:30,  1.14iteration/s, mean_rewards=-242]\u001b[A\n",
            "Training:  71%|███████   | 1419/2000 [29:17<08:17,  1.17iteration/s, mean_rewards=-242]\u001b[A\n",
            "Training:  71%|███████   | 1419/2000 [29:17<08:17,  1.17iteration/s, mean_rewards=-116]\u001b[A\n",
            "Training:  71%|███████   | 1420/2000 [29:18<08:54,  1.08iteration/s, mean_rewards=-116]\u001b[A\n",
            "Training:  71%|███████   | 1420/2000 [29:18<08:54,  1.08iteration/s, mean_rewards=-181]\u001b[A\n",
            "Training:  71%|███████   | 1421/2000 [29:19<08:51,  1.09iteration/s, mean_rewards=-181]\u001b[A\n",
            "Training:  71%|███████   | 1421/2000 [29:19<08:51,  1.09iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  71%|███████   | 1422/2000 [29:20<09:31,  1.01iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  71%|███████   | 1422/2000 [29:20<09:31,  1.01iteration/s, mean_rewards=-326]\u001b[A\n",
            "Training:  71%|███████   | 1423/2000 [29:21<09:13,  1.04iteration/s, mean_rewards=-326]\u001b[A\n",
            "Training:  71%|███████   | 1423/2000 [29:21<09:13,  1.04iteration/s, mean_rewards=-268]\u001b[A\n",
            "Training:  71%|███████   | 1424/2000 [29:22<08:50,  1.09iteration/s, mean_rewards=-268]\u001b[A\n",
            "Training:  71%|███████   | 1424/2000 [29:22<08:50,  1.09iteration/s, mean_rewards=-323]\u001b[A\n",
            "Training:  71%|███████▏  | 1425/2000 [29:23<09:39,  1.01s/iteration, mean_rewards=-323]\u001b[A\n",
            "Training:  71%|███████▏  | 1425/2000 [29:23<09:39,  1.01s/iteration, mean_rewards=-167]\u001b[A\n",
            "Training:  71%|███████▏  | 1426/2000 [29:24<08:41,  1.10iteration/s, mean_rewards=-167]\u001b[A\n",
            "Training:  71%|███████▏  | 1426/2000 [29:24<08:41,  1.10iteration/s, mean_rewards=-50] \u001b[A\n",
            "Training:  71%|███████▏  | 1427/2000 [29:24<07:59,  1.19iteration/s, mean_rewards=-50]\u001b[A\n",
            "Training:  71%|███████▏  | 1427/2000 [29:25<07:59,  1.19iteration/s, mean_rewards=-199]\u001b[A\n",
            "Training:  71%|███████▏  | 1428/2000 [29:25<07:09,  1.33iteration/s, mean_rewards=-199]\u001b[A\n",
            "Training:  71%|███████▏  | 1428/2000 [29:25<07:09,  1.33iteration/s, mean_rewards=-185]\u001b[A\n",
            "Training:  71%|███████▏  | 1429/2000 [29:26<07:12,  1.32iteration/s, mean_rewards=-185]\u001b[A\n",
            "Training:  71%|███████▏  | 1429/2000 [29:26<07:12,  1.32iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  72%|███████▏  | 1430/2000 [29:26<06:59,  1.36iteration/s, mean_rewards=-131]\u001b[A\n",
            "Training:  72%|███████▏  | 1430/2000 [29:27<06:59,  1.36iteration/s, mean_rewards=-236]\u001b[A\n",
            "Training:  72%|███████▏  | 1431/2000 [29:27<07:36,  1.25iteration/s, mean_rewards=-236]\u001b[A\n",
            "Training:  72%|███████▏  | 1431/2000 [29:28<07:36,  1.25iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  72%|███████▏  | 1432/2000 [29:28<07:33,  1.25iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  72%|███████▏  | 1432/2000 [29:28<07:33,  1.25iteration/s, mean_rewards=-97.5]\u001b[A\n",
            "Training:  72%|███████▏  | 1433/2000 [29:29<07:30,  1.26iteration/s, mean_rewards=-97.5]\u001b[A\n",
            "Training:  72%|███████▏  | 1433/2000 [29:29<07:30,  1.26iteration/s, mean_rewards=-76.8]\u001b[A\n",
            "Training:  72%|███████▏  | 1434/2000 [29:30<07:29,  1.26iteration/s, mean_rewards=-76.8]\u001b[A\n",
            "Training:  72%|███████▏  | 1434/2000 [29:30<07:29,  1.26iteration/s, mean_rewards=-232] \u001b[A\n",
            "Training:  72%|███████▏  | 1435/2000 [29:30<07:31,  1.25iteration/s, mean_rewards=-232]\u001b[A\n",
            "Training:  72%|███████▏  | 1435/2000 [29:31<07:31,  1.25iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  72%|███████▏  | 1436/2000 [29:31<08:05,  1.16iteration/s, mean_rewards=-133]\u001b[A\n",
            "Training:  72%|███████▏  | 1436/2000 [29:32<08:05,  1.16iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  72%|███████▏  | 1437/2000 [29:33<09:15,  1.01iteration/s, mean_rewards=-143]\u001b[A\n",
            "Training:  72%|███████▏  | 1437/2000 [29:33<09:15,  1.01iteration/s, mean_rewards=-171]\u001b[A\n",
            "Training:  72%|███████▏  | 1438/2000 [29:34<09:31,  1.02s/iteration, mean_rewards=-171]\u001b[A\n",
            "Training:  72%|███████▏  | 1438/2000 [29:34<09:31,  1.02s/iteration, mean_rewards=-136]\u001b[A\n",
            "Training:  72%|███████▏  | 1439/2000 [29:35<08:53,  1.05iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  72%|███████▏  | 1439/2000 [29:35<08:53,  1.05iteration/s, mean_rewards=-277]\u001b[A\n",
            "Training:  72%|███████▏  | 1440/2000 [29:36<09:19,  1.00iteration/s, mean_rewards=-277]\u001b[A\n",
            "Training:  72%|███████▏  | 1440/2000 [29:36<09:19,  1.00iteration/s, mean_rewards=-235]\u001b[A\n",
            "Training:  72%|███████▏  | 1441/2000 [29:37<09:13,  1.01iteration/s, mean_rewards=-235]\u001b[A\n",
            "Training:  72%|███████▏  | 1441/2000 [29:37<09:13,  1.01iteration/s, mean_rewards=-152]\u001b[A\n",
            "Training:  72%|███████▏  | 1442/2000 [29:37<08:26,  1.10iteration/s, mean_rewards=-152]\u001b[A\n",
            "Training:  72%|███████▏  | 1442/2000 [29:38<08:26,  1.10iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  72%|███████▏  | 1443/2000 [29:39<09:08,  1.02iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  72%|███████▏  | 1443/2000 [29:39<09:08,  1.02iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  72%|███████▏  | 1444/2000 [29:39<08:22,  1.11iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  72%|███████▏  | 1444/2000 [29:40<08:22,  1.11iteration/s, mean_rewards=-270]\u001b[A\n",
            "Training:  72%|███████▏  | 1445/2000 [29:40<07:59,  1.16iteration/s, mean_rewards=-270]\u001b[A\n",
            "Training:  72%|███████▏  | 1445/2000 [29:40<07:59,  1.16iteration/s, mean_rewards=-199]\u001b[A\n",
            "Training:  72%|███████▏  | 1446/2000 [29:41<08:28,  1.09iteration/s, mean_rewards=-199]\u001b[A\n",
            "Training:  72%|███████▏  | 1446/2000 [29:41<08:28,  1.09iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  72%|███████▏  | 1447/2000 [29:42<07:48,  1.18iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  72%|███████▏  | 1447/2000 [29:42<07:48,  1.18iteration/s, mean_rewards=-86.5]\u001b[A\n",
            "Training:  72%|███████▏  | 1448/2000 [29:43<07:58,  1.15iteration/s, mean_rewards=-86.5]\u001b[A\n",
            "Training:  72%|███████▏  | 1448/2000 [29:43<07:58,  1.15iteration/s, mean_rewards=-234] \u001b[A\n",
            "Training:  72%|███████▏  | 1449/2000 [29:44<08:27,  1.09iteration/s, mean_rewards=-234]\u001b[A\n",
            "Training:  72%|███████▏  | 1449/2000 [29:44<08:27,  1.09iteration/s, mean_rewards=-206]\u001b[A\n",
            "Training:  72%|███████▎  | 1450/2000 [29:45<08:36,  1.06iteration/s, mean_rewards=-206]\u001b[A\n",
            "Training:  72%|███████▎  | 1450/2000 [29:45<08:36,  1.06iteration/s, mean_rewards=-232]\u001b[A\n",
            "Training:  73%|███████▎  | 1451/2000 [29:46<09:05,  1.01iteration/s, mean_rewards=-232]\u001b[A\n",
            "Training:  73%|███████▎  | 1451/2000 [29:47<09:05,  1.01iteration/s, mean_rewards=-119]\u001b[A\n",
            "Training:  73%|███████▎  | 1452/2000 [29:47<10:25,  1.14s/iteration, mean_rewards=-119]\u001b[A\n",
            "Training:  73%|███████▎  | 1452/2000 [29:48<10:25,  1.14s/iteration, mean_rewards=-118]\u001b[A\n",
            "Training:  73%|███████▎  | 1453/2000 [29:48<09:07,  1.00s/iteration, mean_rewards=-118]\u001b[A\n",
            "Training:  73%|███████▎  | 1453/2000 [29:48<09:07,  1.00s/iteration, mean_rewards=-219]\u001b[A\n",
            "Training:  73%|███████▎  | 1454/2000 [29:49<08:14,  1.10iteration/s, mean_rewards=-219]\u001b[A\n",
            "Training:  73%|███████▎  | 1454/2000 [29:49<08:14,  1.10iteration/s, mean_rewards=-370]\u001b[A\n",
            "Training:  73%|███████▎  | 1455/2000 [29:50<08:12,  1.11iteration/s, mean_rewards=-370]\u001b[A\n",
            "Training:  73%|███████▎  | 1455/2000 [29:50<08:12,  1.11iteration/s, mean_rewards=-181]\u001b[A\n",
            "Training:  73%|███████▎  | 1456/2000 [29:51<08:37,  1.05iteration/s, mean_rewards=-181]\u001b[A\n",
            "Training:  73%|███████▎  | 1456/2000 [29:51<08:37,  1.05iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  73%|███████▎  | 1457/2000 [29:52<08:31,  1.06iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  73%|███████▎  | 1457/2000 [29:52<08:31,  1.06iteration/s, mean_rewards=-217]\u001b[A\n",
            "Training:  73%|███████▎  | 1458/2000 [29:53<08:31,  1.06iteration/s, mean_rewards=-217]\u001b[A\n",
            "Training:  73%|███████▎  | 1458/2000 [29:53<08:31,  1.06iteration/s, mean_rewards=-304]\u001b[A\n",
            "Training:  73%|███████▎  | 1459/2000 [29:53<08:23,  1.07iteration/s, mean_rewards=-304]\u001b[A\n",
            "Training:  73%|███████▎  | 1459/2000 [29:54<08:23,  1.07iteration/s, mean_rewards=-259]\u001b[A\n",
            "Training:  73%|███████▎  | 1460/2000 [29:54<08:03,  1.12iteration/s, mean_rewards=-259]\u001b[A\n",
            "Training:  73%|███████▎  | 1460/2000 [29:55<08:03,  1.12iteration/s, mean_rewards=-231]\u001b[A\n",
            "Training:  73%|███████▎  | 1461/2000 [29:55<08:10,  1.10iteration/s, mean_rewards=-231]\u001b[A\n",
            "Training:  73%|███████▎  | 1461/2000 [29:56<08:10,  1.10iteration/s, mean_rewards=-337]\u001b[A\n",
            "Training:  73%|███████▎  | 1462/2000 [29:56<08:11,  1.10iteration/s, mean_rewards=-337]\u001b[A\n",
            "Training:  73%|███████▎  | 1462/2000 [29:56<08:11,  1.10iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  73%|███████▎  | 1463/2000 [29:57<07:32,  1.19iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  73%|███████▎  | 1463/2000 [29:57<07:32,  1.19iteration/s, mean_rewards=-86.1]\u001b[A\n",
            "Training:  73%|███████▎  | 1464/2000 [29:58<08:37,  1.04iteration/s, mean_rewards=-86.1]\u001b[A\n",
            "Training:  73%|███████▎  | 1464/2000 [29:58<08:37,  1.04iteration/s, mean_rewards=-98.8]\u001b[A\n",
            "Training:  73%|███████▎  | 1465/2000 [29:59<08:48,  1.01iteration/s, mean_rewards=-98.8]\u001b[A\n",
            "Training:  73%|███████▎  | 1465/2000 [30:00<08:48,  1.01iteration/s, mean_rewards=-240] \u001b[A\n",
            "Training:  73%|███████▎  | 1466/2000 [30:00<08:53,  1.00iteration/s, mean_rewards=-240]\u001b[A\n",
            "Training:  73%|███████▎  | 1466/2000 [30:00<08:53,  1.00iteration/s, mean_rewards=-84.9]\u001b[A\n",
            "Training:  73%|███████▎  | 1467/2000 [30:01<08:09,  1.09iteration/s, mean_rewards=-84.9]\u001b[A\n",
            "Training:  73%|███████▎  | 1467/2000 [30:01<08:09,  1.09iteration/s, mean_rewards=-114] \u001b[A\n",
            "Training:  73%|███████▎  | 1468/2000 [30:02<07:52,  1.13iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  73%|███████▎  | 1468/2000 [30:02<07:52,  1.13iteration/s, mean_rewards=-331]\u001b[A\n",
            "Training:  73%|███████▎  | 1469/2000 [30:02<07:32,  1.17iteration/s, mean_rewards=-331]\u001b[A\n",
            "Training:  73%|███████▎  | 1469/2000 [30:03<07:32,  1.17iteration/s, mean_rewards=-172]\u001b[A\n",
            "Training:  74%|███████▎  | 1470/2000 [30:03<07:04,  1.25iteration/s, mean_rewards=-172]\u001b[A\n",
            "Training:  74%|███████▎  | 1470/2000 [30:03<07:04,  1.25iteration/s, mean_rewards=-89.2]\u001b[A\n",
            "Training:  74%|███████▎  | 1471/2000 [30:04<07:27,  1.18iteration/s, mean_rewards=-89.2]\u001b[A\n",
            "Training:  74%|███████▎  | 1471/2000 [30:04<07:27,  1.18iteration/s, mean_rewards=-161] \u001b[A\n",
            "Training:  74%|███████▎  | 1472/2000 [30:05<07:40,  1.15iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:  74%|███████▎  | 1472/2000 [30:05<07:40,  1.15iteration/s, mean_rewards=-189]\u001b[A\n",
            "Training:  74%|███████▎  | 1473/2000 [30:06<07:29,  1.17iteration/s, mean_rewards=-189]\u001b[A\n",
            "Training:  74%|███████▎  | 1473/2000 [30:06<07:29,  1.17iteration/s, mean_rewards=-201]\u001b[A\n",
            "Training:  74%|███████▎  | 1474/2000 [30:07<08:08,  1.08iteration/s, mean_rewards=-201]\u001b[A\n",
            "Training:  74%|███████▎  | 1474/2000 [30:07<08:08,  1.08iteration/s, mean_rewards=-206]\u001b[A\n",
            "Training:  74%|███████▍  | 1475/2000 [30:08<08:09,  1.07iteration/s, mean_rewards=-206]\u001b[A\n",
            "Training:  74%|███████▍  | 1475/2000 [30:08<08:09,  1.07iteration/s, mean_rewards=-209]\u001b[A\n",
            "Training:  74%|███████▍  | 1476/2000 [30:09<07:53,  1.11iteration/s, mean_rewards=-209]\u001b[A\n",
            "Training:  74%|███████▍  | 1476/2000 [30:09<07:53,  1.11iteration/s, mean_rewards=-259]\u001b[A\n",
            "Training:  74%|███████▍  | 1477/2000 [30:10<08:20,  1.04iteration/s, mean_rewards=-259]\u001b[A\n",
            "Training:  74%|███████▍  | 1477/2000 [30:10<08:20,  1.04iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  74%|███████▍  | 1478/2000 [30:11<09:44,  1.12s/iteration, mean_rewards=-140]\u001b[A\n",
            "Training:  74%|███████▍  | 1478/2000 [30:12<09:44,  1.12s/iteration, mean_rewards=-268]\u001b[A\n",
            "Training:  74%|███████▍  | 1479/2000 [30:12<09:24,  1.08s/iteration, mean_rewards=-268]\u001b[A\n",
            "Training:  74%|███████▍  | 1479/2000 [30:13<09:24,  1.08s/iteration, mean_rewards=-112]\u001b[A\n",
            "Training:  74%|███████▍  | 1480/2000 [30:13<08:17,  1.04iteration/s, mean_rewards=-112]\u001b[A\n",
            "Training:  74%|███████▍  | 1480/2000 [30:13<08:17,  1.04iteration/s, mean_rewards=-189]\u001b[A\n",
            "Training:  74%|███████▍  | 1481/2000 [30:14<07:39,  1.13iteration/s, mean_rewards=-189]\u001b[A\n",
            "Training:  74%|███████▍  | 1481/2000 [30:14<07:39,  1.13iteration/s, mean_rewards=-105]\u001b[A\n",
            "Training:  74%|███████▍  | 1482/2000 [30:15<08:14,  1.05iteration/s, mean_rewards=-105]\u001b[A\n",
            "Training:  74%|███████▍  | 1482/2000 [30:15<08:14,  1.05iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  74%|███████▍  | 1483/2000 [30:15<07:34,  1.14iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  74%|███████▍  | 1483/2000 [30:16<07:34,  1.14iteration/s, mean_rewards=-71.9]\u001b[A\n",
            "Training:  74%|███████▍  | 1484/2000 [30:16<07:44,  1.11iteration/s, mean_rewards=-71.9]\u001b[A\n",
            "Training:  74%|███████▍  | 1484/2000 [30:17<07:44,  1.11iteration/s, mean_rewards=-113] \u001b[A\n",
            "Training:  74%|███████▍  | 1485/2000 [30:17<07:07,  1.21iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  74%|███████▍  | 1485/2000 [30:17<07:07,  1.21iteration/s, mean_rewards=-343]\u001b[A\n",
            "Training:  74%|███████▍  | 1486/2000 [30:18<07:28,  1.15iteration/s, mean_rewards=-343]\u001b[A\n",
            "Training:  74%|███████▍  | 1486/2000 [30:19<07:28,  1.15iteration/s, mean_rewards=-222]\u001b[A\n",
            "Training:  74%|███████▍  | 1487/2000 [30:19<08:19,  1.03iteration/s, mean_rewards=-222]\u001b[A\n",
            "Training:  74%|███████▍  | 1487/2000 [30:20<08:19,  1.03iteration/s, mean_rewards=-425]\u001b[A\n",
            "Training:  74%|███████▍  | 1488/2000 [30:20<08:13,  1.04iteration/s, mean_rewards=-425]\u001b[A\n",
            "Training:  74%|███████▍  | 1488/2000 [30:21<08:13,  1.04iteration/s, mean_rewards=-199]\u001b[A\n",
            "Training:  74%|███████▍  | 1489/2000 [30:21<07:48,  1.09iteration/s, mean_rewards=-199]\u001b[A\n",
            "Training:  74%|███████▍  | 1489/2000 [30:21<07:48,  1.09iteration/s, mean_rewards=-87.1]\u001b[A\n",
            "Training:  74%|███████▍  | 1490/2000 [30:22<08:13,  1.03iteration/s, mean_rewards=-87.1]\u001b[A\n",
            "Training:  74%|███████▍  | 1490/2000 [30:23<08:13,  1.03iteration/s, mean_rewards=-252] \u001b[A\n",
            "Training:  75%|███████▍  | 1491/2000 [30:23<09:00,  1.06s/iteration, mean_rewards=-252]\u001b[A\n",
            "Training:  75%|███████▍  | 1491/2000 [30:24<09:00,  1.06s/iteration, mean_rewards=-191]\u001b[A\n",
            "Training:  75%|███████▍  | 1492/2000 [30:25<09:18,  1.10s/iteration, mean_rewards=-191]\u001b[A\n",
            "Training:  75%|███████▍  | 1492/2000 [30:25<09:18,  1.10s/iteration, mean_rewards=-150]\u001b[A\n",
            "Training:  75%|███████▍  | 1493/2000 [30:26<09:04,  1.07s/iteration, mean_rewards=-150]\u001b[A\n",
            "Training:  75%|███████▍  | 1493/2000 [30:26<09:04,  1.07s/iteration, mean_rewards=-199]\u001b[A\n",
            "Training:  75%|███████▍  | 1494/2000 [30:26<08:21,  1.01iteration/s, mean_rewards=-199]\u001b[A\n",
            "Training:  75%|███████▍  | 1494/2000 [30:27<08:21,  1.01iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  75%|███████▍  | 1495/2000 [30:27<07:27,  1.13iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  75%|███████▍  | 1495/2000 [30:27<07:27,  1.13iteration/s, mean_rewards=-235]\u001b[A\n",
            "Training:  75%|███████▍  | 1496/2000 [30:28<07:33,  1.11iteration/s, mean_rewards=-235]\u001b[A\n",
            "Training:  75%|███████▍  | 1496/2000 [30:28<07:33,  1.11iteration/s, mean_rewards=-102]\u001b[A\n",
            "Training:  75%|███████▍  | 1497/2000 [30:29<06:58,  1.20iteration/s, mean_rewards=-102]\u001b[A\n",
            "Training:  75%|███████▍  | 1497/2000 [30:29<06:58,  1.20iteration/s, mean_rewards=-290]\u001b[A\n",
            "Training:  75%|███████▍  | 1498/2000 [30:30<07:12,  1.16iteration/s, mean_rewards=-290]\u001b[A\n",
            "Training:  75%|███████▍  | 1498/2000 [30:30<07:12,  1.16iteration/s, mean_rewards=-419]\u001b[A\n",
            "Training:  75%|███████▍  | 1499/2000 [30:31<07:27,  1.12iteration/s, mean_rewards=-419]\u001b[A\n",
            "Training:  75%|███████▍  | 1499/2000 [30:31<07:27,  1.12iteration/s, mean_rewards=-272]\u001b[A\n",
            "Training:  75%|███████▌  | 1500/2000 [30:32<07:42,  1.08iteration/s, mean_rewards=-272]\u001b[A\n",
            "Training:  75%|███████▌  | 1500/2000 [30:32<07:42,  1.08iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  75%|███████▌  | 1501/2000 [30:32<07:21,  1.13iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  75%|███████▌  | 1501/2000 [30:33<07:21,  1.13iteration/s, mean_rewards=-105]\u001b[A\n",
            "Training:  75%|███████▌  | 1502/2000 [30:33<06:50,  1.21iteration/s, mean_rewards=-105]\u001b[A\n",
            "Training:  75%|███████▌  | 1502/2000 [30:33<06:50,  1.21iteration/s, mean_rewards=-442]\u001b[A\n",
            "Training:  75%|███████▌  | 1503/2000 [30:34<07:08,  1.16iteration/s, mean_rewards=-442]\u001b[A\n",
            "Training:  75%|███████▌  | 1503/2000 [30:34<07:08,  1.16iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  75%|███████▌  | 1504/2000 [30:35<06:58,  1.19iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  75%|███████▌  | 1504/2000 [30:35<06:58,  1.19iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:  75%|███████▌  | 1505/2000 [30:36<07:14,  1.14iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:  75%|███████▌  | 1505/2000 [30:36<07:14,  1.14iteration/s, mean_rewards=-91.4]\u001b[A\n",
            "Training:  75%|███████▌  | 1506/2000 [30:37<07:43,  1.07iteration/s, mean_rewards=-91.4]\u001b[A\n",
            "Training:  75%|███████▌  | 1506/2000 [30:37<07:43,  1.07iteration/s, mean_rewards=-286] \u001b[A\n",
            "Training:  75%|███████▌  | 1507/2000 [30:38<07:51,  1.05iteration/s, mean_rewards=-286]\u001b[A\n",
            "Training:  75%|███████▌  | 1507/2000 [30:38<07:51,  1.05iteration/s, mean_rewards=-248]\u001b[A\n",
            "Training:  75%|███████▌  | 1508/2000 [30:39<07:47,  1.05iteration/s, mean_rewards=-248]\u001b[A\n",
            "Training:  75%|███████▌  | 1508/2000 [30:39<07:47,  1.05iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:  75%|███████▌  | 1509/2000 [30:40<07:29,  1.09iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:  75%|███████▌  | 1509/2000 [30:40<07:29,  1.09iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  76%|███████▌  | 1510/2000 [30:40<07:15,  1.13iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  76%|███████▌  | 1510/2000 [30:41<07:15,  1.13iteration/s, mean_rewards=-221]\u001b[A\n",
            "Training:  76%|███████▌  | 1511/2000 [30:41<07:24,  1.10iteration/s, mean_rewards=-221]\u001b[A\n",
            "Training:  76%|███████▌  | 1511/2000 [30:42<07:24,  1.10iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  76%|███████▌  | 1512/2000 [30:42<07:09,  1.14iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  76%|███████▌  | 1512/2000 [30:43<07:09,  1.14iteration/s, mean_rewards=-309]\u001b[A\n",
            "Training:  76%|███████▌  | 1513/2000 [30:43<07:30,  1.08iteration/s, mean_rewards=-309]\u001b[A\n",
            "Training:  76%|███████▌  | 1513/2000 [30:44<07:30,  1.08iteration/s, mean_rewards=-230]\u001b[A\n",
            "Training:  76%|███████▌  | 1514/2000 [30:44<07:26,  1.09iteration/s, mean_rewards=-230]\u001b[A\n",
            "Training:  76%|███████▌  | 1514/2000 [30:44<07:26,  1.09iteration/s, mean_rewards=-272]\u001b[A\n",
            "Training:  76%|███████▌  | 1515/2000 [30:45<07:06,  1.14iteration/s, mean_rewards=-272]\u001b[A\n",
            "Training:  76%|███████▌  | 1515/2000 [30:45<07:06,  1.14iteration/s, mean_rewards=-119]\u001b[A\n",
            "Training:  76%|███████▌  | 1516/2000 [30:46<06:56,  1.16iteration/s, mean_rewards=-119]\u001b[A\n",
            "Training:  76%|███████▌  | 1516/2000 [30:46<06:56,  1.16iteration/s, mean_rewards=-226]\u001b[A\n",
            "Training:  76%|███████▌  | 1517/2000 [30:47<07:03,  1.14iteration/s, mean_rewards=-226]\u001b[A\n",
            "Training:  76%|███████▌  | 1517/2000 [30:47<07:03,  1.14iteration/s, mean_rewards=-168]\u001b[A\n",
            "Training:  76%|███████▌  | 1518/2000 [30:48<07:13,  1.11iteration/s, mean_rewards=-168]\u001b[A\n",
            "Training:  76%|███████▌  | 1518/2000 [30:48<07:13,  1.11iteration/s, mean_rewards=-256]\u001b[A\n",
            "Training:  76%|███████▌  | 1519/2000 [30:49<08:23,  1.05s/iteration, mean_rewards=-256]\u001b[A\n",
            "Training:  76%|███████▌  | 1519/2000 [30:50<08:23,  1.05s/iteration, mean_rewards=-260]\u001b[A\n",
            "Training:  76%|███████▌  | 1520/2000 [30:50<09:34,  1.20s/iteration, mean_rewards=-260]\u001b[A\n",
            "Training:  76%|███████▌  | 1520/2000 [30:51<09:34,  1.20s/iteration, mean_rewards=-64.7]\u001b[A\n",
            "Training:  76%|███████▌  | 1521/2000 [30:51<09:04,  1.14s/iteration, mean_rewards=-64.7]\u001b[A\n",
            "Training:  76%|███████▌  | 1521/2000 [30:52<09:04,  1.14s/iteration, mean_rewards=-115] \u001b[A\n",
            "Training:  76%|███████▌  | 1522/2000 [30:53<09:00,  1.13s/iteration, mean_rewards=-115]\u001b[A\n",
            "Training:  76%|███████▌  | 1522/2000 [30:53<09:00,  1.13s/iteration, mean_rewards=-88.5]\u001b[A\n",
            "Training:  76%|███████▌  | 1523/2000 [30:53<07:57,  1.00s/iteration, mean_rewards=-88.5]\u001b[A\n",
            "Training:  76%|███████▌  | 1523/2000 [30:54<07:57,  1.00s/iteration, mean_rewards=-237] \u001b[A\n",
            "Training:  76%|███████▌  | 1524/2000 [30:54<08:07,  1.02s/iteration, mean_rewards=-237]\u001b[A\n",
            "Training:  76%|███████▌  | 1524/2000 [30:55<08:07,  1.02s/iteration, mean_rewards=-247]\u001b[A\n",
            "Training:  76%|███████▋  | 1525/2000 [30:55<07:20,  1.08iteration/s, mean_rewards=-247]\u001b[A\n",
            "Training:  76%|███████▋  | 1525/2000 [30:55<07:20,  1.08iteration/s, mean_rewards=-353]\u001b[A\n",
            "Training:  76%|███████▋  | 1526/2000 [30:56<07:16,  1.09iteration/s, mean_rewards=-353]\u001b[A\n",
            "Training:  76%|███████▋  | 1526/2000 [30:56<07:16,  1.09iteration/s, mean_rewards=-83.5]\u001b[A\n",
            "Training:  76%|███████▋  | 1527/2000 [30:57<06:56,  1.14iteration/s, mean_rewards=-83.5]\u001b[A\n",
            "Training:  76%|███████▋  | 1527/2000 [30:57<06:56,  1.14iteration/s, mean_rewards=-213] \u001b[A\n",
            "Training:  76%|███████▋  | 1528/2000 [30:58<06:52,  1.15iteration/s, mean_rewards=-213]\u001b[A\n",
            "Training:  76%|███████▋  | 1528/2000 [30:58<06:52,  1.15iteration/s, mean_rewards=-303]\u001b[A\n",
            "Training:  76%|███████▋  | 1529/2000 [30:58<06:44,  1.17iteration/s, mean_rewards=-303]\u001b[A\n",
            "Training:  76%|███████▋  | 1529/2000 [30:59<06:44,  1.17iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  76%|███████▋  | 1530/2000 [30:59<06:24,  1.22iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  76%|███████▋  | 1530/2000 [31:00<06:24,  1.22iteration/s, mean_rewards=-256]\u001b[A\n",
            "Training:  77%|███████▋  | 1531/2000 [31:00<07:02,  1.11iteration/s, mean_rewards=-256]\u001b[A\n",
            "Training:  77%|███████▋  | 1531/2000 [31:01<07:02,  1.11iteration/s, mean_rewards=-98.5]\u001b[A\n",
            "Training:  77%|███████▋  | 1532/2000 [31:01<06:48,  1.14iteration/s, mean_rewards=-98.5]\u001b[A\n",
            "Training:  77%|███████▋  | 1532/2000 [31:02<06:48,  1.14iteration/s, mean_rewards=-229] \u001b[A\n",
            "Training:  77%|███████▋  | 1533/2000 [31:03<08:07,  1.04s/iteration, mean_rewards=-229]\u001b[A\n",
            "Training:  77%|███████▋  | 1533/2000 [31:03<08:07,  1.04s/iteration, mean_rewards=-304]\u001b[A\n",
            "Training:  77%|███████▋  | 1534/2000 [31:04<09:08,  1.18s/iteration, mean_rewards=-304]\u001b[A\n",
            "Training:  77%|███████▋  | 1534/2000 [31:04<09:08,  1.18s/iteration, mean_rewards=-218]\u001b[A\n",
            "Training:  77%|███████▋  | 1535/2000 [31:05<08:35,  1.11s/iteration, mean_rewards=-218]\u001b[A\n",
            "Training:  77%|███████▋  | 1535/2000 [31:05<08:35,  1.11s/iteration, mean_rewards=-248]\u001b[A\n",
            "Training:  77%|███████▋  | 1536/2000 [31:06<07:47,  1.01s/iteration, mean_rewards=-248]\u001b[A\n",
            "Training:  77%|███████▋  | 1536/2000 [31:06<07:47,  1.01s/iteration, mean_rewards=-175]\u001b[A\n",
            "Training:  77%|███████▋  | 1537/2000 [31:06<06:59,  1.10iteration/s, mean_rewards=-175]\u001b[A\n",
            "Training:  77%|███████▋  | 1537/2000 [31:07<06:59,  1.10iteration/s, mean_rewards=-214]\u001b[A\n",
            "Training:  77%|███████▋  | 1538/2000 [31:07<07:04,  1.09iteration/s, mean_rewards=-214]\u001b[A\n",
            "Training:  77%|███████▋  | 1538/2000 [31:08<07:04,  1.09iteration/s, mean_rewards=-190]\u001b[A\n",
            "Training:  77%|███████▋  | 1539/2000 [31:08<06:31,  1.18iteration/s, mean_rewards=-190]\u001b[A\n",
            "Training:  77%|███████▋  | 1539/2000 [31:08<06:31,  1.18iteration/s, mean_rewards=-115]\u001b[A\n",
            "Training:  77%|███████▋  | 1540/2000 [31:09<06:26,  1.19iteration/s, mean_rewards=-115]\u001b[A\n",
            "Training:  77%|███████▋  | 1540/2000 [31:09<06:26,  1.19iteration/s, mean_rewards=-177]\u001b[A\n",
            "Training:  77%|███████▋  | 1541/2000 [31:10<06:25,  1.19iteration/s, mean_rewards=-177]\u001b[A\n",
            "Training:  77%|███████▋  | 1541/2000 [31:10<06:25,  1.19iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  77%|███████▋  | 1542/2000 [31:11<06:23,  1.20iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  77%|███████▋  | 1542/2000 [31:11<06:23,  1.20iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  77%|███████▋  | 1543/2000 [31:11<06:39,  1.14iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  77%|███████▋  | 1543/2000 [31:12<06:39,  1.14iteration/s, mean_rewards=-57.9]\u001b[A\n",
            "Training:  77%|███████▋  | 1544/2000 [31:12<05:59,  1.27iteration/s, mean_rewards=-57.9]\u001b[A\n",
            "Training:  77%|███████▋  | 1544/2000 [31:12<05:59,  1.27iteration/s, mean_rewards=-207] \u001b[A\n",
            "Training:  77%|███████▋  | 1545/2000 [31:13<06:01,  1.26iteration/s, mean_rewards=-207]\u001b[A\n",
            "Training:  77%|███████▋  | 1545/2000 [31:13<06:01,  1.26iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  77%|███████▋  | 1546/2000 [31:14<05:46,  1.31iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training:  77%|███████▋  | 1546/2000 [31:14<05:46,  1.31iteration/s, mean_rewards=-76.2]\u001b[A\n",
            "Training:  77%|███████▋  | 1547/2000 [31:15<06:47,  1.11iteration/s, mean_rewards=-76.2]\u001b[A\n",
            "Training:  77%|███████▋  | 1547/2000 [31:15<06:47,  1.11iteration/s, mean_rewards=-129] \u001b[A\n",
            "Training:  77%|███████▋  | 1548/2000 [31:16<06:48,  1.11iteration/s, mean_rewards=-129]\u001b[A\n",
            "Training:  77%|███████▋  | 1548/2000 [31:16<06:48,  1.11iteration/s, mean_rewards=-215]\u001b[A\n",
            "Training:  77%|███████▋  | 1549/2000 [31:17<07:19,  1.03iteration/s, mean_rewards=-215]\u001b[A\n",
            "Training:  77%|███████▋  | 1549/2000 [31:17<07:19,  1.03iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  78%|███████▊  | 1550/2000 [31:18<07:52,  1.05s/iteration, mean_rewards=-121]\u001b[A\n",
            "Training:  78%|███████▊  | 1550/2000 [31:19<07:52,  1.05s/iteration, mean_rewards=-233]\u001b[A\n",
            "Training:  78%|███████▊  | 1551/2000 [31:19<07:54,  1.06s/iteration, mean_rewards=-233]\u001b[A\n",
            "Training:  78%|███████▊  | 1551/2000 [31:20<07:54,  1.06s/iteration, mean_rewards=-233]\u001b[A\n",
            "Training:  78%|███████▊  | 1552/2000 [31:20<07:33,  1.01s/iteration, mean_rewards=-233]\u001b[A\n",
            "Training:  78%|███████▊  | 1552/2000 [31:21<07:33,  1.01s/iteration, mean_rewards=-202]\u001b[A\n",
            "Training:  78%|███████▊  | 1553/2000 [31:21<07:54,  1.06s/iteration, mean_rewards=-202]\u001b[A\n",
            "Training:  78%|███████▊  | 1553/2000 [31:22<07:54,  1.06s/iteration, mean_rewards=-357]\u001b[A\n",
            "Training:  78%|███████▊  | 1554/2000 [31:22<08:14,  1.11s/iteration, mean_rewards=-357]\u001b[A\n",
            "Training:  78%|███████▊  | 1554/2000 [31:23<08:14,  1.11s/iteration, mean_rewards=-279]\u001b[A\n",
            "Training:  78%|███████▊  | 1555/2000 [31:24<08:09,  1.10s/iteration, mean_rewards=-279]\u001b[A\n",
            "Training:  78%|███████▊  | 1555/2000 [31:24<08:09,  1.10s/iteration, mean_rewards=-137]\u001b[A\n",
            "Training:  78%|███████▊  | 1556/2000 [31:24<07:32,  1.02s/iteration, mean_rewards=-137]\u001b[A\n",
            "Training:  78%|███████▊  | 1556/2000 [31:25<07:32,  1.02s/iteration, mean_rewards=-141]\u001b[A\n",
            "Training:  78%|███████▊  | 1557/2000 [31:25<06:46,  1.09iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  78%|███████▊  | 1557/2000 [31:25<06:46,  1.09iteration/s, mean_rewards=-217]\u001b[A\n",
            "Training:  78%|███████▊  | 1558/2000 [31:26<06:49,  1.08iteration/s, mean_rewards=-217]\u001b[A\n",
            "Training:  78%|███████▊  | 1558/2000 [31:26<06:49,  1.08iteration/s, mean_rewards=-229]\u001b[A\n",
            "Training:  78%|███████▊  | 1559/2000 [31:27<06:37,  1.11iteration/s, mean_rewards=-229]\u001b[A\n",
            "Training:  78%|███████▊  | 1559/2000 [31:27<06:37,  1.11iteration/s, mean_rewards=-396]\u001b[A\n",
            "Training:  78%|███████▊  | 1560/2000 [31:28<07:27,  1.02s/iteration, mean_rewards=-396]\u001b[A\n",
            "Training:  78%|███████▊  | 1560/2000 [31:29<07:27,  1.02s/iteration, mean_rewards=-206]\u001b[A\n",
            "Training:  78%|███████▊  | 1561/2000 [31:30<08:41,  1.19s/iteration, mean_rewards=-206]\u001b[A\n",
            "Training:  78%|███████▊  | 1561/2000 [31:30<08:41,  1.19s/iteration, mean_rewards=-164]\u001b[A\n",
            "Training:  78%|███████▊  | 1562/2000 [31:31<08:28,  1.16s/iteration, mean_rewards=-164]\u001b[A\n",
            "Training:  78%|███████▊  | 1562/2000 [31:31<08:28,  1.16s/iteration, mean_rewards=-153]\u001b[A\n",
            "Training:  78%|███████▊  | 1563/2000 [31:32<07:44,  1.06s/iteration, mean_rewards=-153]\u001b[A\n",
            "Training:  78%|███████▊  | 1563/2000 [31:32<07:44,  1.06s/iteration, mean_rewards=-335]\u001b[A\n",
            "Training:  78%|███████▊  | 1564/2000 [31:32<07:15,  1.00iteration/s, mean_rewards=-335]\u001b[A\n",
            "Training:  78%|███████▊  | 1564/2000 [31:33<07:15,  1.00iteration/s, mean_rewards=-328]\u001b[A\n",
            "Training:  78%|███████▊  | 1565/2000 [31:33<06:55,  1.05iteration/s, mean_rewards=-328]\u001b[A\n",
            "Training:  78%|███████▊  | 1565/2000 [31:34<06:55,  1.05iteration/s, mean_rewards=-384]\u001b[A\n",
            "Training:  78%|███████▊  | 1566/2000 [31:34<06:39,  1.09iteration/s, mean_rewards=-384]\u001b[A\n",
            "Training:  78%|███████▊  | 1566/2000 [31:35<06:39,  1.09iteration/s, mean_rewards=-54.7]\u001b[A\n",
            "Training:  78%|███████▊  | 1567/2000 [31:35<06:44,  1.07iteration/s, mean_rewards=-54.7]\u001b[A\n",
            "Training:  78%|███████▊  | 1567/2000 [31:36<06:44,  1.07iteration/s, mean_rewards=-108] \u001b[A\n",
            "Training:  78%|███████▊  | 1568/2000 [31:36<06:50,  1.05iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:  78%|███████▊  | 1568/2000 [31:37<06:50,  1.05iteration/s, mean_rewards=-204]\u001b[A\n",
            "Training:  78%|███████▊  | 1569/2000 [31:37<07:04,  1.02iteration/s, mean_rewards=-204]\u001b[A\n",
            "Training:  78%|███████▊  | 1569/2000 [31:38<07:04,  1.02iteration/s, mean_rewards=-208]\u001b[A\n",
            "Training:  78%|███████▊  | 1570/2000 [31:38<06:59,  1.02iteration/s, mean_rewards=-208]\u001b[A\n",
            "Training:  78%|███████▊  | 1570/2000 [31:39<06:59,  1.02iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  79%|███████▊  | 1571/2000 [31:39<07:05,  1.01iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  79%|███████▊  | 1571/2000 [31:39<07:05,  1.01iteration/s, mean_rewards=-283]\u001b[A\n",
            "Training:  79%|███████▊  | 1572/2000 [31:40<06:41,  1.07iteration/s, mean_rewards=-283]\u001b[A\n",
            "Training:  79%|███████▊  | 1572/2000 [31:40<06:41,  1.07iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  79%|███████▊  | 1573/2000 [31:41<06:51,  1.04iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  79%|███████▊  | 1573/2000 [31:41<06:51,  1.04iteration/s, mean_rewards=-208]\u001b[A\n",
            "Training:  79%|███████▊  | 1574/2000 [31:42<07:07,  1.00s/iteration, mean_rewards=-208]\u001b[A\n",
            "Training:  79%|███████▊  | 1574/2000 [31:42<07:07,  1.00s/iteration, mean_rewards=-72.3]\u001b[A\n",
            "Training:  79%|███████▉  | 1575/2000 [31:43<06:58,  1.02iteration/s, mean_rewards=-72.3]\u001b[A\n",
            "Training:  79%|███████▉  | 1575/2000 [31:44<06:58,  1.02iteration/s, mean_rewards=-347] \u001b[A\n",
            "Training:  79%|███████▉  | 1576/2000 [31:44<07:32,  1.07s/iteration, mean_rewards=-347]\u001b[A\n",
            "Training:  79%|███████▉  | 1576/2000 [31:45<07:32,  1.07s/iteration, mean_rewards=-92.1]\u001b[A\n",
            "Training:  79%|███████▉  | 1577/2000 [31:45<06:38,  1.06iteration/s, mean_rewards=-92.1]\u001b[A\n",
            "Training:  79%|███████▉  | 1577/2000 [31:45<06:38,  1.06iteration/s, mean_rewards=-233] \u001b[A\n",
            "Training:  79%|███████▉  | 1578/2000 [31:46<06:19,  1.11iteration/s, mean_rewards=-233]\u001b[A\n",
            "Training:  79%|███████▉  | 1578/2000 [31:46<06:19,  1.11iteration/s, mean_rewards=-234]\u001b[A\n",
            "Training:  79%|███████▉  | 1579/2000 [31:47<06:06,  1.15iteration/s, mean_rewards=-234]\u001b[A\n",
            "Training:  79%|███████▉  | 1579/2000 [31:47<06:06,  1.15iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  79%|███████▉  | 1580/2000 [31:47<06:02,  1.16iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  79%|███████▉  | 1580/2000 [31:48<06:02,  1.16iteration/s, mean_rewards=-188]\u001b[A\n",
            "Training:  79%|███████▉  | 1581/2000 [31:48<05:55,  1.18iteration/s, mean_rewards=-188]\u001b[A\n",
            "Training:  79%|███████▉  | 1581/2000 [31:49<05:55,  1.18iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  79%|███████▉  | 1582/2000 [31:49<05:54,  1.18iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  79%|███████▉  | 1582/2000 [31:49<05:54,  1.18iteration/s, mean_rewards=-364]\u001b[A\n",
            "Training:  79%|███████▉  | 1583/2000 [31:50<06:04,  1.14iteration/s, mean_rewards=-364]\u001b[A\n",
            "Training:  79%|███████▉  | 1583/2000 [31:50<06:04,  1.14iteration/s, mean_rewards=-239]\u001b[A\n",
            "Training:  79%|███████▉  | 1584/2000 [31:51<06:28,  1.07iteration/s, mean_rewards=-239]\u001b[A\n",
            "Training:  79%|███████▉  | 1584/2000 [31:51<06:28,  1.07iteration/s, mean_rewards=-287]\u001b[A\n",
            "Training:  79%|███████▉  | 1585/2000 [31:52<06:11,  1.12iteration/s, mean_rewards=-287]\u001b[A\n",
            "Training:  79%|███████▉  | 1585/2000 [31:52<06:11,  1.12iteration/s, mean_rewards=-91.1]\u001b[A\n",
            "Training:  79%|███████▉  | 1586/2000 [31:53<06:14,  1.11iteration/s, mean_rewards=-91.1]\u001b[A\n",
            "Training:  79%|███████▉  | 1586/2000 [31:53<06:14,  1.11iteration/s, mean_rewards=-251] \u001b[A\n",
            "Training:  79%|███████▉  | 1587/2000 [31:54<06:34,  1.05iteration/s, mean_rewards=-251]\u001b[A\n",
            "Training:  79%|███████▉  | 1587/2000 [31:54<06:34,  1.05iteration/s, mean_rewards=-297]\u001b[A\n",
            "Training:  79%|███████▉  | 1588/2000 [31:55<07:35,  1.11s/iteration, mean_rewards=-297]\u001b[A\n",
            "Training:  79%|███████▉  | 1588/2000 [31:56<07:35,  1.11s/iteration, mean_rewards=-79.1]\u001b[A\n",
            "Training:  79%|███████▉  | 1589/2000 [31:56<07:13,  1.05s/iteration, mean_rewards=-79.1]\u001b[A\n",
            "Training:  79%|███████▉  | 1589/2000 [31:57<07:13,  1.05s/iteration, mean_rewards=-109] \u001b[A\n",
            "Training:  80%|███████▉  | 1590/2000 [31:57<06:28,  1.06iteration/s, mean_rewards=-109]\u001b[A\n",
            "Training:  80%|███████▉  | 1590/2000 [31:57<06:28,  1.06iteration/s, mean_rewards=-109]\u001b[A\n",
            "Training:  80%|███████▉  | 1591/2000 [31:58<05:56,  1.15iteration/s, mean_rewards=-109]\u001b[A\n",
            "Training:  80%|███████▉  | 1591/2000 [31:58<05:56,  1.15iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  80%|███████▉  | 1592/2000 [31:59<05:58,  1.14iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  80%|███████▉  | 1592/2000 [31:59<05:58,  1.14iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  80%|███████▉  | 1593/2000 [31:59<06:04,  1.12iteration/s, mean_rewards=-153]\u001b[A\n",
            "Training:  80%|███████▉  | 1593/2000 [32:00<06:04,  1.12iteration/s, mean_rewards=-67.3]\u001b[A\n",
            "Training:  80%|███████▉  | 1594/2000 [32:00<05:40,  1.19iteration/s, mean_rewards=-67.3]\u001b[A\n",
            "Training:  80%|███████▉  | 1594/2000 [32:01<05:40,  1.19iteration/s, mean_rewards=-69.6]\u001b[A\n",
            "Training:  80%|███████▉  | 1595/2000 [32:01<06:12,  1.09iteration/s, mean_rewards=-69.6]\u001b[A\n",
            "Training:  80%|███████▉  | 1595/2000 [32:02<06:12,  1.09iteration/s, mean_rewards=-107] \u001b[A\n",
            "Training:  80%|███████▉  | 1596/2000 [32:02<05:55,  1.14iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  80%|███████▉  | 1596/2000 [32:02<05:55,  1.14iteration/s, mean_rewards=-174]\u001b[A\n",
            "Training:  80%|███████▉  | 1597/2000 [32:03<05:47,  1.16iteration/s, mean_rewards=-174]\u001b[A\n",
            "Training:  80%|███████▉  | 1597/2000 [32:03<05:47,  1.16iteration/s, mean_rewards=-239]\u001b[A\n",
            "Training:  80%|███████▉  | 1598/2000 [32:04<05:55,  1.13iteration/s, mean_rewards=-239]\u001b[A\n",
            "Training:  80%|███████▉  | 1598/2000 [32:04<05:55,  1.13iteration/s, mean_rewards=-252]\u001b[A\n",
            "Training:  80%|███████▉  | 1599/2000 [32:05<05:45,  1.16iteration/s, mean_rewards=-252]\u001b[A\n",
            "Training:  80%|███████▉  | 1599/2000 [32:05<05:45,  1.16iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  80%|████████  | 1600/2000 [32:05<05:18,  1.25iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  80%|████████  | 1600/2000 [32:06<05:18,  1.25iteration/s, mean_rewards=-187]\u001b[A\n",
            "Training:  80%|████████  | 1601/2000 [32:06<05:04,  1.31iteration/s, mean_rewards=-187]\u001b[A\n",
            "Training:  80%|████████  | 1601/2000 [32:06<05:04,  1.31iteration/s, mean_rewards=-170]\u001b[A\n",
            "Training:  80%|████████  | 1602/2000 [32:07<06:03,  1.09iteration/s, mean_rewards=-170]\u001b[A\n",
            "Training:  80%|████████  | 1602/2000 [32:08<06:03,  1.09iteration/s, mean_rewards=-88] \u001b[A\n",
            "Training:  80%|████████  | 1603/2000 [32:09<06:57,  1.05s/iteration, mean_rewards=-88]\u001b[A\n",
            "Training:  80%|████████  | 1603/2000 [32:09<06:57,  1.05s/iteration, mean_rewards=-517]\u001b[A\n",
            "Training:  80%|████████  | 1604/2000 [32:10<07:31,  1.14s/iteration, mean_rewards=-517]\u001b[A\n",
            "Training:  80%|████████  | 1604/2000 [32:10<07:31,  1.14s/iteration, mean_rewards=-48.5]\u001b[A\n",
            "Training:  80%|████████  | 1605/2000 [32:11<06:47,  1.03s/iteration, mean_rewards=-48.5]\u001b[A\n",
            "Training:  80%|████████  | 1605/2000 [32:11<06:47,  1.03s/iteration, mean_rewards=-199] \u001b[A\n",
            "Training:  80%|████████  | 1606/2000 [32:12<06:17,  1.04iteration/s, mean_rewards=-199]\u001b[A\n",
            "Training:  80%|████████  | 1606/2000 [32:12<06:17,  1.04iteration/s, mean_rewards=-322]\u001b[A\n",
            "Training:  80%|████████  | 1607/2000 [32:12<06:14,  1.05iteration/s, mean_rewards=-322]\u001b[A\n",
            "Training:  80%|████████  | 1607/2000 [32:13<06:14,  1.05iteration/s, mean_rewards=-184]\u001b[A\n",
            "Training:  80%|████████  | 1608/2000 [32:13<05:58,  1.09iteration/s, mean_rewards=-184]\u001b[A\n",
            "Training:  80%|████████  | 1608/2000 [32:14<05:58,  1.09iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:  80%|████████  | 1609/2000 [32:14<05:46,  1.13iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:  80%|████████  | 1609/2000 [32:14<05:46,  1.13iteration/s, mean_rewards=-60.8]\u001b[A\n",
            "Training:  80%|████████  | 1610/2000 [32:15<05:17,  1.23iteration/s, mean_rewards=-60.8]\u001b[A\n",
            "Training:  80%|████████  | 1610/2000 [32:15<05:17,  1.23iteration/s, mean_rewards=-180] \u001b[A\n",
            "Training:  81%|████████  | 1611/2000 [32:16<05:17,  1.23iteration/s, mean_rewards=-180]\u001b[A\n",
            "Training:  81%|████████  | 1611/2000 [32:16<05:17,  1.23iteration/s, mean_rewards=-187]\u001b[A\n",
            "Training:  81%|████████  | 1612/2000 [32:16<05:21,  1.21iteration/s, mean_rewards=-187]\u001b[A\n",
            "Training:  81%|████████  | 1612/2000 [32:17<05:21,  1.21iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:  81%|████████  | 1613/2000 [32:17<05:21,  1.20iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:  81%|████████  | 1613/2000 [32:18<05:21,  1.20iteration/s, mean_rewards=-89.4]\u001b[A\n",
            "Training:  81%|████████  | 1614/2000 [32:18<05:31,  1.16iteration/s, mean_rewards=-89.4]\u001b[A\n",
            "Training:  81%|████████  | 1614/2000 [32:19<05:31,  1.16iteration/s, mean_rewards=-162] \u001b[A\n",
            "Training:  81%|████████  | 1615/2000 [32:19<05:24,  1.19iteration/s, mean_rewards=-162]\u001b[A\n",
            "Training:  81%|████████  | 1615/2000 [32:19<05:24,  1.19iteration/s, mean_rewards=-315]\u001b[A\n",
            "Training:  81%|████████  | 1616/2000 [32:20<05:37,  1.14iteration/s, mean_rewards=-315]\u001b[A\n",
            "Training:  81%|████████  | 1616/2000 [32:20<05:37,  1.14iteration/s, mean_rewards=-190]\u001b[A\n",
            "Training:  81%|████████  | 1617/2000 [32:21<06:37,  1.04s/iteration, mean_rewards=-190]\u001b[A\n",
            "Training:  81%|████████  | 1617/2000 [32:22<06:37,  1.04s/iteration, mean_rewards=-184]\u001b[A\n",
            "Training:  81%|████████  | 1618/2000 [32:22<06:28,  1.02s/iteration, mean_rewards=-184]\u001b[A\n",
            "Training:  81%|████████  | 1618/2000 [32:23<06:28,  1.02s/iteration, mean_rewards=-311]\u001b[A\n",
            "Training:  81%|████████  | 1619/2000 [32:23<06:21,  1.00s/iteration, mean_rewards=-311]\u001b[A\n",
            "Training:  81%|████████  | 1619/2000 [32:24<06:21,  1.00s/iteration, mean_rewards=-109]\u001b[A\n",
            "Training:  81%|████████  | 1620/2000 [32:24<06:01,  1.05iteration/s, mean_rewards=-109]\u001b[A\n",
            "Training:  81%|████████  | 1620/2000 [32:25<06:01,  1.05iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  81%|████████  | 1621/2000 [32:25<05:56,  1.06iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  81%|████████  | 1621/2000 [32:25<05:56,  1.06iteration/s, mean_rewards=-312]\u001b[A\n",
            "Training:  81%|████████  | 1622/2000 [32:26<05:56,  1.06iteration/s, mean_rewards=-312]\u001b[A\n",
            "Training:  81%|████████  | 1622/2000 [32:26<05:56,  1.06iteration/s, mean_rewards=-179]\u001b[A\n",
            "Training:  81%|████████  | 1623/2000 [32:27<06:22,  1.02s/iteration, mean_rewards=-179]\u001b[A\n",
            "Training:  81%|████████  | 1623/2000 [32:27<06:22,  1.02s/iteration, mean_rewards=-199]\u001b[A\n",
            "Training:  81%|████████  | 1624/2000 [32:28<05:56,  1.05iteration/s, mean_rewards=-199]\u001b[A\n",
            "Training:  81%|████████  | 1624/2000 [32:28<05:56,  1.05iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:  81%|████████▏ | 1625/2000 [32:29<05:35,  1.12iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:  81%|████████▏ | 1625/2000 [32:29<05:35,  1.12iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  81%|████████▏ | 1626/2000 [32:30<05:25,  1.15iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  81%|████████▏ | 1626/2000 [32:30<05:25,  1.15iteration/s, mean_rewards=-202]\u001b[A\n",
            "Training:  81%|████████▏ | 1627/2000 [32:30<05:17,  1.18iteration/s, mean_rewards=-202]\u001b[A\n",
            "Training:  81%|████████▏ | 1627/2000 [32:31<05:17,  1.18iteration/s, mean_rewards=-112]\u001b[A\n",
            "Training:  81%|████████▏ | 1628/2000 [32:31<05:11,  1.20iteration/s, mean_rewards=-112]\u001b[A\n",
            "Training:  81%|████████▏ | 1628/2000 [32:32<05:11,  1.20iteration/s, mean_rewards=-178]\u001b[A\n",
            "Training:  81%|████████▏ | 1629/2000 [32:32<05:06,  1.21iteration/s, mean_rewards=-178]\u001b[A\n",
            "Training:  81%|████████▏ | 1629/2000 [32:32<05:06,  1.21iteration/s, mean_rewards=-99.9]\u001b[A\n",
            "Training:  82%|████████▏ | 1630/2000 [32:33<05:18,  1.16iteration/s, mean_rewards=-99.9]\u001b[A\n",
            "Training:  82%|████████▏ | 1630/2000 [32:33<05:18,  1.16iteration/s, mean_rewards=-162] \u001b[A\n",
            "Training:  82%|████████▏ | 1631/2000 [32:34<05:22,  1.14iteration/s, mean_rewards=-162]\u001b[A\n",
            "Training:  82%|████████▏ | 1631/2000 [32:34<05:22,  1.14iteration/s, mean_rewards=-254]\u001b[A\n",
            "Training:  82%|████████▏ | 1632/2000 [32:35<05:50,  1.05iteration/s, mean_rewards=-254]\u001b[A\n",
            "Training:  82%|████████▏ | 1632/2000 [32:35<05:50,  1.05iteration/s, mean_rewards=-225]\u001b[A\n",
            "Training:  82%|████████▏ | 1633/2000 [32:36<05:46,  1.06iteration/s, mean_rewards=-225]\u001b[A\n",
            "Training:  82%|████████▏ | 1633/2000 [32:36<05:46,  1.06iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  82%|████████▏ | 1634/2000 [32:37<05:19,  1.15iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  82%|████████▏ | 1634/2000 [32:37<05:19,  1.15iteration/s, mean_rewards=-166]\u001b[A\n",
            "Training:  82%|████████▏ | 1635/2000 [32:37<05:13,  1.16iteration/s, mean_rewards=-166]\u001b[A\n",
            "Training:  82%|████████▏ | 1635/2000 [32:38<05:13,  1.16iteration/s, mean_rewards=-272]\u001b[A\n",
            "Training:  82%|████████▏ | 1636/2000 [32:38<05:24,  1.12iteration/s, mean_rewards=-272]\u001b[A\n",
            "Training:  82%|████████▏ | 1636/2000 [32:39<05:24,  1.12iteration/s, mean_rewards=-95.2]\u001b[A\n",
            "Training:  82%|████████▏ | 1637/2000 [32:39<05:31,  1.09iteration/s, mean_rewards=-95.2]\u001b[A\n",
            "Training:  82%|████████▏ | 1637/2000 [32:40<05:31,  1.09iteration/s, mean_rewards=-282] \u001b[A\n",
            "Training:  82%|████████▏ | 1638/2000 [32:40<05:31,  1.09iteration/s, mean_rewards=-282]\u001b[A\n",
            "Training:  82%|████████▏ | 1638/2000 [32:41<05:31,  1.09iteration/s, mean_rewards=-280]\u001b[A\n",
            "Training:  82%|████████▏ | 1639/2000 [32:41<05:21,  1.12iteration/s, mean_rewards=-280]\u001b[A\n",
            "Training:  82%|████████▏ | 1639/2000 [32:41<05:21,  1.12iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  82%|████████▏ | 1640/2000 [32:42<05:10,  1.16iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  82%|████████▏ | 1640/2000 [32:42<05:10,  1.16iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  82%|████████▏ | 1641/2000 [32:43<05:04,  1.18iteration/s, mean_rewards=-111]\u001b[A\n",
            "Training:  82%|████████▏ | 1641/2000 [32:43<05:04,  1.18iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  82%|████████▏ | 1642/2000 [32:43<04:48,  1.24iteration/s, mean_rewards=-118]\u001b[A\n",
            "Training:  82%|████████▏ | 1642/2000 [32:44<04:48,  1.24iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  82%|████████▏ | 1643/2000 [32:44<05:00,  1.19iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  82%|████████▏ | 1643/2000 [32:45<05:00,  1.19iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  82%|████████▏ | 1644/2000 [32:45<05:09,  1.15iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  82%|████████▏ | 1644/2000 [32:46<05:09,  1.15iteration/s, mean_rewards=-186]\u001b[A\n",
            "Training:  82%|████████▏ | 1645/2000 [32:46<05:28,  1.08iteration/s, mean_rewards=-186]\u001b[A\n",
            "Training:  82%|████████▏ | 1645/2000 [32:47<05:28,  1.08iteration/s, mean_rewards=-144]\u001b[A\n",
            "Training:  82%|████████▏ | 1646/2000 [32:48<06:09,  1.04s/iteration, mean_rewards=-144]\u001b[A\n",
            "Training:  82%|████████▏ | 1646/2000 [32:48<06:09,  1.04s/iteration, mean_rewards=-153]\u001b[A\n",
            "Training:  82%|████████▏ | 1647/2000 [32:49<06:21,  1.08s/iteration, mean_rewards=-153]\u001b[A\n",
            "Training:  82%|████████▏ | 1647/2000 [32:49<06:21,  1.08s/iteration, mean_rewards=-424]\u001b[A\n",
            "Training:  82%|████████▏ | 1648/2000 [32:50<06:07,  1.04s/iteration, mean_rewards=-424]\u001b[A\n",
            "Training:  82%|████████▏ | 1648/2000 [32:50<06:07,  1.04s/iteration, mean_rewards=-295]\u001b[A\n",
            "Training:  82%|████████▏ | 1649/2000 [32:51<05:45,  1.02iteration/s, mean_rewards=-295]\u001b[A\n",
            "Training:  82%|████████▏ | 1649/2000 [32:51<05:45,  1.02iteration/s, mean_rewards=-289]\u001b[A\n",
            "Training:  82%|████████▎ | 1650/2000 [32:52<05:42,  1.02iteration/s, mean_rewards=-289]\u001b[A\n",
            "Training:  82%|████████▎ | 1650/2000 [32:52<05:42,  1.02iteration/s, mean_rewards=-177]\u001b[A\n",
            "Training:  83%|████████▎ | 1651/2000 [32:52<05:21,  1.08iteration/s, mean_rewards=-177]\u001b[A\n",
            "Training:  83%|████████▎ | 1651/2000 [32:53<05:21,  1.08iteration/s, mean_rewards=-112]\u001b[A\n",
            "Training:  83%|████████▎ | 1652/2000 [32:53<05:14,  1.11iteration/s, mean_rewards=-112]\u001b[A\n",
            "Training:  83%|████████▎ | 1652/2000 [32:54<05:14,  1.11iteration/s, mean_rewards=-104]\u001b[A\n",
            "Training:  83%|████████▎ | 1653/2000 [32:54<05:01,  1.15iteration/s, mean_rewards=-104]\u001b[A\n",
            "Training:  83%|████████▎ | 1653/2000 [32:54<05:01,  1.15iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:  83%|████████▎ | 1654/2000 [32:55<04:43,  1.22iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:  83%|████████▎ | 1654/2000 [32:55<04:43,  1.22iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  83%|████████▎ | 1655/2000 [32:56<05:22,  1.07iteration/s, mean_rewards=-128]\u001b[A\n",
            "Training:  83%|████████▎ | 1655/2000 [32:56<05:22,  1.07iteration/s, mean_rewards=-334]\u001b[A\n",
            "Training:  83%|████████▎ | 1656/2000 [32:57<05:08,  1.11iteration/s, mean_rewards=-334]\u001b[A\n",
            "Training:  83%|████████▎ | 1656/2000 [32:57<05:08,  1.11iteration/s, mean_rewards=-101]\u001b[A\n",
            "Training:  83%|████████▎ | 1657/2000 [32:58<05:26,  1.05iteration/s, mean_rewards=-101]\u001b[A\n",
            "Training:  83%|████████▎ | 1657/2000 [32:58<05:26,  1.05iteration/s, mean_rewards=-199]\u001b[A\n",
            "Training:  83%|████████▎ | 1658/2000 [32:59<05:48,  1.02s/iteration, mean_rewards=-199]\u001b[A\n",
            "Training:  83%|████████▎ | 1658/2000 [32:59<05:48,  1.02s/iteration, mean_rewards=-154]\u001b[A\n",
            "Training:  83%|████████▎ | 1659/2000 [33:00<05:57,  1.05s/iteration, mean_rewards=-154]\u001b[A\n",
            "Training:  83%|████████▎ | 1659/2000 [33:01<05:57,  1.05s/iteration, mean_rewards=-169]\u001b[A\n",
            "Training:  83%|████████▎ | 1660/2000 [33:01<05:54,  1.04s/iteration, mean_rewards=-169]\u001b[A\n",
            "Training:  83%|████████▎ | 1660/2000 [33:02<05:54,  1.04s/iteration, mean_rewards=-113]\u001b[A\n",
            "Training:  83%|████████▎ | 1661/2000 [33:02<05:32,  1.02iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  83%|████████▎ | 1661/2000 [33:02<05:32,  1.02iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  83%|████████▎ | 1662/2000 [33:03<05:01,  1.12iteration/s, mean_rewards=-158]\u001b[A\n",
            "Training:  83%|████████▎ | 1662/2000 [33:03<05:01,  1.12iteration/s, mean_rewards=-190]\u001b[A\n",
            "Training:  83%|████████▎ | 1663/2000 [33:03<04:35,  1.22iteration/s, mean_rewards=-190]\u001b[A\n",
            "Training:  83%|████████▎ | 1663/2000 [33:04<04:35,  1.22iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  83%|████████▎ | 1664/2000 [33:04<04:20,  1.29iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  83%|████████▎ | 1664/2000 [33:04<04:20,  1.29iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  83%|████████▎ | 1665/2000 [33:05<04:22,  1.27iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  83%|████████▎ | 1665/2000 [33:05<04:22,  1.27iteration/s, mean_rewards=-221]\u001b[A\n",
            "Training:  83%|████████▎ | 1666/2000 [33:06<04:52,  1.14iteration/s, mean_rewards=-221]\u001b[A\n",
            "Training:  83%|████████▎ | 1666/2000 [33:06<04:52,  1.14iteration/s, mean_rewards=-272]\u001b[A\n",
            "Training:  83%|████████▎ | 1667/2000 [33:07<04:47,  1.16iteration/s, mean_rewards=-272]\u001b[A\n",
            "Training:  83%|████████▎ | 1667/2000 [33:07<04:47,  1.16iteration/s, mean_rewards=-189]\u001b[A\n",
            "Training:  83%|████████▎ | 1668/2000 [33:08<05:03,  1.09iteration/s, mean_rewards=-189]\u001b[A\n",
            "Training:  83%|████████▎ | 1668/2000 [33:08<05:03,  1.09iteration/s, mean_rewards=-178]\u001b[A\n",
            "Training:  83%|████████▎ | 1669/2000 [33:09<04:56,  1.12iteration/s, mean_rewards=-178]\u001b[A\n",
            "Training:  83%|████████▎ | 1669/2000 [33:09<04:56,  1.12iteration/s, mean_rewards=-214]\u001b[A\n",
            "Training:  84%|████████▎ | 1670/2000 [33:10<05:14,  1.05iteration/s, mean_rewards=-214]\u001b[A\n",
            "Training:  84%|████████▎ | 1670/2000 [33:10<05:14,  1.05iteration/s, mean_rewards=-244]\u001b[A\n",
            "Training:  84%|████████▎ | 1671/2000 [33:11<04:58,  1.10iteration/s, mean_rewards=-244]\u001b[A\n",
            "Training:  84%|████████▎ | 1671/2000 [33:11<04:58,  1.10iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  84%|████████▎ | 1672/2000 [33:11<04:53,  1.12iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  84%|████████▎ | 1672/2000 [33:12<04:53,  1.12iteration/s, mean_rewards=-231]\u001b[A\n",
            "Training:  84%|████████▎ | 1673/2000 [33:13<05:33,  1.02s/iteration, mean_rewards=-231]\u001b[A\n",
            "Training:  84%|████████▎ | 1673/2000 [33:13<05:33,  1.02s/iteration, mean_rewards=-132]\u001b[A\n",
            "Training:  84%|████████▎ | 1674/2000 [33:14<05:42,  1.05s/iteration, mean_rewards=-132]\u001b[A\n",
            "Training:  84%|████████▎ | 1674/2000 [33:14<05:42,  1.05s/iteration, mean_rewards=-283]\u001b[A\n",
            "Training:  84%|████████▍ | 1675/2000 [33:15<05:17,  1.02iteration/s, mean_rewards=-283]\u001b[A\n",
            "Training:  84%|████████▍ | 1675/2000 [33:15<05:17,  1.02iteration/s, mean_rewards=-175]\u001b[A\n",
            "Training:  84%|████████▍ | 1676/2000 [33:16<05:11,  1.04iteration/s, mean_rewards=-175]\u001b[A\n",
            "Training:  84%|████████▍ | 1676/2000 [33:16<05:11,  1.04iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:  84%|████████▍ | 1677/2000 [33:16<04:55,  1.09iteration/s, mean_rewards=-145]\u001b[A\n",
            "Training:  84%|████████▍ | 1677/2000 [33:17<04:55,  1.09iteration/s, mean_rewards=-271]\u001b[A\n",
            "Training:  84%|████████▍ | 1678/2000 [33:17<04:53,  1.10iteration/s, mean_rewards=-271]\u001b[A\n",
            "Training:  84%|████████▍ | 1678/2000 [33:18<04:53,  1.10iteration/s, mean_rewards=-211]\u001b[A\n",
            "Training:  84%|████████▍ | 1679/2000 [33:18<04:55,  1.09iteration/s, mean_rewards=-211]\u001b[A\n",
            "Training:  84%|████████▍ | 1679/2000 [33:19<04:55,  1.09iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  84%|████████▍ | 1680/2000 [33:19<04:44,  1.12iteration/s, mean_rewards=-122]\u001b[A\n",
            "Training:  84%|████████▍ | 1680/2000 [33:19<04:44,  1.12iteration/s, mean_rewards=-206]\u001b[A\n",
            "Training:  84%|████████▍ | 1681/2000 [33:20<04:35,  1.16iteration/s, mean_rewards=-206]\u001b[A\n",
            "Training:  84%|████████▍ | 1681/2000 [33:20<04:35,  1.16iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  84%|████████▍ | 1682/2000 [33:21<05:09,  1.03iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  84%|████████▍ | 1682/2000 [33:21<05:09,  1.03iteration/s, mean_rewards=-86.9]\u001b[A\n",
            "Training:  84%|████████▍ | 1683/2000 [33:22<04:51,  1.09iteration/s, mean_rewards=-86.9]\u001b[A\n",
            "Training:  84%|████████▍ | 1683/2000 [33:22<04:51,  1.09iteration/s, mean_rewards=-160] \u001b[A\n",
            "Training:  84%|████████▍ | 1684/2000 [33:23<04:27,  1.18iteration/s, mean_rewards=-160]\u001b[A\n",
            "Training:  84%|████████▍ | 1684/2000 [33:23<04:27,  1.18iteration/s, mean_rewards=-240]\u001b[A\n",
            "Training:  84%|████████▍ | 1685/2000 [33:24<04:46,  1.10iteration/s, mean_rewards=-240]\u001b[A\n",
            "Training:  84%|████████▍ | 1685/2000 [33:24<04:46,  1.10iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  84%|████████▍ | 1686/2000 [33:25<04:59,  1.05iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  84%|████████▍ | 1686/2000 [33:25<04:59,  1.05iteration/s, mean_rewards=-121]\u001b[A\n",
            "Training:  84%|████████▍ | 1687/2000 [33:26<05:34,  1.07s/iteration, mean_rewards=-121]\u001b[A\n",
            "Training:  84%|████████▍ | 1687/2000 [33:26<05:34,  1.07s/iteration, mean_rewards=-224]\u001b[A\n",
            "Training:  84%|████████▍ | 1688/2000 [33:27<05:18,  1.02s/iteration, mean_rewards=-224]\u001b[A\n",
            "Training:  84%|████████▍ | 1688/2000 [33:27<05:18,  1.02s/iteration, mean_rewards=-132]\u001b[A\n",
            "Training:  84%|████████▍ | 1689/2000 [33:28<05:21,  1.03s/iteration, mean_rewards=-132]\u001b[A\n",
            "Training:  84%|████████▍ | 1689/2000 [33:28<05:21,  1.03s/iteration, mean_rewards=-114]\u001b[A\n",
            "Training:  84%|████████▍ | 1690/2000 [33:29<05:09,  1.00iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  84%|████████▍ | 1690/2000 [33:29<05:09,  1.00iteration/s, mean_rewards=-234]\u001b[A\n",
            "Training:  85%|████████▍ | 1691/2000 [33:30<04:51,  1.06iteration/s, mean_rewards=-234]\u001b[A\n",
            "Training:  85%|████████▍ | 1691/2000 [33:30<04:51,  1.06iteration/s, mean_rewards=-413]\u001b[A\n",
            "Training:  85%|████████▍ | 1692/2000 [33:31<04:43,  1.09iteration/s, mean_rewards=-413]\u001b[A\n",
            "Training:  85%|████████▍ | 1692/2000 [33:31<04:43,  1.09iteration/s, mean_rewards=-223]\u001b[A\n",
            "Training:  85%|████████▍ | 1693/2000 [33:32<04:56,  1.03iteration/s, mean_rewards=-223]\u001b[A\n",
            "Training:  85%|████████▍ | 1693/2000 [33:32<04:56,  1.03iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  85%|████████▍ | 1694/2000 [33:32<04:43,  1.08iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  85%|████████▍ | 1694/2000 [33:33<04:43,  1.08iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:  85%|████████▍ | 1695/2000 [33:33<04:31,  1.12iteration/s, mean_rewards=-108]\u001b[A\n",
            "Training:  85%|████████▍ | 1695/2000 [33:34<04:31,  1.12iteration/s, mean_rewards=-97.6]\u001b[A\n",
            "Training:  85%|████████▍ | 1696/2000 [33:34<04:11,  1.21iteration/s, mean_rewards=-97.6]\u001b[A\n",
            "Training:  85%|████████▍ | 1696/2000 [33:34<04:11,  1.21iteration/s, mean_rewards=-185] \u001b[A\n",
            "Training:  85%|████████▍ | 1697/2000 [33:35<04:33,  1.11iteration/s, mean_rewards=-185]\u001b[A\n",
            "Training:  85%|████████▍ | 1697/2000 [33:35<04:33,  1.11iteration/s, mean_rewards=-292]\u001b[A\n",
            "Training:  85%|████████▍ | 1698/2000 [33:36<04:25,  1.14iteration/s, mean_rewards=-292]\u001b[A\n",
            "Training:  85%|████████▍ | 1698/2000 [33:36<04:25,  1.14iteration/s, mean_rewards=-253]\u001b[A\n",
            "Training:  85%|████████▍ | 1699/2000 [33:37<04:20,  1.15iteration/s, mean_rewards=-253]\u001b[A\n",
            "Training:  85%|████████▍ | 1699/2000 [33:37<04:20,  1.15iteration/s, mean_rewards=-219]\u001b[A\n",
            "Training:  85%|████████▌ | 1700/2000 [33:38<05:32,  1.11s/iteration, mean_rewards=-219]\u001b[A\n",
            "Training:  85%|████████▌ | 1700/2000 [33:39<05:32,  1.11s/iteration, mean_rewards=-144]\u001b[A\n",
            "Training:  85%|████████▌ | 1701/2000 [33:40<05:43,  1.15s/iteration, mean_rewards=-144]\u001b[A\n",
            "Training:  85%|████████▌ | 1701/2000 [33:40<05:43,  1.15s/iteration, mean_rewards=-178]\u001b[A\n",
            "Training:  85%|████████▌ | 1702/2000 [33:41<06:08,  1.24s/iteration, mean_rewards=-178]\u001b[A\n",
            "Training:  85%|████████▌ | 1702/2000 [33:41<06:08,  1.24s/iteration, mean_rewards=-118]\u001b[A\n",
            "Training:  85%|████████▌ | 1703/2000 [33:42<05:08,  1.04s/iteration, mean_rewards=-118]\u001b[A\n",
            "Training:  85%|████████▌ | 1703/2000 [33:42<05:08,  1.04s/iteration, mean_rewards=-149]\u001b[A\n",
            "Training:  85%|████████▌ | 1704/2000 [33:42<04:49,  1.02iteration/s, mean_rewards=-149]\u001b[A\n",
            "Training:  85%|████████▌ | 1704/2000 [33:43<04:49,  1.02iteration/s, mean_rewards=-73.2]\u001b[A\n",
            "Training:  85%|████████▌ | 1705/2000 [33:43<04:31,  1.09iteration/s, mean_rewards=-73.2]\u001b[A\n",
            "Training:  85%|████████▌ | 1705/2000 [33:44<04:31,  1.09iteration/s, mean_rewards=-86.8]\u001b[A\n",
            "Training:  85%|████████▌ | 1706/2000 [33:44<04:23,  1.12iteration/s, mean_rewards=-86.8]\u001b[A\n",
            "Training:  85%|████████▌ | 1706/2000 [33:44<04:23,  1.12iteration/s, mean_rewards=-244] \u001b[A\n",
            "Training:  85%|████████▌ | 1707/2000 [33:45<04:17,  1.14iteration/s, mean_rewards=-244]\u001b[A\n",
            "Training:  85%|████████▌ | 1707/2000 [33:45<04:17,  1.14iteration/s, mean_rewards=-226]\u001b[A\n",
            "Training:  85%|████████▌ | 1708/2000 [33:46<03:59,  1.22iteration/s, mean_rewards=-226]\u001b[A\n",
            "Training:  85%|████████▌ | 1708/2000 [33:46<03:59,  1.22iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  85%|████████▌ | 1709/2000 [33:47<04:08,  1.17iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  85%|████████▌ | 1709/2000 [33:47<04:08,  1.17iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  86%|████████▌ | 1710/2000 [33:47<03:43,  1.30iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  86%|████████▌ | 1710/2000 [33:47<03:43,  1.30iteration/s, mean_rewards=-69.8]\u001b[A\n",
            "Training:  86%|████████▌ | 1711/2000 [33:48<03:32,  1.36iteration/s, mean_rewards=-69.8]\u001b[A\n",
            "Training:  86%|████████▌ | 1711/2000 [33:48<03:32,  1.36iteration/s, mean_rewards=-261] \u001b[A\n",
            "Training:  86%|████████▌ | 1712/2000 [33:49<03:55,  1.23iteration/s, mean_rewards=-261]\u001b[A\n",
            "Training:  86%|████████▌ | 1712/2000 [33:49<03:55,  1.23iteration/s, mean_rewards=-64.6]\u001b[A\n",
            "Training:  86%|████████▌ | 1713/2000 [33:50<03:56,  1.22iteration/s, mean_rewards=-64.6]\u001b[A\n",
            "Training:  86%|████████▌ | 1713/2000 [33:50<03:56,  1.22iteration/s, mean_rewards=-138] \u001b[A\n",
            "Training:  86%|████████▌ | 1714/2000 [33:51<04:18,  1.11iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:  86%|████████▌ | 1714/2000 [33:51<04:18,  1.11iteration/s, mean_rewards=-420]\u001b[A\n",
            "Training:  86%|████████▌ | 1715/2000 [33:53<05:42,  1.20s/iteration, mean_rewards=-420]\u001b[A\n",
            "Training:  86%|████████▌ | 1715/2000 [33:53<05:42,  1.20s/iteration, mean_rewards=-147]\u001b[A\n",
            "Training:  86%|████████▌ | 1716/2000 [33:53<05:12,  1.10s/iteration, mean_rewards=-147]\u001b[A\n",
            "Training:  86%|████████▌ | 1716/2000 [33:54<05:12,  1.10s/iteration, mean_rewards=-166]\u001b[A\n",
            "Training:  86%|████████▌ | 1717/2000 [33:54<04:45,  1.01s/iteration, mean_rewards=-166]\u001b[A\n",
            "Training:  86%|████████▌ | 1717/2000 [33:55<04:45,  1.01s/iteration, mean_rewards=-281]\u001b[A\n",
            "Training:  86%|████████▌ | 1718/2000 [33:55<04:41,  1.00iteration/s, mean_rewards=-281]\u001b[A\n",
            "Training:  86%|████████▌ | 1718/2000 [33:55<04:41,  1.00iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:  86%|████████▌ | 1719/2000 [33:56<04:15,  1.10iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:  86%|████████▌ | 1719/2000 [33:56<04:15,  1.10iteration/s, mean_rewards=-217]\u001b[A\n",
            "Training:  86%|████████▌ | 1720/2000 [33:57<04:17,  1.09iteration/s, mean_rewards=-217]\u001b[A\n",
            "Training:  86%|████████▌ | 1720/2000 [33:57<04:17,  1.09iteration/s, mean_rewards=-220]\u001b[A\n",
            "Training:  86%|████████▌ | 1721/2000 [33:58<04:08,  1.12iteration/s, mean_rewards=-220]\u001b[A\n",
            "Training:  86%|████████▌ | 1721/2000 [33:58<04:08,  1.12iteration/s, mean_rewards=-383]\u001b[A\n",
            "Training:  86%|████████▌ | 1722/2000 [33:59<04:35,  1.01iteration/s, mean_rewards=-383]\u001b[A\n",
            "Training:  86%|████████▌ | 1722/2000 [33:59<04:35,  1.01iteration/s, mean_rewards=-109]\u001b[A\n",
            "Training:  86%|████████▌ | 1723/2000 [34:00<04:19,  1.07iteration/s, mean_rewards=-109]\u001b[A\n",
            "Training:  86%|████████▌ | 1723/2000 [34:00<04:19,  1.07iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  86%|████████▌ | 1724/2000 [34:01<04:17,  1.07iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  86%|████████▌ | 1724/2000 [34:01<04:17,  1.07iteration/s, mean_rewards=-97.5]\u001b[A\n",
            "Training:  86%|████████▋ | 1725/2000 [34:02<04:27,  1.03iteration/s, mean_rewards=-97.5]\u001b[A\n",
            "Training:  86%|████████▋ | 1725/2000 [34:02<04:27,  1.03iteration/s, mean_rewards=-187] \u001b[A\n",
            "Training:  86%|████████▋ | 1726/2000 [34:03<04:40,  1.02s/iteration, mean_rewards=-187]\u001b[A\n",
            "Training:  86%|████████▋ | 1726/2000 [34:03<04:40,  1.02s/iteration, mean_rewards=-116]\u001b[A\n",
            "Training:  86%|████████▋ | 1727/2000 [34:04<04:28,  1.02iteration/s, mean_rewards=-116]\u001b[A\n",
            "Training:  86%|████████▋ | 1727/2000 [34:04<04:28,  1.02iteration/s, mean_rewards=-313]\u001b[A\n",
            "Training:  86%|████████▋ | 1728/2000 [34:05<04:56,  1.09s/iteration, mean_rewards=-313]\u001b[A\n",
            "Training:  86%|████████▋ | 1728/2000 [34:05<04:56,  1.09s/iteration, mean_rewards=-96] \u001b[A\n",
            "Training:  86%|████████▋ | 1729/2000 [34:06<04:32,  1.00s/iteration, mean_rewards=-96]\u001b[A\n",
            "Training:  86%|████████▋ | 1729/2000 [34:06<04:32,  1.00s/iteration, mean_rewards=-60.7]\u001b[A\n",
            "Training:  86%|████████▋ | 1730/2000 [34:07<04:19,  1.04iteration/s, mean_rewards=-60.7]\u001b[A\n",
            "Training:  86%|████████▋ | 1730/2000 [34:07<04:19,  1.04iteration/s, mean_rewards=-192] \u001b[A\n",
            "Training:  87%|████████▋ | 1731/2000 [34:08<04:07,  1.08iteration/s, mean_rewards=-192]\u001b[A\n",
            "Training:  87%|████████▋ | 1731/2000 [34:08<04:07,  1.08iteration/s, mean_rewards=-95.4]\u001b[A\n",
            "Training:  87%|████████▋ | 1732/2000 [34:09<04:18,  1.04iteration/s, mean_rewards=-95.4]\u001b[A\n",
            "Training:  87%|████████▋ | 1732/2000 [34:09<04:18,  1.04iteration/s, mean_rewards=-331] \u001b[A\n",
            "Training:  87%|████████▋ | 1733/2000 [34:09<04:08,  1.08iteration/s, mean_rewards=-331]\u001b[A\n",
            "Training:  87%|████████▋ | 1733/2000 [34:10<04:08,  1.08iteration/s, mean_rewards=-176]\u001b[A\n",
            "Training:  87%|████████▋ | 1734/2000 [34:10<03:59,  1.11iteration/s, mean_rewards=-176]\u001b[A\n",
            "Training:  87%|████████▋ | 1734/2000 [34:11<03:59,  1.11iteration/s, mean_rewards=-26.3]\u001b[A\n",
            "Training:  87%|████████▋ | 1735/2000 [34:11<03:50,  1.15iteration/s, mean_rewards=-26.3]\u001b[A\n",
            "Training:  87%|████████▋ | 1735/2000 [34:12<03:50,  1.15iteration/s, mean_rewards=-301] \u001b[A\n",
            "Training:  87%|████████▋ | 1736/2000 [34:12<04:07,  1.07iteration/s, mean_rewards=-301]\u001b[A\n",
            "Training:  87%|████████▋ | 1736/2000 [34:13<04:07,  1.07iteration/s, mean_rewards=-220]\u001b[A\n",
            "Training:  87%|████████▋ | 1737/2000 [34:13<03:56,  1.11iteration/s, mean_rewards=-220]\u001b[A\n",
            "Training:  87%|████████▋ | 1737/2000 [34:13<03:56,  1.11iteration/s, mean_rewards=-164]\u001b[A\n",
            "Training:  87%|████████▋ | 1738/2000 [34:14<04:00,  1.09iteration/s, mean_rewards=-164]\u001b[A\n",
            "Training:  87%|████████▋ | 1738/2000 [34:14<04:00,  1.09iteration/s, mean_rewards=-93.3]\u001b[A\n",
            "Training:  87%|████████▋ | 1739/2000 [34:15<03:42,  1.18iteration/s, mean_rewards=-93.3]\u001b[A\n",
            "Training:  87%|████████▋ | 1739/2000 [34:15<03:42,  1.18iteration/s, mean_rewards=-315] \u001b[A\n",
            "Training:  87%|████████▋ | 1740/2000 [34:16<04:08,  1.05iteration/s, mean_rewards=-315]\u001b[A\n",
            "Training:  87%|████████▋ | 1740/2000 [34:16<04:08,  1.05iteration/s, mean_rewards=-184]\u001b[A\n",
            "Training:  87%|████████▋ | 1741/2000 [34:17<04:40,  1.08s/iteration, mean_rewards=-184]\u001b[A\n",
            "Training:  87%|████████▋ | 1741/2000 [34:18<04:40,  1.08s/iteration, mean_rewards=-125]\u001b[A\n",
            "Training:  87%|████████▋ | 1742/2000 [34:19<04:54,  1.14s/iteration, mean_rewards=-125]\u001b[A\n",
            "Training:  87%|████████▋ | 1742/2000 [34:19<04:54,  1.14s/iteration, mean_rewards=-241]\u001b[A\n",
            "Training:  87%|████████▋ | 1743/2000 [34:19<04:36,  1.08s/iteration, mean_rewards=-241]\u001b[A\n",
            "Training:  87%|████████▋ | 1743/2000 [34:20<04:36,  1.08s/iteration, mean_rewards=-80.5]\u001b[A\n",
            "Training:  87%|████████▋ | 1744/2000 [34:20<04:26,  1.04s/iteration, mean_rewards=-80.5]\u001b[A\n",
            "Training:  87%|████████▋ | 1744/2000 [34:21<04:26,  1.04s/iteration, mean_rewards=-199] \u001b[A\n",
            "Training:  87%|████████▋ | 1745/2000 [34:21<04:26,  1.05s/iteration, mean_rewards=-199]\u001b[A\n",
            "Training:  87%|████████▋ | 1745/2000 [34:22<04:26,  1.05s/iteration, mean_rewards=-260]\u001b[A\n",
            "Training:  87%|████████▋ | 1746/2000 [34:22<04:10,  1.02iteration/s, mean_rewards=-260]\u001b[A\n",
            "Training:  87%|████████▋ | 1746/2000 [34:23<04:10,  1.02iteration/s, mean_rewards=-183]\u001b[A\n",
            "Training:  87%|████████▋ | 1747/2000 [34:23<04:06,  1.03iteration/s, mean_rewards=-183]\u001b[A\n",
            "Training:  87%|████████▋ | 1747/2000 [34:24<04:06,  1.03iteration/s, mean_rewards=-170]\u001b[A\n",
            "Training:  87%|████████▋ | 1748/2000 [34:24<04:01,  1.04iteration/s, mean_rewards=-170]\u001b[A\n",
            "Training:  87%|████████▋ | 1748/2000 [34:25<04:01,  1.04iteration/s, mean_rewards=-267]\u001b[A\n",
            "Training:  87%|████████▋ | 1749/2000 [34:25<03:49,  1.09iteration/s, mean_rewards=-267]\u001b[A\n",
            "Training:  87%|████████▋ | 1749/2000 [34:25<03:49,  1.09iteration/s, mean_rewards=-177]\u001b[A\n",
            "Training:  88%|████████▊ | 1750/2000 [34:26<03:53,  1.07iteration/s, mean_rewards=-177]\u001b[A\n",
            "Training:  88%|████████▊ | 1750/2000 [34:26<03:53,  1.07iteration/s, mean_rewards=-174]\u001b[A\n",
            "Training:  88%|████████▊ | 1751/2000 [34:27<03:52,  1.07iteration/s, mean_rewards=-174]\u001b[A\n",
            "Training:  88%|████████▊ | 1751/2000 [34:27<03:52,  1.07iteration/s, mean_rewards=-189]\u001b[A\n",
            "Training:  88%|████████▊ | 1752/2000 [34:28<03:41,  1.12iteration/s, mean_rewards=-189]\u001b[A\n",
            "Training:  88%|████████▊ | 1752/2000 [34:28<03:41,  1.12iteration/s, mean_rewards=-187]\u001b[A\n",
            "Training:  88%|████████▊ | 1753/2000 [34:28<03:26,  1.20iteration/s, mean_rewards=-187]\u001b[A\n",
            "Training:  88%|████████▊ | 1753/2000 [34:29<03:26,  1.20iteration/s, mean_rewards=-278]\u001b[A\n",
            "Training:  88%|████████▊ | 1754/2000 [34:29<03:34,  1.15iteration/s, mean_rewards=-278]\u001b[A\n",
            "Training:  88%|████████▊ | 1754/2000 [34:30<03:34,  1.15iteration/s, mean_rewards=-212]\u001b[A\n",
            "Training:  88%|████████▊ | 1755/2000 [34:31<04:07,  1.01s/iteration, mean_rewards=-212]\u001b[A\n",
            "Training:  88%|████████▊ | 1755/2000 [34:31<04:07,  1.01s/iteration, mean_rewards=-122]\u001b[A\n",
            "Training:  88%|████████▊ | 1756/2000 [34:32<04:23,  1.08s/iteration, mean_rewards=-122]\u001b[A\n",
            "Training:  88%|████████▊ | 1756/2000 [34:32<04:23,  1.08s/iteration, mean_rewards=-132]\u001b[A\n",
            "Training:  88%|████████▊ | 1757/2000 [34:33<04:04,  1.01s/iteration, mean_rewards=-132]\u001b[A\n",
            "Training:  88%|████████▊ | 1757/2000 [34:33<04:04,  1.01s/iteration, mean_rewards=-134]\u001b[A\n",
            "Training:  88%|████████▊ | 1758/2000 [34:34<04:00,  1.01iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  88%|████████▊ | 1758/2000 [34:34<04:00,  1.01iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  88%|████████▊ | 1759/2000 [34:35<03:50,  1.05iteration/s, mean_rewards=-156]\u001b[A\n",
            "Training:  88%|████████▊ | 1759/2000 [34:35<03:50,  1.05iteration/s, mean_rewards=-361]\u001b[A\n",
            "Training:  88%|████████▊ | 1760/2000 [34:35<03:40,  1.09iteration/s, mean_rewards=-361]\u001b[A\n",
            "Training:  88%|████████▊ | 1760/2000 [34:36<03:40,  1.09iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  88%|████████▊ | 1761/2000 [34:36<03:22,  1.18iteration/s, mean_rewards=-136]\u001b[A\n",
            "Training:  88%|████████▊ | 1761/2000 [34:37<03:22,  1.18iteration/s, mean_rewards=-316]\u001b[A\n",
            "Training:  88%|████████▊ | 1762/2000 [34:37<03:31,  1.12iteration/s, mean_rewards=-316]\u001b[A\n",
            "Training:  88%|████████▊ | 1762/2000 [34:38<03:31,  1.12iteration/s, mean_rewards=-273]\u001b[A\n",
            "Training:  88%|████████▊ | 1763/2000 [34:38<03:39,  1.08iteration/s, mean_rewards=-273]\u001b[A\n",
            "Training:  88%|████████▊ | 1763/2000 [34:39<03:39,  1.08iteration/s, mean_rewards=-183]\u001b[A\n",
            "Training:  88%|████████▊ | 1764/2000 [34:39<03:39,  1.07iteration/s, mean_rewards=-183]\u001b[A\n",
            "Training:  88%|████████▊ | 1764/2000 [34:39<03:39,  1.07iteration/s, mean_rewards=-187]\u001b[A\n",
            "Training:  88%|████████▊ | 1765/2000 [34:40<03:33,  1.10iteration/s, mean_rewards=-187]\u001b[A\n",
            "Training:  88%|████████▊ | 1765/2000 [34:40<03:33,  1.10iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  88%|████████▊ | 1766/2000 [34:41<03:33,  1.09iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  88%|████████▊ | 1766/2000 [34:41<03:33,  1.09iteration/s, mean_rewards=-233]\u001b[A\n",
            "Training:  88%|████████▊ | 1767/2000 [34:42<03:31,  1.10iteration/s, mean_rewards=-233]\u001b[A\n",
            "Training:  88%|████████▊ | 1767/2000 [34:42<03:31,  1.10iteration/s, mean_rewards=-164]\u001b[A\n",
            "Training:  88%|████████▊ | 1768/2000 [34:43<03:39,  1.06iteration/s, mean_rewards=-164]\u001b[A\n",
            "Training:  88%|████████▊ | 1768/2000 [34:43<03:39,  1.06iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  88%|████████▊ | 1769/2000 [34:44<03:55,  1.02s/iteration, mean_rewards=-134]\u001b[A\n",
            "Training:  88%|████████▊ | 1769/2000 [34:44<03:55,  1.02s/iteration, mean_rewards=-101]\u001b[A\n",
            "Training:  88%|████████▊ | 1770/2000 [34:45<03:34,  1.07iteration/s, mean_rewards=-101]\u001b[A\n",
            "Training:  88%|████████▊ | 1770/2000 [34:45<03:34,  1.07iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  89%|████████▊ | 1771/2000 [34:45<03:24,  1.12iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  89%|████████▊ | 1771/2000 [34:46<03:24,  1.12iteration/s, mean_rewards=-277]\u001b[A\n",
            "Training:  89%|████████▊ | 1772/2000 [34:46<03:10,  1.20iteration/s, mean_rewards=-277]\u001b[A\n",
            "Training:  89%|████████▊ | 1772/2000 [34:46<03:10,  1.20iteration/s, mean_rewards=-157]\u001b[A\n",
            "Training:  89%|████████▊ | 1773/2000 [34:47<02:59,  1.27iteration/s, mean_rewards=-157]\u001b[A\n",
            "Training:  89%|████████▊ | 1773/2000 [34:47<02:59,  1.27iteration/s, mean_rewards=-328]\u001b[A\n",
            "Training:  89%|████████▊ | 1774/2000 [34:48<03:07,  1.21iteration/s, mean_rewards=-328]\u001b[A\n",
            "Training:  89%|████████▊ | 1774/2000 [34:48<03:07,  1.21iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  89%|████████▉ | 1775/2000 [34:49<03:03,  1.23iteration/s, mean_rewards=-135]\u001b[A\n",
            "Training:  89%|████████▉ | 1775/2000 [34:49<03:03,  1.23iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:  89%|████████▉ | 1776/2000 [34:49<03:01,  1.23iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:  89%|████████▉ | 1776/2000 [34:50<03:01,  1.23iteration/s, mean_rewards=7.86]\u001b[A\n",
            "Training:  89%|████████▉ | 1777/2000 [34:50<03:09,  1.18iteration/s, mean_rewards=7.86]\u001b[A\n",
            "Training:  89%|████████▉ | 1777/2000 [34:51<03:09,  1.18iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  89%|████████▉ | 1778/2000 [34:51<02:58,  1.25iteration/s, mean_rewards=-155]\u001b[A\n",
            "Training:  89%|████████▉ | 1778/2000 [34:51<02:58,  1.25iteration/s, mean_rewards=-152]\u001b[A\n",
            "Training:  89%|████████▉ | 1779/2000 [34:52<03:08,  1.17iteration/s, mean_rewards=-152]\u001b[A\n",
            "Training:  89%|████████▉ | 1779/2000 [34:52<03:08,  1.17iteration/s, mean_rewards=-25.5]\u001b[A\n",
            "Training:  89%|████████▉ | 1780/2000 [34:53<03:13,  1.13iteration/s, mean_rewards=-25.5]\u001b[A\n",
            "Training:  89%|████████▉ | 1780/2000 [34:53<03:13,  1.13iteration/s, mean_rewards=-251] \u001b[A\n",
            "Training:  89%|████████▉ | 1781/2000 [34:54<03:15,  1.12iteration/s, mean_rewards=-251]\u001b[A\n",
            "Training:  89%|████████▉ | 1781/2000 [34:54<03:15,  1.12iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:  89%|████████▉ | 1782/2000 [34:55<03:46,  1.04s/iteration, mean_rewards=-139]\u001b[A\n",
            "Training:  89%|████████▉ | 1782/2000 [34:56<03:46,  1.04s/iteration, mean_rewards=-22.6]\u001b[A\n",
            "Training:  89%|████████▉ | 1783/2000 [34:56<03:53,  1.08s/iteration, mean_rewards=-22.6]\u001b[A\n",
            "Training:  89%|████████▉ | 1783/2000 [34:57<03:53,  1.08s/iteration, mean_rewards=-125] \u001b[A\n",
            "Training:  89%|████████▉ | 1784/2000 [34:57<03:33,  1.01iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  89%|████████▉ | 1784/2000 [34:58<03:33,  1.01iteration/s, mean_rewards=-292]\u001b[A\n",
            "Training:  89%|████████▉ | 1785/2000 [34:58<03:28,  1.03iteration/s, mean_rewards=-292]\u001b[A\n",
            "Training:  89%|████████▉ | 1785/2000 [34:58<03:28,  1.03iteration/s, mean_rewards=-248]\u001b[A\n",
            "Training:  89%|████████▉ | 1786/2000 [34:59<03:15,  1.09iteration/s, mean_rewards=-248]\u001b[A\n",
            "Training:  89%|████████▉ | 1786/2000 [34:59<03:15,  1.09iteration/s, mean_rewards=-333]\u001b[A\n",
            "Training:  89%|████████▉ | 1787/2000 [35:00<03:22,  1.05iteration/s, mean_rewards=-333]\u001b[A\n",
            "Training:  89%|████████▉ | 1787/2000 [35:00<03:22,  1.05iteration/s, mean_rewards=-198]\u001b[A\n",
            "Training:  89%|████████▉ | 1788/2000 [35:01<03:27,  1.02iteration/s, mean_rewards=-198]\u001b[A\n",
            "Training:  89%|████████▉ | 1788/2000 [35:01<03:27,  1.02iteration/s, mean_rewards=-49] \u001b[A\n",
            "Training:  89%|████████▉ | 1789/2000 [35:02<03:30,  1.00iteration/s, mean_rewards=-49]\u001b[A\n",
            "Training:  89%|████████▉ | 1789/2000 [35:02<03:30,  1.00iteration/s, mean_rewards=-216]\u001b[A\n",
            "Training:  90%|████████▉ | 1790/2000 [35:03<03:18,  1.06iteration/s, mean_rewards=-216]\u001b[A\n",
            "Training:  90%|████████▉ | 1790/2000 [35:03<03:18,  1.06iteration/s, mean_rewards=-212]\u001b[A\n",
            "Training:  90%|████████▉ | 1791/2000 [35:04<03:18,  1.05iteration/s, mean_rewards=-212]\u001b[A\n",
            "Training:  90%|████████▉ | 1791/2000 [35:04<03:18,  1.05iteration/s, mean_rewards=-234]\u001b[A\n",
            "Training:  90%|████████▉ | 1792/2000 [35:05<03:10,  1.09iteration/s, mean_rewards=-234]\u001b[A\n",
            "Training:  90%|████████▉ | 1792/2000 [35:05<03:10,  1.09iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  90%|████████▉ | 1793/2000 [35:06<03:11,  1.08iteration/s, mean_rewards=-120]\u001b[A\n",
            "Training:  90%|████████▉ | 1793/2000 [35:06<03:11,  1.08iteration/s, mean_rewards=-326]\u001b[A\n",
            "Training:  90%|████████▉ | 1794/2000 [35:07<03:13,  1.07iteration/s, mean_rewards=-326]\u001b[A\n",
            "Training:  90%|████████▉ | 1794/2000 [35:07<03:13,  1.07iteration/s, mean_rewards=-416]\u001b[A\n",
            "Training:  90%|████████▉ | 1795/2000 [35:08<03:33,  1.04s/iteration, mean_rewards=-416]\u001b[A\n",
            "Training:  90%|████████▉ | 1795/2000 [35:08<03:33,  1.04s/iteration, mean_rewards=-185]\u001b[A\n",
            "Training:  90%|████████▉ | 1796/2000 [35:09<03:44,  1.10s/iteration, mean_rewards=-185]\u001b[A\n",
            "Training:  90%|████████▉ | 1796/2000 [35:10<03:44,  1.10s/iteration, mean_rewards=-219]\u001b[A\n",
            "Training:  90%|████████▉ | 1797/2000 [35:10<03:49,  1.13s/iteration, mean_rewards=-219]\u001b[A\n",
            "Training:  90%|████████▉ | 1797/2000 [35:11<03:49,  1.13s/iteration, mean_rewards=-120]\u001b[A\n",
            "Training:  90%|████████▉ | 1798/2000 [35:11<03:27,  1.03s/iteration, mean_rewards=-120]\u001b[A\n",
            "Training:  90%|████████▉ | 1798/2000 [35:11<03:27,  1.03s/iteration, mean_rewards=-175]\u001b[A\n",
            "Training:  90%|████████▉ | 1799/2000 [35:12<03:20,  1.00iteration/s, mean_rewards=-175]\u001b[A\n",
            "Training:  90%|████████▉ | 1799/2000 [35:12<03:20,  1.00iteration/s, mean_rewards=-207]\u001b[A\n",
            "Training:  90%|█████████ | 1800/2000 [35:13<03:13,  1.03iteration/s, mean_rewards=-207]\u001b[A\n",
            "Training:  90%|█████████ | 1800/2000 [35:13<03:13,  1.03iteration/s, mean_rewards=-260]\u001b[A\n",
            "Training:  90%|█████████ | 1801/2000 [35:14<03:00,  1.10iteration/s, mean_rewards=-260]\u001b[A\n",
            "Training:  90%|█████████ | 1801/2000 [35:14<03:00,  1.10iteration/s, mean_rewards=-173]\u001b[A\n",
            "Training:  90%|█████████ | 1802/2000 [35:15<03:00,  1.10iteration/s, mean_rewards=-173]\u001b[A\n",
            "Training:  90%|█████████ | 1802/2000 [35:15<03:00,  1.10iteration/s, mean_rewards=-316]\u001b[A\n",
            "Training:  90%|█████████ | 1803/2000 [35:16<03:02,  1.08iteration/s, mean_rewards=-316]\u001b[A\n",
            "Training:  90%|█████████ | 1803/2000 [35:16<03:02,  1.08iteration/s, mean_rewards=-307]\u001b[A\n",
            "Training:  90%|█████████ | 1804/2000 [35:16<03:03,  1.07iteration/s, mean_rewards=-307]\u001b[A\n",
            "Training:  90%|█████████ | 1804/2000 [35:17<03:03,  1.07iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  90%|█████████ | 1805/2000 [35:17<02:54,  1.12iteration/s, mean_rewards=-154]\u001b[A\n",
            "Training:  90%|█████████ | 1805/2000 [35:18<02:54,  1.12iteration/s, mean_rewards=-359]\u001b[A\n",
            "Training:  90%|█████████ | 1806/2000 [35:18<02:59,  1.08iteration/s, mean_rewards=-359]\u001b[A\n",
            "Training:  90%|█████████ | 1806/2000 [35:19<02:59,  1.08iteration/s, mean_rewards=-102]\u001b[A\n",
            "Training:  90%|█████████ | 1807/2000 [35:19<02:51,  1.12iteration/s, mean_rewards=-102]\u001b[A\n",
            "Training:  90%|█████████ | 1807/2000 [35:20<02:51,  1.12iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  90%|█████████ | 1808/2000 [35:20<03:02,  1.05iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  90%|█████████ | 1808/2000 [35:21<03:02,  1.05iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:  90%|█████████ | 1809/2000 [35:22<03:25,  1.07s/iteration, mean_rewards=-138]\u001b[A\n",
            "Training:  90%|█████████ | 1809/2000 [35:22<03:25,  1.07s/iteration, mean_rewards=-248]\u001b[A\n",
            "Training:  90%|█████████ | 1810/2000 [35:23<03:21,  1.06s/iteration, mean_rewards=-248]\u001b[A\n",
            "Training:  90%|█████████ | 1810/2000 [35:23<03:21,  1.06s/iteration, mean_rewards=-228]\u001b[A\n",
            "Training:  91%|█████████ | 1811/2000 [35:23<03:04,  1.02iteration/s, mean_rewards=-228]\u001b[A\n",
            "Training:  91%|█████████ | 1811/2000 [35:24<03:04,  1.02iteration/s, mean_rewards=-369]\u001b[A\n",
            "Training:  91%|█████████ | 1812/2000 [35:24<03:00,  1.04iteration/s, mean_rewards=-369]\u001b[A\n",
            "Training:  91%|█████████ | 1812/2000 [35:25<03:00,  1.04iteration/s, mean_rewards=-157]\u001b[A\n",
            "Training:  91%|█████████ | 1813/2000 [35:25<02:52,  1.08iteration/s, mean_rewards=-157]\u001b[A\n",
            "Training:  91%|█████████ | 1813/2000 [35:25<02:52,  1.08iteration/s, mean_rewards=-94.5]\u001b[A\n",
            "Training:  91%|█████████ | 1814/2000 [35:26<02:38,  1.17iteration/s, mean_rewards=-94.5]\u001b[A\n",
            "Training:  91%|█████████ | 1814/2000 [35:26<02:38,  1.17iteration/s, mean_rewards=-324] \u001b[A\n",
            "Training:  91%|█████████ | 1815/2000 [35:27<02:42,  1.14iteration/s, mean_rewards=-324]\u001b[A\n",
            "Training:  91%|█████████ | 1815/2000 [35:27<02:42,  1.14iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  91%|█████████ | 1816/2000 [35:28<03:02,  1.01iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  91%|█████████ | 1816/2000 [35:28<03:02,  1.01iteration/s, mean_rewards=-228]\u001b[A\n",
            "Training:  91%|█████████ | 1817/2000 [35:29<02:57,  1.03iteration/s, mean_rewards=-228]\u001b[A\n",
            "Training:  91%|█████████ | 1817/2000 [35:29<02:57,  1.03iteration/s, mean_rewards=-208]\u001b[A\n",
            "Training:  91%|█████████ | 1818/2000 [35:30<03:09,  1.04s/iteration, mean_rewards=-208]\u001b[A\n",
            "Training:  91%|█████████ | 1818/2000 [35:31<03:09,  1.04s/iteration, mean_rewards=-238]\u001b[A\n",
            "Training:  91%|█████████ | 1819/2000 [35:31<03:04,  1.02s/iteration, mean_rewards=-238]\u001b[A\n",
            "Training:  91%|█████████ | 1819/2000 [35:32<03:04,  1.02s/iteration, mean_rewards=-251]\u001b[A\n",
            "Training:  91%|█████████ | 1820/2000 [35:32<03:16,  1.09s/iteration, mean_rewards=-251]\u001b[A\n",
            "Training:  91%|█████████ | 1820/2000 [35:33<03:16,  1.09s/iteration, mean_rewards=-200]\u001b[A\n",
            "Training:  91%|█████████ | 1821/2000 [35:34<03:28,  1.16s/iteration, mean_rewards=-200]\u001b[A\n",
            "Training:  91%|█████████ | 1821/2000 [35:34<03:28,  1.16s/iteration, mean_rewards=-138]\u001b[A\n",
            "Training:  91%|█████████ | 1822/2000 [35:35<03:19,  1.12s/iteration, mean_rewards=-138]\u001b[A\n",
            "Training:  91%|█████████ | 1822/2000 [35:35<03:19,  1.12s/iteration, mean_rewards=-128]\u001b[A\n",
            "Training:  91%|█████████ | 1823/2000 [35:36<03:23,  1.15s/iteration, mean_rewards=-128]\u001b[A\n",
            "Training:  91%|█████████ | 1823/2000 [35:36<03:23,  1.15s/iteration, mean_rewards=-177]\u001b[A\n",
            "Training:  91%|█████████ | 1824/2000 [35:37<03:24,  1.16s/iteration, mean_rewards=-177]\u001b[A\n",
            "Training:  91%|█████████ | 1824/2000 [35:37<03:24,  1.16s/iteration, mean_rewards=-310]\u001b[A\n",
            "Training:  91%|█████████▏| 1825/2000 [35:38<03:06,  1.06s/iteration, mean_rewards=-310]\u001b[A\n",
            "Training:  91%|█████████▏| 1825/2000 [35:38<03:06,  1.06s/iteration, mean_rewards=-110]\u001b[A\n",
            "Training:  91%|█████████▏| 1826/2000 [35:39<02:59,  1.03s/iteration, mean_rewards=-110]\u001b[A\n",
            "Training:  91%|█████████▏| 1826/2000 [35:39<02:59,  1.03s/iteration, mean_rewards=-97.5]\u001b[A\n",
            "Training:  91%|█████████▏| 1827/2000 [35:40<02:57,  1.03s/iteration, mean_rewards=-97.5]\u001b[A\n",
            "Training:  91%|█████████▏| 1827/2000 [35:40<02:57,  1.03s/iteration, mean_rewards=-204] \u001b[A\n",
            "Training:  91%|█████████▏| 1828/2000 [35:41<02:52,  1.00s/iteration, mean_rewards=-204]\u001b[A\n",
            "Training:  91%|█████████▏| 1828/2000 [35:41<02:52,  1.00s/iteration, mean_rewards=-295]\u001b[A\n",
            "Training:  91%|█████████▏| 1829/2000 [35:42<02:40,  1.06iteration/s, mean_rewards=-295]\u001b[A\n",
            "Training:  91%|█████████▏| 1829/2000 [35:42<02:40,  1.06iteration/s, mean_rewards=-357]\u001b[A\n",
            "Training:  92%|█████████▏| 1830/2000 [35:43<02:47,  1.01iteration/s, mean_rewards=-357]\u001b[A\n",
            "Training:  92%|█████████▏| 1830/2000 [35:43<02:47,  1.01iteration/s, mean_rewards=-213]\u001b[A\n",
            "Training:  92%|█████████▏| 1831/2000 [35:44<02:36,  1.08iteration/s, mean_rewards=-213]\u001b[A\n",
            "Training:  92%|█████████▏| 1831/2000 [35:44<02:36,  1.08iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:  92%|█████████▏| 1832/2000 [35:45<02:40,  1.05iteration/s, mean_rewards=-138]\u001b[A\n",
            "Training:  92%|█████████▏| 1832/2000 [35:45<02:40,  1.05iteration/s, mean_rewards=-241]\u001b[A\n",
            "Training:  92%|█████████▏| 1833/2000 [35:46<03:03,  1.10s/iteration, mean_rewards=-241]\u001b[A\n",
            "Training:  92%|█████████▏| 1833/2000 [35:47<03:03,  1.10s/iteration, mean_rewards=-232]\u001b[A\n",
            "Training:  92%|█████████▏| 1834/2000 [35:47<03:19,  1.20s/iteration, mean_rewards=-232]\u001b[A\n",
            "Training:  92%|█████████▏| 1834/2000 [35:48<03:19,  1.20s/iteration, mean_rewards=-94.5]\u001b[A\n",
            "Training:  92%|█████████▏| 1835/2000 [35:49<03:31,  1.28s/iteration, mean_rewards=-94.5]\u001b[A\n",
            "Training:  92%|█████████▏| 1835/2000 [35:49<03:31,  1.28s/iteration, mean_rewards=-87.1]\u001b[A\n",
            "Training:  92%|█████████▏| 1836/2000 [35:50<03:07,  1.14s/iteration, mean_rewards=-87.1]\u001b[A\n",
            "Training:  92%|█████████▏| 1836/2000 [35:50<03:07,  1.14s/iteration, mean_rewards=-289] \u001b[A\n",
            "Training:  92%|█████████▏| 1837/2000 [35:50<02:43,  1.00s/iteration, mean_rewards=-289]\u001b[A\n",
            "Training:  92%|█████████▏| 1837/2000 [35:51<02:43,  1.00s/iteration, mean_rewards=-226]\u001b[A\n",
            "Training:  92%|█████████▏| 1838/2000 [35:52<02:47,  1.03s/iteration, mean_rewards=-226]\u001b[A\n",
            "Training:  92%|█████████▏| 1838/2000 [35:52<02:47,  1.03s/iteration, mean_rewards=-273]\u001b[A\n",
            "Training:  92%|█████████▏| 1839/2000 [35:52<02:31,  1.06iteration/s, mean_rewards=-273]\u001b[A\n",
            "Training:  92%|█████████▏| 1839/2000 [35:53<02:31,  1.06iteration/s, mean_rewards=-355]\u001b[A\n",
            "Training:  92%|█████████▏| 1840/2000 [35:53<02:33,  1.04iteration/s, mean_rewards=-355]\u001b[A\n",
            "Training:  92%|█████████▏| 1840/2000 [35:54<02:33,  1.04iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  92%|█████████▏| 1841/2000 [35:54<02:24,  1.10iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  92%|█████████▏| 1841/2000 [35:54<02:24,  1.10iteration/s, mean_rewards=-281]\u001b[A\n",
            "Training:  92%|█████████▏| 1842/2000 [35:55<02:24,  1.09iteration/s, mean_rewards=-281]\u001b[A\n",
            "Training:  92%|█████████▏| 1842/2000 [35:55<02:24,  1.09iteration/s, mean_rewards=-187]\u001b[A\n",
            "Training:  92%|█████████▏| 1843/2000 [35:56<02:29,  1.05iteration/s, mean_rewards=-187]\u001b[A\n",
            "Training:  92%|█████████▏| 1843/2000 [35:56<02:29,  1.05iteration/s, mean_rewards=-64.9]\u001b[A\n",
            "Training:  92%|█████████▏| 1844/2000 [35:57<02:21,  1.10iteration/s, mean_rewards=-64.9]\u001b[A\n",
            "Training:  92%|█████████▏| 1844/2000 [35:57<02:21,  1.10iteration/s, mean_rewards=-240] \u001b[A\n",
            "Training:  92%|█████████▏| 1845/2000 [35:58<02:22,  1.09iteration/s, mean_rewards=-240]\u001b[A\n",
            "Training:  92%|█████████▏| 1845/2000 [35:58<02:22,  1.09iteration/s, mean_rewards=-191]\u001b[A\n",
            "Training:  92%|█████████▏| 1846/2000 [35:59<02:37,  1.02s/iteration, mean_rewards=-191]\u001b[A\n",
            "Training:  92%|█████████▏| 1846/2000 [36:00<02:37,  1.02s/iteration, mean_rewards=-249]\u001b[A\n",
            "Training:  92%|█████████▏| 1847/2000 [36:00<02:53,  1.13s/iteration, mean_rewards=-249]\u001b[A\n",
            "Training:  92%|█████████▏| 1847/2000 [36:01<02:53,  1.13s/iteration, mean_rewards=-155]\u001b[A\n",
            "Training:  92%|█████████▏| 1848/2000 [36:01<02:37,  1.04s/iteration, mean_rewards=-155]\u001b[A\n",
            "Training:  92%|█████████▏| 1848/2000 [36:02<02:37,  1.04s/iteration, mean_rewards=-126]\u001b[A\n",
            "Training:  92%|█████████▏| 1849/2000 [36:02<02:26,  1.03iteration/s, mean_rewards=-126]\u001b[A\n",
            "Training:  92%|█████████▏| 1849/2000 [36:02<02:26,  1.03iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  92%|█████████▎| 1850/2000 [36:03<02:24,  1.03iteration/s, mean_rewards=-127]\u001b[A\n",
            "Training:  92%|█████████▎| 1850/2000 [36:03<02:24,  1.03iteration/s, mean_rewards=-260]\u001b[A\n",
            "Training:  93%|█████████▎| 1851/2000 [36:04<02:22,  1.04iteration/s, mean_rewards=-260]\u001b[A\n",
            "Training:  93%|█████████▎| 1851/2000 [36:04<02:22,  1.04iteration/s, mean_rewards=-294]\u001b[A\n",
            "Training:  93%|█████████▎| 1852/2000 [36:05<02:22,  1.04iteration/s, mean_rewards=-294]\u001b[A\n",
            "Training:  93%|█████████▎| 1852/2000 [36:05<02:22,  1.04iteration/s, mean_rewards=-188]\u001b[A\n",
            "Training:  93%|█████████▎| 1853/2000 [36:06<02:20,  1.04iteration/s, mean_rewards=-188]\u001b[A\n",
            "Training:  93%|█████████▎| 1853/2000 [36:06<02:20,  1.04iteration/s, mean_rewards=-229]\u001b[A\n",
            "Training:  93%|█████████▎| 1854/2000 [36:07<02:12,  1.10iteration/s, mean_rewards=-229]\u001b[A\n",
            "Training:  93%|█████████▎| 1854/2000 [36:07<02:12,  1.10iteration/s, mean_rewards=-181]\u001b[A\n",
            "Training:  93%|█████████▎| 1855/2000 [36:07<02:08,  1.13iteration/s, mean_rewards=-181]\u001b[A\n",
            "Training:  93%|█████████▎| 1855/2000 [36:08<02:08,  1.13iteration/s, mean_rewards=-284]\u001b[A\n",
            "Training:  93%|█████████▎| 1856/2000 [36:08<02:12,  1.09iteration/s, mean_rewards=-284]\u001b[A\n",
            "Training:  93%|█████████▎| 1856/2000 [36:09<02:12,  1.09iteration/s, mean_rewards=-253]\u001b[A\n",
            "Training:  93%|█████████▎| 1857/2000 [36:09<02:02,  1.17iteration/s, mean_rewards=-253]\u001b[A\n",
            "Training:  93%|█████████▎| 1857/2000 [36:10<02:02,  1.17iteration/s, mean_rewards=-209]\u001b[A\n",
            "Training:  93%|█████████▎| 1858/2000 [36:11<02:23,  1.01s/iteration, mean_rewards=-209]\u001b[A\n",
            "Training:  93%|█████████▎| 1858/2000 [36:11<02:23,  1.01s/iteration, mean_rewards=-230]\u001b[A\n",
            "Training:  93%|█████████▎| 1859/2000 [36:12<02:27,  1.04s/iteration, mean_rewards=-230]\u001b[A\n",
            "Training:  93%|█████████▎| 1859/2000 [36:12<02:27,  1.04s/iteration, mean_rewards=-162]\u001b[A\n",
            "Training:  93%|█████████▎| 1860/2000 [36:13<02:36,  1.12s/iteration, mean_rewards=-162]\u001b[A\n",
            "Training:  93%|█████████▎| 1860/2000 [36:13<02:36,  1.12s/iteration, mean_rewards=-239]\u001b[A\n",
            "Training:  93%|█████████▎| 1861/2000 [36:14<02:22,  1.03s/iteration, mean_rewards=-239]\u001b[A\n",
            "Training:  93%|█████████▎| 1861/2000 [36:14<02:22,  1.03s/iteration, mean_rewards=-74] \u001b[A\n",
            "Training:  93%|█████████▎| 1862/2000 [36:14<02:06,  1.09iteration/s, mean_rewards=-74]\u001b[A\n",
            "Training:  93%|█████████▎| 1862/2000 [36:15<02:06,  1.09iteration/s, mean_rewards=-82.1]\u001b[A\n",
            "Training:  93%|█████████▎| 1863/2000 [36:15<01:57,  1.17iteration/s, mean_rewards=-82.1]\u001b[A\n",
            "Training:  93%|█████████▎| 1863/2000 [36:16<01:57,  1.17iteration/s, mean_rewards=-150] \u001b[A\n",
            "Training:  93%|█████████▎| 1864/2000 [36:16<02:06,  1.08iteration/s, mean_rewards=-150]\u001b[A\n",
            "Training:  93%|█████████▎| 1864/2000 [36:17<02:06,  1.08iteration/s, mean_rewards=-180]\u001b[A\n",
            "Training:  93%|█████████▎| 1865/2000 [36:17<02:06,  1.07iteration/s, mean_rewards=-180]\u001b[A\n",
            "Training:  93%|█████████▎| 1865/2000 [36:18<02:06,  1.07iteration/s, mean_rewards=-63.4]\u001b[A\n",
            "Training:  93%|█████████▎| 1866/2000 [36:18<02:05,  1.07iteration/s, mean_rewards=-63.4]\u001b[A\n",
            "Training:  93%|█████████▎| 1866/2000 [36:19<02:05,  1.07iteration/s, mean_rewards=-213] \u001b[A\n",
            "Training:  93%|█████████▎| 1867/2000 [36:19<02:16,  1.03s/iteration, mean_rewards=-213]\u001b[A\n",
            "Training:  93%|█████████▎| 1867/2000 [36:20<02:16,  1.03s/iteration, mean_rewards=-160]\u001b[A\n",
            "Training:  93%|█████████▎| 1868/2000 [36:20<02:07,  1.04iteration/s, mean_rewards=-160]\u001b[A\n",
            "Training:  93%|█████████▎| 1868/2000 [36:21<02:07,  1.04iteration/s, mean_rewards=-269]\u001b[A\n",
            "Training:  93%|█████████▎| 1869/2000 [36:21<02:06,  1.03iteration/s, mean_rewards=-269]\u001b[A\n",
            "Training:  93%|█████████▎| 1869/2000 [36:22<02:06,  1.03iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  94%|█████████▎| 1870/2000 [36:22<02:01,  1.07iteration/s, mean_rewards=-134]\u001b[A\n",
            "Training:  94%|█████████▎| 1870/2000 [36:22<02:01,  1.07iteration/s, mean_rewards=-293]\u001b[A\n",
            "Training:  94%|█████████▎| 1871/2000 [36:23<02:11,  1.02s/iteration, mean_rewards=-293]\u001b[A\n",
            "Training:  94%|█████████▎| 1871/2000 [36:24<02:11,  1.02s/iteration, mean_rewards=-269]\u001b[A\n",
            "Training:  94%|█████████▎| 1872/2000 [36:24<02:08,  1.00s/iteration, mean_rewards=-269]\u001b[A\n",
            "Training:  94%|█████████▎| 1872/2000 [36:25<02:08,  1.00s/iteration, mean_rewards=-228]\u001b[A\n",
            "Training:  94%|█████████▎| 1873/2000 [36:26<02:21,  1.11s/iteration, mean_rewards=-228]\u001b[A\n",
            "Training:  94%|█████████▎| 1873/2000 [36:26<02:21,  1.11s/iteration, mean_rewards=-206]\u001b[A\n",
            "Training:  94%|█████████▎| 1874/2000 [36:26<02:08,  1.02s/iteration, mean_rewards=-206]\u001b[A\n",
            "Training:  94%|█████████▎| 1874/2000 [36:27<02:08,  1.02s/iteration, mean_rewards=-353]\u001b[A\n",
            "Training:  94%|█████████▍| 1875/2000 [36:27<02:04,  1.01iteration/s, mean_rewards=-353]\u001b[A\n",
            "Training:  94%|█████████▍| 1875/2000 [36:28<02:04,  1.01iteration/s, mean_rewards=-333]\u001b[A\n",
            "Training:  94%|█████████▍| 1876/2000 [36:28<02:02,  1.01iteration/s, mean_rewards=-333]\u001b[A\n",
            "Training:  94%|█████████▍| 1876/2000 [36:29<02:02,  1.01iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  94%|█████████▍| 1877/2000 [36:29<01:50,  1.11iteration/s, mean_rewards=-137]\u001b[A\n",
            "Training:  94%|█████████▍| 1877/2000 [36:29<01:50,  1.11iteration/s, mean_rewards=-196]\u001b[A\n",
            "Training:  94%|█████████▍| 1878/2000 [36:30<01:47,  1.14iteration/s, mean_rewards=-196]\u001b[A\n",
            "Training:  94%|█████████▍| 1878/2000 [36:30<01:47,  1.14iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  94%|█████████▍| 1879/2000 [36:31<01:45,  1.15iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  94%|█████████▍| 1879/2000 [36:31<01:45,  1.15iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  94%|█████████▍| 1880/2000 [36:31<01:38,  1.22iteration/s, mean_rewards=-140]\u001b[A\n",
            "Training:  94%|█████████▍| 1880/2000 [36:32<01:38,  1.22iteration/s, mean_rewards=-102]\u001b[A\n",
            "Training:  94%|█████████▍| 1881/2000 [36:32<01:32,  1.28iteration/s, mean_rewards=-102]\u001b[A\n",
            "Training:  94%|█████████▍| 1881/2000 [36:32<01:32,  1.28iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  94%|█████████▍| 1882/2000 [36:33<01:32,  1.27iteration/s, mean_rewards=-125]\u001b[A\n",
            "Training:  94%|█████████▍| 1882/2000 [36:33<01:32,  1.27iteration/s, mean_rewards=-96.9]\u001b[A\n",
            "Training:  94%|█████████▍| 1883/2000 [36:34<01:37,  1.20iteration/s, mean_rewards=-96.9]\u001b[A\n",
            "Training:  94%|█████████▍| 1883/2000 [36:34<01:37,  1.20iteration/s, mean_rewards=-96.8]\u001b[A\n",
            "Training:  94%|█████████▍| 1884/2000 [36:35<01:39,  1.17iteration/s, mean_rewards=-96.8]\u001b[A\n",
            "Training:  94%|█████████▍| 1884/2000 [36:35<01:39,  1.17iteration/s, mean_rewards=-177] \u001b[A\n",
            "Training:  94%|█████████▍| 1885/2000 [36:36<01:36,  1.19iteration/s, mean_rewards=-177]\u001b[A\n",
            "Training:  94%|█████████▍| 1885/2000 [36:36<01:36,  1.19iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  94%|█████████▍| 1886/2000 [36:36<01:37,  1.17iteration/s, mean_rewards=-151]\u001b[A\n",
            "Training:  94%|█████████▍| 1886/2000 [36:37<01:37,  1.17iteration/s, mean_rewards=-80.1]\u001b[A\n",
            "Training:  94%|█████████▍| 1887/2000 [36:37<01:39,  1.13iteration/s, mean_rewards=-80.1]\u001b[A\n",
            "Training:  94%|█████████▍| 1887/2000 [36:38<01:39,  1.13iteration/s, mean_rewards=-241] \u001b[A\n",
            "Training:  94%|█████████▍| 1888/2000 [36:39<01:53,  1.01s/iteration, mean_rewards=-241]\u001b[A\n",
            "Training:  94%|█████████▍| 1888/2000 [36:39<01:53,  1.01s/iteration, mean_rewards=-107]\u001b[A\n",
            "Training:  94%|█████████▍| 1889/2000 [36:39<01:45,  1.05iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  94%|█████████▍| 1889/2000 [36:40<01:45,  1.05iteration/s, mean_rewards=-209]\u001b[A\n",
            "Training:  94%|█████████▍| 1890/2000 [36:40<01:40,  1.10iteration/s, mean_rewards=-209]\u001b[A\n",
            "Training:  94%|█████████▍| 1890/2000 [36:41<01:40,  1.10iteration/s, mean_rewards=-176]\u001b[A\n",
            "Training:  95%|█████████▍| 1891/2000 [36:41<01:41,  1.07iteration/s, mean_rewards=-176]\u001b[A\n",
            "Training:  95%|█████████▍| 1891/2000 [36:42<01:41,  1.07iteration/s, mean_rewards=-427]\u001b[A\n",
            "Training:  95%|█████████▍| 1892/2000 [36:42<01:41,  1.06iteration/s, mean_rewards=-427]\u001b[A\n",
            "Training:  95%|█████████▍| 1892/2000 [36:43<01:41,  1.06iteration/s, mean_rewards=-311]\u001b[A\n",
            "Training:  95%|█████████▍| 1893/2000 [36:43<01:36,  1.11iteration/s, mean_rewards=-311]\u001b[A\n",
            "Training:  95%|█████████▍| 1893/2000 [36:43<01:36,  1.11iteration/s, mean_rewards=-257]\u001b[A\n",
            "Training:  95%|█████████▍| 1894/2000 [36:44<01:37,  1.08iteration/s, mean_rewards=-257]\u001b[A\n",
            "Training:  95%|█████████▍| 1894/2000 [36:44<01:37,  1.08iteration/s, mean_rewards=-195]\u001b[A\n",
            "Training:  95%|█████████▍| 1895/2000 [36:45<01:38,  1.06iteration/s, mean_rewards=-195]\u001b[A\n",
            "Training:  95%|█████████▍| 1895/2000 [36:45<01:38,  1.06iteration/s, mean_rewards=-191]\u001b[A\n",
            "Training:  95%|█████████▍| 1896/2000 [36:46<01:40,  1.03iteration/s, mean_rewards=-191]\u001b[A\n",
            "Training:  95%|█████████▍| 1896/2000 [36:46<01:40,  1.03iteration/s, mean_rewards=-175]\u001b[A\n",
            "Training:  95%|█████████▍| 1897/2000 [36:47<01:41,  1.01iteration/s, mean_rewards=-175]\u001b[A\n",
            "Training:  95%|█████████▍| 1897/2000 [36:47<01:41,  1.01iteration/s, mean_rewards=-303]\u001b[A\n",
            "Training:  95%|█████████▍| 1898/2000 [36:48<01:34,  1.08iteration/s, mean_rewards=-303]\u001b[A\n",
            "Training:  95%|█████████▍| 1898/2000 [36:48<01:34,  1.08iteration/s, mean_rewards=-194]\u001b[A\n",
            "Training:  95%|█████████▍| 1899/2000 [36:49<01:30,  1.12iteration/s, mean_rewards=-194]\u001b[A\n",
            "Training:  95%|█████████▍| 1899/2000 [36:49<01:30,  1.12iteration/s, mean_rewards=-272]\u001b[A\n",
            "Training:  95%|█████████▌| 1900/2000 [36:50<01:49,  1.09s/iteration, mean_rewards=-272]\u001b[A\n",
            "Training:  95%|█████████▌| 1900/2000 [36:51<01:49,  1.09s/iteration, mean_rewards=-67.6]\u001b[A\n",
            "Training:  95%|█████████▌| 1901/2000 [36:51<01:48,  1.09s/iteration, mean_rewards=-67.6]\u001b[A\n",
            "Training:  95%|█████████▌| 1901/2000 [36:52<01:48,  1.09s/iteration, mean_rewards=-162] \u001b[A\n",
            "Training:  95%|█████████▌| 1902/2000 [36:52<01:41,  1.04s/iteration, mean_rewards=-162]\u001b[A\n",
            "Training:  95%|█████████▌| 1902/2000 [36:53<01:41,  1.04s/iteration, mean_rewards=-101]\u001b[A\n",
            "Training:  95%|█████████▌| 1903/2000 [36:53<01:34,  1.03iteration/s, mean_rewards=-101]\u001b[A\n",
            "Training:  95%|█████████▌| 1903/2000 [36:53<01:34,  1.03iteration/s, mean_rewards=-261]\u001b[A\n",
            "Training:  95%|█████████▌| 1904/2000 [36:54<01:30,  1.06iteration/s, mean_rewards=-261]\u001b[A\n",
            "Training:  95%|█████████▌| 1904/2000 [36:54<01:30,  1.06iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  95%|█████████▌| 1905/2000 [36:55<01:25,  1.11iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  95%|█████████▌| 1905/2000 [36:55<01:25,  1.11iteration/s, mean_rewards=-89.8]\u001b[A\n",
            "Training:  95%|█████████▌| 1906/2000 [36:55<01:19,  1.19iteration/s, mean_rewards=-89.8]\u001b[A\n",
            "Training:  95%|█████████▌| 1906/2000 [36:56<01:19,  1.19iteration/s, mean_rewards=-115] \u001b[A\n",
            "Training:  95%|█████████▌| 1907/2000 [36:56<01:18,  1.18iteration/s, mean_rewards=-115]\u001b[A\n",
            "Training:  95%|█████████▌| 1907/2000 [36:57<01:18,  1.18iteration/s, mean_rewards=-296]\u001b[A\n",
            "Training:  95%|█████████▌| 1908/2000 [36:57<01:16,  1.21iteration/s, mean_rewards=-296]\u001b[A\n",
            "Training:  95%|█████████▌| 1908/2000 [36:57<01:16,  1.21iteration/s, mean_rewards=-87.3]\u001b[A\n",
            "Training:  95%|█████████▌| 1909/2000 [36:58<01:14,  1.22iteration/s, mean_rewards=-87.3]\u001b[A\n",
            "Training:  95%|█████████▌| 1909/2000 [36:58<01:14,  1.22iteration/s, mean_rewards=-166] \u001b[A\n",
            "Training:  96%|█████████▌| 1910/2000 [36:59<01:11,  1.27iteration/s, mean_rewards=-166]\u001b[A\n",
            "Training:  96%|█████████▌| 1910/2000 [36:59<01:11,  1.27iteration/s, mean_rewards=-191]\u001b[A\n",
            "Training:  96%|█████████▌| 1911/2000 [37:00<01:14,  1.19iteration/s, mean_rewards=-191]\u001b[A\n",
            "Training:  96%|█████████▌| 1911/2000 [37:00<01:14,  1.19iteration/s, mean_rewards=-175]\u001b[A\n",
            "Training:  96%|█████████▌| 1912/2000 [37:00<01:16,  1.15iteration/s, mean_rewards=-175]\u001b[A\n",
            "Training:  96%|█████████▌| 1912/2000 [37:01<01:16,  1.15iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  96%|█████████▌| 1913/2000 [37:01<01:17,  1.13iteration/s, mean_rewards=-114]\u001b[A\n",
            "Training:  96%|█████████▌| 1913/2000 [37:02<01:17,  1.13iteration/s, mean_rewards=-310]\u001b[A\n",
            "Training:  96%|█████████▌| 1914/2000 [37:03<01:22,  1.04iteration/s, mean_rewards=-310]\u001b[A\n",
            "Training:  96%|█████████▌| 1914/2000 [37:03<01:22,  1.04iteration/s, mean_rewards=-236]\u001b[A\n",
            "Training:  96%|█████████▌| 1915/2000 [37:04<01:30,  1.06s/iteration, mean_rewards=-236]\u001b[A\n",
            "Training:  96%|█████████▌| 1915/2000 [37:04<01:30,  1.06s/iteration, mean_rewards=-78.4]\u001b[A\n",
            "Training:  96%|█████████▌| 1916/2000 [37:05<01:27,  1.04s/iteration, mean_rewards=-78.4]\u001b[A\n",
            "Training:  96%|█████████▌| 1916/2000 [37:05<01:27,  1.04s/iteration, mean_rewards=-201] \u001b[A\n",
            "Training:  96%|█████████▌| 1917/2000 [37:06<01:24,  1.02s/iteration, mean_rewards=-201]\u001b[A\n",
            "Training:  96%|█████████▌| 1917/2000 [37:06<01:24,  1.02s/iteration, mean_rewards=-147]\u001b[A\n",
            "Training:  96%|█████████▌| 1918/2000 [37:07<01:22,  1.01s/iteration, mean_rewards=-147]\u001b[A\n",
            "Training:  96%|█████████▌| 1918/2000 [37:07<01:22,  1.01s/iteration, mean_rewards=-369]\u001b[A\n",
            "Training:  96%|█████████▌| 1919/2000 [37:08<01:17,  1.04iteration/s, mean_rewards=-369]\u001b[A\n",
            "Training:  96%|█████████▌| 1919/2000 [37:08<01:17,  1.04iteration/s, mean_rewards=-109]\u001b[A\n",
            "Training:  96%|█████████▌| 1920/2000 [37:08<01:10,  1.13iteration/s, mean_rewards=-109]\u001b[A\n",
            "Training:  96%|█████████▌| 1920/2000 [37:09<01:10,  1.13iteration/s, mean_rewards=-175]\u001b[A\n",
            "Training:  96%|█████████▌| 1921/2000 [37:09<01:05,  1.21iteration/s, mean_rewards=-175]\u001b[A\n",
            "Training:  96%|█████████▌| 1921/2000 [37:09<01:05,  1.21iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  96%|█████████▌| 1922/2000 [37:10<01:05,  1.19iteration/s, mean_rewards=-141]\u001b[A\n",
            "Training:  96%|█████████▌| 1922/2000 [37:10<01:05,  1.19iteration/s, mean_rewards=-166]\u001b[A\n",
            "Training:  96%|█████████▌| 1923/2000 [37:11<01:05,  1.18iteration/s, mean_rewards=-166]\u001b[A\n",
            "Training:  96%|█████████▌| 1923/2000 [37:11<01:05,  1.18iteration/s, mean_rewards=-224]\u001b[A\n",
            "Training:  96%|█████████▌| 1924/2000 [37:12<01:11,  1.07iteration/s, mean_rewards=-224]\u001b[A\n",
            "Training:  96%|█████████▌| 1924/2000 [37:12<01:11,  1.07iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  96%|█████████▋| 1925/2000 [37:13<01:10,  1.07iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  96%|█████████▋| 1925/2000 [37:13<01:10,  1.07iteration/s, mean_rewards=-206]\u001b[A\n",
            "Training:  96%|█████████▋| 1926/2000 [37:14<01:14,  1.01s/iteration, mean_rewards=-206]\u001b[A\n",
            "Training:  96%|█████████▋| 1926/2000 [37:15<01:14,  1.01s/iteration, mean_rewards=-191]\u001b[A\n",
            "Training:  96%|█████████▋| 1927/2000 [37:15<01:20,  1.11s/iteration, mean_rewards=-191]\u001b[A\n",
            "Training:  96%|█████████▋| 1927/2000 [37:16<01:20,  1.11s/iteration, mean_rewards=-128]\u001b[A\n",
            "Training:  96%|█████████▋| 1928/2000 [37:16<01:15,  1.05s/iteration, mean_rewards=-128]\u001b[A\n",
            "Training:  96%|█████████▋| 1928/2000 [37:17<01:15,  1.05s/iteration, mean_rewards=-106]\u001b[A\n",
            "Training:  96%|█████████▋| 1929/2000 [37:17<01:17,  1.08s/iteration, mean_rewards=-106]\u001b[A\n",
            "Training:  96%|█████████▋| 1929/2000 [37:18<01:17,  1.08s/iteration, mean_rewards=-365]\u001b[A\n",
            "Training:  96%|█████████▋| 1930/2000 [37:19<01:20,  1.15s/iteration, mean_rewards=-365]\u001b[A\n",
            "Training:  96%|█████████▋| 1930/2000 [37:19<01:20,  1.15s/iteration, mean_rewards=-203]\u001b[A\n",
            "Training:  97%|█████████▋| 1931/2000 [37:20<01:16,  1.10s/iteration, mean_rewards=-203]\u001b[A\n",
            "Training:  97%|█████████▋| 1931/2000 [37:20<01:16,  1.10s/iteration, mean_rewards=-126]\u001b[A\n",
            "Training:  97%|█████████▋| 1932/2000 [37:21<01:09,  1.02s/iteration, mean_rewards=-126]\u001b[A\n",
            "Training:  97%|█████████▋| 1932/2000 [37:21<01:09,  1.02s/iteration, mean_rewards=-97.2]\u001b[A\n",
            "Training:  97%|█████████▋| 1933/2000 [37:21<01:04,  1.03iteration/s, mean_rewards=-97.2]\u001b[A\n",
            "Training:  97%|█████████▋| 1933/2000 [37:22<01:04,  1.03iteration/s, mean_rewards=-259] \u001b[A\n",
            "Training:  97%|█████████▋| 1934/2000 [37:22<01:04,  1.03iteration/s, mean_rewards=-259]\u001b[A\n",
            "Training:  97%|█████████▋| 1934/2000 [37:23<01:04,  1.03iteration/s, mean_rewards=-107]\u001b[A\n",
            "Training:  97%|█████████▋| 1935/2000 [37:24<01:05,  1.01s/iteration, mean_rewards=-107]\u001b[A\n",
            "Training:  97%|█████████▋| 1935/2000 [37:24<01:05,  1.01s/iteration, mean_rewards=-110]\u001b[A\n",
            "Training:  97%|█████████▋| 1936/2000 [37:24<01:01,  1.05iteration/s, mean_rewards=-110]\u001b[A\n",
            "Training:  97%|█████████▋| 1936/2000 [37:25<01:01,  1.05iteration/s, mean_rewards=-291]\u001b[A\n",
            "Training:  97%|█████████▋| 1937/2000 [37:25<00:58,  1.08iteration/s, mean_rewards=-291]\u001b[A\n",
            "Training:  97%|█████████▋| 1937/2000 [37:25<00:58,  1.08iteration/s, mean_rewards=-98.2]\u001b[A\n",
            "Training:  97%|█████████▋| 1938/2000 [37:26<00:53,  1.16iteration/s, mean_rewards=-98.2]\u001b[A\n",
            "Training:  97%|█████████▋| 1938/2000 [37:26<00:53,  1.16iteration/s, mean_rewards=-270] \u001b[A\n",
            "Training:  97%|█████████▋| 1939/2000 [37:27<00:54,  1.12iteration/s, mean_rewards=-270]\u001b[A\n",
            "Training:  97%|█████████▋| 1939/2000 [37:27<00:54,  1.12iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  97%|█████████▋| 1940/2000 [37:28<00:55,  1.09iteration/s, mean_rewards=-142]\u001b[A\n",
            "Training:  97%|█████████▋| 1940/2000 [37:28<00:55,  1.09iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  97%|█████████▋| 1941/2000 [37:29<00:58,  1.01iteration/s, mean_rewards=-146]\u001b[A\n",
            "Training:  97%|█████████▋| 1941/2000 [37:30<00:58,  1.01iteration/s, mean_rewards=-219]\u001b[A\n",
            "Training:  97%|█████████▋| 1942/2000 [37:30<01:03,  1.09s/iteration, mean_rewards=-219]\u001b[A\n",
            "Training:  97%|█████████▋| 1942/2000 [37:31<01:03,  1.09s/iteration, mean_rewards=-113]\u001b[A\n",
            "Training:  97%|█████████▋| 1943/2000 [37:31<01:02,  1.10s/iteration, mean_rewards=-113]\u001b[A\n",
            "Training:  97%|█████████▋| 1943/2000 [37:32<01:02,  1.10s/iteration, mean_rewards=-348]\u001b[A\n",
            "Training:  97%|█████████▋| 1944/2000 [37:32<00:57,  1.03s/iteration, mean_rewards=-348]\u001b[A\n",
            "Training:  97%|█████████▋| 1944/2000 [37:33<00:57,  1.03s/iteration, mean_rewards=-231]\u001b[A\n",
            "Training:  97%|█████████▋| 1945/2000 [37:33<00:52,  1.04iteration/s, mean_rewards=-231]\u001b[A\n",
            "Training:  97%|█████████▋| 1945/2000 [37:34<00:52,  1.04iteration/s, mean_rewards=-351]\u001b[A\n",
            "Training:  97%|█████████▋| 1946/2000 [37:34<00:54,  1.01s/iteration, mean_rewards=-351]\u001b[A\n",
            "Training:  97%|█████████▋| 1946/2000 [37:35<00:54,  1.01s/iteration, mean_rewards=-90.3]\u001b[A\n",
            "Training:  97%|█████████▋| 1947/2000 [37:35<00:48,  1.09iteration/s, mean_rewards=-90.3]\u001b[A\n",
            "Training:  97%|█████████▋| 1947/2000 [37:35<00:48,  1.09iteration/s, mean_rewards=-139] \u001b[A\n",
            "Training:  97%|█████████▋| 1948/2000 [37:36<00:46,  1.12iteration/s, mean_rewards=-139]\u001b[A\n",
            "Training:  97%|█████████▋| 1948/2000 [37:36<00:46,  1.12iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:  97%|█████████▋| 1949/2000 [37:37<00:46,  1.10iteration/s, mean_rewards=-147]\u001b[A\n",
            "Training:  97%|█████████▋| 1949/2000 [37:37<00:46,  1.10iteration/s, mean_rewards=-276]\u001b[A\n",
            "Training:  98%|█████████▊| 1950/2000 [37:38<00:49,  1.00iteration/s, mean_rewards=-276]\u001b[A\n",
            "Training:  98%|█████████▊| 1950/2000 [37:38<00:49,  1.00iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  98%|█████████▊| 1951/2000 [37:39<00:46,  1.05iteration/s, mean_rewards=-113]\u001b[A\n",
            "Training:  98%|█████████▊| 1951/2000 [37:39<00:46,  1.05iteration/s, mean_rewards=-63.1]\u001b[A\n",
            "Training:  98%|█████████▊| 1952/2000 [37:40<00:44,  1.08iteration/s, mean_rewards=-63.1]\u001b[A\n",
            "Training:  98%|█████████▊| 1952/2000 [37:40<00:44,  1.08iteration/s, mean_rewards=-273] \u001b[A\n",
            "Training:  98%|█████████▊| 1953/2000 [37:41<00:46,  1.02iteration/s, mean_rewards=-273]\u001b[A\n",
            "Training:  98%|█████████▊| 1953/2000 [37:41<00:46,  1.02iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:  98%|█████████▊| 1954/2000 [37:42<00:43,  1.05iteration/s, mean_rewards=-161]\u001b[A\n",
            "Training:  98%|█████████▊| 1954/2000 [37:42<00:43,  1.05iteration/s, mean_rewards=-191]\u001b[A\n",
            "Training:  98%|█████████▊| 1955/2000 [37:43<00:47,  1.06s/iteration, mean_rewards=-191]\u001b[A\n",
            "Training:  98%|█████████▊| 1955/2000 [37:43<00:47,  1.06s/iteration, mean_rewards=-239]\u001b[A\n",
            "Training:  98%|█████████▊| 1956/2000 [37:44<00:47,  1.09s/iteration, mean_rewards=-239]\u001b[A\n",
            "Training:  98%|█████████▊| 1956/2000 [37:45<00:47,  1.09s/iteration, mean_rewards=-329]\u001b[A\n",
            "Training:  98%|█████████▊| 1957/2000 [37:45<00:50,  1.16s/iteration, mean_rewards=-329]\u001b[A\n",
            "Training:  98%|█████████▊| 1957/2000 [37:46<00:50,  1.16s/iteration, mean_rewards=-112]\u001b[A\n",
            "Training:  98%|█████████▊| 1958/2000 [37:46<00:44,  1.06s/iteration, mean_rewards=-112]\u001b[A\n",
            "Training:  98%|█████████▊| 1958/2000 [37:47<00:44,  1.06s/iteration, mean_rewards=-102]\u001b[A\n",
            "Training:  98%|█████████▊| 1959/2000 [37:47<00:39,  1.05iteration/s, mean_rewards=-102]\u001b[A\n",
            "Training:  98%|█████████▊| 1959/2000 [37:47<00:39,  1.05iteration/s, mean_rewards=-179]\u001b[A\n",
            "Training:  98%|█████████▊| 1960/2000 [37:48<00:41,  1.03s/iteration, mean_rewards=-179]\u001b[A\n",
            "Training:  98%|█████████▊| 1960/2000 [37:48<00:41,  1.03s/iteration, mean_rewards=-124]\u001b[A\n",
            "Training:  98%|█████████▊| 1961/2000 [37:49<00:36,  1.07iteration/s, mean_rewards=-124]\u001b[A\n",
            "Training:  98%|█████████▊| 1961/2000 [37:49<00:36,  1.07iteration/s, mean_rewards=-213]\u001b[A\n",
            "Training:  98%|█████████▊| 1962/2000 [37:50<00:36,  1.03iteration/s, mean_rewards=-213]\u001b[A\n",
            "Training:  98%|█████████▊| 1962/2000 [37:50<00:36,  1.03iteration/s, mean_rewards=-65.4]\u001b[A\n",
            "Training:  98%|█████████▊| 1963/2000 [37:51<00:32,  1.14iteration/s, mean_rewards=-65.4]\u001b[A\n",
            "Training:  98%|█████████▊| 1963/2000 [37:51<00:32,  1.14iteration/s, mean_rewards=-174] \u001b[A\n",
            "Training:  98%|█████████▊| 1964/2000 [37:52<00:32,  1.12iteration/s, mean_rewards=-174]\u001b[A\n",
            "Training:  98%|█████████▊| 1964/2000 [37:52<00:32,  1.12iteration/s, mean_rewards=-352]\u001b[A\n",
            "Training:  98%|█████████▊| 1965/2000 [37:53<00:32,  1.08iteration/s, mean_rewards=-352]\u001b[A\n",
            "Training:  98%|█████████▊| 1965/2000 [37:53<00:32,  1.08iteration/s, mean_rewards=-324]\u001b[A\n",
            "Training:  98%|█████████▊| 1966/2000 [37:53<00:30,  1.10iteration/s, mean_rewards=-324]\u001b[A\n",
            "Training:  98%|█████████▊| 1966/2000 [37:54<00:30,  1.10iteration/s, mean_rewards=-173]\u001b[A\n",
            "Training:  98%|█████████▊| 1967/2000 [37:54<00:30,  1.09iteration/s, mean_rewards=-173]\u001b[A\n",
            "Training:  98%|█████████▊| 1967/2000 [37:55<00:30,  1.09iteration/s, mean_rewards=-197]\u001b[A\n",
            "Training:  98%|█████████▊| 1968/2000 [37:55<00:30,  1.03iteration/s, mean_rewards=-197]\u001b[A\n",
            "Training:  98%|█████████▊| 1968/2000 [37:56<00:30,  1.03iteration/s, mean_rewards=-102]\u001b[A\n",
            "Training:  98%|█████████▊| 1969/2000 [37:57<00:32,  1.06s/iteration, mean_rewards=-102]\u001b[A\n",
            "Training:  98%|█████████▊| 1969/2000 [37:57<00:32,  1.06s/iteration, mean_rewards=-127]\u001b[A\n",
            "Training:  98%|█████████▊| 1970/2000 [37:58<00:34,  1.16s/iteration, mean_rewards=-127]\u001b[A\n",
            "Training:  98%|█████████▊| 1970/2000 [37:58<00:34,  1.16s/iteration, mean_rewards=-106]\u001b[A\n",
            "Training:  99%|█████████▊| 1971/2000 [37:59<00:30,  1.06s/iteration, mean_rewards=-106]\u001b[A\n",
            "Training:  99%|█████████▊| 1971/2000 [37:59<00:30,  1.06s/iteration, mean_rewards=-65.1]\u001b[A\n",
            "Training:  99%|█████████▊| 1972/2000 [38:00<00:28,  1.03s/iteration, mean_rewards=-65.1]\u001b[A\n",
            "Training:  99%|█████████▊| 1972/2000 [38:00<00:28,  1.03s/iteration, mean_rewards=-204] \u001b[A\n",
            "Training:  99%|█████████▊| 1973/2000 [38:01<00:25,  1.07iteration/s, mean_rewards=-204]\u001b[A\n",
            "Training:  99%|█████████▊| 1973/2000 [38:01<00:25,  1.07iteration/s, mean_rewards=-87] \u001b[A\n",
            "Training:  99%|█████████▊| 1974/2000 [38:01<00:23,  1.11iteration/s, mean_rewards=-87]\u001b[A\n",
            "Training:  99%|█████████▊| 1974/2000 [38:02<00:23,  1.11iteration/s, mean_rewards=-178]\u001b[A\n",
            "Training:  99%|█████████▉| 1975/2000 [38:02<00:21,  1.18iteration/s, mean_rewards=-178]\u001b[A\n",
            "Training:  99%|█████████▉| 1975/2000 [38:03<00:21,  1.18iteration/s, mean_rewards=-199]\u001b[A\n",
            "Training:  99%|█████████▉| 1976/2000 [38:03<00:21,  1.13iteration/s, mean_rewards=-199]\u001b[A\n",
            "Training:  99%|█████████▉| 1976/2000 [38:04<00:21,  1.13iteration/s, mean_rewards=-260]\u001b[A\n",
            "Training:  99%|█████████▉| 1977/2000 [38:04<00:20,  1.12iteration/s, mean_rewards=-260]\u001b[A\n",
            "Training:  99%|█████████▉| 1977/2000 [38:04<00:20,  1.12iteration/s, mean_rewards=-175]\u001b[A\n",
            "Training:  99%|█████████▉| 1978/2000 [38:05<00:21,  1.05iteration/s, mean_rewards=-175]\u001b[A\n",
            "Training:  99%|█████████▉| 1978/2000 [38:05<00:21,  1.05iteration/s, mean_rewards=-174]\u001b[A\n",
            "Training:  99%|█████████▉| 1979/2000 [38:06<00:18,  1.13iteration/s, mean_rewards=-174]\u001b[A\n",
            "Training:  99%|█████████▉| 1979/2000 [38:06<00:18,  1.13iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  99%|█████████▉| 1980/2000 [38:07<00:17,  1.11iteration/s, mean_rewards=-117]\u001b[A\n",
            "Training:  99%|█████████▉| 1980/2000 [38:07<00:17,  1.11iteration/s, mean_rewards=-235]\u001b[A\n",
            "Training:  99%|█████████▉| 1981/2000 [38:08<00:18,  1.02iteration/s, mean_rewards=-235]\u001b[A\n",
            "Training:  99%|█████████▉| 1981/2000 [38:08<00:18,  1.02iteration/s, mean_rewards=-123]\u001b[A\n",
            "Training:  99%|█████████▉| 1982/2000 [38:09<00:18,  1.05s/iteration, mean_rewards=-123]\u001b[A\n",
            "Training:  99%|█████████▉| 1982/2000 [38:10<00:18,  1.05s/iteration, mean_rewards=-210]\u001b[A\n",
            "Training:  99%|█████████▉| 1983/2000 [38:11<00:19,  1.14s/iteration, mean_rewards=-210]\u001b[A\n",
            "Training:  99%|█████████▉| 1983/2000 [38:11<00:19,  1.14s/iteration, mean_rewards=-402]\u001b[A\n",
            "Training:  99%|█████████▉| 1984/2000 [38:12<00:17,  1.10s/iteration, mean_rewards=-402]\u001b[A\n",
            "Training:  99%|█████████▉| 1984/2000 [38:12<00:17,  1.10s/iteration, mean_rewards=-197]\u001b[A\n",
            "Training:  99%|█████████▉| 1985/2000 [38:13<00:16,  1.08s/iteration, mean_rewards=-197]\u001b[A\n",
            "Training:  99%|█████████▉| 1985/2000 [38:13<00:16,  1.08s/iteration, mean_rewards=-269]\u001b[A\n",
            "Training:  99%|█████████▉| 1986/2000 [38:14<00:15,  1.09s/iteration, mean_rewards=-269]\u001b[A\n",
            "Training:  99%|█████████▉| 1986/2000 [38:14<00:15,  1.09s/iteration, mean_rewards=-71.9]\u001b[A\n",
            "Training:  99%|█████████▉| 1987/2000 [38:14<00:12,  1.02iteration/s, mean_rewards=-71.9]\u001b[A\n",
            "Training:  99%|█████████▉| 1987/2000 [38:15<00:12,  1.02iteration/s, mean_rewards=-222] \u001b[A\n",
            "Training:  99%|█████████▉| 1988/2000 [38:15<00:10,  1.11iteration/s, mean_rewards=-222]\u001b[A\n",
            "Training:  99%|█████████▉| 1988/2000 [38:15<00:10,  1.11iteration/s, mean_rewards=-202]\u001b[A\n",
            "Training:  99%|█████████▉| 1989/2000 [38:16<00:09,  1.14iteration/s, mean_rewards=-202]\u001b[A\n",
            "Training:  99%|█████████▉| 1989/2000 [38:16<00:09,  1.14iteration/s, mean_rewards=-112]\u001b[A\n",
            "Training: 100%|█████████▉| 1990/2000 [38:17<00:09,  1.08iteration/s, mean_rewards=-112]\u001b[A\n",
            "Training: 100%|█████████▉| 1990/2000 [38:17<00:09,  1.08iteration/s, mean_rewards=-218]\u001b[A\n",
            "Training: 100%|█████████▉| 1991/2000 [38:18<00:08,  1.12iteration/s, mean_rewards=-218]\u001b[A\n",
            "Training: 100%|█████████▉| 1991/2000 [38:18<00:08,  1.12iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training: 100%|█████████▉| 1992/2000 [38:19<00:06,  1.19iteration/s, mean_rewards=-148]\u001b[A\n",
            "Training: 100%|█████████▉| 1992/2000 [38:19<00:06,  1.19iteration/s, mean_rewards=-257]\u001b[A\n",
            "Training: 100%|█████████▉| 1993/2000 [38:19<00:06,  1.14iteration/s, mean_rewards=-257]\u001b[A\n",
            "Training: 100%|█████████▉| 1993/2000 [38:20<00:06,  1.14iteration/s, mean_rewards=-204]\u001b[A\n",
            "Training: 100%|█████████▉| 1994/2000 [38:20<00:05,  1.16iteration/s, mean_rewards=-204]\u001b[A\n",
            "Training: 100%|█████████▉| 1994/2000 [38:21<00:05,  1.16iteration/s, mean_rewards=-391]\u001b[A\n",
            "Training: 100%|█████████▉| 1995/2000 [38:22<00:05,  1.12s/iteration, mean_rewards=-391]\u001b[A\n",
            "Training: 100%|█████████▉| 1995/2000 [38:23<00:05,  1.12s/iteration, mean_rewards=-78.5]\u001b[A\n",
            "Training: 100%|█████████▉| 1996/2000 [38:24<00:05,  1.31s/iteration, mean_rewards=-78.5]\u001b[A\n",
            "Training: 100%|█████████▉| 1996/2000 [38:24<00:05,  1.31s/iteration, mean_rewards=-214] \u001b[A\n",
            "Training: 100%|█████████▉| 1997/2000 [38:25<00:03,  1.22s/iteration, mean_rewards=-214]\u001b[A\n",
            "Training: 100%|█████████▉| 1997/2000 [38:25<00:03,  1.22s/iteration, mean_rewards=-423]\u001b[A\n",
            "Training: 100%|█████████▉| 1998/2000 [38:26<00:02,  1.23s/iteration, mean_rewards=-423]\u001b[A\n",
            "Training: 100%|█████████▉| 1998/2000 [38:26<00:02,  1.23s/iteration, mean_rewards=-147]\u001b[A\n",
            "Training: 100%|█████████▉| 1999/2000 [38:27<00:01,  1.10s/iteration, mean_rewards=-147]\u001b[A\n",
            "Training: 100%|█████████▉| 1999/2000 [38:27<00:01,  1.10s/iteration, mean_rewards=-213]\u001b[A\n",
            "Training: 100%|██████████| 2000/2000 [38:28<00:00,  1.15s/iteration, mean_rewards=-213]\n"
          ]
        }
      ],
      "source": [
        "opt = \"PACE\"\n",
        "train(env, opt, peturbations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cns3O9h59MxI"
      },
      "source": [
        "## Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "M8HLRgLk9OCT",
        "outputId": "02ff9ffb-db4e-4004-e8c2-7ff41331bf5b"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot(env,seed)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
